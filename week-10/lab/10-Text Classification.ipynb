{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "See Section 7.2 in the sklearn User Guide  http://scikit-learn.org/stable/user_guide.html for the dataset used in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the data - a subset from 20 News groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['rec.sport.baseball', 'talk.politics.guns','comp.graphics', 'sci.med']\n",
    "twentyTrain = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check the target names (categories) and some data files by following commands.\n",
    "list(twentyTrain.target_names) #prints all the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(twentyTrain)  # the type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(twentyTrain.data)  # the size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(twentyTrain.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(twentyTrain.data[0])   # print one instance of the data - .data is the data\n",
    "print(\"\\n\".join(twentyTrain.data[0].split(\"\\n\")[:3]))  #print out the first 3 lines only\n",
    "print(\"Target class is {}\".format(twentyTrain.target_names[twentyTrain.target[0]]))   #print the class of that instance - .target is the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the meta data so the classifier doesn't overfit to the headers etc.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['rec.sport.baseball', 'talk.politics.guns','comp.graphics', 'sci.med']\n",
    "twentyTrain = fetch_20newsgroups(subset='train', \n",
    "                                 categories=categories, \n",
    "                                 remove=('headers', 'footers', 'quotes'), \n",
    "                                 shuffle=True, \n",
    "                                 random_state=42)    # random seed \n",
    "print(twentyTrain.data[0])   # print one instance of the data - .data is the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(twentyTrain.target[:10])   #.target are the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in twentyTrain.target[:10]:\n",
    "    print(twentyTrain.target_names[t])  # .target_names are the class names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tokenising\n",
    "\n",
    "The tokenising can be changed by changing the parameters to the Vectorizer:  \n",
    "- `analyser` and `ngram_range` params will allow tokenising by char n-grams.  \n",
    "- `max_df` and `min_df` will allow document frequency reduction to be performed\n",
    "\n",
    "Look up the documentation to see what can be changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()       \n",
    "count_vect.get_params()      #shows the default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Term-Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm = count_vect.fit_transform(twentyTrain.data)   #tdm is a matrix - 2-d array\n",
    "tdm.shape     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect.vocabulary_.get('and')  #count_vect is a dictionary - show the freq of word 'and'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the TDM to a normalised tf or tf-idf matrix \n",
    "\n",
    "Check the `TfidfTransformer` parameters - they allow for tf vs tfidf and l1 vs l2 normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()   \n",
    "transformer.get_params()     #show default parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm_tfidf = transformer.fit_transform(tdm)   #transform the TDM\n",
    "tdm_tfidf.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a NB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(tdm_tfidf, twentyTrain.target)    #build the classifier (data, classes)\n",
    "\n",
    "docs_test = ['I am sick', 'No more gun control']      #set up 2 test instances\n",
    "\n",
    "# transform the test data in the same way as the training through CountVector and TfidfTransformer\n",
    "test_counts = count_vect.transform(docs_test)       # don't fit as the vocab has been generated from the training data\n",
    "test_tfidf = transformer.transform(test_counts)\n",
    "\n",
    "predicted = clf.predict(test_tfidf)   #predict  \n",
    "\n",
    "for doc, category in zip(docs_test, predicted):\n",
    "    print('%r => %s' % (doc, twentyTrain.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Pipeline to do it all in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),])\n",
    "\n",
    "text_clf.fit(twentyTrain.data, twentyTrain.target)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the 20 NG test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test', \n",
    "                                 categories=categories, \n",
    "                                 shuffle=True, \n",
    "                                 random_state=42)  \n",
    "docs_test = twenty_test.data\n",
    "\n",
    "import numpy as np\n",
    "predicted = text_clf.predict(docs_test)   # predict\n",
    "np.mean(predicted == twenty_test.target)  #report accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using metrics package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))    #print classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(twenty_test.target, predicted)  #print confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(twenty_test.target, predicted, average='macro')   #print f-score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TfidfVectorizer \n",
    "TfidfVectorizer combines using CountVectorizer and TfidfTransformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "categories = ['alt.atheism', 'talk.religion.misc',\n",
    "              'comp.graphics', 'sci.med']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      categories=categories,\n",
    "                                    shuffle=True,\n",
    "                                     random_state=42)\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',\n",
    "                                     categories=categories,\n",
    "                                     shuffle=True,\n",
    "                                     random_state=42)\n",
    "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
    "\n",
    "classifier = MultinomialNB(alpha=.01)\n",
    "classifier.fit(vectors, newsgroups_train.target)\n",
    "predicted = classifier.predict(vectors_test)\n",
    "print(metrics.classification_report(newsgroups_test.target, predicted,\n",
    "    target_names=newsgroups_train.target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
