{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Decision Tree Algorithm\n",
    "\n",
    "This notebook will take you through the steps involved in building a decision tree algorithm from scratch. Remember that scikit-learn provides its own implementation of the decision tree algorithm; and most of the time this is what you'll want to use. However, it's always useful to know what's happening under the hood, if you ever need functionality that isn't implemented out of the box, then this knowledge will let you build the algorithm yourself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Entropy\n",
    "\n",
    "The concept of **entropy** is fundamental to the decision tree algorithm. Entropy is a rough guide to how *mixed up* a dataset is. As a reminder, here's the algorithm for entropy.\n",
    "\n",
    "![Entropy Formula](entropy_formula.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break that down; the partial entropy for each possible *level*, *i* is, (the probability of choosing a label with the value *i*) * (log to the base 2 of the probability of choosing a label with the value of *i*). We calculate the partial entropy for each level, sum them all together and multiply the result by -1.\n",
    "\n",
    "We'll start by defining a function to calculate the partial entropy for a given level with respect to a categorical feature (the bit to the right of SIGMA, above). Our calculate_partial_entropy function will take a dataframe as a parameter, along with the column name we're calculating entropy for, and the particular value (we'll do this for each possible value of the target column).\n",
    "\n",
    "### Method\n",
    "\n",
    "To work out the probability of choosing a value at random we just find the percentage of rows which have that value. Take the census dataset as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stream</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Vegetation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>steep</td>\n",
       "      <td>high</td>\n",
       "      <td>chapparal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>moderate</td>\n",
       "      <td>low</td>\n",
       "      <td>riparian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>steep</td>\n",
       "      <td>medium</td>\n",
       "      <td>riparian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>steep</td>\n",
       "      <td>medium</td>\n",
       "      <td>chapparal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>flat</td>\n",
       "      <td>high</td>\n",
       "      <td>conifer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>steep</td>\n",
       "      <td>highest</td>\n",
       "      <td>conifer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>steep</td>\n",
       "      <td>high</td>\n",
       "      <td>chapparal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stream     Slope Elevation Vegetation\n",
       "ID                                       \n",
       "1    False     steep      high  chapparal\n",
       "2     True  moderate       low   riparian\n",
       "3     True     steep    medium   riparian\n",
       "4    False     steep    medium  chapparal\n",
       "5    False      flat      high    conifer\n",
       "6     True     steep   highest    conifer\n",
       "7     True     steep      high  chapparal"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('vegetation.csv')\n",
    "df = df.set_index('ID')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to work out the entropy of the Vegetation column. We'll start by working out the partial entropy of `chapparal`. What's the probability of choosing the value `chapparal` if we choose a row at random from this dataset?\n",
    "\n",
    "The probability of choosing a particular value *v* from a dataset *d* is \n",
    "\n",
    "<pre>\n",
    "    number of rows with value <em>v</em> / number of rows in <em>d</em>\n",
    "</pre>\n",
    "\n",
    "Pandas lets us count the number of rows in a dataframe using the `len()` function. To find the number of rows with value *v* we first filter the dataframe and then count the rows. Applying this, we can calculate the probability of choosing `chapparal` from the dataset above as\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Recap\n",
    "\n",
    "The Pandas library gives us a python equivalent of R's dataframes. We can access a particular column in a pandas dataframe using sqaure-bracket notation. To return only the vegetation column in our pandas dataframe we can use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "1    chapparal\n",
       "2     riparian\n",
       "3     riparian\n",
       "4    chapparal\n",
       "5      conifer\n",
       "6      conifer\n",
       "7    chapparal\n",
       "Name: Vegetation, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Vegetation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter and subset a pandas dataframe using the `.loc` property (short for *locate*). `.loc` allows us to use logical indexing, returning only rows that meet a specific criterion, for example, to return only rows with a value of `medium` for elevation we can use the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stream</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Vegetation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>steep</td>\n",
       "      <td>medium</td>\n",
       "      <td>riparian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>steep</td>\n",
       "      <td>medium</td>\n",
       "      <td>chapparal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stream  Slope Elevation Vegetation\n",
       "ID                                    \n",
       "3     True  steep    medium   riparian\n",
       "4    False  steep    medium  chapparal"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Elevation'] == 'medium']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `len()` function returns the total number of rows in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to find ourselves needing to find the *probability of selecting a value at random* repeatedly when building decision trees. Essentially this is the percentage of rows containing a given value. Put the above information together to create a function which calculates this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_probability(df: pd.DataFrame, column: str, val: any):\n",
    "    return len(df.loc[df[column] == val]) / len(df)\n",
    "\n",
    "calculate_probability(df, 'Elevation', 'medium') # 0.286...\n",
    "calculate_probability(df, 'Slope', 'steep') # 0.714..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The partial entropy of `chapparal` is 0.5238824662870492\n",
      "The partial entropy of `riparian` is 0.5163871205878868\n",
      "The partial entropy of `conifer` is 0.5163871205878868\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Copy the implementation of this function from the cell above\n",
    "# It will come in handy when calculating partial entropy\n",
    "def calculate_probability(df: pd.DataFrame, column: str, val: any):\n",
    "    return len(df.loc[df[column] == val]) / len(df)\n",
    "\n",
    "# partial_entropy is defined as the probability of selecting the target level at random\n",
    "# multiply by log to the base 2 of that probability\n",
    "# we'll multiply the result by -1 to ensure a positive result\n",
    "def calculate_partial_entropy(df: pd.DataFrame, column_name: str, target_level: str):\n",
    "    prob = calculate_probability(df, column_name, target_level)\n",
    "    return prob * math.log2(prob) * -1\n",
    "\n",
    "p_ent_chapparal = calculate_partial_entropy(df, 'Vegetation', 'chapparal')\n",
    "p_ent_riparian = calculate_partial_entropy(df, 'Vegetation', 'riparian')\n",
    "p_ent_conifer = calculate_partial_entropy(df, 'Vegetation', 'conifer')\n",
    "\n",
    "print(f\"The partial entropy of `chapparal` is {p_ent_chapparal}\") # -0.524...\n",
    "print(f\"The partial entropy of `riparian` is {p_ent_riparian}\") # -0.516...\n",
    "print(f\"The partial entropy of `conifer` is {p_ent_conifer}\") # -0.516..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Total Entropy\n",
    "\n",
    "We've worked out how to calculate the *partial entropy*, in order to calculate the total entropy of a dataset for a column, we need to add together the partial entropy for each possible value and multiply the result by -1.\n",
    "\n",
    "The `unique()` method of a pandas column returns a list of each of the unique values found in that column (unsurprisingly). We can now put together the full algorithm for calculating the entropy of a given dataset\n",
    "\n",
    "1. Get all unique label values for a column\n",
    "2. For each unique value, calculate the partial entropy\n",
    "3. Sum all partial entropies\n",
    "4. Multiply the result by -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5566567074628228"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_entropy(df: pd.DataFrame, column_name: str):\n",
    "    def calculate_partial_entropy(target_level: str):\n",
    "        prob = len(df.loc[df[column_name] == target_level]) / len(df)\n",
    "        partial_entropy = prob * math.log2(prob) * -1\n",
    "        return partial_entropy\n",
    "    \n",
    "    return sum([calculate_partial_entropy(v) for v in df[column_name].unique()])\n",
    "\n",
    "calculate_entropy(df, \"Vegetation\") # 1.557"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Information Gain\n",
    "\n",
    "Now that we can calculate the entropy of any given dataset, we can work out how much information would be gained by splitting a dataset on a given column. Information Gain is, roughly speaking, the amount by which we expect to reduce entropy after splitting a dataset on a given column. The formula for information gain is given by\n",
    "\n",
    "![Information Gain Formula](information_gain.png)\n",
    "\n",
    "\n",
    "In the equation above, the |vertical bars| refer to the **cardinality** or number of rows. |S<sub>v</sub>| is the number of rows containing the value *v*, |S| is the total number of rows. This is essentially the same thing as the probability of a row containing the value *v*. The intuition here is that to calculate information gain from splitting on a feature we find the weighted average of all potential subsets we might end up with, with the weight being directly proportional to the likelihood of that split occurring. If a dataset contains 99 rows with the value `registered` and only row with the value `unregistered`, we are much more likely to end up with a subset of 99 rows than 1 so we give more weight to the entropy resulting from a value of `registered`.\n",
    "\n",
    "Our decision tree algorithm works by looking at each column and working out the expecrted information gain resulting from splitting the dataset on that column. At each stage, the column resulting in the largest information gain is chosen. Returning to our census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Stream', 'Slope', 'Elevation', 'Vegetation'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Vegetation.csv')\n",
    "df = df.set_index('ID') # use the ID column as the index for the dataframe\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming now that *Vegetation* is our target variable, we have a choice of 3 columns on which to split the dataset. Let's look at each of these in turn and calculate the information gain resulting from each split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current entropy is 1.5566567074628228\n",
      "[False  True]\n",
      "Information Gain for stream = 0.30595849286804166\n",
      "['steep' 'moderate' 'flat']\n",
      "Information Gain for slope = 0.5774062828523452\n"
     ]
    }
   ],
   "source": [
    "current_entropy = calculate_entropy(df, 'Vegetation')\n",
    "print(f\"Current entropy is {current_entropy}\")\n",
    "\n",
    "# split the dataset on stream\n",
    "print(df['Stream'].unique())\n",
    "\n",
    "entropy_stream_false = calculate_entropy(df.loc[df['Stream'] == False], 'Vegetation')\n",
    "entropy_stream_true = calculate_entropy(df.loc[df['Stream'] == True], 'Vegetation')\n",
    "\n",
    "entropy_stream = (calculate_probability(df, 'Stream', False) * entropy_stream_false) + \\\n",
    "                (calculate_probability(df, 'Stream', True) * entropy_stream_true)\n",
    "\n",
    "ig_stream = current_entropy - entropy_stream\n",
    "\n",
    "print(f\"Information Gain for stream = {ig_stream}\")\n",
    "\n",
    "# split the dataset on slope\n",
    "print(df['Slope'].unique())\n",
    "entropy_slope_flat = calculate_entropy(df.loc[df['Slope'] == 'flat'], 'Vegetation')\n",
    "entropy_slope_moderate = calculate_entropy(df.loc[df['Slope'] == 'moderate'], 'Vegetation')\n",
    "entropy_slope_steep = calculate_entropy(df.loc[df['Slope'] == 'steep'], 'Vegetation')\n",
    "\n",
    "entropy_slope = (calculate_probability(df, 'Slope', 'flat') * entropy_slope_flat) + \\\n",
    "            (calculate_probability(df, 'Slope', 'moderate') * entropy_slope_moderate) + \\\n",
    "            (calculate_probability(df, 'Slope', 'steep') * entropy_slope_steep)\n",
    "\n",
    "ig_slope = current_entropy - entropy_slope\n",
    "print(f\"Information Gain for slope = {ig_slope}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the same logic as above to calculate the information gain for elevation. Which feature should the decision tree choose to split on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['high' 'low' 'medium' 'highest']\n",
      "Information Gain for elevation is 0.8773870642966131\n"
     ]
    }
   ],
   "source": [
    "current_entropy = calculate_entropy(df, 'Vegetation')\n",
    "\n",
    "print(df['Elevation'].unique())\n",
    "\n",
    "entropy_elevation_highest = calculate_entropy(df.loc[df['Elevation'] == 'highest'], 'Vegetation')\n",
    "entropy_elevation_high = calculate_entropy(df.loc[df['Elevation'] == 'high'], 'Vegetation')\n",
    "entropy_elevation_medium = calculate_entropy(df.loc[df['Elevation'] == 'medium'], 'Vegetation')\n",
    "entropy_elevation_low = calculate_entropy(df.loc[df['Elevation'] == 'low'], 'Vegetation')\n",
    "\n",
    "entropy_elevation = (calculate_probability(df, 'Elevation', 'highest') * entropy_elevation_highest) + \\\n",
    "    (calculate_probability(df, 'Elevation', 'high') * entropy_elevation_high) + \\\n",
    "    (calculate_probability(df, 'Elevation', 'medium') * entropy_elevation_medium) + \\\n",
    "    (calculate_probability(df, 'Elevation', 'low') * entropy_elevation_low)\n",
    "\n",
    "ig_elevation = current_entropy - entropy_elevation\n",
    "\n",
    "print(f\"Information Gain for elevation is {ig_elevation}\") # 0.878..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was quite a lot of typing, and most of the work was repetitive. We can make our lives a lot easier by rolling this up into a formula. First, we'll start with the definition. What parameters will we need to calulcate the expected information_gain for a column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_info_gain(df: pd.DataFrame, split_column: str, target_column: str):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to break our algorithm down into steps, or pseudo-code. Try this before moving on, look back over the previous cells to help guide you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculate the current entropy\n",
    "2. Find all unique values for split_column\n",
    "3. For each unique value *s*, of split_column:\n",
    "    1. Filter the dataframe to only rows containing *s*\n",
    "    2. Calculate the entropy of the filtered dataframe\n",
    "    3. Multiply the entropy by the `|s|/|df|` (the probabiliy of selecting s at random)\n",
    "4. Sum the outputs for each value of 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start by creating a function to handle A. B.and C. above. Fill in the function below. This function should calculate the probability of selecting split_value randomly from split_column. It should then calculate the entropy on the dataset (filtered by split_value) and return the weighted entropy (probability * entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_entropy(df: pd.DataFrame, split_column: str, split_value: str, target_column: str):\n",
    "    prob = calculate_probability(df, split_column, split_value)\n",
    "    entropy = calculate_entropy(df.loc[df[split_column] == split_value], target_column)\n",
    "    weighted = prob * entropy\n",
    "    return weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can carry out steps 1., 2., 3. and 4. Implement the calculate_info_gain function below. You can use the `calculate_weighted_entropy` function above to help you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30595849286804166\n",
      "0.5774062828523452\n",
      "0.8773870642966131\n"
     ]
    }
   ],
   "source": [
    "def calculate_info_gain(df: pd.DataFrame, split_column: str, target_column: str):\n",
    "    current_entropy = calculate_entropy(df, 'Vegetation')\n",
    "    return current_entropy - sum([calculate_weighted_entropy(df, split_column, v, target_column) for v in df[split_column].unique()])\n",
    "\n",
    "print(calculate_info_gain(df, 'Stream', 'Vegetation')) # 0.306\n",
    "print(calculate_info_gain(df, 'Slope', 'Vegetation')) # 0.578\n",
    "print(calculate_info_gain(df, 'Elevation', 'Vegetation')) # 0.878"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the Split Column\n",
    "\n",
    "We now know how to calculate the expected information gain for any column. All we need to do is find the column with the largest expected information gain, and use that to split the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Elevation'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def choose_next_column(df: pd.DataFrame, target_column: str):\n",
    "    # make sure we don't split on the target_column, that's cheating \n",
    "    # (and not very useful for an unseen instance)!\n",
    "    all_columns = [c for c in df.columns.values if c != target_column]\n",
    "    \n",
    "    # find the index of the column with the largest info_gain\n",
    "    chosen_index = np.argmax([calculate_info_gain(df, c, target_column) for c in all_columns])\n",
    "    \n",
    "    # return the column with the largest info gain\n",
    "    return all_columns[chosen_index]\n",
    "\n",
    "\n",
    "choose_next_column(df, 'Vegetation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "1. So far we've built a decision tree algorithm which uses Information Gain to determine the next column to split on. Create a new function choose_next_column_igr to use the Info Gain Ratio instead, you may re-use the functions already created in this notebook\n",
    "\n",
    "2. Create a new function, choose_next_column_gini() which uses the Gini coefficien to determine the next column to split on\n",
    "\n",
    "3. Load up the census.csv dataset, which column would a decision tree using Info Gain choose to split on first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
