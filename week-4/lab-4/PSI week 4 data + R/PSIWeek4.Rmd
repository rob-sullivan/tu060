---
title: "R Notebook - Week 4 Probability and Statistical Inference"
author: "Deirdre Lawless"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: console
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 


### SETUP

```{r}
#We are using a .sav file created from the SPSS file survey.sav  taken from SPSS Survival Manual 6th Edition Julie Pallant
#http://spss.allenandunwin.com.s3-website-ap-southeast-2.amazonaws.com/data-files.html#.Wb0vvnWP-po
#Results on a survey on well being
#We need to load the file so that we can use it in R.

#Either make sure both the script and the file are in the same folder or qualify the path to the file.

survey <- read.table("survey.dat") 


#Setting the column names to be that used in the dataset but in lowercase to make life a bit easier
colnames(survey) <- tolower(colnames(survey))
#Remember to install these packages if you haven't already done so

#First check that package required is installed, if not install it
# Specify your packages
needed_packages <- c("pastecs", "ggplot2", "moments", "FSA") #semTools                               
# Extract not installed packages
not_installed <- needed_packages[!(needed_packages %in% installed.packages()[ , "Package"])]    
# Install not installed packages
if(length(not_installed)) install.packages(not_installed)                              



library(pastecs) #For creating descriptive statistic summaries
library(ggplot2) #For creating histograms with more detail than plot
library(moments) #For skewness and kurtosis
```
### TPCOISS Generate histogram
```{r}

#We will allocate the histogram to a variable to allow use to manipulate it
gg <- ggplot(survey, aes(x=survey$tpcoiss))

#Change the label of the x axis
gg <- gg + labs(x="Feeling of Control")

#manage binwidth and colours
gg <- gg + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gg <- gg + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")

#adding a normal curve
#use stat_function to compute a normalised score for each value of tpcoiss
#pass the mean and standard deviation
#use the na.rm parameter to say how missing values are handled
gg <- gg + stat_function(fun=dnorm, color="red",args=list(mean=mean(survey$tpcoiss, na.rm=TRUE), sd=sd(survey$tpcoiss, na.rm=TRUE)))

#to display the graph request the contents of the variable be shown
gg
```
### TPCOISS Generate Q-Q Plot
```{r}
#Create a qqplot
qqnorm(survey$tpcoiss)
qqline(survey$tpcoiss, col=2) #show a line on theplot
```


### TPCOISS Generate Summary Statistics 
```{r}


#stat.desc is a function from pastecs - make sure you include the basic switch=F to ensure you don't get scienfitic notation
pastecs::stat.desc(survey$tpcoiss, basic=F)

#We can make our decision based on the value of the standardised score for skew and kurtosis
#We divide the skew statistic by the standard error to get the standardised score
#This will indicate if we have a problem

#sem tools is broken for the tested R installation and on ubuntu, using moments instead
#tpskew<-semTools::skew(survey$tpcoiss)
#tpkurt<-semTools::kurtosis(survey$tpcoiss)
#tpskew[1]/tpskew[2]
#tpkurt[1]/tpkurt[2]
skewness(survey$tpcoiss)
kurtosis(survey$tpcoiss)

#and by calculating the percentage of standardised scores for the variable itself that are outside our acceptable range
#This will tell us how big a problem we have
# Calculate the percentage of standardised scores that are greated than 1.96
# the perc function which is part of the FSA package which calculate the percentage that are within a range - you can look for greater than "gt", greater than or equal "geq", "gt", less than or equal "leq",  or less than "lt"),
# scale is a function that creates z scores, abs gets absolute value

ztpcoiss<- abs(scale(survey$tpcoiss))

FSA::perc(as.numeric(ztpcoiss), 1.96, "gt")
FSA::perc(as.numeric(ztpcoiss), 3.29, "gt")

```





###  TPSTRESS Generate Histogram
```{r}
#Create histogram
gs <- ggplot(survey, aes(x=survey$tpstress))
gs <- gs + labs(x="Perceived Stress")
gs <- gs + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gs <- gs + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")
gs <- gs + stat_function(fun=dnorm, color="red",args=list(mean=mean(survey$tpstress, na.rm=TRUE), sd=sd(survey$tpstress, na.rm=TRUE)))
gs


```
###  TPSTRESS Generate Q-Q Plot
```{r}
#Create a qqplot
qqnorm(survey$tpstress)
qqline(survey$tpstress, col=2) #show a line on theplot




```

### TPSTRESS Generate Summary Statistics
```{r}
#Generate regular summary statistics - lots of packages offer mechanisms to do this
pastecs::stat.desc(survey$tpstress, basic=F)


#We can make our decision based on the standardised score for skew and kurtosis
#We divide the skew statistic by the standard error to get the standardised score
#This will tell us if we have a problem

#semTools doesn't work anymore
#tpskew<-semTools::skew(survey$tpstress)
#tpkurt<-semTools::kurtosis(survey$tpstress)
#tpskew[1]/tpskew[2]
#tpkurt[1]/tpkurt[2]

skewness(survey$tpstress)
kurtosis(survey$tpstress)
#and by calculating the percentage of standardised scores for the variable itself that are outside our acceptable range
#this will tell us how big a problem we have
# Calculate the percentage of standardised scores that are greated than 1.96
# the perc function which is part of the FSA package which calculate the percentage that are within a range - you can look for greater than "gt", greater than or equal "geq", "gt", less than or equal "leq",  or less than "lt"),
# scale is a function that creates z scores
ztpstress<- abs(scale(survey$tpstress))

FSA::perc(as.numeric(ztpstress), 1.96, "gt")
FSA::perc(as.numeric(ztpstress), 3.29, "gt")

```

### CORRELATION
#### Scatterplot
```{r}

#Simple scatterplot of feeling of control and perceived stress
#aes(x,y)
scatter <- ggplot(survey, aes(survey$tpstress, survey$tpcoiss))

#Add a regression line
scatter + geom_point() + geom_smooth(method = "lm", colour = "Red", se = F) + labs(x = "Total Perceived Stress", y = "Total PCOISS") 
```

#### Conducting Correlation Tests - Pearson, Spearman, Kendall
 
```{r}

#Pearson Correlation
stats::cor.test(survey$tpcoiss, survey$tpstress, method='pearson')

#If our data does not fit a normal distribution we would report either Spearman or Kurtosis
#All tests are included here for completeness of explanation - in reality you would only include the most appropriate test.
#Spearman Correlation
#Change the method to be spearman.
#This test will give an error since this method uses ranking but cannot handle ties but that is ok with us - we consider this to be missing data
cor.test(survey$tpcoiss, survey$tpstress, method = "spearman")

#We can also use kendall's tau which does handle ties
cor.test(survey$tpcoiss, survey$tpstress, method = "kendall")
```