j = 4 ^ i
# name file
png(file = paste("freq_hist_", i, ".png", sep=""))
hist(rnorm(n = j * 10, mean = 50, sd = 10), breaks = seq(0, 100, length = j + 1), main=paste("n=", j * 10, ", " , j, " bins"), xlab = "")
# save
dev.off()
}
# for the final histogram, create histograms both with frequencies and with densities
#---------------------
i = 6
j = 4 ^ i
final_data = rnorm(n = j * 10, mean = 50, sd = 10)
# name file
png(file = paste("freq_hist_", i, ".png", sep=""))
hist(final_data, breaks = seq(0, 100, length = j + 1), main=paste("n=", j * 10, ", " , j, " bins"), xlab = "")
dev.off()
# name file
png(file = paste("dens_hist_", i, ".png", sep=""))
hist(final_data, breaks = seq(0, 100, length = j + 1), main=paste("n=", j * 10, ", " , j, " bins"), xlab = "", freq = FALSE)
dev.off()
# plot normal distribution
#--------------------------------
x = seq(0, 100, length = j + 1)
normal_data = dnorm(x, mean = 50, sd = 10, log = FALSE)
png(file = "pdf_norm.png")
plot(x, normal_data, main=paste("Probability density function"), xlab = "", ylab = "Probability density")
dev.off()
for (i in 1:5 ) {
j = 4 ^ i
# name file
png(file = paste("freq_hist_", i, ".png", sep=""))
hist(rnorm(n = j * 10, mean = 50, sd = 10), breaks = seq(0, 100, length = j + 1), main=paste("n=", j * 10, ", " , j, " bins"), xlab = "")
# save
dev.off()
}
for (i in 1:5 ) {
j = 4 ^ i
# name file
png(file = paste("freq_hist_", i, ".png", sep=""))
hist(rnorm(n = j * 10, mean = 50, sd = 10), breaks = seq(0, 100, length = j + 1), main=paste("n=", j * 10, ", " , j, " bins"), xlab = "")
# save
dev.off()
}
for(i in 1:5){}
for(i in 1:5){
j = 4 ^ i
png(file = paste("freq_hist_", i, ".png", sep=""))
hist(rnorm(n = j * 10, mean = 50, sd = 10), breaks = seq(0, 100, length = j + 1), main=paste("n=", j * 10, ", " , j, " bins"), xlab = "")
dev.off()
}
# for the final histogram, create histograms both with frequencies and with densities
#---------------------
i = 6
# for increasing sample size and bucket count, create histogram
#---------------------
for (i in 1:5 ) {
j = 4 ^ i
# name file
png(file = paste("freq_hist_", i, ".png", sep=""))
hist(rnorm(n = j * 10, mean = 50, sd = 10), breaks = seq(0, 100, length = j + 1), main=paste("n=", j * 10, ", " , j, " bins"), xlab = "")
# save
dev.off()
}
# for the final histogram, create histograms both with frequencies and with densities
#---------------------
i = 6
j = 4 ^ i
final_data = rnorm(n = j * 10, mean = 50, sd = 10)
# name file
png(file = paste("freq_hist_", i, ".png", sep=""))
hist(final_data, breaks = seq(0, 100, length = j + 1), main=paste("n=", j * 10, ", " , j, " bins"), xlab = "")
dev.off()
# name file
png(file = paste("dens_hist_", i, ".png", sep=""))
hist(final_data, breaks = seq(0, 100, length = j + 1), main=paste("n=", j * 10, ", " , j, " bins"), xlab = "", freq = FALSE)
dev.off()
# plot normal distribution
#--------------------------------
x = seq(0, 100, length = j + 1)
normal_data = dnorm(x, mean = 50, sd = 10, log = FALSE)
png(file = "pdf_norm.png")
plot(x, normal_data, main=paste("Probability density function"), xlab = "", ylab = "Probability density")
dev.off()
clear
str(airquality)
Temperature <- airquality$Temp
hist(Temperature)
View(data)
gc()
for (i in 1:5 ) {
j = 4 ^ i
# name file
png(file = paste("freq_hist_", i, ".png", sep=""))
hist(rnorm(n = j * 10, mean = 50, sd = 10), breaks = seq(0, 100, length = j + 1), main=paste("n=", j * 10, ", " , j, " bins"), xlab = "")
# save
dev.off()
}
i = 6
j = 4 ^ i
final_data = rnorm(n = j * 10, mean = 50, sd = 10)
png(file = paste("freq_hist_", i, ".png", sep=""))
hist(final_data, breaks = seq(0, 100, length = j + 1), main=paste("n=", j * 10, ", " , j, " bins"), xlab = "")
png(file = paste("dens_hist_", i, ".png", sep=""))
hist(final_data, breaks = seq(0, 100, length = j + 1), main=paste("n=", j * 10, ", " , j, " bins"), xlab = "", freq = FALSE)
x = seq(0, 100, length = j + 1)
normal_data = dnorm(x, mean = 50, sd = 10, log = FALSE)
png(file = "pdf_norm.png")
plot(x, normal_data, main=paste("Probability density function"), xlab = "", ylab = "Probability density")
dev.off()
#load packages
#install packman for managing add-ons
install.packages("packman")
#load packages
#install pacman for managing add-ons
install.packages("pacman")
require(pacman) #gives confirmation message
#now use pacman to load other libraries
pacman::p_load(pacman, dplyr, GGally, ggplot2, ggthemes, ggvis, httr, lubridate, plotly, rio, rmarkdown, shiny, stringr, tidyr)
# to clean up
#to clear packages
#p_unload(dplyr, tidyr)
p_unload(all) #unloads all of pacman libraries
library(datasets) #base packages need to be loaded in like this
detach("package:datasets")
#clear the console
cat("\014")
#basic graphics
#default plot command ( or basic x and y graph)
#first we load in datasets
library(datasets)
head(iris)
#basic graphics
#default plot command ( or basic x and y graph)
#first we load in datasets
?library(datasets)
?datasets
?plot
plot(iris$Species)
plot(iris$Petal.Length)
plot(iris$Species) # categorical variable
plot(iris$Petal.Length) #quantitative variable
plot(iris$Species, iris$Petal.Width) #cat x quant
plot(iris$Petal.Length, iris$Petal.Width) #cat x quant
plot(iris)
#plot with options
plot(iris$Petal.Length, iris$Petal.Width,
col = "#cc0000",
pch = 19,
main = "Iris: Petal Length vs. Petal Width",
xlab = "Petal Length",
ylab = "Petal Width")
#plot formulas with plot()
plot(cos, 0, 2*pi)
plot(exp, 1, 5)
plot(dnorm, -3, +3)
#standard normal distribution
plot(dnorm, -3, +3,
col = "#cc0000",
lwd = 5,
main = "Standard Normal Distribution",
xlab = "z-scores",
ylab = "Density")
#first we load in datasets
library(datasets)
#bar charts
?mtcars
head(mtcars)
barplot(mtcars$cyl)
# for frequencies we need a summary table because it prints out for each row
cylinders <- table(mtcars$cyl)
cylinders <- table(mtcars$cyl)
plot(cylinders)
barplot(cylinders)
#histograms
#use for quant data. we want to see shape, gaps, outlier and symmetry
?iris
head(iris)
#histogram 4 quant variables
hist(iris$Sepal.Length)
hist(iris$Sepal.Width)
hist(iris$Petal.Length)
hist(iris$Petal.Width)
#to fix do his by group, in three rows and 1 column
par(mflow = c(3,1))
#to fix do his by group, in three rows and 1 column
par(mfrow = c(3,1))
##his for each species using options
hist(iris$Petal.Width [iris$Species == "setosa"],
xlim = c(0, 3),
breaks = 9,
main = "Petal Width for Setosa",
xlab = "",
col = "red")
hist(iris$Petal.Width [iris$Species == "versicolor"],
xlim = c(0, 3),
breaks = 9,
main = "Petal Width for Versicolor",
xlab = "",
col = "purple")
hist(iris$Petal.Width [iris$Species == "virginica"],
xlim = c(0, 3),
breaks = 9,
main = "Petal Width for Virginica",
xlab = "",
col = "blue")
#restore graphic parameter
par(mfrow=c(1,1))
head(iris)
#scatter plot
#used to compare association between two quantitative variables
#looking for linear, spread, outliers and correlation
?mtcars
#first check univariate distributions
hist(mtcars$wt)
hist(mtcars$mpg)
#now basic plot of two on x and y
plot(mtcars$wt, mtcars$mpg)
#now basic plot of two on x and y
plot(mtcars$wt, mtcars$mpg
col="blue"
)
##his for each species using options
hist(iris$Petal.Width [iris$Species == "setosa"],
xlim = c(0, 3),
breaks = 9,
main = "Petal Width for Setosa",
xlab = "",
col = "red")
#now basic plot of two on x and y
plot(mtcars$wt, mtcars$mpg
col="blue"
)
#now basic plot of two on x and y
plot(mtcars$wt, mtcars$mpg,
col="blue"
)
#now basic plot of two on x and y
plot(mtcars$wt, mtcars$mpg,
pch=19,
cex=1.5,
col="blue")
#now basic plot of two on x and y
plot(mtcars$wt, mtcars$mpg,
pch=19,
cex=1.5,
main="How much gas used by weight of car"
col="blue")
#now basic plot of two on x and y
plot(mtcars$wt, mtcars$mpg,
pch=19,
cex=1.5,
main="How much gas used by weight of car",
col="blue")
#now basic plot of two on x and y
plot(mtcars$wt, mtcars$mpg,
pch=19,
cex=1.5,
main="How much gas used by weight of car",
xlab = "Weight [k pounds]",
ylab = "Fuel [mpg]",
col="blue")
#overlay plots
?lynx
hist(iris$Petal.Width [iris$Species == "versicolor"],
xlim = c(0, 3),
breaks = 9,
main = "Petal Width for Versicolor",
xlab = "",
col = "purple")
head(lynx)
#create a histogram
hist(lynx)
hist(lynx,
breaks=14,
freq = False,
col = "thistle1",
main = "lynx trappings 1821-1934",
xlab = "# trapped")
hist(lynx,
breaks=14,
freq = FALSE,
col = "thistle1",
main = "lynx trappings 1821-1934",
xlab = "# trapped")
#normal distribution chart
curve(dnorm(x, mean = mean(lynx), sd=sd(lynx))
col="blue",
lwd = 2,
add = TRUE)
#normal distribution chart
curve(dnorm(x, mean = mean(lynx), sd=sd(lynx)),
col="blue",
lwd = 2,
add = TRUE)
#add two kernal density estimators
lines(denisty(lynx), col = "red", lwd =2)
#add two kernal density estimators
lines(density(lynx), col = "red", lwd =2)
lines(density(lynx, adjust = 3), col = "green", lwd =3)
#add rug lines
rug(lynx, lwd=2, col="black")
#summary
head(iris)
summary(iris$Species)
summary(iris$Length)
summary(iris$Sepal.Length)
summary(iris)
hist(iris)
his(iris)
his(iris)
hist(iris)
#describe
require(pacman)
pacman::p_load(pacman, dplyr, GGally, ggplot2, ggthemes, ggvis, httr, lubridate, plotly, rio, rmarkdown, shiny, stringr, tidyr)
describe(iris)
pacman::p_load(pacman, dplyr, GGally, ggplot2, ggthemes, ggvis, httr, lubridate, plotly, rio, rmarkdown, shiny, stringr, tidyr, psych)
#describe
library(pacman)
#now basic plot of two on x and y
plot(mtcars$wt, mtcars$mpg,
pch=19,
cex=1.5,
main="How much gas used by weight of car",
xlab = "Weight [k pounds]",
ylab = "Fuel [mpg]",
col="blue")
pacman::p_load(pacman, dplyr, GGally, ggplot2, ggthemes, ggvis, httr, lubridate, plotly, rio, rmarkdown, shiny, stringr, tidyr)
p_load(psych)
p_load(psych) #sudo apt-get install gfortran required
sum(3,6,8,NA)
numbers <- 1:11
numbers
print(numbers>5)
greater.than.5 <- numbers[numbers>5]
setwd("~/projects/tu060/week-4")
getwkd
getwk()
getwd()
clear
url <- 'http://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip'
download.file(url, destfile = 'bank.zip')
unzip('bank.zip', list = T)
head(T)
head(list)
list
T
T.bank]
unzip('bank.zip', list = T)
unzip('bank.zip', list = T, exdir='./bankData')
getwd()
unzip('bank.zip', list = T)
unzip('bank.zip', list = T)
library(readr)
bankData <- read.delim('./bankData/ban-full.csv', delim=';', na=c('unknown'), guess_max=50000)
bankData <- read.delim('./bankData/bank-full.csv', delim=';', na=c('unknown'), guess_max=50000)
bankData <- read.delim('./bankData/bank-full.csv', delim=';', na=c('unknown'), guess_max=50000)
bankData <- read.delim('./bankData/bank-full.csv', delim=';', na=c('unknown'), guess_max=50000)
bankData <- read.delim('bankData/bank-full.csv', delim=';', na=c('unknown'), guess_max=50000)
bankData <- read.delim('bank-full.csv', delim=';', na=c('unknown'), guess_max=50000)
# url <- 'http://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip'
download.file(url, destfile = 'bank.zip')
unzip('bank.zip', list = T)
unzip('bank.zip', exdir='./bankData')
library(readr)
bankData <- read_delim('./bankData/bank-full.csv', delim=';', na=c('unknown'), col_types = 'nccccncccncnnnncc')
View(bankData)
#bankData <- read_delim('./bankData/bank-full.csv', delim=';', na=c('unknown'), col_types = 'nccccncccncnnnncc')
bankData <- read_delim('./bankData/bank-full.csv', delim=';', na=c('unknown'), guess_max=50000)
problems(bankData)
nrow(bankData)
nCol(bankData)
# url <- 'http://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip'
download.file(url, destfile = 'bank.zip')
head(bankData)
tail(bankData)
nCol(bankData)
#download and unzip file into a bankdata folder
url <- 'http://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip'
download.file(url, destfile = 'bank.zip')
unzip('bank.zip', exdir='./bankData')
#use readr library and read in csv file
library(readr)
#bankData <- read_delim('./bankData/bank-full.csv', delim=';', na=c('unknown'), col_types = 'nccccncccncnnnncc')
bankData <- read_delim('./bankData/bank-full.csv', delim=';', na=c('unknown'), guess_max=50000)
#basic checks
problems(bankData)
nrow(bankData)
nCol(bankData)
head(bankData)
tail(bankData)
#with loops
factor_indices <- c(2:5, 7:9, 11, 16:17)
bankData[[i]] <- as.factor(bankData[[i]])
for (i in factor_indices){
bankData[[i]] <- as.factor(bankData[[i]])
}
head(bankData)
#find and repalce n/a
#ask R
missing <- is.na(bankData$education)
count <- sum(missing)
total <- nrow(bankData)
percent <-(100 * count)/total
round(percent,2)
percent <-round((100 * count)/total,2)
ncol(bankData)
#for all cols na
allMissing <- is.na(bankData)
counts <- colSums(missing)
counts <- colSums(allMissing)
total <-round((counts)/nrow(bankData)*100,2)
print(total)
View(allMissing)
View(bankData)
avgAge <- mean(bankData$age)
round(avgAge)
avgDuration <- mean(bankData$duration)
round(avgDuration)
round(avgPdays)
avgPdays <- mean(bankData$pdays)
round(avgPdays)
#download and unzip file into a bankdata folder
url <- 'http://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip'
download.file(url, destfile = 'bank.zip')
unzip('bank.zip', exdir='./bankData')
#use readr library and read in csv file
library(readr)
#bankData <- read_delim('./bankData/bank-full.csv', delim=';', na=c('unknown'), col_types = 'nccccncccncnnnncc')
bankData <- read_delim('./bankData/bank-full.csv', delim=';', na=c('unknown'), guess_max=50000)
#basic checks
problems(bankData)
nrow(bankData)
ncol(bankData)
head(bankData)
tail(bankData)
#convert data from characters into usable factors
#bankData[[2]] <- as.factor(bankData[[2]])
#with loops
factor_indices <- c(2:5, 7:9, 11, 16:17)
for (i in factor_indices){
bankData[[i]] <- as.factor(bankData[[i]])
}
head(bankData)
#find and repalce n/a
#ask R
missing <- is.na(bankData$education)
count <- sum(missing)
total <- nrow(bankData)
percent <-round((100 * count)/total,2)
#for all cols na
allMissing <- is.na(bankData)
counts <- colSums(allMissing)
total <-round((counts)/nrow(bankData)*100,2)
print(total)
#calculate averages for age duration and pdays
avgAge <- mean(bankData$age)
round(avgAge)
avgDuration <- mean(bankData$duration)
round(avgDuration)
avgPdays <- mean(bankData$pdays)
round(avgPdays)
#watch out pdays has -1 for client not previously contacted -1 is not useful for mean
#repalce -1 with na then tell R to ignore na
#option 1
fix1 <- bankData
#get the index of every row with a value of -1 [True, False,...] etc.
indices <-(fix1$pdays == -1)
countNoContact <- sum(indices)
percent <- (100 * countNoContact)/nrow(bankData)
print(paste("Percent NAS: ", round(percent), ""))
#set the value of pdays to NA on each row that had a value of -1
fix1$pdays[indices] <- NA
#exclude NAs when calculating the mean
avgPdays <- mean(fix1$pdays, na.rm = T)
print(paste("Avg Pdays", round(avgPdays), ""))
#-1 is meaningful for other stuff so dont get rid of it just ignore it for mean
#option 2
#get the index of every customer who was contacted (i.e not -1)
indices <-(bankData$pdays != -1)
head(indices)
# sum the values to get the total number contacted (T=1, F=0)
countContacted <- sum(indices)
countContacted
#only select those who have been contacted to send to our mean() function
avgPdays <- mean(bankData$pdays[indices])
round(avgPdays)
#omitting rows containing NA
no.nas <- na.omit(bankData)
percentage.left <- nrow(no.nas) / nrow(bankData) * 100
round(100 - percentage.left, 2)
#summary stats is useful to understand the shape of the data
#mean sensitive to outliers so median can show skewness
random.data <- c(14, 15, 9, 14, 8, 9, 6, 7, 8, 12)
sorted.data <- sort(random.data)
sorted.data
percentile.index <- ceiling (length(sorted.data) * 0.1)
tenth.percentile <- sorted.data[[percentile.index]]
tenth.percentile
for(i in c(0.3, 0.5, 0.75)){
index <- ceiling(length(sorted.data) * i)
value <- sorted.data[[index]]
print(paste0("The ", i * 100, "th percentile is ", value))
}
#quantiles and interpolation (uses some linear interpolation method of curve fitting)
for(i in c(0.1, 0.3, 0.5, 0.75)){
print(paste0("The ", i * 100, "th percentile is ", quantile(sorted.data, i)))
}
for(i in c(0.1, 0.3, 0.5, 0.75)){
print(paste0("The ", i * 100, "th percentile is ", quantile(sorted.data, i, type =1)))
}
#five number summary
fivenum(bankData$age)
