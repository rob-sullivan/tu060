{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addiction Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Virtual Environment\n",
    "1. make sure python3 is installed on your system.\n",
    "2. make sure you have a python virtual environment setup: \n",
    "python -m pip install --upgrade pip setuptools virtualenv\n",
    "3. create a python environment: \n",
    "python -m venv venv (this creates a virtual environment called venv)\n",
    "4. if applicable add /venv/ to your .gitignore.\n",
    "5. activate the virtual environment: \n",
    "either \\venv\\Scripts\\activate.bat on windows \n",
    "or source venv/bin/activate on mac+linux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic\n",
    "from os import system, name\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "#pytorch for gpu processing of ML model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#rich library for Terminal UI\n",
    "from rich.jupyter import print\n",
    "#from rich import print\n",
    "from rich.prompt import IntPrompt\n",
    "\n",
    "\n",
    "#hide pytorch warnings (should eventually be resolved)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent's Brain (Deep Q-Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):  \n",
    "    def __init__(self, input_size, nb_action):\n",
    "        #ref: https://discuss.pytorch.org/t/super-model-in-init/97426\n",
    "        #super(Network, self).__init__()\n",
    "        super().__init__() #pytorch's NN model\n",
    "        self.input_size = input_size\n",
    "        self.nb_action = nb_action\n",
    "        self.fc1 = nn.Linear(input_size, 30)#arbitrarily chose 30 hidden layers\n",
    "        self.fc2 = nn.Linear(30, nb_action)\n",
    "    \n",
    "    #base pytorch NN model runs and we override the\n",
    "    #forward function with our own relu activation function\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        q_values = self.fc2(x)\n",
    "        return q_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience Replay Model\n",
    "This model is used for training our DQN model. It stores the transitions that the agent observes, allowing us to reuse this data later. By sampling from it randomly, the transitions that build up a batch are decorrelated. It has been shown that this greatly stabilizes and improves the DQN training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(): \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "    \n",
    "    def push(self, event):\n",
    "        self.memory.append(event)\n",
    "        if len(self.memory) > self.capacity:\n",
    "            del self.memory[0]\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        samples = zip(*random.sample(self.memory, batch_size))\n",
    "        return map(lambda x: Variable(torch.cat(x, 0)), samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN Ensemble\n",
    "Comprised of a neural network model and a memory model. \n",
    "* The NN takes in observation of sensor data (brain chemicals) and chooses actions based on the relu activation function. \n",
    "* The agent will sample some of the sensor data and store in long term memory to be reused later for training. \n",
    "* We also use the Adam Optimisation algorithm. This is an extension to stocastic gradient desent to update weights of the neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dqn():\n",
    "    def __init__(self, input_size, nb_action, gamma):\n",
    "        self.gamma = gamma\n",
    "        self.reward_window = []\n",
    "        self.model = Network(input_size, nb_action)\n",
    "        self.memory = ReplayMemory(100000)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr = 0.001)\n",
    "        self.last_state = torch.Tensor(input_size).unsqueeze(0)\n",
    "        self.last_action = 0\n",
    "        self.last_reward = 0\n",
    "    \n",
    "    # select action for x duration\n",
    "    def select_action(self, state):\n",
    "        #softmax converts numbers into probabilities\n",
    "        #Q values are the output of the neural network\n",
    "            #view q values\n",
    "        q_value_tensor = self.model(Variable(state, volatile = True)) \n",
    "        q_values = [q_value.detach().numpy() for q_value in q_value_tensor]\n",
    "            #print(q_values)\n",
    "            #viz q value for each action, (T value by user choice)\n",
    "            #pie chart 0/1 #seperate action\n",
    "        # Temperature value = 100. closer to zero the less sure the NN will be to taking the action\n",
    "        probs = F.softmax(self.model(Variable(state, volatile = True))*100) # T=100\n",
    "        action_prob = [prob.detach().numpy() for prob in probs]\n",
    "\n",
    "        action = probs.multinomial(num_samples=1) # action taken\n",
    "        #q_values[0][action] #qualiy of taking action in state\n",
    "        #action_prob[0][action] #probability of taking action\n",
    "\n",
    "        return action.data[0,0], q_values[0][action], action_prob[0][action]\n",
    "    \n",
    "    #to train our AI\n",
    "    #forward propagation then backproagation\n",
    "    # get our output, target, compare our output to the target to compute the loss error\n",
    "    # backproagate loss error into the nn and use stochastic gradient descent we update the weights according to how much they contributed to the loss error\n",
    "    def learn(self, batch_state, batch_next_state, batch_reward, batch_action):\n",
    "        outputs = self.model(batch_state).gather(1, batch_action.unsqueeze(1)).squeeze(1)\n",
    "        next_outputs = self.model(batch_next_state).detach().max(1)[0]\n",
    "        target = self.gamma*next_outputs + batch_reward\n",
    "        td_loss = F.smooth_l1_loss(outputs, target)\n",
    "        self.optimizer.zero_grad()\n",
    "        td_loss.backward(retain_graph = True)\n",
    "        self.optimizer.step()\n",
    "    \n",
    "    #When ai reaches a new state we update everything\n",
    "    #update action, last action becomes the new action but also the last state becomes the new state and last reward becomes the new state\n",
    "    # we then get this new transition and update our reward window to track training progress and exploration\n",
    "    def update(self, reward, new_signal):\n",
    "        new_state = torch.Tensor(new_signal).float().unsqueeze(0)\n",
    "        self.memory.push((self.last_state, new_state, torch.LongTensor([int(self.last_action)]), torch.Tensor([self.last_reward])))\n",
    "        action, q, p = self.select_action(new_state)\n",
    "        if len(self.memory.memory) > 100:\n",
    "            batch_state, batch_next_state, batch_action, batch_reward = self.memory.sample(100)\n",
    "            self.learn(batch_state, batch_next_state, batch_reward, batch_action)\n",
    "        self.last_action = action\n",
    "        self.last_state = new_state\n",
    "        self.last_reward = reward\n",
    "        self.reward_window.append(reward)\n",
    "        if len(self.reward_window) > 1000:\n",
    "            del self.reward_window[0]\n",
    "        return action, q, p\n",
    "    \n",
    "    def score(self):\n",
    "        return sum(self.reward_window)/(len(self.reward_window)+1.0)\n",
    "    \n",
    "    def save(self):\n",
    "        torch.save({'state_dict': self.model.state_dict(),\n",
    "                    'optimizer' : self.optimizer.state_dict(),\n",
    "                   }, 'last_brain.pth')\n",
    "    def load(self):\n",
    "        if os.path.isfile('last_brain.pth'):\n",
    "            print(\"=> loading checkpoint... \")\n",
    "            checkpoint = torch.load('last_brain.pth')\n",
    "            self.model.load_state_dict(checkpoint['state_dict'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"done !\")\n",
    "        else:\n",
    "            print(\"no checkpoint found...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulation():    \n",
    "    def __init__(self):\n",
    "        # Agent Brain - a neural network that represents our Q-function\n",
    "        self.agent = Dqn(2,3,0.9) # 4 sensors, 8 actions, gama = 0.9\n",
    "        #Agent's Actions\n",
    "        #self.actions = ['Sleep', 'Binge on Internet', 'Work', 'Exercise', 'Socialise', 'Drink Alcohol', 'Smoke', 'Take Cocaine'] #8 actions\n",
    "        self.actions = ['Do Nothing', 'In-Active Lever', 'Active Lever']\n",
    "        \n",
    "        # Mehdi Keramati's definition of an animal ref Mehdi Keramati's Homeostatic RL sim of addiction\n",
    "        ## fatigue or lever/action cost\n",
    "        self.fatigue = 1\n",
    "        #Keramati's outcome, e.g cocaine = 50, representing the dose of self-administered drug,\n",
    "        self.outcome = [0,0,50] #all others were scaled from cocaine as their assumed impact on the brain. #[0,10,5,12.5,12.5,10,25,50]#self.outcome = [0,0,0,0,0,0,0,50] #all others were scaled from cocaine as their assumed impact on the brain. #[0,10,5,12.5,12.5,10,25,50]\n",
    "        self.outcomeBuffer = 0\n",
    "\n",
    "        ## Homeostatic System\n",
    "        self.initialInState = 0\n",
    "        self.initialSetpoint = 200\n",
    "        self.inStateLowerBound = 0\n",
    "        self.outcomeDegradationRate = 0.007 # e.g dose of cocaine that the animal loses in every time-step\n",
    "        self.outcomeAbsorptionRatio = 0.12 # e.g proportion of the injected cocaine that affects the brain right after infusion\n",
    "        self.estimatedNonHomeostaticReward = 0.0\n",
    "\n",
    "        ## Allostatic (Stress) System\n",
    "        self.setpointShiftRate = 0.0018\n",
    "        self.setpointRecoveryRate = 0.00016\n",
    "        self.optimalInStateLowerBound = 100\n",
    "        self.optimalInStateUpperBound = 200\n",
    "\n",
    "        ## Drive Function\n",
    "        self.m = 3 # Parameter of the drive function : m-th root\n",
    "        self.n = 4 # Parameter of the drive function : n-th pawer\n",
    "        self.driveReductionReward = 0.0\n",
    "\n",
    "        ## Goal-directed system\n",
    "        self.updateRewardRate = 0.2  # Learning rate for updating the non-homeostatic reward function\n",
    "        self.updateOutcomeRate = 0.2  # Learning rate for updating the outcome function\n",
    "        \n",
    "        #agent's sensors or observation space\n",
    "        self.last_action = 0 #c(external state /exited)\n",
    "        self.internal_state = float(self.initialInState) #internal variable that moves homeostatic setpoint\n",
    "        self.setpoint_S = float(self.initialSetpoint) #homeostatic setpoint\n",
    "\n",
    "        \n",
    "        # the mean score curve (sliding window of the rewards) with \n",
    "        # respect to time.\n",
    "        self.scores = []\n",
    "\n",
    "        #Environment: the agent's grid world is elapsing time from 1 to endpoint\n",
    "        self.total_time = 1 # total time in hours (size of the world) e.g 1 year or 8760hrs\n",
    "        self.total_epochs = (self.total_time*3600)/4 #e.g 20 secs is 5 trials or epochs of time or 1 hour = 3600secs/4secs = 900 epochs, 8760hrs is 7,884,000 epochs\n",
    "\n",
    "        self.current_epoch = 0 # e.g 1=4secs\n",
    "\n",
    "        # reward agent wants to maximise this will be the homeostatic reward\n",
    "        self.reward_received = 0.0\n",
    "\n",
    "        #create data table\n",
    "        self.df = pd.DataFrame(columns=['epoch', 'action', 'transition_probability', 'q_value', 'internal_variable', 'homeostatic_setpoint', 'reward', 'score'])\n",
    "\n",
    "        self.finish = False #trigger to end simulation\n",
    "        while not self.finish:\n",
    "            self.finish = self.next_time_interval()# begin simulation and repeat until triggered not to\n",
    "        if(self.finish):\n",
    "            #print(\"saving brain...\")\n",
    "            #brain.save()\n",
    "            plt.title(\"Scores [average reward/100 epochs]\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Reward\")\n",
    "            plt.plot(self.scores)\n",
    "            plt.show()\n",
    "\n",
    "    def next_time_interval(self):\n",
    "        ## get the time left\n",
    "        epochs_left = int(self.total_epochs - self.current_epoch)\n",
    "        \n",
    "        ## agent input state vector, composed of the five brain signals or observations received from being in the environment\n",
    "        current_state = [self.internal_state, self.setpoint_S] #self.last_action,, self.current_epoch\n",
    "        action_to_take, qValue, transitionProb = self.agent.update(self.reward_received, current_state) # playing the action from the ai (dqn class)\n",
    "        self.scores.append(self.agent.score()) # appending the score (average of the last 100 rewards to the reward window)\n",
    "\n",
    "        #we can take the agent's NN and call forward to output via softmax q values for each state.\n",
    "        suggested_action = self.actions[action_to_take]\n",
    "        #sa = int(0 if suggested_action==\"Sleep\" else 1 if suggested_action==\"Binge on Internet\" else 2 if suggested_action==\"Work\" else 3 if suggested_action==\"Exercise\" else 4 if suggested_action==\"Socialise\" else 5 if suggested_action==\"Drink Alcohol\" else 6 if suggested_action==\"Smoke\" else 7 if suggested_action==\"Take Cocaine\" else -1)\n",
    "        sa = int(0 if suggested_action==\"Do Nothing\" else 1 if suggested_action==\"In-Active Lever\" else 2 if suggested_action==\"Active Lever\" else -1)\n",
    "        #give user options\n",
    "        #print(\"0. [bold dark_violet]Sleep[/bold dark_violet]\\n1. [bold dark_violet]Binge on Internet[/bold dark_violet]\\n2. [bold dark_violet]Work[/bold dark_violet]\\n3. [bold dark_violet]Exercise[/bold dark_violet]\\n4. [bold dark_violet]Socialise[/bold dark_violet]\\n5. [bold dark_violet]Drink Alcohol[/bold dark_violet]\\n6. [bold dark_violet]Smoke[/bold dark_violet]\\n\")\n",
    "        #action_taken = 0\n",
    "        #action_taken = IntPrompt.ask(\"Choose from 1 to 6\", default=sa)\n",
    "        action_taken = sa #automatic\n",
    "        self.last_action = action_taken #automatic\n",
    "        #update agent brain chemicals after action taken\n",
    "        if(action_taken == 0): #Do Nothing/Sleep\n",
    "            #1. update internal sensors or observations of the environment\n",
    "            #self.current_state = next_state\n",
    "\n",
    "            ## Update internal state upon consumption  \n",
    "            interS = self.internal_state + (self.outcome[action_taken] * self.outcomeAbsorptionRatio) - self.outcomeDegradationRate * (self.internal_state - self.inStateLowerBound)\n",
    "            if interS < self.inStateLowerBound:\n",
    "                interS = self.inStateLowerBound    \n",
    "            self.internal_state = interS\n",
    "\n",
    "            ## Update homeostatic setpoint\n",
    "            optInS = self.setpoint_S + self.outcome[action_taken]  * self.setpointShiftRate - self.setpointRecoveryRate\n",
    "            if optInS < self.optimalInStateLowerBound:\n",
    "                optInS = self.optimalInStateLowerBound\n",
    "            if optInS > self.optimalInStateUpperBound:\n",
    "                optInS = self.optimalInStateUpperBound\n",
    "            self.setpoint_S = optInS\n",
    "\n",
    "        elif((action_taken != 0) or (action_taken != -1)): #In-Active Lever/Active Lever #Binge on Internet, Work, Exercise, Socialise, Drink Alcohol, Smoke\n",
    "            #1. determine the next state that the agent fell into from taking action\n",
    "            #n/a\n",
    "            \n",
    "            #2. get Non-Homeostatic reward e.g energy cost or fatigue of doing an action\n",
    "                ## if the agent is not sleeping then it is doing something that costs energy\n",
    "                #nonHomeoRew = -self.fatigue\n",
    "            self.estimatedNonHomeostaticReward = (1.0 - self.updateRewardRate) * self.estimatedNonHomeostaticReward + self.updateRewardRate * (-self.fatigue)\n",
    "            \n",
    "            #3. get Homeostatically-regulated Reward of doing action (drive reduction)\n",
    "            d1 = math.pow(math.fabs(math.pow(self.setpoint_S - self.internal_state, self.n*1.0)),(1.0/self.m))\n",
    "            d2 = math.pow(math.fabs(math.pow(self.setpoint_S - self.internal_state - self.outcome[action_taken], self.n*1.0)),(1.0/self.m))\n",
    "                #HomeoRew = d1 - d2\n",
    "            self.driveReductionReward = (1.0 - self.updateOutcomeRate) * self.driveReductionReward + self.updateOutcomeRate * (d1 - d2)\n",
    "            \n",
    "            #4. Now calculate agent reward\n",
    "            #self.reward_received = values[action] +  transitionProb * ( self.driveReductionReward + self.estimatedNonHomeostaticReward )\n",
    "            #self.reward_received = qValue +  transitionProb * ( self.driveReductionReward + self.estimatedNonHomeostaticReward )\n",
    "            self.reward_received = self.driveReductionReward + self.estimatedNonHomeostaticReward\n",
    "            #5. update estimated next state\n",
    "            # n/a\n",
    "            \n",
    "            #6. update internal sensors or observations of the environment\n",
    "            \n",
    "            ## Update internal state upon consumption\n",
    "            self.outcomeBuffer = self.outcomeBuffer + self.outcome[action_taken]   \n",
    "            interS = self.internal_state + (self.outcomeBuffer * self.outcomeAbsorptionRatio) - self.outcomeDegradationRate * (self.internal_state - self.inStateLowerBound)\n",
    "            if interS < self.inStateLowerBound:\n",
    "                interS = self.inStateLowerBound    \n",
    "            self.internal_state = interS\n",
    "\n",
    "            ## Update homeostatic setpoint\n",
    "            optInS = self.setpoint_S + self.outcome[action_taken]  * self.setpointShiftRate - self.setpointRecoveryRate\n",
    "            if optInS < self.optimalInStateLowerBound:\n",
    "                optInS = self.optimalInStateLowerBound\n",
    "            if optInS > self.optimalInStateUpperBound:\n",
    "                optInS = self.optimalInStateUpperBound\n",
    "            self.setpoint_S = optInS \n",
    "\n",
    "            ## Update outcome buffer\n",
    "            self.outcomeBuffer = self.outcomeBuffer * (1 - self.outcomeAbsorptionRatio)\n",
    "\n",
    "        elif(action_taken == -1):#quit\n",
    "            return True   #end simulation\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print(\"** Current Time: [bold dark_violet]\" + str(round((1/900)*(self.current_epoch),2)) + \n",
    "              \"[/bold dark_violet] hrs, Epoch Left: [bold dark_violet]\" + str(round((1/900)*(epochs_left),2)) + \n",
    "              \"[/bold dark_violet] hrs, **\\n[bold dark_green]Last Action: \" + str(suggested_action) + \n",
    "              \"[/bold dark_green], [bold dark_green]Current Homeostatic Variable: \" + str(round(self.internal_state, 4)) + \n",
    "              \"[/bold dark_green], [bold dark_green]Current Homeostatic Setpoint: \" + str(round(self.setpoint_S, 4)) +\n",
    "              \"[/bold dark_green], [bold dark_green]Reward Received: \" + str(round(self.reward_received,2)) + \n",
    "              \"[/bold dark_green], [bold dark_green]Score: \" + str(round(self.scores[-1],2)) + \"[/bold dark_green]\")\n",
    "        self.df.loc[self.current_epoch] = [self.current_epoch , suggested_action, transitionProb, qValue, self.internal_state, self.setpoint_S, self.reward_received, self.scores[-1]]\n",
    "        #check if this is the last round otherwise continue\n",
    "        if(self.current_epoch >= self.total_epochs):\n",
    "            return True   #end simulation\n",
    "        else:    \n",
    "            # Updating the last time from the agent to the end time (goal)\n",
    "            self.current_epoch += 1  #update to next day interval\n",
    "            return False\n",
    "\n",
    "    def clear(self): \n",
    "        \"\"\"\n",
    "        This function was taken from https://www.geeksforgeeks.org/clear-screen-python/ to\n",
    "        allow the terminal to be cleared when changing menus or showing the user important\n",
    "        messages. It checks what operating system is being used and uses the correct \n",
    "        clearing command.\n",
    "        \"\"\"\n",
    "        # for windows \n",
    "        if name == 'nt': \n",
    "            _ = system('cls') \n",
    "\n",
    "        # for mac and linux(here, os.name is 'posix')\n",
    "        else: \n",
    "            _ = system('clear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">** Current Time: <span style=\"color: #af00d7; text-decoration-color: #af00d7; font-weight: bold\">1.0</span> hrs, Epoch Left: <span style=\"color: #af00d7; text-decoration-color: #af00d7; font-weight: bold\">0.0</span> hrs, **\n",
       "<span style=\"color: #005f00; text-decoration-color: #005f00; font-weight: bold\">Last Action: Do Nothing</span>, <span style=\"color: #005f00; text-decoration-color: #005f00; font-weight: bold\">Current Homeostatic Variable: </span><span style=\"color: #005f00; text-decoration-color: #005f00; font-weight: bold\">0.0699</span>, <span style=\"color: #005f00; text-decoration-color: #005f00; font-weight: bold\">Current Homeostatic Setpoint: </span><span style=\"color: #005f00; text-decoration-color: #005f00; font-weight: bold\">199.8746</span>, <span style=\"color: #005f00; text-decoration-color: #005f00; font-weight: bold\">Reward </span>\n",
       "<span style=\"color: #005f00; text-decoration-color: #005f00; font-weight: bold\">Received: </span><span style=\"color: #005f00; text-decoration-color: #005f00; font-weight: bold\">132.27</span>, <span style=\"color: #005f00; text-decoration-color: #005f00; font-weight: bold\">Score: </span><span style=\"color: #005f00; text-decoration-color: #005f00; font-weight: bold\">114.93</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "** Current Time: \u001b[1;38;5;128m1.0\u001b[0m hrs, Epoch Left: \u001b[1;38;5;128m0.0\u001b[0m hrs, **\n",
       "\u001b[1;38;5;22mLast Action: Do Nothing\u001b[0m, \u001b[1;38;5;22mCurrent Homeostatic Variable: \u001b[0m\u001b[1;38;5;22m0.0699\u001b[0m, \u001b[1;38;5;22mCurrent Homeostatic Setpoint: \u001b[0m\u001b[1;38;5;22m199.8746\u001b[0m, \u001b[1;38;5;22mReward \u001b[0m\n",
       "\u001b[1;38;5;22mReceived: \u001b[0m\u001b[1;38;5;22m132.27\u001b[0m, \u001b[1;38;5;22mScore: \u001b[0m\u001b[1;38;5;22m114.93\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    env = Simulation() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>action</th>\n",
       "      <th>transition_probability</th>\n",
       "      <th>q_value</th>\n",
       "      <th>internal_variable</th>\n",
       "      <th>homeostatic_setpoint</th>\n",
       "      <th>reward</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Active Lever</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.345362</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>74.322634</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Active Lever</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.866026</td>\n",
       "      <td>17.238000</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>132.915065</td>\n",
       "      <td>24.774211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Active Lever</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.000860</td>\n",
       "      <td>33.043734</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>178.110059</td>\n",
       "      <td>51.809425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Active Lever</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.796480</td>\n",
       "      <td>52.827660</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>211.761830</td>\n",
       "      <td>77.069552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Active Lever</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.288961</td>\n",
       "      <td>76.071270</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>235.266020</td>\n",
       "      <td>99.518265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>In-Active Lever</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-72.251350</td>\n",
       "      <td>648.485717</td>\n",
       "      <td>199.98992</td>\n",
       "      <td>-1.000885</td>\n",
       "      <td>-58.719000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>166</td>\n",
       "      <td>In-Active Lever</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-69.533028</td>\n",
       "      <td>643.955380</td>\n",
       "      <td>199.98976</td>\n",
       "      <td>-1.000708</td>\n",
       "      <td>-58.375440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>167</td>\n",
       "      <td>In-Active Lever</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-66.772461</td>\n",
       "      <td>639.455668</td>\n",
       "      <td>199.98960</td>\n",
       "      <td>-1.000567</td>\n",
       "      <td>-58.035944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>168</td>\n",
       "      <td>In-Active Lever</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-63.861481</td>\n",
       "      <td>634.986497</td>\n",
       "      <td>199.98944</td>\n",
       "      <td>-1.000453</td>\n",
       "      <td>-57.700442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>169</td>\n",
       "      <td>In-Active Lever</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-60.808495</td>\n",
       "      <td>630.547768</td>\n",
       "      <td>199.98928</td>\n",
       "      <td>-1.000363</td>\n",
       "      <td>-57.368863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch           action  transition_probability    q_value  \\\n",
       "0        0     Active Lever                     1.0  27.345362   \n",
       "1        1     Active Lever                     1.0  26.866026   \n",
       "2        2     Active Lever                     1.0  26.000860   \n",
       "3        3     Active Lever                     1.0  24.796480   \n",
       "4        4     Active Lever                     1.0  23.288961   \n",
       "..     ...              ...                     ...        ...   \n",
       "165    165  In-Active Lever                     1.0 -72.251350   \n",
       "166    166  In-Active Lever                     1.0 -69.533028   \n",
       "167    167  In-Active Lever                     1.0 -66.772461   \n",
       "168    168  In-Active Lever                     1.0 -63.861481   \n",
       "169    169  In-Active Lever                     1.0 -60.808495   \n",
       "\n",
       "     internal_variable  homeostatic_setpoint      reward      score  \n",
       "0             6.000000             200.00000   74.322634   0.000000  \n",
       "1            17.238000             200.00000  132.915065  24.774211  \n",
       "2            33.043734             200.00000  178.110059  51.809425  \n",
       "3            52.827660             200.00000  211.761830  77.069552  \n",
       "4            76.071270             200.00000  235.266020  99.518265  \n",
       "..                 ...                   ...         ...        ...  \n",
       "165         648.485717             199.98992   -1.000885 -58.719000  \n",
       "166         643.955380             199.98976   -1.000708 -58.375440  \n",
       "167         639.455668             199.98960   -1.000567 -58.035944  \n",
       "168         634.986497             199.98944   -1.000453 -57.700442  \n",
       "169         630.547768             199.98928   -1.000363 -57.368863  \n",
       "\n",
       "[170 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.df.head(170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = datetime.datetime.now()\n",
    "file_name = str(x.year) + \"_\" + str(x.month) + \"_\" + str(x.day) + \"_\" + str(x.strftime(\"%H\")) + \"_\" + str(x.strftime(\"%M\")) + \"_\" + str(x.strftime(\"%S\")) + \".csv\"\n",
    "env.df.to_csv(file_name, index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5794a404577a32ff418895c331e736516539893dd666baf27c4118b4263cef3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
