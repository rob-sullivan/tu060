---
title: "R Notebook - Week 4 Probability and Statistical Inference - Lab Solution"
author: "Deirdre Lawless"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: console
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 


### SETUP

```{r}
#We are using a .sav file created from the SPSS file survey.sav  taken from SPSS Survival Manual 6th Edition Julie Pallant
#http://spss.allenandunwin.com.s3-website-ap-southeast-2.amazonaws.com/data-files.html#.Wb0vvnWP-po
#Results on a survey on well being
#We need to load the file so that we can use it in R.

#Either make sure both the script and the file are in the same folder or qualify the path to the file.

survey <- read.table("survey.dat") 


#Setting the column names to be that used in the dataset but in lowercase to make life a bit easier
colnames(survey) <- tolower(colnames(survey))
#Remember to install these packages if you haven't already done so

#First check that package required is installed, if not install it
# Specify your packages
needed_packages <- c("pastecs", "ggplot2", "semTools", "FSA")                                    
# Extract not installed packages
not_installed <- needed_packages[!(needed_packages %in% installed.packages()[ , "Package"])]    
# Install not installed packages
if(length(not_installed)) install.packages(not_installed)                              



library(pastecs) #For creating descriptive statistic summaries
library(ggplot2) #For creating histograms with more detail than plot
library(semTools) #For skewness and kurtosis
```

## 1. Investigate the relationship between Total Postive Affect and Total Perceived Stress.
### Tposaff Total Positive Affect 
```{r}

#We will allocate the histogram to a variable to allow use to manipulate it
gg <- ggplot(survey, aes(x=tposaff))

#Change the label of the x axis
gg <- gg + labs(x="Total Positive Affect")

#manage binwidth and colours
gg <- gg + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gg <- gg + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")

#adding a normal curve
#use stat_function to compute a normalised score for each value of tposaff
#pass the mean and standard deviation
#use the na.rm parameter to say how missing values are handled
gg <- gg + stat_function(fun=dnorm, color="red",args=list(mean=mean(survey$tposaff, na.rm=TRUE), sd=sd(survey$tposaff, na.rm=TRUE)))

#to display the graph request the contents of the variable be shown
gg
```
### tposaff Generate Q-Q Plot
```{r}
#Create a qqplot
qqnorm(survey$tposaff)
qqline(survey$tposaff, col=2) #show a line on theplot
```


### tposaff Generate Summary Statistics 
```{r}
#stat.desc is a function from pastecs - make sure you include the basic switch=F to ensure you don't get scienfitic notation
pastecs::stat.desc(survey$tposaff, basic=F)

#We can make our decision based on the value of the standardised score for skew and kurtosis
#We divide the skew statistic by the standard error to get the standardised score
#This will indicate if we have a problem
tpskew<-semTools::skew(survey$tposaff)
tpkurt<-semTools::kurtosis(survey$tposaff)
tpskew[1]/tpskew[2]
tpkurt[1]/tpkurt[2]

#and by calculating the percentage of standardised scores for the variable itself that are outside our acceptable range
#This will tell us how big a problem we have
# Calculate the percentage of standardised scores that are greated than 1.96
# the perc function which is part of the FSA package which calculate the percentage that are within a range - you can look for greater than "gt", greater than or equal "geq", "gt", less than or equal "leq",  or less than "lt"),
# scale is a function that creates z scores, abs gets absolute value

ztposaff<- abs(scale(survey$tposaff))

FSA::perc(as.numeric(ztposaff), 1.96, "gt")
FSA::perc(as.numeric(ztposaff), 3.29, "gt")

```



###  TPSTRESS Generate Histogram
```{r}
#Create histogram
gs <- ggplot(survey, aes(x=tpstress))
gs <- gs + labs(x="Perceived Stress")
gs <- gs + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gs <- gs + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")
gs <- gs + stat_function(fun=dnorm, color="red",args=list(mean=mean(survey$tpstress, na.rm=TRUE), sd=sd(survey$tpstress, na.rm=TRUE)))
gs


```
###  TPSTRESS Generate Q-Q Plot
```{r}
#Create a qqplot
qqnorm(survey$tpstress)
qqline(survey$tpstress, col=2) #show a line on theplot

```

### TPSTRESS Generate Summary Statistics
```{r}
#Generate regular summary statistics - lots of packages offer mechanisms to do this
pastecs::stat.desc(survey$tpstress, basic=F)


#We can make our decision based on the standardised score for skew and kurtosis
#We divide the skew statistic by the standard error to get the standardised score
#This will tell us if we have a problem
tpskew<-semTools::skew(survey$tpstress)
tpkurt<-semTools::kurtosis(survey$tpstress)
tpskew[1]/tpskew[2]
tpkurt[1]/tpkurt[2]

#and by calculating the percentage of standardised scores for the variable itself that are outside our acceptable range
#this will tell us how big a problem we have
# Calculate the percentage of standardised scores that are greated than 1.96
# the perc function which is part of the FSA package which calculate the percentage that are within a range - you can look for greater than "gt", greater than or equal "geq", "gt", less than or equal "leq",  or less than "lt"),
# scale is a function that creates z scores
ztpstress<- abs(scale(survey$tpstress))

FSA::perc(as.numeric(ztpstress), 1.96, "gt")
FSA::perc(as.numeric(ztpstress), 3.29, "gt")

```

### CORRELATION
#### Scatterplot
```{r}

#Simple scatterplot of postivie affect and perceived stress
#aes(x,y)
scatter <- ggplot(survey, aes(tposaff, tpstress))

#Add a regression line
scatter + geom_point() + geom_smooth(method = "lm", colour = "Red", se = F) + labs(x = "Total Positive Affect", y = "Total Perceived Stress") 
```

#### Conducting Correlation Test Positive Affect and Stress - Pearson
 
```{r}
#As both variables can be considered approximately normal use Pearson
#Pearson Correlation
stats::cor.test(survey$tposaff, survey$tpstress, method='pearson')
#Moderate negative correlation which is statistically significant (r=-0.44, n=431, p< 0.001)
```
#### Reporting the findings for Postivie Affect and Perceived Stress adhering to APA guidelines
```
The relationship between Total Positive Affect and Total Perceived stress was investigated using a Pearson correlation. A statitically significant moderate negative correlation was found  (r(431)=-0.44, p< 0.001).

```



## 2. Investigate the relationship between Total Life Satisfaction (independent variable) and Total Perceived Control of Internal States (dependent variable)
### Tlifesat Total Life satisfaction
```{r}

#We will allocate the histogram to a variable to allow use to manipulate it
gg <- ggplot(survey, aes(x=tlifesat))

#Change the label of the x axis
gg <- gg + labs(x="Total Life Satisfaction")

#manage binwidth and colours
gg <- gg + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gg <- gg + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")

#adding a normal curve
#use stat_function to compute a normalised score for each value of tlifesat
#pass the mean and standard deviation
#use the na.rm parameter to say how missing values are handled
gg <- gg + stat_function(fun=dnorm, color="red",args=list(mean=mean(survey$tlifesat, na.rm=TRUE), sd=sd(survey$tlifesat, na.rm=TRUE)))

#to display the graph request the contents of the variable be shown
gg
```
### tlifesat Generate Q-Q Plot
```{r}
#Create a qqplot
qqnorm(survey$tlifesat)
qqline(survey$tlifesat, col=2) #show a line on theplot
```


### tlifesat Generate Summary Statistics 
```{r}


#stat.desc is a function from pastecs - make sure you include the basic switch=F to ensure you don't get scienfitic notation
pastecs::stat.desc(survey$tlifesat, basic=F)

#We can make our decision based on the value of the standardised score for skew and kurtosis
#We divide the skew statistic by the standard error to get the standardised score
#This will indicate if we have a problem
tpskew<-semTools::skew(survey$tlifesat)
tpkurt<-semTools::kurtosis(survey$tlifesat)
tpskew[1]/tpskew[2]
tpkurt[1]/tpkurt[2]

#and by calculating the percentage of standardised scores for the variable itself that are outside our acceptable range
#This will tell us how big a problem we have
# Calculate the percentage of standardised scores that are greated than 1.96
# the perc function which is part of the FSA package which calculate the percentage that are within a range - you can look for greater than "gt", greater than or equal "geq", "gt", less than or equal "leq",  or less than "lt"),
# scale is a function that creates z scores, abs gets absolute value

zlifesat<- abs(scale(survey$tlifesat))

FSA::perc(as.numeric(zlifesat), 1.96, "gt")
FSA::perc(as.numeric(zlifesat), 3.29, "gt")
```
### TPCOISS Generate histogram
```{r}

#We will allocate the histogram to a variable to allow use to manipulate it
gg <- ggplot(survey, aes(x=tpcoiss))

#Change the label of the x axis
gg <- gg + labs(x="Feeling of Control")

#manage binwidth and colours
gg <- gg + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gg <- gg + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")

#adding a normal curve
#use stat_function to compute a normalised score for each value of tpcoiss
#pass the mean and standard deviation
#use the na.rm parameter to say how missing values are handled
gg <- gg + stat_function(fun=dnorm, color="red",args=list(mean=mean(survey$tpcoiss, na.rm=TRUE), sd=sd(survey$tpcoiss, na.rm=TRUE)))

#to display the graph request the contents of the variable be shown
gg
```
### TPCOISS Generate Q-Q Plot
```{r}
#Create a qqplot
qqnorm(survey$tpcoiss)
qqline(survey$tpcoiss, col=2) #show a line on theplot
```


### TPCOISS Generate Summary Statistics 
```{r}
#stat.desc is a function from pastecs - make sure you include the basic switch=F to ensure you don't get scienfitic notation
pastecs::stat.desc(survey$tpcoiss, basic=F)

#We can make our decision based on the value of the standardised score for skew and kurtosis
#We divide the skew statistic by the standard error to get the standardised score
#This will indicate if we have a problem
tpskew<-semTools::skew(survey$tpcoiss)
tpkurt<-semTools::kurtosis(survey$tpcoiss)
tpskew[1]/tpskew[2]
tpkurt[1]/tpkurt[2]

#and by calculating the percentage of standardised scores for the variable itself that are outside our acceptable range
#This will tell us how big a problem we have
# Calculate the percentage of standardised scores that are greated than 1.96
# the perc function which is part of the FSA package which calculate the percentage that are within a range - you can look for greater than "gt", greater than or equal "geq", "gt", less than or equal "leq",  or less than "lt"),
# scale is a function that creates z scores, abs gets absolute value

ztpcoiss<- abs(scale(survey$tpcoiss))

FSA::perc(as.numeric(ztpcoiss), 1.96, "gt")
FSA::perc(as.numeric(ztpcoiss), 3.29, "gt")

```
### Correlation
#### Scatterplot
```{r}

#Simple scatterplot of life satisfaction and perceived control
#aes(x,y)
scatter <- ggplot(survey, aes(tlifesat, tpcoiss))

#Add a regression line
scatter + geom_point() + geom_smooth(method = "lm", colour = "Red", se = F) + labs(x = "Total Life Satistifaction", y = "Total Perceived Control") 
```


#### Conducting Correlation Test- Life Satistifaction and Perceived Control - Pearson
 
```{r}
#As both variables can be considered approximately normal use Pearson
#Pearson Correlation
stats::cor.test(survey$tlifesat, survey$tpcoiss, method='pearson')
#Moderate positive correlation which is statistically significant (r=0.37, n=427, p< 0.001)
```
#### Reporting the findings for Total Life Satisfaction and Perceived Control adhering to APA guidelines
```
The relationship between Total Life Satisfaction and Total Perceived Control was investigated using a Pearson correlation. A statitically significant moderate positive  correlation was found  (r(427)=0.37, p< 0.001).

```

### 3.	Relationship between Total Mastery and Total Optimism (dependent variable)
### Tmast histogram
```{r}

#We will allocate the histogram to a variable to allow use to manipulate it
gg <- ggplot(survey, aes(x=tmast))

#Change the label of the x axis
gg <- gg + labs(x="Total Mastery")

#manage binwidth and colours
gg <- gg + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gg <- gg + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")

#adding a normal curve
#use stat_function to compute a normalised score for each value of tlifesat
#pass the mean and standard deviation
#use the na.rm parameter to say how missing values are handled
gg <- gg + stat_function(fun=dnorm, color="red",args=list(mean=mean(survey$tmast, na.rm=TRUE), sd=sd(survey$tmast, na.rm=TRUE)))

#to display the graph request the contents of the variable be shown
gg
```
### tmast Generate Q-Q Plot
```{r}
#Create a qqplot
qqnorm(survey$tmast)
qqline(survey$tmast, col=2) #show a line on theplot
```


### tmast Generate Summary Statistics 
```{r}


#stat.desc is a function from pastecs - make sure you include the basic switch=F to ensure you don't get scienfitic notation
pastecs::stat.desc(survey$tmast, basic=F)

#We can make our decision based on the value of the standardised score for skew and kurtosis
#We divide the skew statistic by the standard error to get the standardised score
#This will indicate if we have a problem
tpskew<-semTools::skew(survey$tmast)
tpkurt<-semTools::kurtosis(survey$tmast)
tpskew[1]/tpskew[2]
tpkurt[1]/tpkurt[2]

#and by calculating the percentage of standardised scores for the variable itself that are outside our acceptable range
#This will tell us how big a problem we have
# Calculate the percentage of standardised scores that are greated than 1.96
# the perc function which is part of the FSA package which calculate the percentage that are within a range - you can look for greater than "gt", greater than or equal "geq", "gt", less than or equal "leq",  or less than "lt"),
# scale is a function that creates z scores, abs gets absolute value

ztmast<- abs(scale(survey$tmast))

FSA::perc(as.numeric(ztmast), 1.96, "gt")
FSA::perc(as.numeric(ztmast), 3.29, "gt")
```
### TOPTIM Generate histogram
```{r}

#We will allocate the histogram to a variable to allow use to manipulate it
gg <- ggplot(survey, aes(x=toptim))

#Change the label of the x axis
gg <- gg + labs(x="Total Optimism")

#manage binwidth and colours
gg <- gg + geom_histogram(binwidth=2, colour="black", aes(y=..density.., fill=..count..))
gg <- gg + scale_fill_gradient("Count", low="#DCDCDC", high="#7C7C7C")

#adding a normal curve
#use stat_function to compute a normalised score for each value of tpcoiss
#pass the mean and standard deviation
#use the na.rm parameter to say how missing values are handled
gg <- gg + stat_function(fun=dnorm, color="red",args=list(mean=mean(survey$toptim, na.rm=TRUE), sd=sd(survey$toptim, na.rm=TRUE)))

#to display the graph request the contents of the variable be shown
gg
```
### TOPTIM Generate Q-Q Plot
```{r}
#Create a qqplot
qqnorm(survey$toptim)
qqline(survey$toptim, col=2) #show a line on theplot
```


### TOPTIM Generate Summary Statistics 
```{r}

#stat.desc is a function from pastecs - make sure you include the basic switch=F to ensure you don't get scienfitic notation
pastecs::stat.desc(survey$toptim, basic=F)

#We can make our decision based on the value of the standardised score for skew and kurtosis
#We divide the skew statistic by the standard error to get the standardised score
#This will indicate if we have a problem
tpskew<-semTools::skew(survey$toptim)
tpkurt<-semTools::kurtosis(survey$toptim)
tpskew[1]/tpskew[2]
tpkurt[1]/tpkurt[2]

#and by calculating the percentage of standardised scores for the variable itself that are outside our acceptable range
#This will tell us how big a problem we have
# Calculate the percentage of standardised scores that are greated than 1.96
# the perc function which is part of the FSA package which calculate the percentage that are within a range - you can look for greater than "gt", greater than or equal "geq", "gt", less than or equal "leq",  or less than "lt"),
# scale is a function that creates z scores, abs gets absolute value

ztoptim<- abs(scale(survey$toptim))

FSA::perc(as.numeric(ztoptim), 1.96, "gt")
FSA::perc(as.numeric(ztoptim), 3.29, "gt")
```
### Correlation
#### Scatterplot
```{r}

#Simple scatterplot of total mastery and total optimism
#aes(x,y)
scatter <- ggplot(survey, aes(tmast, toptim))

#Add a regression line
scatter + geom_point() + geom_smooth(method = "lm", colour = "Red", se = F) + labs(x = "Total Mastery", y = "Total Optimism") 
```

#### Conducting Correlation Mastery and Total Optimism - Pearson
 
```{r}
#As both variables can be considered approximately normal use Pearson
#Pearson Correlation
stats::cor.test(survey$tmast, survey$toptim, method='pearson')
#Strong positive correlation which is statistically significant (r=0.55, n=433, p< 0.001)
```

#### Reporting the findings for Total Mastery and Total Optimism adhering to APA guidelines
```
The relationship between Total Mastery and Total Optimism was investigated using a Pearson correlation. A statitically significant strong positive correlation was found  (r(433)=0.55, p< 0.001).

```