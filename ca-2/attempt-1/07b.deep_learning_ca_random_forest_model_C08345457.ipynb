{"cells":[{"cell_type":"markdown","metadata":{"id":"etn1qOLMP7lQ"},"source":["#Random Forest Model\n","https://www.tensorflow.org/decision_forests/tutorials/beginner_colab"]},{"cell_type":"code","source":["!pip install tensorflow_decision_forests"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"rOr5cmq8LSoN","executionInfo":{"status":"ok","timestamp":1682770917809,"user_tz":-60,"elapsed":5878,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"outputId":"86ccf118-1076-421a-94d1-b46ac4235112"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow_decision_forests in /usr/local/lib/python3.10/dist-packages (1.3.0)\n","Requirement already satisfied: tensorflow~=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.12.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.4.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.16.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.5.3)\n","Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (3.0.3)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (0.40.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.22.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (23.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (3.8.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (3.3.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (16.0.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (2.12.2)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (2.12.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (1.6.3)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (1.14.1)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (0.4.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (0.32.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (4.5.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (23.3.3)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (0.4.8)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (2.3.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (1.54.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (67.7.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (3.20.3)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tensorflow_decision_forests) (2.12.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n","Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.12.0->tensorflow_decision_forests) (0.1.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.12.0->tensorflow_decision_forests) (1.10.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (3.4.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (1.0.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (2.17.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (0.7.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (2.27.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (2.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (4.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (0.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (1.3.1)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (2022.12.7)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tensorflow_decision_forests) (3.2.2)\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"NeE3T42UtGwX","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1682770919151,"user_tz":-60,"elapsed":1346,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"outputId":"928524cf-c09f-4a8d-f9f6-346fd904f526"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#get data from google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"U4oHTCgSsyM4","executionInfo":{"status":"ok","timestamp":1682770925763,"user_tz":-60,"elapsed":6615,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}}},"outputs":[],"source":["# Libraries\n","import pandas as pd\n","import numpy as np\n","from collections import Counter\n","\n","# load numpy array from csv file\n","from numpy import loadtxt\n","\n","#plotting performance\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import tensorflow_decision_forests as tfdf"]},{"cell_type":"markdown","source":["## Load prepared dataset"],"metadata":{"id":"edmpW6keGxIY"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"0lFT9ZRFtBn-","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1682770929701,"user_tz":-60,"elapsed":3952,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"outputId":"a3ce2daf-f0bb-4503-a05c-cee824237b1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[2.5500e+02 1.2175e+04 4.5290e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n"," [9.5500e+02 4.6240e+03 2.0400e+02 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n"," [1.0710e+03 2.2600e+02 3.8400e+02 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n"," ...\n"," [4.8200e+02 1.5190e+03 2.3740e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n"," [1.0380e+04 4.2600e+02 3.6280e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n"," [1.0000e+00 5.5100e+02 5.6530e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]]\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n"]}],"source":["# load array\n","X = loadtxt('/content/drive/MyDrive/data/X.csv', delimiter=',')\n","y = loadtxt('/content/drive/MyDrive/data/y.csv', delimiter=',')\n","\n","# print the array\n","print(X)\n","print(y)"]},{"cell_type":"code","source":["X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"B2nGzqNJdHbV","executionInfo":{"status":"ok","timestamp":1682770929701,"user_tz":-60,"elapsed":22,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"outputId":"970d55b9-e421-450d-8675-7eddca9a835e"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(14972, 255)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"mh6pOfw3dKYc","executionInfo":{"status":"ok","timestamp":1682770929701,"user_tz":-60,"elapsed":18,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"outputId":"5eee2579-d1eb-4087-ab71-d07bf8066093"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(14972, 76)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["y = np.argmax(y, axis=1)"],"metadata":{"id":"SRfxJ3oceQ0g","executionInfo":{"status":"ok","timestamp":1682770929702,"user_tz":-60,"elapsed":17,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"ii-AsXqcfYqh","executionInfo":{"status":"ok","timestamp":1682770929702,"user_tz":-60,"elapsed":17,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"outputId":"ba3e64d4-5c3a-4fc5-f05f-c7990953f08a"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([16, 10, 20, ..., 26, 20,  8])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"ymqKWPT2fT_m","executionInfo":{"status":"ok","timestamp":1682770929703,"user_tz":-60,"elapsed":16,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"outputId":"0a56f297-6da3-4d05-a9a8-57946692e144"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(14972,)"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"hMcR_HIyPOd4"},"source":["## Split sample into 80% training, 10% test & 10% validation datasets\n","Next, 10% of the data was split off for testting, 10% for validation and the remaining 80% was used as for training data."]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","#first split data for training and test data (90:10)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n","\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1111, random_state=42)\n","\n","print(\"Training data shape:\", X_train.shape)\n","print(\"Training labels shape:\", y_train.shape)\n","print(\"Validation data shape:\", X_val.shape)\n","print(\"Validation labels shape:\", y_val.shape)\n","print(\"Test data shape:\", X_test.shape)\n","print(\"Test labels shape:\", y_test.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"alKlCzAyRHJ_","executionInfo":{"status":"ok","timestamp":1682770929977,"user_tz":-60,"elapsed":288,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"outputId":"02b60125-325e-42d4-c646-99e09a65ea8b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Training data shape: (11977, 255)\n","Training labels shape: (11977,)\n","Validation data shape: (1497, 255)\n","Validation labels shape: (1497,)\n","Test data shape: (1498, 255)\n","Test labels shape: (1498,)\n"]}]},{"cell_type":"markdown","source":["## Random Forest  Model"],"metadata":{"id":"j7zx4gspg88x"}},{"cell_type":"code","source":["train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n","val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n","test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"],"metadata":{"id":"_SLCAoaqz-19","executionInfo":{"status":"ok","timestamp":1682770931978,"user_tz":-60,"elapsed":155,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["train_dataset = train_dataset.batch(100)"],"metadata":{"id":"TCZpCjDU5cyl","executionInfo":{"status":"ok","timestamp":1682770932283,"user_tz":-60,"elapsed":308,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["val_dataset = val_dataset.batch(100)"],"metadata":{"id":"jIW8OZ9A9cLZ","executionInfo":{"status":"ok","timestamp":1682770932284,"user_tz":-60,"elapsed":11,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["test_dataset = test_dataset.batch(100)"],"metadata":{"id":"tVN6Axm878oV","executionInfo":{"status":"ok","timestamp":1682770932284,"user_tz":-60,"elapsed":11,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["rf_model = tfdf.keras.RandomForestModel(verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"rQ04n6yHgII3","executionInfo":{"status":"ok","timestamp":1682770932284,"user_tz":-60,"elapsed":10,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"outputId":"9a993236-5183-48ac-8e1f-5ef04529465c"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Use 2 thread(s) for training\n","Use /tmp/tmpoarv9dfo as temporary training directory\n"]}]},{"cell_type":"code","source":["# Train the model.\n","rf_history = rf_model.fit(train_dataset, validation_data=val_dataset)"],"metadata":{"id":"VUQjnrbKMEQ-","executionInfo":{"status":"ok","timestamp":1682771329831,"user_tz":-60,"elapsed":397552,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"e7f07981-76b6-4d7a-be7b-c43996d643d7"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading training dataset...\n","Training tensor examples:\n","Features: Tensor(\"data:0\", shape=(None, 255), dtype=float64)\n","Label: Tensor(\"data_1:0\", shape=(None,), dtype=int64)\n","Weights: None\n","Normalized tensor features:\n"," {'data:0.0': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice:0' shape=(None,) dtype=float32>), 'data:0.1': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_1:0' shape=(None,) dtype=float32>), 'data:0.2': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_2:0' shape=(None,) dtype=float32>), 'data:0.3': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_3:0' shape=(None,) dtype=float32>), 'data:0.4': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_4:0' shape=(None,) dtype=float32>), 'data:0.5': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_5:0' shape=(None,) dtype=float32>), 'data:0.6': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_6:0' shape=(None,) dtype=float32>), 'data:0.7': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_7:0' shape=(None,) dtype=float32>), 'data:0.8': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_8:0' shape=(None,) dtype=float32>), 'data:0.9': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_9:0' shape=(None,) dtype=float32>), 'data:0.10': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_10:0' shape=(None,) dtype=float32>), 'data:0.11': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_11:0' shape=(None,) dtype=float32>), 'data:0.12': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_12:0' shape=(None,) dtype=float32>), 'data:0.13': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_13:0' shape=(None,) dtype=float32>), 'data:0.14': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_14:0' shape=(None,) dtype=float32>), 'data:0.15': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_15:0' shape=(None,) dtype=float32>), 'data:0.16': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_16:0' shape=(None,) dtype=float32>), 'data:0.17': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_17:0' shape=(None,) dtype=float32>), 'data:0.18': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_18:0' shape=(None,) dtype=float32>), 'data:0.19': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_19:0' shape=(None,) dtype=float32>), 'data:0.20': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_20:0' shape=(None,) dtype=float32>), 'data:0.21': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_21:0' shape=(None,) dtype=float32>), 'data:0.22': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_22:0' shape=(None,) dtype=float32>), 'data:0.23': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_23:0' shape=(None,) dtype=float32>), 'data:0.24': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_24:0' shape=(None,) dtype=float32>), 'data:0.25': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_25:0' shape=(None,) dtype=float32>), 'data:0.26': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_26:0' shape=(None,) dtype=float32>), 'data:0.27': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_27:0' shape=(None,) dtype=float32>), 'data:0.28': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_28:0' shape=(None,) dtype=float32>), 'data:0.29': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_29:0' shape=(None,) dtype=float32>), 'data:0.30': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_30:0' shape=(None,) dtype=float32>), 'data:0.31': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_31:0' shape=(None,) dtype=float32>), 'data:0.32': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_32:0' shape=(None,) dtype=float32>), 'data:0.33': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_33:0' shape=(None,) dtype=float32>), 'data:0.34': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_34:0' shape=(None,) dtype=float32>), 'data:0.35': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_35:0' shape=(None,) dtype=float32>), 'data:0.36': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_36:0' shape=(None,) dtype=float32>), 'data:0.37': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_37:0' shape=(None,) dtype=float32>), 'data:0.38': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_38:0' shape=(None,) dtype=float32>), 'data:0.39': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_39:0' shape=(None,) dtype=float32>), 'data:0.40': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_40:0' shape=(None,) dtype=float32>), 'data:0.41': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_41:0' shape=(None,) dtype=float32>), 'data:0.42': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_42:0' shape=(None,) dtype=float32>), 'data:0.43': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_43:0' shape=(None,) dtype=float32>), 'data:0.44': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_44:0' shape=(None,) dtype=float32>), 'data:0.45': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_45:0' shape=(None,) dtype=float32>), 'data:0.46': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_46:0' shape=(None,) dtype=float32>), 'data:0.47': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_47:0' shape=(None,) dtype=float32>), 'data:0.48': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_48:0' shape=(None,) dtype=float32>), 'data:0.49': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_49:0' shape=(None,) dtype=float32>), 'data:0.50': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_50:0' shape=(None,) dtype=float32>), 'data:0.51': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_51:0' shape=(None,) dtype=float32>), 'data:0.52': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_52:0' shape=(None,) dtype=float32>), 'data:0.53': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_53:0' shape=(None,) dtype=float32>), 'data:0.54': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_54:0' shape=(None,) dtype=float32>), 'data:0.55': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_55:0' shape=(None,) dtype=float32>), 'data:0.56': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_56:0' shape=(None,) dtype=float32>), 'data:0.57': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_57:0' shape=(None,) dtype=float32>), 'data:0.58': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_58:0' shape=(None,) dtype=float32>), 'data:0.59': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_59:0' shape=(None,) dtype=float32>), 'data:0.60': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_60:0' shape=(None,) dtype=float32>), 'data:0.61': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_61:0' shape=(None,) dtype=float32>), 'data:0.62': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_62:0' shape=(None,) dtype=float32>), 'data:0.63': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_63:0' shape=(None,) dtype=float32>), 'data:0.64': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_64:0' shape=(None,) dtype=float32>), 'data:0.65': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_65:0' shape=(None,) dtype=float32>), 'data:0.66': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_66:0' shape=(None,) dtype=float32>), 'data:0.67': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_67:0' shape=(None,) dtype=float32>), 'data:0.68': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_68:0' shape=(None,) dtype=float32>), 'data:0.69': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_69:0' shape=(None,) dtype=float32>), 'data:0.70': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_70:0' shape=(None,) dtype=float32>), 'data:0.71': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_71:0' shape=(None,) dtype=float32>), 'data:0.72': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_72:0' shape=(None,) dtype=float32>), 'data:0.73': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_73:0' shape=(None,) dtype=float32>), 'data:0.74': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_74:0' shape=(None,) dtype=float32>), 'data:0.75': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_75:0' shape=(None,) dtype=float32>), 'data:0.76': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_76:0' shape=(None,) dtype=float32>), 'data:0.77': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_77:0' shape=(None,) dtype=float32>), 'data:0.78': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_78:0' shape=(None,) dtype=float32>), 'data:0.79': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_79:0' shape=(None,) dtype=float32>), 'data:0.80': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_80:0' shape=(None,) dtype=float32>), 'data:0.81': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_81:0' shape=(None,) dtype=float32>), 'data:0.82': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_82:0' shape=(None,) dtype=float32>), 'data:0.83': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_83:0' shape=(None,) dtype=float32>), 'data:0.84': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_84:0' shape=(None,) dtype=float32>), 'data:0.85': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_85:0' shape=(None,) dtype=float32>), 'data:0.86': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_86:0' shape=(None,) dtype=float32>), 'data:0.87': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_87:0' shape=(None,) dtype=float32>), 'data:0.88': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_88:0' shape=(None,) dtype=float32>), 'data:0.89': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_89:0' shape=(None,) dtype=float32>), 'data:0.90': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_90:0' shape=(None,) dtype=float32>), 'data:0.91': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_91:0' shape=(None,) dtype=float32>), 'data:0.92': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_92:0' shape=(None,) dtype=float32>), 'data:0.93': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_93:0' shape=(None,) dtype=float32>), 'data:0.94': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_94:0' shape=(None,) dtype=float32>), 'data:0.95': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_95:0' shape=(None,) dtype=float32>), 'data:0.96': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_96:0' shape=(None,) dtype=float32>), 'data:0.97': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_97:0' shape=(None,) dtype=float32>), 'data:0.98': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_98:0' shape=(None,) dtype=float32>), 'data:0.99': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_99:0' shape=(None,) dtype=float32>), 'data:0.100': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_100:0' shape=(None,) dtype=float32>), 'data:0.101': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_101:0' shape=(None,) dtype=float32>), 'data:0.102': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_102:0' shape=(None,) dtype=float32>), 'data:0.103': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_103:0' shape=(None,) dtype=float32>), 'data:0.104': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_104:0' shape=(None,) dtype=float32>), 'data:0.105': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_105:0' shape=(None,) dtype=float32>), 'data:0.106': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_106:0' shape=(None,) dtype=float32>), 'data:0.107': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_107:0' shape=(None,) dtype=float32>), 'data:0.108': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_108:0' shape=(None,) dtype=float32>), 'data:0.109': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_109:0' shape=(None,) dtype=float32>), 'data:0.110': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_110:0' shape=(None,) dtype=float32>), 'data:0.111': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_111:0' shape=(None,) dtype=float32>), 'data:0.112': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_112:0' shape=(None,) dtype=float32>), 'data:0.113': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_113:0' shape=(None,) dtype=float32>), 'data:0.114': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_114:0' shape=(None,) dtype=float32>), 'data:0.115': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_115:0' shape=(None,) dtype=float32>), 'data:0.116': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_116:0' shape=(None,) dtype=float32>), 'data:0.117': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_117:0' shape=(None,) dtype=float32>), 'data:0.118': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_118:0' shape=(None,) dtype=float32>), 'data:0.119': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_119:0' shape=(None,) dtype=float32>), 'data:0.120': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_120:0' shape=(None,) dtype=float32>), 'data:0.121': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_121:0' shape=(None,) dtype=float32>), 'data:0.122': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_122:0' shape=(None,) dtype=float32>), 'data:0.123': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_123:0' shape=(None,) dtype=float32>), 'data:0.124': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_124:0' shape=(None,) dtype=float32>), 'data:0.125': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_125:0' shape=(None,) dtype=float32>), 'data:0.126': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_126:0' shape=(None,) dtype=float32>), 'data:0.127': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_127:0' shape=(None,) dtype=float32>), 'data:0.128': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_128:0' shape=(None,) dtype=float32>), 'data:0.129': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_129:0' shape=(None,) dtype=float32>), 'data:0.130': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_130:0' shape=(None,) dtype=float32>), 'data:0.131': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_131:0' shape=(None,) dtype=float32>), 'data:0.132': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_132:0' shape=(None,) dtype=float32>), 'data:0.133': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_133:0' shape=(None,) dtype=float32>), 'data:0.134': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_134:0' shape=(None,) dtype=float32>), 'data:0.135': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_135:0' shape=(None,) dtype=float32>), 'data:0.136': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_136:0' shape=(None,) dtype=float32>), 'data:0.137': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_137:0' shape=(None,) dtype=float32>), 'data:0.138': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_138:0' shape=(None,) dtype=float32>), 'data:0.139': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_139:0' shape=(None,) dtype=float32>), 'data:0.140': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_140:0' shape=(None,) dtype=float32>), 'data:0.141': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_141:0' shape=(None,) dtype=float32>), 'data:0.142': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_142:0' shape=(None,) dtype=float32>), 'data:0.143': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_143:0' shape=(None,) dtype=float32>), 'data:0.144': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_144:0' shape=(None,) dtype=float32>), 'data:0.145': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_145:0' shape=(None,) dtype=float32>), 'data:0.146': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_146:0' shape=(None,) dtype=float32>), 'data:0.147': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_147:0' shape=(None,) dtype=float32>), 'data:0.148': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_148:0' shape=(None,) dtype=float32>), 'data:0.149': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_149:0' shape=(None,) dtype=float32>), 'data:0.150': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_150:0' shape=(None,) dtype=float32>), 'data:0.151': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_151:0' shape=(None,) dtype=float32>), 'data:0.152': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_152:0' shape=(None,) dtype=float32>), 'data:0.153': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_153:0' shape=(None,) dtype=float32>), 'data:0.154': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_154:0' shape=(None,) dtype=float32>), 'data:0.155': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_155:0' shape=(None,) dtype=float32>), 'data:0.156': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_156:0' shape=(None,) dtype=float32>), 'data:0.157': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_157:0' shape=(None,) dtype=float32>), 'data:0.158': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_158:0' shape=(None,) dtype=float32>), 'data:0.159': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_159:0' shape=(None,) dtype=float32>), 'data:0.160': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_160:0' shape=(None,) dtype=float32>), 'data:0.161': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_161:0' shape=(None,) dtype=float32>), 'data:0.162': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_162:0' shape=(None,) dtype=float32>), 'data:0.163': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_163:0' shape=(None,) dtype=float32>), 'data:0.164': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_164:0' shape=(None,) dtype=float32>), 'data:0.165': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_165:0' shape=(None,) dtype=float32>), 'data:0.166': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_166:0' shape=(None,) dtype=float32>), 'data:0.167': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_167:0' shape=(None,) dtype=float32>), 'data:0.168': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_168:0' shape=(None,) dtype=float32>), 'data:0.169': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_169:0' shape=(None,) dtype=float32>), 'data:0.170': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_170:0' shape=(None,) dtype=float32>), 'data:0.171': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_171:0' shape=(None,) dtype=float32>), 'data:0.172': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_172:0' shape=(None,) dtype=float32>), 'data:0.173': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_173:0' shape=(None,) dtype=float32>), 'data:0.174': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_174:0' shape=(None,) dtype=float32>), 'data:0.175': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_175:0' shape=(None,) dtype=float32>), 'data:0.176': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_176:0' shape=(None,) dtype=float32>), 'data:0.177': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_177:0' shape=(None,) dtype=float32>), 'data:0.178': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_178:0' shape=(None,) dtype=float32>), 'data:0.179': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_179:0' shape=(None,) dtype=float32>), 'data:0.180': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_180:0' shape=(None,) dtype=float32>), 'data:0.181': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_181:0' shape=(None,) dtype=float32>), 'data:0.182': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_182:0' shape=(None,) dtype=float32>), 'data:0.183': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_183:0' shape=(None,) dtype=float32>), 'data:0.184': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_184:0' shape=(None,) dtype=float32>), 'data:0.185': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_185:0' shape=(None,) dtype=float32>), 'data:0.186': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_186:0' shape=(None,) dtype=float32>), 'data:0.187': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_187:0' shape=(None,) dtype=float32>), 'data:0.188': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_188:0' shape=(None,) dtype=float32>), 'data:0.189': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_189:0' shape=(None,) dtype=float32>), 'data:0.190': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_190:0' shape=(None,) dtype=float32>), 'data:0.191': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_191:0' shape=(None,) dtype=float32>), 'data:0.192': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_192:0' shape=(None,) dtype=float32>), 'data:0.193': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_193:0' shape=(None,) dtype=float32>), 'data:0.194': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_194:0' shape=(None,) dtype=float32>), 'data:0.195': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_195:0' shape=(None,) dtype=float32>), 'data:0.196': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_196:0' shape=(None,) dtype=float32>), 'data:0.197': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_197:0' shape=(None,) dtype=float32>), 'data:0.198': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_198:0' shape=(None,) dtype=float32>), 'data:0.199': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_199:0' shape=(None,) dtype=float32>), 'data:0.200': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_200:0' shape=(None,) dtype=float32>), 'data:0.201': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_201:0' shape=(None,) dtype=float32>), 'data:0.202': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_202:0' shape=(None,) dtype=float32>), 'data:0.203': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_203:0' shape=(None,) dtype=float32>), 'data:0.204': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_204:0' shape=(None,) dtype=float32>), 'data:0.205': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_205:0' shape=(None,) dtype=float32>), 'data:0.206': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_206:0' shape=(None,) dtype=float32>), 'data:0.207': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_207:0' shape=(None,) dtype=float32>), 'data:0.208': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_208:0' shape=(None,) dtype=float32>), 'data:0.209': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_209:0' shape=(None,) dtype=float32>), 'data:0.210': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_210:0' shape=(None,) dtype=float32>), 'data:0.211': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_211:0' shape=(None,) dtype=float32>), 'data:0.212': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_212:0' shape=(None,) dtype=float32>), 'data:0.213': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_213:0' shape=(None,) dtype=float32>), 'data:0.214': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_214:0' shape=(None,) dtype=float32>), 'data:0.215': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_215:0' shape=(None,) dtype=float32>), 'data:0.216': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_216:0' shape=(None,) dtype=float32>), 'data:0.217': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_217:0' shape=(None,) dtype=float32>), 'data:0.218': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_218:0' shape=(None,) dtype=float32>), 'data:0.219': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_219:0' shape=(None,) dtype=float32>), 'data:0.220': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_220:0' shape=(None,) dtype=float32>), 'data:0.221': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_221:0' shape=(None,) dtype=float32>), 'data:0.222': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_222:0' shape=(None,) dtype=float32>), 'data:0.223': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_223:0' shape=(None,) dtype=float32>), 'data:0.224': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_224:0' shape=(None,) dtype=float32>), 'data:0.225': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_225:0' shape=(None,) dtype=float32>), 'data:0.226': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_226:0' shape=(None,) dtype=float32>), 'data:0.227': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_227:0' shape=(None,) dtype=float32>), 'data:0.228': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_228:0' shape=(None,) dtype=float32>), 'data:0.229': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_229:0' shape=(None,) dtype=float32>), 'data:0.230': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_230:0' shape=(None,) dtype=float32>), 'data:0.231': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_231:0' shape=(None,) dtype=float32>), 'data:0.232': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_232:0' shape=(None,) dtype=float32>), 'data:0.233': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_233:0' shape=(None,) dtype=float32>), 'data:0.234': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_234:0' shape=(None,) dtype=float32>), 'data:0.235': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_235:0' shape=(None,) dtype=float32>), 'data:0.236': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_236:0' shape=(None,) dtype=float32>), 'data:0.237': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_237:0' shape=(None,) dtype=float32>), 'data:0.238': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_238:0' shape=(None,) dtype=float32>), 'data:0.239': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_239:0' shape=(None,) dtype=float32>), 'data:0.240': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_240:0' shape=(None,) dtype=float32>), 'data:0.241': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_241:0' shape=(None,) dtype=float32>), 'data:0.242': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_242:0' shape=(None,) dtype=float32>), 'data:0.243': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_243:0' shape=(None,) dtype=float32>), 'data:0.244': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_244:0' shape=(None,) dtype=float32>), 'data:0.245': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_245:0' shape=(None,) dtype=float32>), 'data:0.246': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_246:0' shape=(None,) dtype=float32>), 'data:0.247': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_247:0' shape=(None,) dtype=float32>), 'data:0.248': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_248:0' shape=(None,) dtype=float32>), 'data:0.249': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_249:0' shape=(None,) dtype=float32>), 'data:0.250': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_250:0' shape=(None,) dtype=float32>), 'data:0.251': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_251:0' shape=(None,) dtype=float32>), 'data:0.252': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_252:0' shape=(None,) dtype=float32>), 'data:0.253': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_253:0' shape=(None,) dtype=float32>), 'data:0.254': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_254:0' shape=(None,) dtype=float32>)}\n","Training dataset read in 0:00:13.102483. Found 11977 examples.\n","Reading validation dataset...\n","Validation tensor examples:\n","Features: Tensor(\"data:0\", shape=(None, 255), dtype=float64)\n","Label: Tensor(\"data_1:0\", shape=(None,), dtype=int64)\n","Weights: None\n","Normalized tensor features:\n"," {'data:0.0': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice:0' shape=(None,) dtype=float32>), 'data:0.1': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_1:0' shape=(None,) dtype=float32>), 'data:0.2': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_2:0' shape=(None,) dtype=float32>), 'data:0.3': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_3:0' shape=(None,) dtype=float32>), 'data:0.4': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_4:0' shape=(None,) dtype=float32>), 'data:0.5': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_5:0' shape=(None,) dtype=float32>), 'data:0.6': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_6:0' shape=(None,) dtype=float32>), 'data:0.7': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_7:0' shape=(None,) dtype=float32>), 'data:0.8': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_8:0' shape=(None,) dtype=float32>), 'data:0.9': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_9:0' shape=(None,) dtype=float32>), 'data:0.10': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_10:0' shape=(None,) dtype=float32>), 'data:0.11': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_11:0' shape=(None,) dtype=float32>), 'data:0.12': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_12:0' shape=(None,) dtype=float32>), 'data:0.13': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_13:0' shape=(None,) dtype=float32>), 'data:0.14': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_14:0' shape=(None,) dtype=float32>), 'data:0.15': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_15:0' shape=(None,) dtype=float32>), 'data:0.16': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_16:0' shape=(None,) dtype=float32>), 'data:0.17': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_17:0' shape=(None,) dtype=float32>), 'data:0.18': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_18:0' shape=(None,) dtype=float32>), 'data:0.19': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_19:0' shape=(None,) dtype=float32>), 'data:0.20': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_20:0' shape=(None,) dtype=float32>), 'data:0.21': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_21:0' shape=(None,) dtype=float32>), 'data:0.22': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_22:0' shape=(None,) dtype=float32>), 'data:0.23': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_23:0' shape=(None,) dtype=float32>), 'data:0.24': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_24:0' shape=(None,) dtype=float32>), 'data:0.25': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_25:0' shape=(None,) dtype=float32>), 'data:0.26': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_26:0' shape=(None,) dtype=float32>), 'data:0.27': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_27:0' shape=(None,) dtype=float32>), 'data:0.28': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_28:0' shape=(None,) dtype=float32>), 'data:0.29': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_29:0' shape=(None,) dtype=float32>), 'data:0.30': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_30:0' shape=(None,) dtype=float32>), 'data:0.31': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_31:0' shape=(None,) dtype=float32>), 'data:0.32': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_32:0' shape=(None,) dtype=float32>), 'data:0.33': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_33:0' shape=(None,) dtype=float32>), 'data:0.34': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_34:0' shape=(None,) dtype=float32>), 'data:0.35': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_35:0' shape=(None,) dtype=float32>), 'data:0.36': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_36:0' shape=(None,) dtype=float32>), 'data:0.37': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_37:0' shape=(None,) dtype=float32>), 'data:0.38': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_38:0' shape=(None,) dtype=float32>), 'data:0.39': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_39:0' shape=(None,) dtype=float32>), 'data:0.40': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_40:0' shape=(None,) dtype=float32>), 'data:0.41': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_41:0' shape=(None,) dtype=float32>), 'data:0.42': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_42:0' shape=(None,) dtype=float32>), 'data:0.43': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_43:0' shape=(None,) dtype=float32>), 'data:0.44': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_44:0' shape=(None,) dtype=float32>), 'data:0.45': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_45:0' shape=(None,) dtype=float32>), 'data:0.46': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_46:0' shape=(None,) dtype=float32>), 'data:0.47': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_47:0' shape=(None,) dtype=float32>), 'data:0.48': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_48:0' shape=(None,) dtype=float32>), 'data:0.49': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_49:0' shape=(None,) dtype=float32>), 'data:0.50': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_50:0' shape=(None,) dtype=float32>), 'data:0.51': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_51:0' shape=(None,) dtype=float32>), 'data:0.52': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_52:0' shape=(None,) dtype=float32>), 'data:0.53': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_53:0' shape=(None,) dtype=float32>), 'data:0.54': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_54:0' shape=(None,) dtype=float32>), 'data:0.55': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_55:0' shape=(None,) dtype=float32>), 'data:0.56': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_56:0' shape=(None,) dtype=float32>), 'data:0.57': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_57:0' shape=(None,) dtype=float32>), 'data:0.58': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_58:0' shape=(None,) dtype=float32>), 'data:0.59': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_59:0' shape=(None,) dtype=float32>), 'data:0.60': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_60:0' shape=(None,) dtype=float32>), 'data:0.61': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_61:0' shape=(None,) dtype=float32>), 'data:0.62': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_62:0' shape=(None,) dtype=float32>), 'data:0.63': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_63:0' shape=(None,) dtype=float32>), 'data:0.64': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_64:0' shape=(None,) dtype=float32>), 'data:0.65': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_65:0' shape=(None,) dtype=float32>), 'data:0.66': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_66:0' shape=(None,) dtype=float32>), 'data:0.67': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_67:0' shape=(None,) dtype=float32>), 'data:0.68': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_68:0' shape=(None,) dtype=float32>), 'data:0.69': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_69:0' shape=(None,) dtype=float32>), 'data:0.70': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_70:0' shape=(None,) dtype=float32>), 'data:0.71': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_71:0' shape=(None,) dtype=float32>), 'data:0.72': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_72:0' shape=(None,) dtype=float32>), 'data:0.73': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_73:0' shape=(None,) dtype=float32>), 'data:0.74': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_74:0' shape=(None,) dtype=float32>), 'data:0.75': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_75:0' shape=(None,) dtype=float32>), 'data:0.76': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_76:0' shape=(None,) dtype=float32>), 'data:0.77': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_77:0' shape=(None,) dtype=float32>), 'data:0.78': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_78:0' shape=(None,) dtype=float32>), 'data:0.79': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_79:0' shape=(None,) dtype=float32>), 'data:0.80': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_80:0' shape=(None,) dtype=float32>), 'data:0.81': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_81:0' shape=(None,) dtype=float32>), 'data:0.82': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_82:0' shape=(None,) dtype=float32>), 'data:0.83': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_83:0' shape=(None,) dtype=float32>), 'data:0.84': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_84:0' shape=(None,) dtype=float32>), 'data:0.85': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_85:0' shape=(None,) dtype=float32>), 'data:0.86': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_86:0' shape=(None,) dtype=float32>), 'data:0.87': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_87:0' shape=(None,) dtype=float32>), 'data:0.88': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_88:0' shape=(None,) dtype=float32>), 'data:0.89': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_89:0' shape=(None,) dtype=float32>), 'data:0.90': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_90:0' shape=(None,) dtype=float32>), 'data:0.91': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_91:0' shape=(None,) dtype=float32>), 'data:0.92': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_92:0' shape=(None,) dtype=float32>), 'data:0.93': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_93:0' shape=(None,) dtype=float32>), 'data:0.94': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_94:0' shape=(None,) dtype=float32>), 'data:0.95': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_95:0' shape=(None,) dtype=float32>), 'data:0.96': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_96:0' shape=(None,) dtype=float32>), 'data:0.97': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_97:0' shape=(None,) dtype=float32>), 'data:0.98': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_98:0' shape=(None,) dtype=float32>), 'data:0.99': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_99:0' shape=(None,) dtype=float32>), 'data:0.100': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_100:0' shape=(None,) dtype=float32>), 'data:0.101': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_101:0' shape=(None,) dtype=float32>), 'data:0.102': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_102:0' shape=(None,) dtype=float32>), 'data:0.103': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_103:0' shape=(None,) dtype=float32>), 'data:0.104': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_104:0' shape=(None,) dtype=float32>), 'data:0.105': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_105:0' shape=(None,) dtype=float32>), 'data:0.106': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_106:0' shape=(None,) dtype=float32>), 'data:0.107': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_107:0' shape=(None,) dtype=float32>), 'data:0.108': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_108:0' shape=(None,) dtype=float32>), 'data:0.109': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_109:0' shape=(None,) dtype=float32>), 'data:0.110': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_110:0' shape=(None,) dtype=float32>), 'data:0.111': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_111:0' shape=(None,) dtype=float32>), 'data:0.112': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_112:0' shape=(None,) dtype=float32>), 'data:0.113': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_113:0' shape=(None,) dtype=float32>), 'data:0.114': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_114:0' shape=(None,) dtype=float32>), 'data:0.115': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_115:0' shape=(None,) dtype=float32>), 'data:0.116': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_116:0' shape=(None,) dtype=float32>), 'data:0.117': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_117:0' shape=(None,) dtype=float32>), 'data:0.118': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_118:0' shape=(None,) dtype=float32>), 'data:0.119': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_119:0' shape=(None,) dtype=float32>), 'data:0.120': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_120:0' shape=(None,) dtype=float32>), 'data:0.121': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_121:0' shape=(None,) dtype=float32>), 'data:0.122': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_122:0' shape=(None,) dtype=float32>), 'data:0.123': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_123:0' shape=(None,) dtype=float32>), 'data:0.124': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_124:0' shape=(None,) dtype=float32>), 'data:0.125': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_125:0' shape=(None,) dtype=float32>), 'data:0.126': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_126:0' shape=(None,) dtype=float32>), 'data:0.127': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_127:0' shape=(None,) dtype=float32>), 'data:0.128': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_128:0' shape=(None,) dtype=float32>), 'data:0.129': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_129:0' shape=(None,) dtype=float32>), 'data:0.130': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_130:0' shape=(None,) dtype=float32>), 'data:0.131': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_131:0' shape=(None,) dtype=float32>), 'data:0.132': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_132:0' shape=(None,) dtype=float32>), 'data:0.133': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_133:0' shape=(None,) dtype=float32>), 'data:0.134': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_134:0' shape=(None,) dtype=float32>), 'data:0.135': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_135:0' shape=(None,) dtype=float32>), 'data:0.136': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_136:0' shape=(None,) dtype=float32>), 'data:0.137': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_137:0' shape=(None,) dtype=float32>), 'data:0.138': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_138:0' shape=(None,) dtype=float32>), 'data:0.139': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_139:0' shape=(None,) dtype=float32>), 'data:0.140': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_140:0' shape=(None,) dtype=float32>), 'data:0.141': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_141:0' shape=(None,) dtype=float32>), 'data:0.142': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_142:0' shape=(None,) dtype=float32>), 'data:0.143': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_143:0' shape=(None,) dtype=float32>), 'data:0.144': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_144:0' shape=(None,) dtype=float32>), 'data:0.145': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_145:0' shape=(None,) dtype=float32>), 'data:0.146': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_146:0' shape=(None,) dtype=float32>), 'data:0.147': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_147:0' shape=(None,) dtype=float32>), 'data:0.148': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_148:0' shape=(None,) dtype=float32>), 'data:0.149': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_149:0' shape=(None,) dtype=float32>), 'data:0.150': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_150:0' shape=(None,) dtype=float32>), 'data:0.151': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_151:0' shape=(None,) dtype=float32>), 'data:0.152': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_152:0' shape=(None,) dtype=float32>), 'data:0.153': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_153:0' shape=(None,) dtype=float32>), 'data:0.154': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_154:0' shape=(None,) dtype=float32>), 'data:0.155': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_155:0' shape=(None,) dtype=float32>), 'data:0.156': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_156:0' shape=(None,) dtype=float32>), 'data:0.157': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_157:0' shape=(None,) dtype=float32>), 'data:0.158': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_158:0' shape=(None,) dtype=float32>), 'data:0.159': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_159:0' shape=(None,) dtype=float32>), 'data:0.160': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_160:0' shape=(None,) dtype=float32>), 'data:0.161': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_161:0' shape=(None,) dtype=float32>), 'data:0.162': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_162:0' shape=(None,) dtype=float32>), 'data:0.163': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_163:0' shape=(None,) dtype=float32>), 'data:0.164': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_164:0' shape=(None,) dtype=float32>), 'data:0.165': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_165:0' shape=(None,) dtype=float32>), 'data:0.166': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_166:0' shape=(None,) dtype=float32>), 'data:0.167': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_167:0' shape=(None,) dtype=float32>), 'data:0.168': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_168:0' shape=(None,) dtype=float32>), 'data:0.169': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_169:0' shape=(None,) dtype=float32>), 'data:0.170': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_170:0' shape=(None,) dtype=float32>), 'data:0.171': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_171:0' shape=(None,) dtype=float32>), 'data:0.172': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_172:0' shape=(None,) dtype=float32>), 'data:0.173': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_173:0' shape=(None,) dtype=float32>), 'data:0.174': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_174:0' shape=(None,) dtype=float32>), 'data:0.175': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_175:0' shape=(None,) dtype=float32>), 'data:0.176': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_176:0' shape=(None,) dtype=float32>), 'data:0.177': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_177:0' shape=(None,) dtype=float32>), 'data:0.178': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_178:0' shape=(None,) dtype=float32>), 'data:0.179': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_179:0' shape=(None,) dtype=float32>), 'data:0.180': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_180:0' shape=(None,) dtype=float32>), 'data:0.181': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_181:0' shape=(None,) dtype=float32>), 'data:0.182': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_182:0' shape=(None,) dtype=float32>), 'data:0.183': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_183:0' shape=(None,) dtype=float32>), 'data:0.184': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_184:0' shape=(None,) dtype=float32>), 'data:0.185': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_185:0' shape=(None,) dtype=float32>), 'data:0.186': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_186:0' shape=(None,) dtype=float32>), 'data:0.187': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_187:0' shape=(None,) dtype=float32>), 'data:0.188': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_188:0' shape=(None,) dtype=float32>), 'data:0.189': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_189:0' shape=(None,) dtype=float32>), 'data:0.190': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_190:0' shape=(None,) dtype=float32>), 'data:0.191': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_191:0' shape=(None,) dtype=float32>), 'data:0.192': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_192:0' shape=(None,) dtype=float32>), 'data:0.193': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_193:0' shape=(None,) dtype=float32>), 'data:0.194': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_194:0' shape=(None,) dtype=float32>), 'data:0.195': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_195:0' shape=(None,) dtype=float32>), 'data:0.196': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_196:0' shape=(None,) dtype=float32>), 'data:0.197': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_197:0' shape=(None,) dtype=float32>), 'data:0.198': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_198:0' shape=(None,) dtype=float32>), 'data:0.199': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_199:0' shape=(None,) dtype=float32>), 'data:0.200': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_200:0' shape=(None,) dtype=float32>), 'data:0.201': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_201:0' shape=(None,) dtype=float32>), 'data:0.202': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_202:0' shape=(None,) dtype=float32>), 'data:0.203': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_203:0' shape=(None,) dtype=float32>), 'data:0.204': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_204:0' shape=(None,) dtype=float32>), 'data:0.205': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_205:0' shape=(None,) dtype=float32>), 'data:0.206': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_206:0' shape=(None,) dtype=float32>), 'data:0.207': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_207:0' shape=(None,) dtype=float32>), 'data:0.208': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_208:0' shape=(None,) dtype=float32>), 'data:0.209': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_209:0' shape=(None,) dtype=float32>), 'data:0.210': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_210:0' shape=(None,) dtype=float32>), 'data:0.211': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_211:0' shape=(None,) dtype=float32>), 'data:0.212': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_212:0' shape=(None,) dtype=float32>), 'data:0.213': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_213:0' shape=(None,) dtype=float32>), 'data:0.214': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_214:0' shape=(None,) dtype=float32>), 'data:0.215': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_215:0' shape=(None,) dtype=float32>), 'data:0.216': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_216:0' shape=(None,) dtype=float32>), 'data:0.217': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_217:0' shape=(None,) dtype=float32>), 'data:0.218': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_218:0' shape=(None,) dtype=float32>), 'data:0.219': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_219:0' shape=(None,) dtype=float32>), 'data:0.220': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_220:0' shape=(None,) dtype=float32>), 'data:0.221': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_221:0' shape=(None,) dtype=float32>), 'data:0.222': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_222:0' shape=(None,) dtype=float32>), 'data:0.223': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_223:0' shape=(None,) dtype=float32>), 'data:0.224': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_224:0' shape=(None,) dtype=float32>), 'data:0.225': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_225:0' shape=(None,) dtype=float32>), 'data:0.226': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_226:0' shape=(None,) dtype=float32>), 'data:0.227': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_227:0' shape=(None,) dtype=float32>), 'data:0.228': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_228:0' shape=(None,) dtype=float32>), 'data:0.229': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_229:0' shape=(None,) dtype=float32>), 'data:0.230': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_230:0' shape=(None,) dtype=float32>), 'data:0.231': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_231:0' shape=(None,) dtype=float32>), 'data:0.232': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_232:0' shape=(None,) dtype=float32>), 'data:0.233': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_233:0' shape=(None,) dtype=float32>), 'data:0.234': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_234:0' shape=(None,) dtype=float32>), 'data:0.235': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_235:0' shape=(None,) dtype=float32>), 'data:0.236': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_236:0' shape=(None,) dtype=float32>), 'data:0.237': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_237:0' shape=(None,) dtype=float32>), 'data:0.238': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_238:0' shape=(None,) dtype=float32>), 'data:0.239': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_239:0' shape=(None,) dtype=float32>), 'data:0.240': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_240:0' shape=(None,) dtype=float32>), 'data:0.241': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_241:0' shape=(None,) dtype=float32>), 'data:0.242': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_242:0' shape=(None,) dtype=float32>), 'data:0.243': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_243:0' shape=(None,) dtype=float32>), 'data:0.244': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_244:0' shape=(None,) dtype=float32>), 'data:0.245': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_245:0' shape=(None,) dtype=float32>), 'data:0.246': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_246:0' shape=(None,) dtype=float32>), 'data:0.247': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_247:0' shape=(None,) dtype=float32>), 'data:0.248': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_248:0' shape=(None,) dtype=float32>), 'data:0.249': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_249:0' shape=(None,) dtype=float32>), 'data:0.250': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_250:0' shape=(None,) dtype=float32>), 'data:0.251': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_251:0' shape=(None,) dtype=float32>), 'data:0.252': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_252:0' shape=(None,) dtype=float32>), 'data:0.253': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_253:0' shape=(None,) dtype=float32>), 'data:0.254': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_254:0' shape=(None,) dtype=float32>)}\n","Num validation examples: tf.Tensor(1497, shape=(), dtype=int32)\n","Validation dataset read in 0:00:02.410279. Found 1497 examples.\n","Training model...\n","Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"]},{"output_type":"stream","name":"stderr","text":["[INFO 23-04-29 12:22:26.8071 UTC kernel.cc:773] Start Yggdrasil model training\n","[INFO 23-04-29 12:22:26.8072 UTC kernel.cc:774] Collect training examples\n","[INFO 23-04-29 12:22:26.8072 UTC kernel.cc:787] Dataspec guide:\n","column_guides {\n","  column_name_pattern: \"^__LABEL$\"\n","  type: CATEGORICAL\n","  categorial {\n","    min_vocab_frequency: 0\n","    max_vocab_count: -1\n","  }\n","}\n","default_column_guide {\n","  categorial {\n","    max_vocab_count: 2000\n","  }\n","  discretized_numerical {\n","    maximum_num_bins: 255\n","  }\n","}\n","ignore_columns_without_guides: false\n","detect_numerical_as_discretized_numerical: false\n","\n","[INFO 23-04-29 12:22:26.8088 UTC kernel.cc:393] Number of batches: 120\n","[INFO 23-04-29 12:22:26.8088 UTC kernel.cc:394] Number of examples: 11977\n","[INFO 23-04-29 12:22:26.8420 UTC kernel.cc:794] Training dataset:\n","Number of records: 11977\n","Number of columns: 256\n","\n","Number of columns by type:\n","\tNUMERICAL: 255 (99.6094%)\n","\tCATEGORICAL: 1 (0.390625%)\n","\n","Columns:\n","\n","NUMERICAL: 255 (99.6094%)\n","\t1: \"data:0.0\" NUMERICAL mean:2431.26 min:1 max:14951 sd:3418.18\n","\t2: \"data:0.1\" NUMERICAL mean:2529.56 min:1 max:14946 sd:3432.83\n","\t3: \"data:0.10\" NUMERICAL mean:2208.15 min:0 max:14950 sd:3184.14\n","\t4: \"data:0.100\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t5: \"data:0.101\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t6: \"data:0.102\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t7: \"data:0.103\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t8: \"data:0.104\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t9: \"data:0.105\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t10: \"data:0.106\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t11: \"data:0.107\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t12: \"data:0.108\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t13: \"data:0.109\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t14: \"data:0.11\" NUMERICAL mean:2191.54 min:0 max:14946 sd:3159.13\n","\t15: \"data:0.110\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t16: \"data:0.111\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t17: \"data:0.112\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t18: \"data:0.113\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t19: \"data:0.114\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t20: \"data:0.115\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t21: \"data:0.116\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t22: \"data:0.117\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t23: \"data:0.118\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t24: \"data:0.119\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t25: \"data:0.12\" NUMERICAL mean:2182.82 min:0 max:14921 sd:3183.95\n","\t26: \"data:0.120\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t27: \"data:0.121\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t28: \"data:0.122\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t29: \"data:0.123\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t30: \"data:0.124\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t31: \"data:0.125\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t32: \"data:0.126\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t33: \"data:0.127\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t34: \"data:0.128\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t35: \"data:0.129\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t36: \"data:0.13\" NUMERICAL mean:2157.68 min:0 max:14928 sd:3153.27\n","\t37: \"data:0.130\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t38: \"data:0.131\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t39: \"data:0.132\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t40: \"data:0.133\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t41: \"data:0.134\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t42: \"data:0.135\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t43: \"data:0.136\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t44: \"data:0.137\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t45: \"data:0.138\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t46: \"data:0.139\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t47: \"data:0.14\" NUMERICAL mean:2196.32 min:0 max:14952 sd:3188.38\n","\t48: \"data:0.140\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t49: \"data:0.141\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t50: \"data:0.142\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t51: \"data:0.143\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t52: \"data:0.144\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t53: \"data:0.145\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t54: \"data:0.146\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t55: \"data:0.147\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t56: \"data:0.148\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t57: \"data:0.149\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t58: \"data:0.15\" NUMERICAL mean:2207.79 min:0 max:14934 sd:3190.84\n","\t59: \"data:0.150\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t60: \"data:0.151\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t61: \"data:0.152\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t62: \"data:0.153\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t63: \"data:0.154\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t64: \"data:0.155\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t65: \"data:0.156\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t66: \"data:0.157\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t67: \"data:0.158\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t68: \"data:0.159\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t69: \"data:0.16\" NUMERICAL mean:2195.28 min:0 max:14950 sd:3179.75\n","\t70: \"data:0.160\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t71: \"data:0.161\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t72: \"data:0.162\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t73: \"data:0.163\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t74: \"data:0.164\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t75: \"data:0.165\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t76: \"data:0.166\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t77: \"data:0.167\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t78: \"data:0.168\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t79: \"data:0.169\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t80: \"data:0.17\" NUMERICAL mean:2119.2 min:0 max:14942 sd:3138.13\n","\t81: \"data:0.170\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t82: \"data:0.171\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t83: \"data:0.172\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t84: \"data:0.173\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t85: \"data:0.174\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t86: \"data:0.175\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t87: \"data:0.176\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t88: \"data:0.177\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t89: \"data:0.178\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t90: \"data:0.179\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t91: \"data:0.18\" NUMERICAL mean:2193.42 min:0 max:14930 sd:3193.09\n","\t92: \"data:0.180\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t93: \"data:0.181\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t94: \"data:0.182\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t95: \"data:0.183\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t96: \"data:0.184\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t97: \"data:0.185\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t98: \"data:0.186\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t99: \"data:0.187\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t100: \"data:0.188\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t101: \"data:0.189\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t102: \"data:0.19\" NUMERICAL mean:2167.14 min:0 max:14941 sd:3169.96\n","\t103: \"data:0.190\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t104: \"data:0.191\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t105: \"data:0.192\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t106: \"data:0.193\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t107: \"data:0.194\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t108: \"data:0.195\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t109: \"data:0.196\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t110: \"data:0.197\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t111: \"data:0.198\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t112: \"data:0.199\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t113: \"data:0.2\" NUMERICAL mean:2340.41 min:1 max:14952 sd:3292.89\n","\t114: \"data:0.20\" NUMERICAL mean:2098.15 min:0 max:14952 sd:3096.87\n","\t115: \"data:0.200\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t116: \"data:0.201\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t117: \"data:0.202\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t118: \"data:0.203\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t119: \"data:0.204\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t120: \"data:0.205\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t121: \"data:0.206\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t122: \"data:0.207\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t123: \"data:0.208\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t124: \"data:0.209\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t125: \"data:0.21\" NUMERICAL mean:2144.07 min:0 max:14948 sd:3134.64\n","\t126: \"data:0.210\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t127: \"data:0.211\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t128: \"data:0.212\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t129: \"data:0.213\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t130: \"data:0.214\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t131: \"data:0.215\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t132: \"data:0.216\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t133: \"data:0.217\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t134: \"data:0.218\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t135: \"data:0.219\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t136: \"data:0.22\" NUMERICAL mean:2165.04 min:0 max:14925 sd:3157.26\n","\t137: \"data:0.220\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t138: \"data:0.221\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t139: \"data:0.222\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t140: \"data:0.223\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t141: \"data:0.224\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t142: \"data:0.225\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t143: \"data:0.226\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t144: \"data:0.227\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t145: \"data:0.228\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t146: \"data:0.229\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t147: \"data:0.23\" NUMERICAL mean:2190.46 min:0 max:14914 sd:3182.47\n","\t148: \"data:0.230\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t149: \"data:0.231\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t150: \"data:0.232\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t151: \"data:0.233\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t152: \"data:0.234\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t153: \"data:0.235\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t154: \"data:0.236\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t155: \"data:0.237\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t156: \"data:0.238\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t157: \"data:0.239\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t158: \"data:0.24\" NUMERICAL mean:2174.01 min:0 max:14929 sd:3191.9\n","\t159: \"data:0.240\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t160: \"data:0.241\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t161: \"data:0.242\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t162: \"data:0.243\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t163: \"data:0.244\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t164: \"data:0.245\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t165: \"data:0.246\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t166: \"data:0.247\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t167: \"data:0.248\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t168: \"data:0.249\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t169: \"data:0.25\" NUMERICAL mean:2119.44 min:0 max:14933 sd:3116.33\n","\t170: \"data:0.250\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t171: \"data:0.251\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t172: \"data:0.252\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t173: \"data:0.253\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t174: \"data:0.254\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t175: \"data:0.26\" NUMERICAL mean:2122.12 min:0 max:14947 sd:3136.35\n","\t176: \"data:0.27\" NUMERICAL mean:2155.79 min:0 max:14931 sd:3175.99\n","\t177: \"data:0.28\" NUMERICAL mean:2131.05 min:0 max:14938 sd:3163.34\n","\t178: \"data:0.29\" NUMERICAL mean:2092.64 min:0 max:14899 sd:3113.67\n","\t179: \"data:0.3\" NUMERICAL mean:2298.82 min:0 max:14951 sd:3262.57\n","\t180: \"data:0.30\" NUMERICAL mean:2097.9 min:0 max:14945 sd:3141.99\n","\t181: \"data:0.31\" NUMERICAL mean:1996.72 min:0 max:14945 sd:3119.95\n","\t182: \"data:0.32\" NUMERICAL mean:1875.04 min:0 max:14941 sd:3053.8\n","\t183: \"data:0.33\" NUMERICAL mean:1670.51 min:0 max:14937 sd:2966.46\n","\t184: \"data:0.34\" NUMERICAL mean:1391.28 min:0 max:14941 sd:2819.78\n","\t185: \"data:0.35\" NUMERICAL mean:1073.68 min:0 max:14930 sd:2562.7\n","\t186: \"data:0.36\" NUMERICAL mean:741.816 min:0 max:14937 sd:2174.09\n","\t187: \"data:0.37\" NUMERICAL mean:460.998 min:0 max:14934 sd:1768.89\n","\t188: \"data:0.38\" NUMERICAL mean:294.254 min:0 max:14768 sd:1414.57\n","\t189: \"data:0.39\" NUMERICAL mean:156.089 min:0 max:14922 sd:1035.88\n","\t190: \"data:0.4\" NUMERICAL mean:2303.84 min:0 max:14947 sd:3234.17\n","\t191: \"data:0.40\" NUMERICAL mean:79.4155 min:0 max:14766 sd:753.883\n","\t192: \"data:0.41\" NUMERICAL mean:45.1616 min:0 max:14203 sd:596.806\n","\t193: \"data:0.42\" NUMERICAL mean:19.1854 min:0 max:14592 sd:380.009\n","\t194: \"data:0.43\" NUMERICAL mean:7.33681 min:0 max:13234 sd:212.802\n","\t195: \"data:0.44\" NUMERICAL mean:6.26209 min:0 max:13884 sd:222.511\n","\t196: \"data:0.45\" NUMERICAL mean:3.73165 min:0 max:8470 sd:157.525\n","\t197: \"data:0.46\" NUMERICAL mean:1.57552 min:0 max:14724 sd:135.49\n","\t198: \"data:0.47\" NUMERICAL mean:2.82784 min:0 max:14625 sd:156.334\n","\t199: \"data:0.48\" NUMERICAL mean:0.758203 min:0 max:3227 sd:41.8498\n","\t200: \"data:0.49\" NUMERICAL mean:0.0811555 min:0 max:674 sd:6.59216\n","\t201: \"data:0.5\" NUMERICAL mean:2299.52 min:0 max:14952 sd:3261.78\n","\t202: \"data:0.50\" NUMERICAL mean:8.34934e-05 min:0 max:1 sd:0.00913709\n","\t203: \"data:0.51\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t204: \"data:0.52\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t205: \"data:0.53\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t206: \"data:0.54\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t207: \"data:0.55\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t208: \"data:0.56\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t209: \"data:0.57\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t210: \"data:0.58\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t211: \"data:0.59\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t212: \"data:0.6\" NUMERICAL mean:2206.42 min:0 max:14950 sd:3117.09\n","\t213: \"data:0.60\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t214: \"data:0.61\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t215: \"data:0.62\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t216: \"data:0.63\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t217: \"data:0.64\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t218: \"data:0.65\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t219: \"data:0.66\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t220: \"data:0.67\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t221: \"data:0.68\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t222: \"data:0.69\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t223: \"data:0.7\" NUMERICAL mean:2248.69 min:0 max:14947 sd:3202.66\n","\t224: \"data:0.70\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t225: \"data:0.71\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t226: \"data:0.72\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t227: \"data:0.73\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t228: \"data:0.74\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t229: \"data:0.75\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t230: \"data:0.76\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t231: \"data:0.77\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t232: \"data:0.78\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t233: \"data:0.79\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t234: \"data:0.8\" NUMERICAL mean:2196.27 min:0 max:14945 sd:3178.79\n","\t235: \"data:0.80\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t236: \"data:0.81\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t237: \"data:0.82\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t238: \"data:0.83\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t239: \"data:0.84\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t240: \"data:0.85\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t241: \"data:0.86\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t242: \"data:0.87\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t243: \"data:0.88\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t244: \"data:0.89\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t245: \"data:0.9\" NUMERICAL mean:2200.9 min:0 max:14936 sd:3148.61\n","\t246: \"data:0.90\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t247: \"data:0.91\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t248: \"data:0.92\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t249: \"data:0.93\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t250: \"data:0.94\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t251: \"data:0.95\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t252: \"data:0.96\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t253: \"data:0.97\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t254: \"data:0.98\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t255: \"data:0.99\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\n","CATEGORICAL: 1 (0.390625%)\n","\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:77 no-ood-item\n","\n","Terminology:\n","\tnas: Number of non-available (i.e. missing) values.\n","\tood: Out of dictionary.\n","\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n","\ttokenized: The attribute value is obtained through tokenization.\n","\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n","\tvocab-size: Number of unique values.\n","\n","[INFO 23-04-29 12:22:26.8422 UTC kernel.cc:799] Collect validation dataset\n","[INFO 23-04-29 12:22:26.8435 UTC kernel.cc:393] Number of batches: 15\n","[INFO 23-04-29 12:22:26.8435 UTC kernel.cc:394] Number of examples: 1497\n","[INFO 23-04-29 12:22:26.8624 UTC kernel.cc:805] Validation dataset:\n","Number of records: 1497\n","Number of columns: 256\n","\n","Number of columns by type:\n","\tNUMERICAL: 255 (99.6094%)\n","\tCATEGORICAL: 1 (0.390625%)\n","\n","Columns:\n","\n","NUMERICAL: 255 (99.6094%)\n","\t1: \"data:0.0\" NUMERICAL mean:2407.15 min:1 max:14949 sd:3391.94\n","\t2: \"data:0.1\" NUMERICAL mean:2539.28 min:1 max:14942 sd:3480.75\n","\t3: \"data:0.10\" NUMERICAL mean:2079.53 min:0 max:14944 sd:2986.22\n","\t4: \"data:0.100\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t5: \"data:0.101\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t6: \"data:0.102\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t7: \"data:0.103\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t8: \"data:0.104\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t9: \"data:0.105\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t10: \"data:0.106\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t11: \"data:0.107\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t12: \"data:0.108\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t13: \"data:0.109\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t14: \"data:0.11\" NUMERICAL mean:2165.53 min:0 max:14926 sd:3132.36\n","\t15: \"data:0.110\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t16: \"data:0.111\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t17: \"data:0.112\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t18: \"data:0.113\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t19: \"data:0.114\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t20: \"data:0.115\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t21: \"data:0.116\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t22: \"data:0.117\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t23: \"data:0.118\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t24: \"data:0.119\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t25: \"data:0.12\" NUMERICAL mean:2155.22 min:0 max:14949 sd:3171.45\n","\t26: \"data:0.120\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t27: \"data:0.121\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t28: \"data:0.122\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t29: \"data:0.123\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t30: \"data:0.124\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t31: \"data:0.125\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t32: \"data:0.126\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t33: \"data:0.127\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t34: \"data:0.128\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t35: \"data:0.129\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t36: \"data:0.13\" NUMERICAL mean:2065.96 min:0 max:14812 sd:3007.55\n","\t37: \"data:0.130\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t38: \"data:0.131\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t39: \"data:0.132\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t40: \"data:0.133\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t41: \"data:0.134\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t42: \"data:0.135\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t43: \"data:0.136\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t44: \"data:0.137\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t45: \"data:0.138\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t46: \"data:0.139\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t47: \"data:0.14\" NUMERICAL mean:2164.11 min:0 max:14820 sd:3142.31\n","\t48: \"data:0.140\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t49: \"data:0.141\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t50: \"data:0.142\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t51: \"data:0.143\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t52: \"data:0.144\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t53: \"data:0.145\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t54: \"data:0.146\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t55: \"data:0.147\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t56: \"data:0.148\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t57: \"data:0.149\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t58: \"data:0.15\" NUMERICAL mean:2197.63 min:0 max:14712 sd:3223.5\n","\t59: \"data:0.150\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t60: \"data:0.151\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t61: \"data:0.152\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t62: \"data:0.153\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t63: \"data:0.154\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t64: \"data:0.155\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t65: \"data:0.156\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t66: \"data:0.157\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t67: \"data:0.158\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t68: \"data:0.159\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t69: \"data:0.16\" NUMERICAL mean:2076.31 min:0 max:14906 sd:3079.28\n","\t70: \"data:0.160\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t71: \"data:0.161\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t72: \"data:0.162\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t73: \"data:0.163\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t74: \"data:0.164\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t75: \"data:0.165\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t76: \"data:0.166\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t77: \"data:0.167\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t78: \"data:0.168\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t79: \"data:0.169\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t80: \"data:0.17\" NUMERICAL mean:2132.17 min:0 max:14798 sd:3026.74\n","\t81: \"data:0.170\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t82: \"data:0.171\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t83: \"data:0.172\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t84: \"data:0.173\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t85: \"data:0.174\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t86: \"data:0.175\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t87: \"data:0.176\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t88: \"data:0.177\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t89: \"data:0.178\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t90: \"data:0.179\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t91: \"data:0.18\" NUMERICAL mean:2193.44 min:0 max:14780 sd:3251.04\n","\t92: \"data:0.180\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t93: \"data:0.181\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t94: \"data:0.182\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t95: \"data:0.183\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t96: \"data:0.184\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t97: \"data:0.185\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t98: \"data:0.186\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t99: \"data:0.187\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t100: \"data:0.188\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t101: \"data:0.189\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t102: \"data:0.19\" NUMERICAL mean:2219.55 min:0 max:14935 sd:3249.45\n","\t103: \"data:0.190\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t104: \"data:0.191\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t105: \"data:0.192\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t106: \"data:0.193\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t107: \"data:0.194\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t108: \"data:0.195\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t109: \"data:0.196\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t110: \"data:0.197\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t111: \"data:0.198\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t112: \"data:0.199\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t113: \"data:0.2\" NUMERICAL mean:2516.58 min:1 max:14907 sd:3449.2\n","\t114: \"data:0.20\" NUMERICAL mean:2129.26 min:0 max:14840 sd:3214.27\n","\t115: \"data:0.200\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t116: \"data:0.201\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t117: \"data:0.202\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t118: \"data:0.203\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t119: \"data:0.204\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t120: \"data:0.205\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t121: \"data:0.206\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t122: \"data:0.207\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t123: \"data:0.208\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t124: \"data:0.209\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t125: \"data:0.21\" NUMERICAL mean:2169.17 min:0 max:14909 sd:3217.64\n","\t126: \"data:0.210\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t127: \"data:0.211\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t128: \"data:0.212\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t129: \"data:0.213\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t130: \"data:0.214\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t131: \"data:0.215\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t132: \"data:0.216\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t133: \"data:0.217\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t134: \"data:0.218\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t135: \"data:0.219\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t136: \"data:0.22\" NUMERICAL mean:2180.4 min:0 max:14788 sd:3171.63\n","\t137: \"data:0.220\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t138: \"data:0.221\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t139: \"data:0.222\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t140: \"data:0.223\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t141: \"data:0.224\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t142: \"data:0.225\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t143: \"data:0.226\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t144: \"data:0.227\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t145: \"data:0.228\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t146: \"data:0.229\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t147: \"data:0.23\" NUMERICAL mean:2134.16 min:0 max:14658 sd:3182.54\n","\t148: \"data:0.230\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t149: \"data:0.231\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t150: \"data:0.232\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t151: \"data:0.233\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t152: \"data:0.234\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t153: \"data:0.235\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t154: \"data:0.236\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t155: \"data:0.237\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t156: \"data:0.238\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t157: \"data:0.239\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t158: \"data:0.24\" NUMERICAL mean:2057.53 min:0 max:14851 sd:3022.06\n","\t159: \"data:0.240\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t160: \"data:0.241\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t161: \"data:0.242\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t162: \"data:0.243\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t163: \"data:0.244\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t164: \"data:0.245\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t165: \"data:0.246\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t166: \"data:0.247\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t167: \"data:0.248\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t168: \"data:0.249\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t169: \"data:0.25\" NUMERICAL mean:2235.3 min:0 max:14890 sd:3281.18\n","\t170: \"data:0.250\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t171: \"data:0.251\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t172: \"data:0.252\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t173: \"data:0.253\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t174: \"data:0.254\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t175: \"data:0.26\" NUMERICAL mean:2011 min:0 max:14927 sd:3004.55\n","\t176: \"data:0.27\" NUMERICAL mean:2006.32 min:0 max:14826 sd:2991.74\n","\t177: \"data:0.28\" NUMERICAL mean:1998.14 min:0 max:14889 sd:3061.45\n","\t178: \"data:0.29\" NUMERICAL mean:2204.46 min:0 max:14916 sd:3182.41\n","\t179: \"data:0.3\" NUMERICAL mean:2276.29 min:0 max:14944 sd:3368.95\n","\t180: \"data:0.30\" NUMERICAL mean:2182.04 min:0 max:14945 sd:3306.33\n","\t181: \"data:0.31\" NUMERICAL mean:2070.56 min:0 max:14950 sd:3234.08\n","\t182: \"data:0.32\" NUMERICAL mean:1902.45 min:0 max:14927 sd:3121.62\n","\t183: \"data:0.33\" NUMERICAL mean:1825.99 min:0 max:14926 sd:3134.23\n","\t184: \"data:0.34\" NUMERICAL mean:1367.99 min:0 max:14613 sd:2653.39\n","\t185: \"data:0.35\" NUMERICAL mean:1009.75 min:0 max:14923 sd:2444.99\n","\t186: \"data:0.36\" NUMERICAL mean:659.228 min:0 max:14888 sd:1974.83\n","\t187: \"data:0.37\" NUMERICAL mean:484.57 min:0 max:14652 sd:1915.3\n","\t188: \"data:0.38\" NUMERICAL mean:228.117 min:0 max:14156 sd:1218.41\n","\t189: \"data:0.39\" NUMERICAL mean:127.206 min:0 max:13710 sd:987.939\n","\t190: \"data:0.4\" NUMERICAL mean:2069.33 min:0 max:14803 sd:3076.27\n","\t191: \"data:0.40\" NUMERICAL mean:89.3206 min:0 max:14808 sd:963.705\n","\t192: \"data:0.41\" NUMERICAL mean:26.5197 min:0 max:10701 sd:412.608\n","\t193: \"data:0.42\" NUMERICAL mean:25.2799 min:0 max:13403 sd:508.3\n","\t194: \"data:0.43\" NUMERICAL mean:4.20174 min:0 max:6289 sd:162.49\n","\t195: \"data:0.44\" NUMERICAL mean:0.450234 min:0 max:674 sd:17.4142\n","\t196: \"data:0.45\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t197: \"data:0.46\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t198: \"data:0.47\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t199: \"data:0.48\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t200: \"data:0.49\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t201: \"data:0.5\" NUMERICAL mean:2416.81 min:0 max:14699 sd:3400.65\n","\t202: \"data:0.50\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t203: \"data:0.51\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t204: \"data:0.52\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t205: \"data:0.53\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t206: \"data:0.54\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t207: \"data:0.55\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t208: \"data:0.56\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t209: \"data:0.57\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t210: \"data:0.58\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t211: \"data:0.59\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t212: \"data:0.6\" NUMERICAL mean:2223.64 min:0 max:14812 sd:3212.67\n","\t213: \"data:0.60\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t214: \"data:0.61\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t215: \"data:0.62\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t216: \"data:0.63\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t217: \"data:0.64\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t218: \"data:0.65\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t219: \"data:0.66\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t220: \"data:0.67\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t221: \"data:0.68\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t222: \"data:0.69\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t223: \"data:0.7\" NUMERICAL mean:2267.73 min:0 max:14741 sd:3158.9\n","\t224: \"data:0.70\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t225: \"data:0.71\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t226: \"data:0.72\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t227: \"data:0.73\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t228: \"data:0.74\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t229: \"data:0.75\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t230: \"data:0.76\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t231: \"data:0.77\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t232: \"data:0.78\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t233: \"data:0.79\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t234: \"data:0.8\" NUMERICAL mean:2232.56 min:0 max:14942 sd:3184.48\n","\t235: \"data:0.80\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t236: \"data:0.81\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t237: \"data:0.82\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t238: \"data:0.83\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t239: \"data:0.84\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t240: \"data:0.85\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t241: \"data:0.86\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t242: \"data:0.87\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t243: \"data:0.88\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t244: \"data:0.89\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t245: \"data:0.9\" NUMERICAL mean:2208.77 min:0 max:14907 sd:3193.18\n","\t246: \"data:0.90\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t247: \"data:0.91\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t248: \"data:0.92\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t249: \"data:0.93\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t250: \"data:0.94\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t251: \"data:0.95\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t252: \"data:0.96\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t253: \"data:0.97\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t254: \"data:0.98\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\t255: \"data:0.99\" NUMERICAL mean:0 min:0 max:0 sd:0\n","\n","CATEGORICAL: 1 (0.390625%)\n","\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:77 no-ood-item\n","\n","Terminology:\n","\tnas: Number of non-available (i.e. missing) values.\n","\tood: Out of dictionary.\n","\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n","\ttokenized: The attribute value is obtained through tokenization.\n","\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n","\tvocab-size: Number of unique values.\n","\n","[INFO 23-04-29 12:22:26.8633 UTC kernel.cc:810] Configure learner\n","[INFO 23-04-29 12:22:26.8643 UTC kernel.cc:824] Training config:\n","learner: \"RANDOM_FOREST\"\n","features: \"^data:0\\\\.0$\"\n","features: \"^data:0\\\\.1$\"\n","features: \"^data:0\\\\.10$\"\n","features: \"^data:0\\\\.100$\"\n","features: \"^data:0\\\\.101$\"\n","features: \"^data:0\\\\.102$\"\n","features: \"^data:0\\\\.103$\"\n","features: \"^data:0\\\\.104$\"\n","features: \"^data:0\\\\.105$\"\n","features: \"^data:0\\\\.106$\"\n","features: \"^data:0\\\\.107$\"\n","features: \"^data:0\\\\.108$\"\n","features: \"^data:0\\\\.109$\"\n","features: \"^data:0\\\\.11$\"\n","features: \"^data:0\\\\.110$\"\n","features: \"^data:0\\\\.111$\"\n","features: \"^data:0\\\\.112$\"\n","features: \"^data:0\\\\.113$\"\n","features: \"^data:0\\\\.114$\"\n","features: \"^data:0\\\\.115$\"\n","features: \"^data:0\\\\.116$\"\n","features: \"^data:0\\\\.117$\"\n","features: \"^data:0\\\\.118$\"\n","features: \"^data:0\\\\.119$\"\n","features: \"^data:0\\\\.12$\"\n","features: \"^data:0\\\\.120$\"\n","features: \"^data:0\\\\.121$\"\n","features: \"^data:0\\\\.122$\"\n","features: \"^data:0\\\\.123$\"\n","features: \"^data:0\\\\.124$\"\n","features: \"^data:0\\\\.125$\"\n","features: \"^data:0\\\\.126$\"\n","features: \"^data:0\\\\.127$\"\n","features: \"^data:0\\\\.128$\"\n","features: \"^data:0\\\\.129$\"\n","features: \"^data:0\\\\.13$\"\n","features: \"^data:0\\\\.130$\"\n","features: \"^data:0\\\\.131$\"\n","features: \"^data:0\\\\.132$\"\n","features: \"^data:0\\\\.133$\"\n","features: \"^data:0\\\\.134$\"\n","features: \"^data:0\\\\.135$\"\n","features: \"^data:0\\\\.136$\"\n","features: \"^data:0\\\\.137$\"\n","features: \"^data:0\\\\.138$\"\n","features: \"^data:0\\\\.139$\"\n","features: \"^data:0\\\\.14$\"\n","features: \"^data:0\\\\.140$\"\n","features: \"^data:0\\\\.141$\"\n","features: \"^data:0\\\\.142$\"\n","features: \"^data:0\\\\.143$\"\n","features: \"^data:0\\\\.144$\"\n","features: \"^data:0\\\\.145$\"\n","features: \"^data:0\\\\.146$\"\n","features: \"^data:0\\\\.147$\"\n","features: \"^data:0\\\\.148$\"\n","features: \"^data:0\\\\.149$\"\n","features: \"^data:0\\\\.15$\"\n","features: \"^data:0\\\\.150$\"\n","features: \"^data:0\\\\.151$\"\n","features: \"^data:0\\\\.152$\"\n","features: \"^data:0\\\\.153$\"\n","features: \"^data:0\\\\.154$\"\n","features: \"^data:0\\\\.155$\"\n","features: \"^data:0\\\\.156$\"\n","features: \"^data:0\\\\.157$\"\n","features: \"^data:0\\\\.158$\"\n","features: \"^data:0\\\\.159$\"\n","features: \"^data:0\\\\.16$\"\n","features: \"^data:0\\\\.160$\"\n","features: \"^data:0\\\\.161$\"\n","features: \"^data:0\\\\.162$\"\n","features: \"^data:0\\\\.163$\"\n","features: \"^data:0\\\\.164$\"\n","features: \"^data:0\\\\.165$\"\n","features: \"^data:0\\\\.166$\"\n","features: \"^data:0\\\\.167$\"\n","features: \"^data:0\\\\.168$\"\n","features: \"^data:0\\\\.169$\"\n","features: \"^data:0\\\\.17$\"\n","features: \"^data:0\\\\.170$\"\n","features: \"^data:0\\\\.171$\"\n","features: \"^data:0\\\\.172$\"\n","features: \"^data:0\\\\.173$\"\n","features: \"^data:0\\\\.174$\"\n","features: \"^data:0\\\\.175$\"\n","features: \"^data:0\\\\.176$\"\n","features: \"^data:0\\\\.177$\"\n","features: \"^data:0\\\\.178$\"\n","features: \"^data:0\\\\.179$\"\n","features: \"^data:0\\\\.18$\"\n","features: \"^data:0\\\\.180$\"\n","features: \"^data:0\\\\.181$\"\n","features: \"^data:0\\\\.182$\"\n","features: \"^data:0\\\\.183$\"\n","features: \"^data:0\\\\.184$\"\n","features: \"^data:0\\\\.185$\"\n","features: \"^data:0\\\\.186$\"\n","features: \"^data:0\\\\.187$\"\n","features: \"^data:0\\\\.188$\"\n","features: \"^data:0\\\\.189$\"\n","features: \"^data:0\\\\.19$\"\n","features: \"^data:0\\\\.190$\"\n","features: \"^data:0\\\\.191$\"\n","features: \"^data:0\\\\.192$\"\n","features: \"^data:0\\\\.193$\"\n","features: \"^data:0\\\\.194$\"\n","features: \"^data:0\\\\.195$\"\n","features: \"^data:0\\\\.196$\"\n","features: \"^data:0\\\\.197$\"\n","features: \"^data:0\\\\.198$\"\n","features: \"^data:0\\\\.199$\"\n","features: \"^data:0\\\\.2$\"\n","features: \"^data:0\\\\.20$\"\n","features: \"^data:0\\\\.200$\"\n","features: \"^data:0\\\\.201$\"\n","features: \"^data:0\\\\.202$\"\n","features: \"^data:0\\\\.203$\"\n","features: \"^data:0\\\\.204$\"\n","features: \"^data:0\\\\.205$\"\n","features: \"^data:0\\\\.206$\"\n","features: \"^data:0\\\\.207$\"\n","features: \"^data:0\\\\.208$\"\n","features: \"^data:0\\\\.209$\"\n","features: \"^data:0\\\\.21$\"\n","features: \"^data:0\\\\.210$\"\n","features: \"^data:0\\\\.211$\"\n","features: \"^data:0\\\\.212$\"\n","features: \"^data:0\\\\.213$\"\n","features: \"^data:0\\\\.214$\"\n","features: \"^data:0\\\\.215$\"\n","features: \"^data:0\\\\.216$\"\n","features: \"^data:0\\\\.217$\"\n","features: \"^data:0\\\\.218$\"\n","features: \"^data:0\\\\.219$\"\n","features: \"^data:0\\\\.22$\"\n","features: \"^data:0\\\\.220$\"\n","features: \"^data:0\\\\.221$\"\n","features: \"^data:0\\\\.222$\"\n","features: \"^data:0\\\\.223$\"\n","features: \"^data:0\\\\.224$\"\n","features: \"^data:0\\\\.225$\"\n","features: \"^data:0\\\\.226$\"\n","features: \"^data:0\\\\.227$\"\n","features: \"^data:0\\\\.228$\"\n","features: \"^data:0\\\\.229$\"\n","features: \"^data:0\\\\.23$\"\n","features: \"^data:0\\\\.230$\"\n","features: \"^data:0\\\\.231$\"\n","features: \"^data:0\\\\.232$\"\n","features: \"^data:0\\\\.233$\"\n","features: \"^data:0\\\\.234$\"\n","features: \"^data:0\\\\.235$\"\n","features: \"^data:0\\\\.236$\"\n","features: \"^data:0\\\\.237$\"\n","features: \"^data:0\\\\.238$\"\n","features: \"^data:0\\\\.239$\"\n","features: \"^data:0\\\\.24$\"\n","features: \"^data:0\\\\.240$\"\n","features: \"^data:0\\\\.241$\"\n","features: \"^data:0\\\\.242$\"\n","features: \"^data:0\\\\.243$\"\n","features: \"^data:0\\\\.244$\"\n","features: \"^data:0\\\\.245$\"\n","features: \"^data:0\\\\.246$\"\n","features: \"^data:0\\\\.247$\"\n","features: \"^data:0\\\\.248$\"\n","features: \"^data:0\\\\.249$\"\n","features: \"^data:0\\\\.25$\"\n","features: \"^data:0\\\\.250$\"\n","features: \"^data:0\\\\.251$\"\n","features: \"^data:0\\\\.252$\"\n","features: \"^data:0\\\\.253$\"\n","features: \"^data:0\\\\.254$\"\n","features: \"^data:0\\\\.26$\"\n","features: \"^data:0\\\\.27$\"\n","features: \"^data:0\\\\.28$\"\n","features: \"^data:0\\\\.29$\"\n","features: \"^data:0\\\\.3$\"\n","features: \"^data:0\\\\.30$\"\n","features: \"^data:0\\\\.31$\"\n","features: \"^data:0\\\\.32$\"\n","features: \"^data:0\\\\.33$\"\n","features: \"^data:0\\\\.34$\"\n","features: \"^data:0\\\\.35$\"\n","features: \"^data:0\\\\.36$\"\n","features: \"^data:0\\\\.37$\"\n","features: \"^data:0\\\\.38$\"\n","features: \"^data:0\\\\.39$\"\n","features: \"^data:0\\\\.4$\"\n","features: \"^data:0\\\\.40$\"\n","features: \"^data:0\\\\.41$\"\n","features: \"^data:0\\\\.42$\"\n","features: \"^data:0\\\\.43$\"\n","features: \"^data:0\\\\.44$\"\n","features: \"^data:0\\\\.45$\"\n","features: \"^data:0\\\\.46$\"\n","features: \"^data:0\\\\.47$\"\n","features: \"^data:0\\\\.48$\"\n","features: \"^data:0\\\\.49$\"\n","features: \"^data:0\\\\.5$\"\n","features: \"^data:0\\\\.50$\"\n","features: \"^data:0\\\\.51$\"\n","features: \"^data:0\\\\.52$\"\n","features: \"^data:0\\\\.53$\"\n","features: \"^data:0\\\\.54$\"\n","features: \"^data:0\\\\.55$\"\n","features: \"^data:0\\\\.56$\"\n","features: \"^data:0\\\\.57$\"\n","features: \"^data:0\\\\.58$\"\n","features: \"^data:0\\\\.59$\"\n","features: \"^data:0\\\\.6$\"\n","features: \"^data:0\\\\.60$\"\n","features: \"^data:0\\\\.61$\"\n","features: \"^data:0\\\\.62$\"\n","features: \"^data:0\\\\.63$\"\n","features: \"^data:0\\\\.64$\"\n","features: \"^data:0\\\\.65$\"\n","features: \"^data:0\\\\.66$\"\n","features: \"^data:0\\\\.67$\"\n","features: \"^data:0\\\\.68$\"\n","features: \"^data:0\\\\.69$\"\n","features: \"^data:0\\\\.7$\"\n","features: \"^data:0\\\\.70$\"\n","features: \"^data:0\\\\.71$\"\n","features: \"^data:0\\\\.72$\"\n","features: \"^data:0\\\\.73$\"\n","features: \"^data:0\\\\.74$\"\n","features: \"^data:0\\\\.75$\"\n","features: \"^data:0\\\\.76$\"\n","features: \"^data:0\\\\.77$\"\n","features: \"^data:0\\\\.78$\"\n","features: \"^data:0\\\\.79$\"\n","features: \"^data:0\\\\.8$\"\n","features: \"^data:0\\\\.80$\"\n","features: \"^data:0\\\\.81$\"\n","features: \"^data:0\\\\.82$\"\n","features: \"^data:0\\\\.83$\"\n","features: \"^data:0\\\\.84$\"\n","features: \"^data:0\\\\.85$\"\n","features: \"^data:0\\\\.86$\"\n","features: \"^data:0\\\\.87$\"\n","features: \"^data:0\\\\.88$\"\n","features: \"^data:0\\\\.89$\"\n","features: \"^data:0\\\\.9$\"\n","features: \"^data:0\\\\.90$\"\n","features: \"^data:0\\\\.91$\"\n","features: \"^data:0\\\\.92$\"\n","features: \"^data:0\\\\.93$\"\n","features: \"^data:0\\\\.94$\"\n","features: \"^data:0\\\\.95$\"\n","features: \"^data:0\\\\.96$\"\n","features: \"^data:0\\\\.97$\"\n","features: \"^data:0\\\\.98$\"\n","features: \"^data:0\\\\.99$\"\n","label: \"^__LABEL$\"\n","task: CLASSIFICATION\n","random_seed: 123456\n","metadata {\n","  framework: \"TF Keras\"\n","}\n","pure_serving_model: false\n","[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n","  num_trees: 300\n","  decision_tree {\n","    max_depth: 16\n","    min_examples: 5\n","    in_split_min_examples_check: true\n","    keep_non_leaf_label_distribution: true\n","    num_candidate_attributes: 0\n","    missing_value_policy: GLOBAL_IMPUTATION\n","    allow_na_conditions: false\n","    categorical_set_greedy_forward {\n","      sampling: 0.1\n","      max_num_items: -1\n","      min_item_frequency: 1\n","    }\n","    growing_strategy_local {\n","    }\n","    categorical {\n","      cart {\n","      }\n","    }\n","    axis_aligned_split {\n","    }\n","    internal {\n","      sorting_strategy: PRESORTED\n","    }\n","    uplift {\n","      min_examples_in_treatment: 5\n","      split_score: KULLBACK_LEIBLER\n","    }\n","  }\n","  winner_take_all_inference: true\n","  compute_oob_performances: true\n","  compute_oob_variable_importances: false\n","  num_oob_variable_importances_permutations: 1\n","  bootstrap_training_dataset: true\n","  bootstrap_size_ratio: 1\n","  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n","  sampling_with_replacement: true\n","}\n","\n","[INFO 23-04-29 12:22:26.8652 UTC kernel.cc:827] Deployment config:\n","cache_path: \"/tmp/tmpoarv9dfo/working_cache\"\n","num_threads: 2\n","try_resume_training: true\n","\n","[INFO 23-04-29 12:22:26.8704 UTC kernel.cc:889] Train model\n","[INFO 23-04-29 12:22:26.8841 UTC random_forest.cc:416] Training random forest on 11977 example(s) and 255 feature(s).\n","[INFO 23-04-29 12:22:29.8260 UTC random_forest.cc:805] Training of tree  1/300 (tree index:1) done accuracy:0.0832757 logloss:33.0421\n","[INFO 23-04-29 12:22:40.4559 UTC random_forest.cc:805] Training of tree  11/300 (tree index:10) done accuracy:0.093035 logloss:27.6324\n","[INFO 23-04-29 12:22:51.2950 UTC random_forest.cc:805] Training of tree  21/300 (tree index:20) done accuracy:0.104885 logloss:22.8776\n","[INFO 23-04-29 12:23:02.1475 UTC random_forest.cc:805] Training of tree  31/300 (tree index:30) done accuracy:0.11497 logloss:19.4306\n","[INFO 23-04-29 12:23:12.0436 UTC random_forest.cc:805] Training of tree  41/300 (tree index:40) done accuracy:0.118978 logloss:17.0533\n","[INFO 23-04-29 12:23:22.1445 UTC random_forest.cc:805] Training of tree  51/300 (tree index:50) done accuracy:0.122652 logloss:15.0915\n","[INFO 23-04-29 12:23:32.9437 UTC random_forest.cc:805] Training of tree  61/300 (tree index:60) done accuracy:0.12691 logloss:13.5948\n","[INFO 23-04-29 12:23:43.3344 UTC random_forest.cc:805] Training of tree  69/300 (tree index:68) done accuracy:0.125908 logloss:12.6609\n","[INFO 23-04-29 12:23:52.2745 UTC random_forest.cc:805] Training of tree  79/300 (tree index:78) done accuracy:0.133088 logloss:11.6835\n","[INFO 23-04-29 12:24:03.0968 UTC random_forest.cc:805] Training of tree  89/300 (tree index:88) done accuracy:0.13384 logloss:10.8463\n","[INFO 23-04-29 12:24:13.9929 UTC random_forest.cc:805] Training of tree  99/300 (tree index:98) done accuracy:0.132754 logloss:10.1826\n","[INFO 23-04-29 12:24:24.8977 UTC random_forest.cc:805] Training of tree  109/300 (tree index:108) done accuracy:0.136595 logloss:9.67045\n","[INFO 23-04-29 12:24:33.9297 UTC random_forest.cc:805] Training of tree  119/300 (tree index:118) done accuracy:0.135009 logloss:9.1832\n","[INFO 23-04-29 12:24:44.7558 UTC random_forest.cc:805] Training of tree  129/300 (tree index:128) done accuracy:0.138098 logloss:8.82286\n","[INFO 23-04-29 12:24:55.6364 UTC random_forest.cc:805] Training of tree  139/300 (tree index:138) done accuracy:0.140686 logloss:8.48443\n","[INFO 23-04-29 12:25:06.4345 UTC random_forest.cc:805] Training of tree  149/300 (tree index:148) done accuracy:0.14077 logloss:8.18947\n","[INFO 23-04-29 12:25:16.0785 UTC random_forest.cc:805] Training of tree  159/300 (tree index:158) done accuracy:0.142106 logloss:7.91926\n","[INFO 23-04-29 12:25:26.9026 UTC random_forest.cc:805] Training of tree  169/300 (tree index:168) done accuracy:0.144527 logloss:7.64233\n","[INFO 23-04-29 12:25:37.8927 UTC random_forest.cc:805] Training of tree  179/300 (tree index:178) done accuracy:0.145362 logloss:7.41237\n","[INFO 23-04-29 12:25:47.5288 UTC random_forest.cc:805] Training of tree  189/300 (tree index:188) done accuracy:0.144861 logloss:7.21382\n","[INFO 23-04-29 12:25:57.7677 UTC random_forest.cc:805] Training of tree  199/300 (tree index:198) done accuracy:0.144694 logloss:7.07029\n","[INFO 23-04-29 12:26:08.7759 UTC random_forest.cc:805] Training of tree  209/300 (tree index:208) done accuracy:0.145195 logloss:6.88605\n","[INFO 23-04-29 12:26:19.6857 UTC random_forest.cc:805] Training of tree  219/300 (tree index:218) done accuracy:0.145362 logloss:6.74025\n","[INFO 23-04-29 12:26:29.1439 UTC random_forest.cc:805] Training of tree  229/300 (tree index:229) done accuracy:0.146197 logloss:6.5731\n","[INFO 23-04-29 12:26:39.6150 UTC random_forest.cc:805] Training of tree  239/300 (tree index:238) done accuracy:0.148117 logloss:6.42884\n","[INFO 23-04-29 12:26:50.4463 UTC random_forest.cc:805] Training of tree  249/300 (tree index:248) done accuracy:0.148201 logloss:6.28412\n","[INFO 23-04-29 12:27:01.3350 UTC random_forest.cc:805] Training of tree  259/300 (tree index:259) done accuracy:0.149704 logloss:6.18188\n","[INFO 23-04-29 12:27:10.2009 UTC random_forest.cc:805] Training of tree  269/300 (tree index:268) done accuracy:0.150789 logloss:6.06641\n","[INFO 23-04-29 12:27:21.0642 UTC random_forest.cc:805] Training of tree  279/300 (tree index:278) done accuracy:0.150205 logloss:5.9365\n","[INFO 23-04-29 12:27:31.8022 UTC random_forest.cc:805] Training of tree  289/300 (tree index:288) done accuracy:0.151123 logloss:5.84996\n","[INFO 23-04-29 12:27:43.0477 UTC random_forest.cc:805] Training of tree  299/300 (tree index:298) done accuracy:0.149119 logloss:5.75803\n","[INFO 23-04-29 12:27:43.1154 UTC random_forest.cc:805] Training of tree  300/300 (tree index:299) done accuracy:0.149119 logloss:5.74482\n","[INFO 23-04-29 12:27:43.1156 UTC random_forest.cc:885] Final OOB metrics: accuracy:0.149119 logloss:5.74482\n","[INFO 23-04-29 12:27:44.4237 UTC kernel.cc:926] Export model in log directory: /tmp/tmpoarv9dfo with prefix eb5d89ac4ffc45cb\n","[INFO 23-04-29 12:27:47.0737 UTC kernel.cc:944] Save model in resources\n","[INFO 23-04-29 12:27:47.0809 UTC abstract_model.cc:849] Model self evaluation:\n","Number of predictions (without weights): 11977\n","Number of predictions (with weights): 11977\n","Task: CLASSIFICATION\n","Label: __LABEL\n","\n","Accuracy: 0.149119  CI95[W][0.143787 0.154578]\n","LogLoss: : 5.74482\n","ErrorRate: : 0.850881\n","\n","Default Accuracy: : 0.0991066\n","Default LogLoss: : 3.26515\n","Default ErrorRate: : 0.900893\n","\n","Confusion Table:\n","truth\\prediction\n","    0   1    2    3    4   5  6  7    8   9   10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76\n"," 0  0   0    0    0    0   0  0  0    0   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"," 1  0  45  337   76   48   2  0  0   33   2   64  14   0   0   2   2   0   5   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"," 2  0  53  669  152   74   2  0  0   68  10  113  23   0   0   4   4   0   6   0   3   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"," 3  0  15  356  225   90   3  0  0   29   8  112   9   0   0   1   2   0  12   0   2   1   2   0   0   0   0   1   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"," 4  0  19  285  168  154   3  0  0   14   9   84   8   0   0   1   2   0  10   0   1   1   8   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"," 5  0   9  120   67   43  16  0  0    2   2   45   6   0   0   0   1   0   6   0  11   2   6   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"," 6  0   0    7    1    2   0  0  0    1   0    2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"," 7  0   2   48   13    4   0  0  9    3   0    7   0   0   0   0   0   0   1   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"," 8  0  17  377   56   26   0  0  0  100   3   60  13   1   0   1   3   0   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"," 9  0  25  289   79   47   0  0  0   24  14   67  11   0   0   0   0   0  10   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","10  0  24  425  139   78   4  0  0   33   9  269  16   0   0   1   1   0  19   0   1   0   7   1   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","11  0  21  282   68   29   1  0  0   40   8   83  38   0   0   1   1   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","12  0  11   98   15    7   0  0  0   14   0   20   6  10   0   0   1   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","13  0   3   63   23   16   2  0  0    6   7   27   0   0   0   0   1   0   6   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","14  0  28  283   65   37   2  0  0   20   6   51  11   0   0   3   2   0   4   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","15  0  13  151   62   37   2  0  0    8   3   53   8   0   1   1  47   0   6   0   8   1  10   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","16  0   3   83   32   25   1  0  0   10   4   22   4   0   0   1   0   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","17  0   8  147   69   71   2  0  0    8   8   78   3   3   0   0   3   0  41   0   1   0   3   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","18  0  12   71   33   24   1  0  0    7   2   21   3   0   0   0   2   0   3   0   9   0   3   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","19  0   8  125   66   29   1  0  0    4   2   38   1   0   0   0   5   0   8   0  82   4  13   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","20  0   6   56   25   26   1  0  0    1   4   18   1   0   0   0   4   0   1   0  43   1  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","21  0  15  146   81   79   3  0  0    6   3   46   1   0   0   1  25   0   8   1  43   5  22   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","22  0  12  205   56   21   2  0  0   22   6   47   9   1   0   0   4   0   3   0   0   0   1   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","23  0   0    6    1    3   0  0  0    0   0    1   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","24  0   3   41   14   19   2  0  0    0   0   21   3   0   0   0   1   0   5   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","25  0   7   70   16   12   0  0  0    4   1   10   1   0   0   0   1   0   4   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","26  0   9  218   39   16   1  0  0   17   2   74   7   0   0   2   3   0   5   0   3   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","27  0   7   80   37   18   2  0  0    7   3   15   0   0   0   0   0   0   2   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","28  0   0    7    1    0   0  0  0    0   0    1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","29  0   3   31   23   21   2  0  0    3   0   10   1   0   0   0   1   0   2   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","30  0   1    7    0    2   0  0  0    2   0    5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","31  0   2   49   23   18   1  0  0    7   1   23   0   0   0   1   0   0   2   0   0   0   1   0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","32  0   5   49   40   21   4  0  0    4   1   29   1   0   0   0   1   0   2   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","33  0   1   12    4    3   0  0  0    1   0    5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","34  0   0    7    2    2   1  0  0    0   0    1   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","35  0   0    2    3    0   0  0  0    0   0    1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","36  0   3   24    1    2   0  0  0    5   1    9   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","37  0   0    3    1    0   0  0  0    0   0    1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","38  0   1    6    0    0   0  0  0    0   0    2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","39  0   0    1    0    2   0  0  0    1   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","40  0   2   15    5    2   0  0  0    2   0    5   0   0   0   0   0   0   2   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","41  0   1    5    1    1   0  0  0    0   0    5   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","42  0   0    1    0    0   0  0  0    0   0    1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","43  0   0    6    1    0   0  0  0    0   0    0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","44  0   0    1    0    0   0  0  0    0   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","45  0   0    5    0    0   0  0  0    0   0    2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","46  0   6   53   20   11   1  0  0    4   2   18   3   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","47  0   1    0    1    0   0  0  0    0   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","48  0   1   17    5    2   0  0  0    0   0    4   0   0   0   0   1   0   0   0   2   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","49  0   0    4    1    1   0  0  0    0   0    1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","50  0   2    3    1    0   0  0  0    1   1    2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","51  0   0    0    0    0   0  0  0    0   1    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","52  0   0    1    0    0   0  0  0    0   0    4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","53  0   0    4    1    0   0  0  0    0   0    3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","54  0   0    4    2    0   0  0  0    0   0    2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","55  0   1    0    0    0   0  0  0    0   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","56  0   2    8    0    1   0  0  0    1   0    4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","57  0   0    0    0    0   0  0  0    0   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","58  0   0    1    0    0   0  0  0    0   0    1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","59  0   0    3    3    0   0  0  0    1   1    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","60  0   0    0    0    0   0  0  0    0   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","61  0   0    1    0    0   0  0  0    0   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","62  0   0    1    0    0   0  0  0    0   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","63  0   0    1    0    0   0  0  0    0   0    1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","64  0   0    0    0    0   0  0  0    0   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","65  0   0    0    0    1   0  0  0    0   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","66  0   0    0    0    0   0  0  0    0   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","67  0   0    0    0    0   0  0  0    0   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","68  0   0    0    0    0   0  0  0    0   0    1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","69  0   0    0    0    0   0  0  0    1   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","70  0   0    1    0    0   0  0  0    0   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","71  0   0    2    0    0   0  0  0    0   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","72  0   0    1    0    0   0  0  0    0   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","73  0   0    1    0    0   0  0  0    0   0    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","74  0   0    0    0    0   0  0  0    0   0    1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","75  0   0    0    0    0   0  0  0    0   0    1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","76  0   0    3    1    0   0  0  0    0   0    2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n","Total: 11977\n","\n","One vs other classes:\n","\n","[INFO 23-04-29 12:27:47.5984 UTC kernel.cc:1242] Loading model from path /tmp/tmpoarv9dfo/model/ with prefix eb5d89ac4ffc45cb\n","[INFO 23-04-29 12:27:50.6878 UTC decision_forest.cc:660] Model loaded with 300 root(s), 992624 node(s), and 48 input feature(s).\n","[INFO 23-04-29 12:27:50.6878 UTC abstract_model.cc:1311] Engine \"RandomForestGeneric\" built\n","[INFO 23-04-29 12:27:50.6879 UTC kernel.cc:1074] Use fast generic engine\n"]},{"output_type":"stream","name":"stdout","text":["Model trained in 0:05:24.494697\n","Compiling model...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7efdf2405ab0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: could not get source code\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7efdf2405ab0> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: could not get source code\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","Model compiled.\n"]}]},{"cell_type":"code","source":["rf_model.compile(metrics=[\"accuracy\"])"],"metadata":{"id":"EAX1hp_T6rTy","executionInfo":{"status":"ok","timestamp":1682771329832,"user_tz":-60,"elapsed":17,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["rf_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"rMxlT3g2BSq4","executionInfo":{"status":"ok","timestamp":1682771886641,"user_tz":-60,"elapsed":170,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"outputId":"758b95f1-bb01-4131-c196-98334a9b6370"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"random_forest_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n","=================================================================\n","Total params: 1\n","Trainable params: 0\n","Non-trainable params: 1\n","_________________________________________________________________\n","Type: \"RANDOM_FOREST\"\n","Task: CLASSIFICATION\n","Label: \"__LABEL\"\n","\n","Input Features (255):\n","\tdata:0.0\n","\tdata:0.1\n","\tdata:0.10\n","\tdata:0.100\n","\tdata:0.101\n","\tdata:0.102\n","\tdata:0.103\n","\tdata:0.104\n","\tdata:0.105\n","\tdata:0.106\n","\tdata:0.107\n","\tdata:0.108\n","\tdata:0.109\n","\tdata:0.11\n","\tdata:0.110\n","\tdata:0.111\n","\tdata:0.112\n","\tdata:0.113\n","\tdata:0.114\n","\tdata:0.115\n","\tdata:0.116\n","\tdata:0.117\n","\tdata:0.118\n","\tdata:0.119\n","\tdata:0.12\n","\tdata:0.120\n","\tdata:0.121\n","\tdata:0.122\n","\tdata:0.123\n","\tdata:0.124\n","\tdata:0.125\n","\tdata:0.126\n","\tdata:0.127\n","\tdata:0.128\n","\tdata:0.129\n","\tdata:0.13\n","\tdata:0.130\n","\tdata:0.131\n","\tdata:0.132\n","\tdata:0.133\n","\tdata:0.134\n","\tdata:0.135\n","\tdata:0.136\n","\tdata:0.137\n","\tdata:0.138\n","\tdata:0.139\n","\tdata:0.14\n","\tdata:0.140\n","\tdata:0.141\n","\tdata:0.142\n","\tdata:0.143\n","\tdata:0.144\n","\tdata:0.145\n","\tdata:0.146\n","\tdata:0.147\n","\tdata:0.148\n","\tdata:0.149\n","\tdata:0.15\n","\tdata:0.150\n","\tdata:0.151\n","\tdata:0.152\n","\tdata:0.153\n","\tdata:0.154\n","\tdata:0.155\n","\tdata:0.156\n","\tdata:0.157\n","\tdata:0.158\n","\tdata:0.159\n","\tdata:0.16\n","\tdata:0.160\n","\tdata:0.161\n","\tdata:0.162\n","\tdata:0.163\n","\tdata:0.164\n","\tdata:0.165\n","\tdata:0.166\n","\tdata:0.167\n","\tdata:0.168\n","\tdata:0.169\n","\tdata:0.17\n","\tdata:0.170\n","\tdata:0.171\n","\tdata:0.172\n","\tdata:0.173\n","\tdata:0.174\n","\tdata:0.175\n","\tdata:0.176\n","\tdata:0.177\n","\tdata:0.178\n","\tdata:0.179\n","\tdata:0.18\n","\tdata:0.180\n","\tdata:0.181\n","\tdata:0.182\n","\tdata:0.183\n","\tdata:0.184\n","\tdata:0.185\n","\tdata:0.186\n","\tdata:0.187\n","\tdata:0.188\n","\tdata:0.189\n","\tdata:0.19\n","\tdata:0.190\n","\tdata:0.191\n","\tdata:0.192\n","\tdata:0.193\n","\tdata:0.194\n","\tdata:0.195\n","\tdata:0.196\n","\tdata:0.197\n","\tdata:0.198\n","\tdata:0.199\n","\tdata:0.2\n","\tdata:0.20\n","\tdata:0.200\n","\tdata:0.201\n","\tdata:0.202\n","\tdata:0.203\n","\tdata:0.204\n","\tdata:0.205\n","\tdata:0.206\n","\tdata:0.207\n","\tdata:0.208\n","\tdata:0.209\n","\tdata:0.21\n","\tdata:0.210\n","\tdata:0.211\n","\tdata:0.212\n","\tdata:0.213\n","\tdata:0.214\n","\tdata:0.215\n","\tdata:0.216\n","\tdata:0.217\n","\tdata:0.218\n","\tdata:0.219\n","\tdata:0.22\n","\tdata:0.220\n","\tdata:0.221\n","\tdata:0.222\n","\tdata:0.223\n","\tdata:0.224\n","\tdata:0.225\n","\tdata:0.226\n","\tdata:0.227\n","\tdata:0.228\n","\tdata:0.229\n","\tdata:0.23\n","\tdata:0.230\n","\tdata:0.231\n","\tdata:0.232\n","\tdata:0.233\n","\tdata:0.234\n","\tdata:0.235\n","\tdata:0.236\n","\tdata:0.237\n","\tdata:0.238\n","\tdata:0.239\n","\tdata:0.24\n","\tdata:0.240\n","\tdata:0.241\n","\tdata:0.242\n","\tdata:0.243\n","\tdata:0.244\n","\tdata:0.245\n","\tdata:0.246\n","\tdata:0.247\n","\tdata:0.248\n","\tdata:0.249\n","\tdata:0.25\n","\tdata:0.250\n","\tdata:0.251\n","\tdata:0.252\n","\tdata:0.253\n","\tdata:0.254\n","\tdata:0.26\n","\tdata:0.27\n","\tdata:0.28\n","\tdata:0.29\n","\tdata:0.3\n","\tdata:0.30\n","\tdata:0.31\n","\tdata:0.32\n","\tdata:0.33\n","\tdata:0.34\n","\tdata:0.35\n","\tdata:0.36\n","\tdata:0.37\n","\tdata:0.38\n","\tdata:0.39\n","\tdata:0.4\n","\tdata:0.40\n","\tdata:0.41\n","\tdata:0.42\n","\tdata:0.43\n","\tdata:0.44\n","\tdata:0.45\n","\tdata:0.46\n","\tdata:0.47\n","\tdata:0.48\n","\tdata:0.49\n","\tdata:0.5\n","\tdata:0.50\n","\tdata:0.51\n","\tdata:0.52\n","\tdata:0.53\n","\tdata:0.54\n","\tdata:0.55\n","\tdata:0.56\n","\tdata:0.57\n","\tdata:0.58\n","\tdata:0.59\n","\tdata:0.6\n","\tdata:0.60\n","\tdata:0.61\n","\tdata:0.62\n","\tdata:0.63\n","\tdata:0.64\n","\tdata:0.65\n","\tdata:0.66\n","\tdata:0.67\n","\tdata:0.68\n","\tdata:0.69\n","\tdata:0.7\n","\tdata:0.70\n","\tdata:0.71\n","\tdata:0.72\n","\tdata:0.73\n","\tdata:0.74\n","\tdata:0.75\n","\tdata:0.76\n","\tdata:0.77\n","\tdata:0.78\n","\tdata:0.79\n","\tdata:0.8\n","\tdata:0.80\n","\tdata:0.81\n","\tdata:0.82\n","\tdata:0.83\n","\tdata:0.84\n","\tdata:0.85\n","\tdata:0.86\n","\tdata:0.87\n","\tdata:0.88\n","\tdata:0.89\n","\tdata:0.9\n","\tdata:0.90\n","\tdata:0.91\n","\tdata:0.92\n","\tdata:0.93\n","\tdata:0.94\n","\tdata:0.95\n","\tdata:0.96\n","\tdata:0.97\n","\tdata:0.98\n","\tdata:0.99\n","\n","No weights\n","\n","Variable Importance: INV_MEAN_MIN_DEPTH:\n","    1.  \"data:0.0\"  0.154086 ################\n","    2.  \"data:0.1\"  0.128171 ##########\n","    3. \"data:0.36\"  0.122619 #########\n","    4.  \"data:0.2\"  0.117888 ########\n","    5. \"data:0.35\"  0.106319 ######\n","    6.  \"data:0.3\"  0.100701 #####\n","    7. \"data:0.34\"  0.097722 ####\n","    8. \"data:0.37\"  0.096518 ####\n","    9.  \"data:0.4\"  0.094445 ###\n","   10.  \"data:0.8\"  0.088681 ##\n","   11. \"data:0.33\"  0.084857 #\n","   12. \"data:0.38\"  0.084837 #\n","   13. \"data:0.32\"  0.084831 #\n","   14. \"data:0.18\"  0.083078 #\n","   15.  \"data:0.9\"  0.082828 #\n","   16. \"data:0.11\"  0.082813 #\n","   17. \"data:0.26\"  0.082781 #\n","   18. \"data:0.12\"  0.082461 #\n","   19. \"data:0.25\"  0.082376 #\n","   20. \"data:0.17\"  0.082302 #\n","   21.  \"data:0.7\"  0.081934 #\n","   22. \"data:0.40\"  0.081662 #\n","   23. \"data:0.15\"  0.081607 #\n","   24.  \"data:0.5\"  0.081495 #\n","   25. \"data:0.14\"  0.081235 #\n","   26. \"data:0.27\"  0.081174 #\n","   27. \"data:0.13\"  0.080934 #\n","   28. \"data:0.20\"  0.080874 #\n","   29. \"data:0.28\"  0.080836 #\n","   30. \"data:0.10\"  0.080777 #\n","   31. \"data:0.29\"  0.080666 #\n","   32. \"data:0.16\"  0.080658 #\n","   33. \"data:0.31\"  0.080607 #\n","   34.  \"data:0.6\"  0.080535 #\n","   35. \"data:0.30\"  0.080528 #\n","   36. \"data:0.24\"  0.080302 #\n","   37. \"data:0.21\"  0.080166 \n","   38. \"data:0.19\"  0.080061 \n","   39. \"data:0.23\"  0.080051 \n","   40. \"data:0.22\"  0.079589 \n","   41. \"data:0.39\"  0.078127 \n","   42. \"data:0.42\"  0.077589 \n","   43. \"data:0.41\"  0.077016 \n","   44. \"data:0.43\"  0.075470 \n","   45. \"data:0.45\"  0.075407 \n","   46. \"data:0.44\"  0.075371 \n","   47. \"data:0.46\"  0.075367 \n","   48. \"data:0.47\"  0.075366 \n","\n","Variable Importance: NUM_AS_ROOT:\n","    1. \"data:0.36\" 101.000000 ################\n","    2. \"data:0.35\" 75.000000 ###########\n","    3. \"data:0.34\" 41.000000 ######\n","    4. \"data:0.37\" 40.000000 ######\n","    5. \"data:0.38\" 12.000000 #\n","    6.  \"data:0.1\"  8.000000 \n","    7. \"data:0.33\"  6.000000 \n","    8.  \"data:0.0\"  5.000000 \n","    9.  \"data:0.2\"  3.000000 \n","   10.  \"data:0.3\"  3.000000 \n","   11. \"data:0.32\"  2.000000 \n","   12. \"data:0.39\"  2.000000 \n","   13.  \"data:0.4\"  2.000000 \n","\n","Variable Importance: NUM_NODES:\n","    1.  \"data:0.0\" 18731.000000 ################\n","    2.  \"data:0.1\" 17099.000000 ##############\n","    3.  \"data:0.2\" 14839.000000 ############\n","    4.  \"data:0.4\" 14524.000000 ############\n","    5.  \"data:0.3\" 14260.000000 ############\n","    6.  \"data:0.8\" 13982.000000 ###########\n","    7.  \"data:0.5\" 13932.000000 ###########\n","    8.  \"data:0.7\" 13915.000000 ###########\n","    9.  \"data:0.9\" 13830.000000 ###########\n","   10. \"data:0.17\" 13792.000000 ###########\n","   11. \"data:0.18\" 13788.000000 ###########\n","   12.  \"data:0.6\" 13778.000000 ###########\n","   13. \"data:0.28\" 13771.000000 ###########\n","   14. \"data:0.11\" 13729.000000 ###########\n","   15. \"data:0.10\" 13675.000000 ###########\n","   16. \"data:0.12\" 13654.000000 ###########\n","   17. \"data:0.13\" 13639.000000 ###########\n","   18. \"data:0.20\" 13635.000000 ###########\n","   19. \"data:0.14\" 13617.000000 ###########\n","   20. \"data:0.29\" 13591.000000 ###########\n","   21. \"data:0.21\" 13577.000000 ###########\n","   22. \"data:0.24\" 13562.000000 ###########\n","   23. \"data:0.27\" 13532.000000 ###########\n","   24. \"data:0.15\" 13516.000000 ###########\n","   25. \"data:0.16\" 13516.000000 ###########\n","   26. \"data:0.23\" 13507.000000 ###########\n","   27. \"data:0.19\" 13460.000000 ###########\n","   28. \"data:0.22\" 13457.000000 ###########\n","   29. \"data:0.26\" 13440.000000 ###########\n","   30. \"data:0.30\" 13397.000000 ###########\n","   31. \"data:0.25\" 13244.000000 ###########\n","   32. \"data:0.31\" 13082.000000 ###########\n","   33. \"data:0.32\" 12218.000000 ##########\n","   34. \"data:0.33\" 10713.000000 #########\n","   35. \"data:0.34\" 8596.000000 #######\n","   36. \"data:0.35\" 6455.000000 #####\n","   37. \"data:0.36\" 4635.000000 ###\n","   38. \"data:0.37\" 3122.000000 ##\n","   39. \"data:0.38\" 1755.000000 #\n","   40. \"data:0.39\" 725.000000 \n","   41. \"data:0.40\" 482.000000 \n","   42. \"data:0.41\" 163.000000 \n","   43. \"data:0.42\" 139.000000 \n","   44. \"data:0.43\" 47.000000 \n","   45. \"data:0.45\" 18.000000 \n","   46. \"data:0.44\" 16.000000 \n","   47. \"data:0.46\"  5.000000 \n","   48. \"data:0.47\"  2.000000 \n","\n","Variable Importance: SUM_SCORE:\n","    1.  \"data:0.0\" 515816.086673 ################\n","    2.  \"data:0.1\" 409438.374766 ############\n","    3.  \"data:0.2\" 324886.243130 ##########\n","    4.  \"data:0.4\" 271560.386776 ########\n","    5.  \"data:0.3\" 265069.930771 ########\n","    6.  \"data:0.8\" 256739.469544 #######\n","    7.  \"data:0.9\" 231932.789504 #######\n","    8. \"data:0.18\" 228996.934209 #######\n","    9.  \"data:0.7\" 227498.621075 #######\n","   10. \"data:0.11\" 227406.377909 #######\n","   11. \"data:0.17\" 226968.816475 #######\n","   12.  \"data:0.5\" 224258.354543 ######\n","   13. \"data:0.12\" 223335.493661 ######\n","   14. \"data:0.10\" 223152.132558 ######\n","   15. \"data:0.14\" 221978.880294 ######\n","   16. \"data:0.28\" 221304.753225 ######\n","   17. \"data:0.15\" 221067.732223 ######\n","   18. \"data:0.20\" 220752.529217 ######\n","   19. \"data:0.13\" 220184.899021 ######\n","   20. \"data:0.26\" 220074.684462 ######\n","   21.  \"data:0.6\" 219212.443507 ######\n","   22. \"data:0.27\" 218051.667085 ######\n","   23. \"data:0.23\" 217639.021919 ######\n","   24. \"data:0.21\" 217424.549779 ######\n","   25. \"data:0.16\" 217294.998733 ######\n","   26. \"data:0.29\" 217103.749433 ######\n","   27. \"data:0.24\" 215394.698876 ######\n","   28. \"data:0.30\" 213477.696421 ######\n","   29. \"data:0.19\" 212999.689544 ######\n","   30. \"data:0.25\" 212741.143272 ######\n","   31. \"data:0.31\" 211736.061257 ######\n","   32. \"data:0.22\" 211075.807906 ######\n","   33. \"data:0.32\" 206283.725526 ######\n","   34. \"data:0.33\" 177025.273040 #####\n","   35. \"data:0.34\" 155691.022694 ####\n","   36. \"data:0.35\" 132225.348090 ####\n","   37. \"data:0.36\" 113564.718630 ###\n","   38. \"data:0.37\" 71149.650241 ##\n","   39. \"data:0.38\" 37781.666978 #\n","   40. \"data:0.40\" 18759.580435 \n","   41. \"data:0.39\" 15047.769777 \n","   42. \"data:0.42\" 7020.503755 \n","   43. \"data:0.41\" 4919.897337 \n","   44. \"data:0.43\" 988.513531 \n","   45. \"data:0.45\" 409.590052 \n","   46. \"data:0.44\" 216.281970 \n","   47. \"data:0.46\" 42.905151 \n","   48. \"data:0.47\"  5.982863 \n","\n","\n","\n","Winner takes all: true\n","Out-of-bag evaluation: accuracy:0.149119 logloss:5.74482\n","Number of trees: 300\n","Total number of nodes: 992624\n","\n","Number of nodes by tree:\n","Count: 300 Average: 3308.75 StdDev: 146.711\n","Min: 2683 Max: 3609 Ignored: 0\n","----------------------------------------------\n","[ 2683, 2729)  1   0.33%   0.33%\n","[ 2729, 2775)  0   0.00%   0.33%\n","[ 2775, 2822)  0   0.00%   0.33%\n","[ 2822, 2868)  0   0.00%   0.33%\n","[ 2868, 2914)  2   0.67%   1.00%\n","[ 2914, 2961)  4   1.33%   2.33% #\n","[ 2961, 3007)  3   1.00%   3.33% #\n","[ 3007, 3053)  5   1.67%   5.00% #\n","[ 3053, 3100)  8   2.67%   7.67% ##\n","[ 3100, 3146) 23   7.67%  15.33% #####\n","[ 3146, 3192) 24   8.00%  23.33% #####\n","[ 3192, 3239) 17   5.67%  29.00% ####\n","[ 3239, 3285) 26   8.67%  37.67% ######\n","[ 3285, 3331) 38  12.67%  50.33% #########\n","[ 3331, 3378) 44  14.67%  65.00% ##########\n","[ 3378, 3424) 41  13.67%  78.67% #########\n","[ 3424, 3470) 25   8.33%  87.00% ######\n","[ 3470, 3517) 22   7.33%  94.33% #####\n","[ 3517, 3563) 14   4.67%  99.00% ###\n","[ 3563, 3609]  3   1.00% 100.00% #\n","\n","Depth by leafs:\n","Count: 496462 Average: 12.267 StdDev: 1.99462\n","Min: 4 Max: 15 Ignored: 0\n","----------------------------------------------\n","[  4,  5)    19   0.00%   0.00%\n","[  5,  6)   286   0.06%   0.06%\n","[  6,  7)  1603   0.32%   0.38%\n","[  7,  8)  5099   1.03%   1.41% #\n","[  8,  9) 12634   2.54%   3.96% #\n","[  9, 10) 27526   5.54%   9.50% ###\n","[ 10, 11) 48874   9.84%  19.35% ######\n","[ 11, 12) 71861  14.47%  33.82% ########\n","[ 12, 13) 87528  17.63%  51.45% ##########\n","[ 13, 14) 88182  17.76%  69.21% ##########\n","[ 14, 15) 74182  14.94%  84.15% ########\n","[ 15, 15] 78668  15.85% 100.00% #########\n","\n","Number of training obs by leaf:\n","Count: 496462 Average: 7.23741 StdDev: 4.631\n","Min: 5 Max: 390 Ignored: 0\n","----------------------------------------------\n","[   5,  24) 491363  98.97%  98.97% ##########\n","[  24,  43)   3836   0.77%  99.75%\n","[  43,  62)    764   0.15%  99.90%\n","[  62,  82)    280   0.06%  99.96%\n","[  82, 101)    104   0.02%  99.98%\n","[ 101, 120)     38   0.01%  99.98%\n","[ 120, 140)     28   0.01%  99.99%\n","[ 140, 159)     18   0.00%  99.99%\n","[ 159, 178)     10   0.00% 100.00%\n","[ 178, 198)      8   0.00% 100.00%\n","[ 198, 217)      5   0.00% 100.00%\n","[ 217, 236)      3   0.00% 100.00%\n","[ 236, 255)      1   0.00% 100.00%\n","[ 255, 275)      1   0.00% 100.00%\n","[ 275, 294)      0   0.00% 100.00%\n","[ 294, 313)      1   0.00% 100.00%\n","[ 313, 333)      0   0.00% 100.00%\n","[ 333, 352)      0   0.00% 100.00%\n","[ 352, 371)      1   0.00% 100.00%\n","[ 371, 390]      1   0.00% 100.00%\n","\n","Attribute in nodes:\n","\t18731 : data:0.0 [NUMERICAL]\n","\t17099 : data:0.1 [NUMERICAL]\n","\t14839 : data:0.2 [NUMERICAL]\n","\t14524 : data:0.4 [NUMERICAL]\n","\t14260 : data:0.3 [NUMERICAL]\n","\t13982 : data:0.8 [NUMERICAL]\n","\t13932 : data:0.5 [NUMERICAL]\n","\t13915 : data:0.7 [NUMERICAL]\n","\t13830 : data:0.9 [NUMERICAL]\n","\t13792 : data:0.17 [NUMERICAL]\n","\t13788 : data:0.18 [NUMERICAL]\n","\t13778 : data:0.6 [NUMERICAL]\n","\t13771 : data:0.28 [NUMERICAL]\n","\t13729 : data:0.11 [NUMERICAL]\n","\t13675 : data:0.10 [NUMERICAL]\n","\t13654 : data:0.12 [NUMERICAL]\n","\t13639 : data:0.13 [NUMERICAL]\n","\t13635 : data:0.20 [NUMERICAL]\n","\t13617 : data:0.14 [NUMERICAL]\n","\t13591 : data:0.29 [NUMERICAL]\n","\t13577 : data:0.21 [NUMERICAL]\n","\t13562 : data:0.24 [NUMERICAL]\n","\t13532 : data:0.27 [NUMERICAL]\n","\t13516 : data:0.16 [NUMERICAL]\n","\t13516 : data:0.15 [NUMERICAL]\n","\t13507 : data:0.23 [NUMERICAL]\n","\t13460 : data:0.19 [NUMERICAL]\n","\t13457 : data:0.22 [NUMERICAL]\n","\t13440 : data:0.26 [NUMERICAL]\n","\t13397 : data:0.30 [NUMERICAL]\n","\t13244 : data:0.25 [NUMERICAL]\n","\t13082 : data:0.31 [NUMERICAL]\n","\t12218 : data:0.32 [NUMERICAL]\n","\t10713 : data:0.33 [NUMERICAL]\n","\t8596 : data:0.34 [NUMERICAL]\n","\t6455 : data:0.35 [NUMERICAL]\n","\t4635 : data:0.36 [NUMERICAL]\n","\t3122 : data:0.37 [NUMERICAL]\n","\t1755 : data:0.38 [NUMERICAL]\n","\t725 : data:0.39 [NUMERICAL]\n","\t482 : data:0.40 [NUMERICAL]\n","\t163 : data:0.41 [NUMERICAL]\n","\t139 : data:0.42 [NUMERICAL]\n","\t47 : data:0.43 [NUMERICAL]\n","\t18 : data:0.45 [NUMERICAL]\n","\t16 : data:0.44 [NUMERICAL]\n","\t5 : data:0.46 [NUMERICAL]\n","\t2 : data:0.47 [NUMERICAL]\n","\n","Attribute in nodes with depth <= 0:\n","\t101 : data:0.36 [NUMERICAL]\n","\t75 : data:0.35 [NUMERICAL]\n","\t41 : data:0.34 [NUMERICAL]\n","\t40 : data:0.37 [NUMERICAL]\n","\t12 : data:0.38 [NUMERICAL]\n","\t8 : data:0.1 [NUMERICAL]\n","\t6 : data:0.33 [NUMERICAL]\n","\t5 : data:0.0 [NUMERICAL]\n","\t3 : data:0.3 [NUMERICAL]\n","\t3 : data:0.2 [NUMERICAL]\n","\t2 : data:0.4 [NUMERICAL]\n","\t2 : data:0.39 [NUMERICAL]\n","\t2 : data:0.32 [NUMERICAL]\n","\n","Attribute in nodes with depth <= 1:\n","\t121 : data:0.36 [NUMERICAL]\n","\t104 : data:0.0 [NUMERICAL]\n","\t88 : data:0.2 [NUMERICAL]\n","\t84 : data:0.35 [NUMERICAL]\n","\t69 : data:0.37 [NUMERICAL]\n","\t66 : data:0.1 [NUMERICAL]\n","\t54 : data:0.3 [NUMERICAL]\n","\t52 : data:0.40 [NUMERICAL]\n","\t50 : data:0.34 [NUMERICAL]\n","\t45 : data:0.38 [NUMERICAL]\n","\t44 : data:0.4 [NUMERICAL]\n","\t18 : data:0.39 [NUMERICAL]\n","\t16 : data:0.42 [NUMERICAL]\n","\t16 : data:0.25 [NUMERICAL]\n","\t14 : data:0.41 [NUMERICAL]\n","\t12 : data:0.26 [NUMERICAL]\n","\t11 : data:0.8 [NUMERICAL]\n","\t8 : data:0.33 [NUMERICAL]\n","\t4 : data:0.32 [NUMERICAL]\n","\t4 : data:0.27 [NUMERICAL]\n","\t3 : data:0.12 [NUMERICAL]\n","\t3 : data:0.11 [NUMERICAL]\n","\t2 : data:0.7 [NUMERICAL]\n","\t2 : data:0.24 [NUMERICAL]\n","\t2 : data:0.21 [NUMERICAL]\n","\t2 : data:0.16 [NUMERICAL]\n","\t2 : data:0.15 [NUMERICAL]\n","\t1 : data:0.43 [NUMERICAL]\n","\t1 : data:0.28 [NUMERICAL]\n","\t1 : data:0.17 [NUMERICAL]\n","\t1 : data:0.10 [NUMERICAL]\n","\n","Attribute in nodes with depth <= 2:\n","\t343 : data:0.0 [NUMERICAL]\n","\t268 : data:0.1 [NUMERICAL]\n","\t221 : data:0.2 [NUMERICAL]\n","\t153 : data:0.3 [NUMERICAL]\n","\t136 : data:0.4 [NUMERICAL]\n","\t133 : data:0.36 [NUMERICAL]\n","\t92 : data:0.35 [NUMERICAL]\n","\t90 : data:0.37 [NUMERICAL]\n","\t87 : data:0.40 [NUMERICAL]\n","\t75 : data:0.34 [NUMERICAL]\n","\t56 : data:0.38 [NUMERICAL]\n","\t43 : data:0.42 [NUMERICAL]\n","\t36 : data:0.8 [NUMERICAL]\n","\t27 : data:0.39 [NUMERICAL]\n","\t26 : data:0.25 [NUMERICAL]\n","\t24 : data:0.41 [NUMERICAL]\n","\t24 : data:0.26 [NUMERICAL]\n","\t23 : data:0.33 [NUMERICAL]\n","\t22 : data:0.5 [NUMERICAL]\n","\t20 : data:0.11 [NUMERICAL]\n","\t15 : data:0.7 [NUMERICAL]\n","\t15 : data:0.32 [NUMERICAL]\n","\t14 : data:0.27 [NUMERICAL]\n","\t13 : data:0.18 [NUMERICAL]\n","\t12 : data:0.17 [NUMERICAL]\n","\t12 : data:0.15 [NUMERICAL]\n","\t10 : data:0.24 [NUMERICAL]\n","\t10 : data:0.10 [NUMERICAL]\n","\t9 : data:0.23 [NUMERICAL]\n","\t9 : data:0.12 [NUMERICAL]\n","\t8 : data:0.28 [NUMERICAL]\n","\t8 : data:0.22 [NUMERICAL]\n","\t8 : data:0.21 [NUMERICAL]\n","\t8 : data:0.16 [NUMERICAL]\n","\t7 : data:0.9 [NUMERICAL]\n","\t7 : data:0.30 [NUMERICAL]\n","\t7 : data:0.29 [NUMERICAL]\n","\t5 : data:0.6 [NUMERICAL]\n","\t5 : data:0.19 [NUMERICAL]\n","\t5 : data:0.14 [NUMERICAL]\n","\t5 : data:0.13 [NUMERICAL]\n","\t3 : data:0.43 [NUMERICAL]\n","\t3 : data:0.20 [NUMERICAL]\n","\t2 : data:0.45 [NUMERICAL]\n","\t1 : data:0.31 [NUMERICAL]\n","\n","Attribute in nodes with depth <= 3:\n","\t769 : data:0.0 [NUMERICAL]\n","\t563 : data:0.1 [NUMERICAL]\n","\t453 : data:0.2 [NUMERICAL]\n","\t273 : data:0.3 [NUMERICAL]\n","\t246 : data:0.4 [NUMERICAL]\n","\t153 : data:0.36 [NUMERICAL]\n","\t121 : data:0.40 [NUMERICAL]\n","\t117 : data:0.35 [NUMERICAL]\n","\t114 : data:0.37 [NUMERICAL]\n","\t108 : data:0.8 [NUMERICAL]\n","\t108 : data:0.34 [NUMERICAL]\n","\t75 : data:0.38 [NUMERICAL]\n","\t74 : data:0.5 [NUMERICAL]\n","\t67 : data:0.25 [NUMERICAL]\n","\t65 : data:0.42 [NUMERICAL]\n","\t62 : data:0.15 [NUMERICAL]\n","\t61 : data:0.26 [NUMERICAL]\n","\t54 : data:0.33 [NUMERICAL]\n","\t54 : data:0.10 [NUMERICAL]\n","\t52 : data:0.7 [NUMERICAL]\n","\t50 : data:0.17 [NUMERICAL]\n","\t48 : data:0.27 [NUMERICAL]\n","\t48 : data:0.23 [NUMERICAL]\n","\t47 : data:0.32 [NUMERICAL]\n","\t47 : data:0.16 [NUMERICAL]\n","\t47 : data:0.11 [NUMERICAL]\n","\t45 : data:0.9 [NUMERICAL]\n","\t45 : data:0.30 [NUMERICAL]\n","\t45 : data:0.12 [NUMERICAL]\n","\t44 : data:0.18 [NUMERICAL]\n","\t43 : data:0.28 [NUMERICAL]\n","\t40 : data:0.39 [NUMERICAL]\n","\t38 : data:0.24 [NUMERICAL]\n","\t38 : data:0.19 [NUMERICAL]\n","\t36 : data:0.41 [NUMERICAL]\n","\t36 : data:0.29 [NUMERICAL]\n","\t35 : data:0.13 [NUMERICAL]\n","\t33 : data:0.14 [NUMERICAL]\n","\t31 : data:0.20 [NUMERICAL]\n","\t27 : data:0.31 [NUMERICAL]\n","\t26 : data:0.22 [NUMERICAL]\n","\t24 : data:0.21 [NUMERICAL]\n","\t23 : data:0.6 [NUMERICAL]\n","\t9 : data:0.43 [NUMERICAL]\n","\t6 : data:0.45 [NUMERICAL]\n","\n","Attribute in nodes with depth <= 5:\n","\t2264 : data:0.0 [NUMERICAL]\n","\t1654 : data:0.1 [NUMERICAL]\n","\t1192 : data:0.2 [NUMERICAL]\n","\t776 : data:0.4 [NUMERICAL]\n","\t705 : data:0.3 [NUMERICAL]\n","\t524 : data:0.8 [NUMERICAL]\n","\t430 : data:0.5 [NUMERICAL]\n","\t414 : data:0.17 [NUMERICAL]\n","\t376 : data:0.15 [NUMERICAL]\n","\t374 : data:0.10 [NUMERICAL]\n","\t373 : data:0.25 [NUMERICAL]\n","\t372 : data:0.14 [NUMERICAL]\n","\t369 : data:0.9 [NUMERICAL]\n","\t365 : data:0.7 [NUMERICAL]\n","\t360 : data:0.11 [NUMERICAL]\n","\t356 : data:0.20 [NUMERICAL]\n","\t353 : data:0.12 [NUMERICAL]\n","\t350 : data:0.31 [NUMERICAL]\n","\t338 : data:0.26 [NUMERICAL]\n","\t335 : data:0.34 [NUMERICAL]\n","\t335 : data:0.13 [NUMERICAL]\n","\t334 : data:0.16 [NUMERICAL]\n","\t331 : data:0.23 [NUMERICAL]\n","\t325 : data:0.27 [NUMERICAL]\n","\t324 : data:0.6 [NUMERICAL]\n","\t324 : data:0.29 [NUMERICAL]\n","\t323 : data:0.18 [NUMERICAL]\n","\t321 : data:0.30 [NUMERICAL]\n","\t321 : data:0.28 [NUMERICAL]\n","\t320 : data:0.32 [NUMERICAL]\n","\t318 : data:0.19 [NUMERICAL]\n","\t308 : data:0.24 [NUMERICAL]\n","\t299 : data:0.36 [NUMERICAL]\n","\t298 : data:0.21 [NUMERICAL]\n","\t294 : data:0.22 [NUMERICAL]\n","\t285 : data:0.35 [NUMERICAL]\n","\t277 : data:0.33 [NUMERICAL]\n","\t251 : data:0.37 [NUMERICAL]\n","\t203 : data:0.38 [NUMERICAL]\n","\t192 : data:0.40 [NUMERICAL]\n","\t102 : data:0.39 [NUMERICAL]\n","\t92 : data:0.42 [NUMERICAL]\n","\t55 : data:0.41 [NUMERICAL]\n","\t20 : data:0.43 [NUMERICAL]\n","\t11 : data:0.44 [NUMERICAL]\n","\t10 : data:0.45 [NUMERICAL]\n","\t3 : data:0.46 [NUMERICAL]\n","\t1 : data:0.47 [NUMERICAL]\n","\n","Condition type in nodes:\n","\t496162 : HigherCondition\n","Condition type in nodes with depth <= 0:\n","\t300 : HigherCondition\n","Condition type in nodes with depth <= 1:\n","\t900 : HigherCondition\n","Condition type in nodes with depth <= 2:\n","\t2100 : HigherCondition\n","Condition type in nodes with depth <= 3:\n","\t4500 : HigherCondition\n","Condition type in nodes with depth <= 5:\n","\t18557 : HigherCondition\n","Node format: NOT_SET\n","\n","Training OOB:\n","\ttrees: 1, Out-of-bag evaluation: accuracy:0.0832757 logloss:33.0421\n","\ttrees: 11, Out-of-bag evaluation: accuracy:0.093035 logloss:27.6324\n","\ttrees: 21, Out-of-bag evaluation: accuracy:0.104885 logloss:22.8776\n","\ttrees: 31, Out-of-bag evaluation: accuracy:0.11497 logloss:19.4306\n","\ttrees: 41, Out-of-bag evaluation: accuracy:0.118978 logloss:17.0533\n","\ttrees: 51, Out-of-bag evaluation: accuracy:0.122652 logloss:15.0915\n","\ttrees: 61, Out-of-bag evaluation: accuracy:0.12691 logloss:13.5948\n","\ttrees: 69, Out-of-bag evaluation: accuracy:0.125908 logloss:12.6609\n","\ttrees: 79, Out-of-bag evaluation: accuracy:0.133088 logloss:11.6835\n","\ttrees: 89, Out-of-bag evaluation: accuracy:0.13384 logloss:10.8463\n","\ttrees: 99, Out-of-bag evaluation: accuracy:0.132754 logloss:10.1826\n","\ttrees: 109, Out-of-bag evaluation: accuracy:0.136595 logloss:9.67045\n","\ttrees: 119, Out-of-bag evaluation: accuracy:0.135009 logloss:9.1832\n","\ttrees: 129, Out-of-bag evaluation: accuracy:0.138098 logloss:8.82286\n","\ttrees: 139, Out-of-bag evaluation: accuracy:0.140686 logloss:8.48443\n","\ttrees: 149, Out-of-bag evaluation: accuracy:0.14077 logloss:8.18947\n","\ttrees: 159, Out-of-bag evaluation: accuracy:0.142106 logloss:7.91926\n","\ttrees: 169, Out-of-bag evaluation: accuracy:0.144527 logloss:7.64233\n","\ttrees: 179, Out-of-bag evaluation: accuracy:0.145362 logloss:7.41237\n","\ttrees: 189, Out-of-bag evaluation: accuracy:0.144861 logloss:7.21382\n","\ttrees: 199, Out-of-bag evaluation: accuracy:0.144694 logloss:7.07029\n","\ttrees: 209, Out-of-bag evaluation: accuracy:0.145195 logloss:6.88605\n","\ttrees: 219, Out-of-bag evaluation: accuracy:0.145362 logloss:6.74025\n","\ttrees: 229, Out-of-bag evaluation: accuracy:0.146197 logloss:6.5731\n","\ttrees: 239, Out-of-bag evaluation: accuracy:0.148117 logloss:6.42884\n","\ttrees: 249, Out-of-bag evaluation: accuracy:0.148201 logloss:6.28412\n","\ttrees: 259, Out-of-bag evaluation: accuracy:0.149704 logloss:6.18188\n","\ttrees: 269, Out-of-bag evaluation: accuracy:0.150789 logloss:6.06641\n","\ttrees: 279, Out-of-bag evaluation: accuracy:0.150205 logloss:5.9365\n","\ttrees: 289, Out-of-bag evaluation: accuracy:0.151123 logloss:5.84996\n","\ttrees: 299, Out-of-bag evaluation: accuracy:0.149119 logloss:5.75803\n","\ttrees: 300, Out-of-bag evaluation: accuracy:0.149119 logloss:5.74482\n","\n"]}]},{"cell_type":"code","source":["rf_model.make_inspector().variable_importances()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"AFE3SbyiBgkp","executionInfo":{"status":"ok","timestamp":1682771946668,"user_tz":-60,"elapsed":4,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"outputId":"d85a3489-490c-405f-a402-55f771c7177e"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'NUM_NODES': [(\"data:0.0\" (1; #1), 18731.0),\n","  (\"data:0.1\" (1; #2), 17099.0),\n","  (\"data:0.2\" (1; #113), 14839.0),\n","  (\"data:0.4\" (1; #190), 14524.0),\n","  (\"data:0.3\" (1; #179), 14260.0),\n","  (\"data:0.8\" (1; #234), 13982.0),\n","  (\"data:0.5\" (1; #201), 13932.0),\n","  (\"data:0.7\" (1; #223), 13915.0),\n","  (\"data:0.9\" (1; #245), 13830.0),\n","  (\"data:0.17\" (1; #80), 13792.0),\n","  (\"data:0.18\" (1; #91), 13788.0),\n","  (\"data:0.6\" (1; #212), 13778.0),\n","  (\"data:0.28\" (1; #177), 13771.0),\n","  (\"data:0.11\" (1; #14), 13729.0),\n","  (\"data:0.10\" (1; #3), 13675.0),\n","  (\"data:0.12\" (1; #25), 13654.0),\n","  (\"data:0.13\" (1; #36), 13639.0),\n","  (\"data:0.20\" (1; #114), 13635.0),\n","  (\"data:0.14\" (1; #47), 13617.0),\n","  (\"data:0.29\" (1; #178), 13591.0),\n","  (\"data:0.21\" (1; #125), 13577.0),\n","  (\"data:0.24\" (1; #158), 13562.0),\n","  (\"data:0.27\" (1; #176), 13532.0),\n","  (\"data:0.15\" (1; #58), 13516.0),\n","  (\"data:0.16\" (1; #69), 13516.0),\n","  (\"data:0.23\" (1; #147), 13507.0),\n","  (\"data:0.19\" (1; #102), 13460.0),\n","  (\"data:0.22\" (1; #136), 13457.0),\n","  (\"data:0.26\" (1; #175), 13440.0),\n","  (\"data:0.30\" (1; #180), 13397.0),\n","  (\"data:0.25\" (1; #169), 13244.0),\n","  (\"data:0.31\" (1; #181), 13082.0),\n","  (\"data:0.32\" (1; #182), 12218.0),\n","  (\"data:0.33\" (1; #183), 10713.0),\n","  (\"data:0.34\" (1; #184), 8596.0),\n","  (\"data:0.35\" (1; #185), 6455.0),\n","  (\"data:0.36\" (1; #186), 4635.0),\n","  (\"data:0.37\" (1; #187), 3122.0),\n","  (\"data:0.38\" (1; #188), 1755.0),\n","  (\"data:0.39\" (1; #189), 725.0),\n","  (\"data:0.40\" (1; #191), 482.0),\n","  (\"data:0.41\" (1; #192), 163.0),\n","  (\"data:0.42\" (1; #193), 139.0),\n","  (\"data:0.43\" (1; #194), 47.0),\n","  (\"data:0.45\" (1; #196), 18.0),\n","  (\"data:0.44\" (1; #195), 16.0),\n","  (\"data:0.46\" (1; #197), 5.0),\n","  (\"data:0.47\" (1; #198), 2.0)],\n"," 'SUM_SCORE': [(\"data:0.0\" (1; #1), 515816.086673446),\n","  (\"data:0.1\" (1; #2), 409438.374765981),\n","  (\"data:0.2\" (1; #113), 324886.24312962126),\n","  (\"data:0.4\" (1; #190), 271560.38677556254),\n","  (\"data:0.3\" (1; #179), 265069.93077128194),\n","  (\"data:0.8\" (1; #234), 256739.46954378858),\n","  (\"data:0.9\" (1; #245), 231932.78950355388),\n","  (\"data:0.18\" (1; #91), 228996.9342085272),\n","  (\"data:0.7\" (1; #223), 227498.62107499293),\n","  (\"data:0.11\" (1; #14), 227406.3779091239),\n","  (\"data:0.17\" (1; #80), 226968.8164745213),\n","  (\"data:0.5\" (1; #201), 224258.35454272456),\n","  (\"data:0.12\" (1; #25), 223335.4936610572),\n","  (\"data:0.10\" (1; #3), 223152.13255780656),\n","  (\"data:0.14\" (1; #47), 221978.88029412366),\n","  (\"data:0.28\" (1; #177), 221304.7532252092),\n","  (\"data:0.15\" (1; #58), 221067.73222303088),\n","  (\"data:0.20\" (1; #114), 220752.52921681292),\n","  (\"data:0.13\" (1; #36), 220184.89902088977),\n","  (\"data:0.26\" (1; #175), 220074.68446247),\n","  (\"data:0.6\" (1; #212), 219212.44350725412),\n","  (\"data:0.27\" (1; #176), 218051.6670846194),\n","  (\"data:0.23\" (1; #147), 217639.0219192151),\n","  (\"data:0.21\" (1; #125), 217424.5497786142),\n","  (\"data:0.16\" (1; #69), 217294.9987327559),\n","  (\"data:0.29\" (1; #178), 217103.74943316705),\n","  (\"data:0.24\" (1; #158), 215394.6988762524),\n","  (\"data:0.30\" (1; #180), 213477.69642112404),\n","  (\"data:0.19\" (1; #102), 212999.68954407773),\n","  (\"data:0.25\" (1; #169), 212741.14327231236),\n","  (\"data:0.31\" (1; #181), 211736.0612568967),\n","  (\"data:0.22\" (1; #136), 211075.80790617876),\n","  (\"data:0.32\" (1; #182), 206283.72552610748),\n","  (\"data:0.33\" (1; #183), 177025.27304015495),\n","  (\"data:0.34\" (1; #184), 155691.02269383892),\n","  (\"data:0.35\" (1; #185), 132225.348090393),\n","  (\"data:0.36\" (1; #186), 113564.71862976253),\n","  (\"data:0.37\" (1; #187), 71149.65024115704),\n","  (\"data:0.38\" (1; #188), 37781.66697757691),\n","  (\"data:0.40\" (1; #191), 18759.580434758216),\n","  (\"data:0.39\" (1; #189), 15047.76977740135),\n","  (\"data:0.42\" (1; #193), 7020.503755442798),\n","  (\"data:0.41\" (1; #192), 4919.897337237373),\n","  (\"data:0.43\" (1; #194), 988.5135309323668),\n","  (\"data:0.45\" (1; #196), 409.5900519862771),\n","  (\"data:0.44\" (1; #195), 216.28197024017572),\n","  (\"data:0.46\" (1; #197), 42.905150920152664),\n","  (\"data:0.47\" (1; #198), 5.982862576842308)],\n"," 'INV_MEAN_MIN_DEPTH': [(\"data:0.0\" (1; #1), 0.1540860713972237),\n","  (\"data:0.1\" (1; #2), 0.12817116398905484),\n","  (\"data:0.36\" (1; #186), 0.1226189038833913),\n","  (\"data:0.2\" (1; #113), 0.11788833637430299),\n","  (\"data:0.35\" (1; #185), 0.10631945524337413),\n","  (\"data:0.3\" (1; #179), 0.10070095247645254),\n","  (\"data:0.34\" (1; #184), 0.09772199259950497),\n","  (\"data:0.37\" (1; #187), 0.09651771268252346),\n","  (\"data:0.4\" (1; #190), 0.09444457093567998),\n","  (\"data:0.8\" (1; #234), 0.08868060032782336),\n","  (\"data:0.33\" (1; #183), 0.08485666126688421),\n","  (\"data:0.38\" (1; #188), 0.08483665237822206),\n","  (\"data:0.32\" (1; #182), 0.08483143133266945),\n","  (\"data:0.18\" (1; #91), 0.08307765450466303),\n","  (\"data:0.9\" (1; #245), 0.08282829455564016),\n","  (\"data:0.11\" (1; #14), 0.08281278336098506),\n","  (\"data:0.26\" (1; #175), 0.08278125855691805),\n","  (\"data:0.12\" (1; #25), 0.08246120014902986),\n","  (\"data:0.25\" (1; #169), 0.08237611385828882),\n","  (\"data:0.17\" (1; #80), 0.08230242092200335),\n","  (\"data:0.7\" (1; #223), 0.08193386925638829),\n","  (\"data:0.40\" (1; #191), 0.08166213728414662),\n","  (\"data:0.15\" (1; #58), 0.08160699112583202),\n","  (\"data:0.5\" (1; #201), 0.08149514132988689),\n","  (\"data:0.14\" (1; #47), 0.08123532438749094),\n","  (\"data:0.27\" (1; #176), 0.08117394131630087),\n","  (\"data:0.13\" (1; #36), 0.08093405960898795),\n","  (\"data:0.20\" (1; #114), 0.08087367437668551),\n","  (\"data:0.28\" (1; #177), 0.08083552676285319),\n","  (\"data:0.10\" (1; #3), 0.08077661123713667),\n","  (\"data:0.29\" (1; #178), 0.08066564551599471),\n","  (\"data:0.16\" (1; #69), 0.08065797613532855),\n","  (\"data:0.31\" (1; #181), 0.08060744254962685),\n","  (\"data:0.6\" (1; #212), 0.08053457515341658),\n","  (\"data:0.30\" (1; #180), 0.08052815591837384),\n","  (\"data:0.24\" (1; #158), 0.08030208017667506),\n","  (\"data:0.21\" (1; #125), 0.08016576124059865),\n","  (\"data:0.19\" (1; #102), 0.08006148514019017),\n","  (\"data:0.23\" (1; #147), 0.08005079824111008),\n","  (\"data:0.22\" (1; #136), 0.07958869291884768),\n","  (\"data:0.39\" (1; #189), 0.07812680787318085),\n","  (\"data:0.42\" (1; #193), 0.07758863761308274),\n","  (\"data:0.41\" (1; #192), 0.07701631869844523),\n","  (\"data:0.43\" (1; #194), 0.07547022764009789),\n","  (\"data:0.45\" (1; #196), 0.07540716943012678),\n","  (\"data:0.44\" (1; #195), 0.07537062360092128),\n","  (\"data:0.46\" (1; #197), 0.0753666060081029),\n","  (\"data:0.47\" (1; #198), 0.07536617014018068)],\n"," 'NUM_AS_ROOT': [(\"data:0.36\" (1; #186), 101.0),\n","  (\"data:0.35\" (1; #185), 75.0),\n","  (\"data:0.34\" (1; #184), 41.0),\n","  (\"data:0.37\" (1; #187), 40.0),\n","  (\"data:0.38\" (1; #188), 12.0),\n","  (\"data:0.1\" (1; #2), 8.0),\n","  (\"data:0.33\" (1; #183), 6.0),\n","  (\"data:0.0\" (1; #1), 5.0),\n","  (\"data:0.2\" (1; #113), 3.0),\n","  (\"data:0.3\" (1; #179), 3.0),\n","  (\"data:0.32\" (1; #182), 2.0),\n","  (\"data:0.39\" (1; #189), 2.0),\n","  (\"data:0.4\" (1; #190), 2.0)]}"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["evaluation = rf_model.evaluate(test_dataset, return_dict=True)\n","print()"],"metadata":{"id":"pIVgNCRFMLEF","executionInfo":{"status":"ok","timestamp":1682771330589,"user_tz":-60,"elapsed":763,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"0551f9bd-c08c-4688-bc93-f9f0f5f11b67"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["15/15 [==============================] - 1s 23ms/step - loss: 0.0000e+00 - accuracy: 0.1615\n","\n"]}]},{"cell_type":"code","source":["for name, value in evaluation.items():\n","  print(f\"{name}: {value:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"0d7vVEX_64SJ","executionInfo":{"status":"ok","timestamp":1682771330590,"user_tz":-60,"elapsed":5,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"outputId":"d0921280-3f24-43dc-8f15-ffbd1df55303"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["loss: 0.0000\n","accuracy: 0.1615\n"]}]},{"cell_type":"code","source":["tfdf.model_plotter.plot_model_in_colab(rf_model, tree_idx=0, max_depth=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":405},"id":"DYrXAA_OA4zN","executionInfo":{"status":"ok","timestamp":1682771786886,"user_tz":-60,"elapsed":468,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"outputId":"a40208cf-9ed2-4e8e-b853-fdbc2be26ea5"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<script src=\"https://d3js.org/d3.v6.min.js\"></script>\n","<div id=\"tree_plot_36db0a86d0b04a998a3a203941aee493\"></div>\n","<script>\n","/*\n"," * Copyright 2021 Google LLC.\n"," * Licensed under the Apache License, Version 2.0 (the \"License\");\n"," * you may not use this file except in compliance with the License.\n"," * You may obtain a copy of the License at\n"," *\n"," *     https://www.apache.org/licenses/LICENSE-2.0\n"," *\n"," * Unless required by applicable law or agreed to in writing, software\n"," * distributed under the License is distributed on an \"AS IS\" BASIS,\n"," * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n"," * See the License for the specific language governing permissions and\n"," * limitations under the License.\n"," */\n","\n","/**\n"," *  Plotting of decision trees generated by TF-DF.\n"," *\n"," *  A tree is a recursive structure of node objects.\n"," *  A node contains one or more of the following components:\n"," *\n"," *    - A value: Representing the output of the node. If the node is not a leaf,\n"," *      the value is only present for analysis i.e. it is not used for\n"," *      predictions.\n"," *\n"," *    - A condition : For non-leaf nodes, the condition (also known as split)\n"," *      defines a binary test to branch to the positive or negative child.\n"," *\n"," *    - An explanation: Generally a plot showing the relation between the label\n"," *      and the condition to give insights about the effect of the condition.\n"," *\n"," *    - Two children : For non-leaf nodes, the children nodes. The first\n"," *      children (i.e. \"node.children[0]\") is the negative children (drawn in\n"," *      red). The second children is the positive one (drawn in green).\n"," *\n"," */\n","\n","/**\n"," * Plots a single decision tree into a DOM element.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {!tree} raw_tree Recursive tree structure.\n"," * @param {string} canvas_id Id of the output dom element.\n"," */\n","function display_tree(options, raw_tree, canvas_id) {\n","  console.log(options);\n","\n","  // Determine the node placement.\n","  const tree_struct = d3.tree().nodeSize(\n","      [options.node_y_offset, options.node_x_offset])(d3.hierarchy(raw_tree));\n","\n","  // Boundaries of the node placement.\n","  let x_min = Infinity;\n","  let x_max = -x_min;\n","  let y_min = Infinity;\n","  let y_max = -x_min;\n","\n","  tree_struct.each(d => {\n","    if (d.x > x_max) x_max = d.x;\n","    if (d.x < x_min) x_min = d.x;\n","    if (d.y > y_max) y_max = d.y;\n","    if (d.y < y_min) y_min = d.y;\n","  });\n","\n","  // Size of the plot.\n","  const width = y_max - y_min + options.node_x_size + options.margin * 2;\n","  const height = x_max - x_min + options.node_y_size + options.margin * 2 +\n","      options.node_y_offset - options.node_y_size;\n","\n","  const plot = d3.select(canvas_id);\n","\n","  // Tool tip\n","  options.tooltip = plot.append('div')\n","                        .attr('width', 100)\n","                        .attr('height', 100)\n","                        .style('padding', '4px')\n","                        .style('background', '#fff')\n","                        .style('box-shadow', '4px 4px 0px rgba(0,0,0,0.1)')\n","                        .style('border', '1px solid black')\n","                        .style('font-family', 'sans-serif')\n","                        .style('font-size', options.font_size)\n","                        .style('position', 'absolute')\n","                        .style('z-index', '10')\n","                        .attr('pointer-events', 'none')\n","                        .style('display', 'none');\n","\n","  // Create canvas\n","  const svg = plot.append('svg').attr('width', width).attr('height', height);\n","  const graph =\n","      svg.style('overflow', 'visible')\n","          .append('g')\n","          .attr('font-family', 'sans-serif')\n","          .attr('font-size', options.font_size)\n","          .attr(\n","              'transform',\n","              () => `translate(${options.margin},${\n","                  - x_min + options.node_y_offset / 2 + options.margin})`);\n","\n","  // Plot bounding box.\n","  if (options.show_plot_bounding_box) {\n","    svg.append('rect')\n","        .attr('width', width)\n","        .attr('height', height)\n","        .attr('fill', 'none')\n","        .attr('stroke-width', 1.0)\n","        .attr('stroke', 'black');\n","  }\n","\n","  // Draw the edges.\n","  display_edges(options, graph, tree_struct);\n","\n","  // Draw the nodes.\n","  display_nodes(options, graph, tree_struct);\n","}\n","\n","/**\n"," * Draw the nodes of the tree.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {!graph} graph D3 search handle containing the graph.\n"," * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n"," *     data, etc.).\n"," */\n","function display_nodes(options, graph, tree_struct) {\n","  const nodes = graph.append('g')\n","                    .selectAll('g')\n","                    .data(tree_struct.descendants())\n","                    .join('g')\n","                    .attr('transform', d => `translate(${d.y},${d.x})`);\n","\n","  nodes.append('rect')\n","      .attr('x', 0.5)\n","      .attr('y', 0.5)\n","      .attr('width', options.node_x_size)\n","      .attr('height', options.node_y_size)\n","      .attr('stroke', 'lightgrey')\n","      .attr('stroke-width', 1)\n","      .attr('fill', 'white')\n","      .attr('y', -options.node_y_size / 2);\n","\n","  // Brackets on the right of condition nodes without children.\n","  non_leaf_node_without_children =\n","      nodes.filter(node => node.data.condition != null && node.children == null)\n","          .append('g')\n","          .attr('transform', `translate(${options.node_x_size},0)`);\n","\n","  non_leaf_node_without_children.append('path')\n","      .attr('d', 'M0,0 C 10,0 0,10 10,10')\n","      .attr('fill', 'none')\n","      .attr('stroke-width', 1.0)\n","      .attr('stroke', '#F00');\n","\n","  non_leaf_node_without_children.append('path')\n","      .attr('d', 'M0,0 C 10,0 0,-10 10,-10')\n","      .attr('fill', 'none')\n","      .attr('stroke-width', 1.0)\n","      .attr('stroke', '#0F0');\n","\n","  const node_content = nodes.append('g').attr(\n","      'transform',\n","      `translate(0,${options.node_padding - options.node_y_size / 2})`);\n","\n","  node_content.append(node => create_node_element(options, node));\n","}\n","\n","/**\n"," * Creates the D3 content for a single node.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {!node} node Node to draw.\n"," * @return {!d3} D3 content.\n"," */\n","function create_node_element(options, node) {\n","  // Output accumulator.\n","  let output = {\n","    // Content to draw.\n","    content: d3.create('svg:g'),\n","    // Vertical offset to the next element to draw.\n","    vertical_offset: 0\n","  };\n","\n","  // Conditions.\n","  if (node.data.condition != null) {\n","    display_condition(options, node.data.condition, output);\n","  }\n","\n","  // Values.\n","  if (node.data.value != null) {\n","    display_value(options, node.data.value, output);\n","  }\n","\n","  // Explanations.\n","  if (node.data.explanation != null) {\n","    display_explanation(options, node.data.explanation, output);\n","  }\n","\n","  return output.content.node();\n","}\n","\n","\n","/**\n"," * Adds a single line of text inside of a node.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {string} text Text to display.\n"," * @param {!output} output Output display accumulator.\n"," */\n","function display_node_text(options, text, output) {\n","  output.content.append('text')\n","      .attr('x', options.node_padding)\n","      .attr('y', output.vertical_offset)\n","      .attr('alignment-baseline', 'hanging')\n","      .text(text);\n","  output.vertical_offset += 10;\n","}\n","\n","/**\n"," * Adds a single line of text inside of a node with a tooltip.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {string} text Text to display.\n"," * @param {string} tooltip Text in the Tooltip.\n"," * @param {!output} output Output display accumulator.\n"," */\n","function display_node_text_with_tooltip(options, text, tooltip, output) {\n","  const item = output.content.append('text')\n","                   .attr('x', options.node_padding)\n","                   .attr('alignment-baseline', 'hanging')\n","                   .text(text);\n","\n","  add_tooltip(options, item, () => tooltip);\n","  output.vertical_offset += 10;\n","}\n","\n","/**\n"," * Adds a tooltip to a dom element.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {!dom} target Dom element to equip with a tooltip.\n"," * @param {!func} get_content Generates the html content of the tooltip.\n"," */\n","function add_tooltip(options, target, get_content) {\n","  function show(d) {\n","    options.tooltip.style('display', 'block');\n","    options.tooltip.html(get_content());\n","  }\n","\n","  function hide(d) {\n","    options.tooltip.style('display', 'none');\n","  }\n","\n","  function move(d) {\n","    options.tooltip.style('display', 'block');\n","    options.tooltip.style('left', (d.pageX + 5) + 'px');\n","    options.tooltip.style('top', d.pageY + 'px');\n","  }\n","\n","  target.on('mouseover', show);\n","  target.on('mouseout', hide);\n","  target.on('mousemove', move);\n","}\n","\n","/**\n"," * Adds a condition inside of a node.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {!condition} condition Condition to display.\n"," * @param {!output} output Output display accumulator.\n"," */\n","function display_condition(options, condition, output) {\n","  threshold_format = d3.format('r');\n","\n","  if (condition.type === 'IS_MISSING') {\n","    display_node_text(options, `${condition.attribute} is missing`, output);\n","    return;\n","  }\n","\n","  if (condition.type === 'IS_TRUE') {\n","    display_node_text(options, `${condition.attribute} is true`, output);\n","    return;\n","  }\n","\n","  if (condition.type === 'NUMERICAL_IS_HIGHER_THAN') {\n","    format = d3.format('r');\n","    display_node_text(\n","        options,\n","        `${condition.attribute} >= ${threshold_format(condition.threshold)}`,\n","        output);\n","    return;\n","  }\n","\n","  if (condition.type === 'CATEGORICAL_IS_IN') {\n","    display_node_text_with_tooltip(\n","        options, `${condition.attribute} in [...]`,\n","        `${condition.attribute} in [${condition.mask}]`, output);\n","    return;\n","  }\n","\n","  if (condition.type === 'CATEGORICAL_SET_CONTAINS') {\n","    display_node_text_with_tooltip(\n","        options, `${condition.attribute} intersect [...]`,\n","        `${condition.attribute} intersect [${condition.mask}]`, output);\n","    return;\n","  }\n","\n","  if (condition.type === 'NUMERICAL_SPARSE_OBLIQUE') {\n","    display_node_text_with_tooltip(\n","        options, `Sparse oblique split...`,\n","        `[${condition.attributes}]*[${condition.weights}]>=${\n","            threshold_format(condition.threshold)}`,\n","        output);\n","    return;\n","  }\n","\n","  display_node_text(\n","      options, `Non supported condition ${condition.type}`, output);\n","}\n","\n","/**\n"," * Adds a value inside of a node.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {!value} value Value to display.\n"," * @param {!output} output Output display accumulator.\n"," */\n","function display_value(options, value, output) {\n","  if (value.type === 'PROBABILITY') {\n","    const left_margin = 0;\n","    const right_margin = 50;\n","    const plot_width = options.node_x_size - options.node_padding * 2 -\n","        left_margin - right_margin;\n","\n","    let cusum = Array.from(d3.cumsum(value.distribution));\n","    cusum.unshift(0);\n","    const distribution_plot = output.content.append('g').attr(\n","        'transform', `translate(0,${output.vertical_offset + 0.5})`);\n","\n","    distribution_plot.selectAll('rect')\n","        .data(value.distribution)\n","        .join('rect')\n","        .attr('height', 10)\n","        .attr(\n","            'x',\n","            (d, i) =>\n","                (cusum[i] * plot_width + left_margin + options.node_padding))\n","        .attr('width', (d, i) => d * plot_width)\n","        .style('fill', (d, i) => d3.schemeSet1[i]);\n","\n","    const num_examples =\n","        output.content.append('g')\n","            .attr('transform', `translate(0,${output.vertical_offset})`)\n","            .append('text')\n","            .attr('x', options.node_x_size - options.node_padding)\n","            .attr('alignment-baseline', 'hanging')\n","            .attr('text-anchor', 'end')\n","            .text(`(${value.num_examples})`);\n","\n","    const distribution_details = d3.create('ul');\n","    distribution_details.selectAll('li')\n","        .data(value.distribution)\n","        .join('li')\n","        .append('span')\n","        .text(\n","            (d, i) =>\n","                'class ' + i + ': ' + d3.format('.3%')(value.distribution[i]));\n","\n","    add_tooltip(options, distribution_plot, () => distribution_details.html());\n","    add_tooltip(options, num_examples, () => 'Number of examples');\n","\n","    output.vertical_offset += 10;\n","    return;\n","  }\n","\n","  if (value.type === 'REGRESSION') {\n","    display_node_text(\n","        options,\n","        'value: ' + d3.format('r')(value.value) + ` (` +\n","            d3.format('.6')(value.num_examples) + `)`,\n","        output);\n","    return;\n","  }\n","\n","  display_node_text(options, `Non supported value ${value.type}`, output);\n","}\n","\n","/**\n"," * Adds an explanation inside of a node.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {!explanation} explanation Explanation to display.\n"," * @param {!output} output Output display accumulator.\n"," */\n","function display_explanation(options, explanation, output) {\n","  // Margin before the explanation.\n","  output.vertical_offset += 10;\n","\n","  display_node_text(\n","      options, `Non supported explanation ${explanation.type}`, output);\n","}\n","\n","\n","/**\n"," * Draw the edges of the tree.\n"," * @param {!options} options Dictionary of configurations.\n"," * @param {!graph} graph D3 search handle containing the graph.\n"," * @param {!tree_struct} tree_struct Structure of the tree (node placement,\n"," *     data, etc.).\n"," */\n","function display_edges(options, graph, tree_struct) {\n","  // Draw an edge between a parent and a child node with a bezier.\n","  function draw_single_edge(d) {\n","    return 'M' + (d.source.y + options.node_x_size) + ',' + d.source.x + ' C' +\n","        (d.source.y + options.node_x_size + options.edge_rounding) + ',' +\n","        d.source.x + ' ' + (d.target.y - options.edge_rounding) + ',' +\n","        d.target.x + ' ' + d.target.y + ',' + d.target.x;\n","  }\n","\n","  graph.append('g')\n","      .attr('fill', 'none')\n","      .attr('stroke-width', 1.2)\n","      .selectAll('path')\n","      .data(tree_struct.links())\n","      .join('path')\n","      .attr('d', draw_single_edge)\n","      .attr(\n","          'stroke', d => (d.target === d.source.children[0]) ? '#0F0' : '#F00');\n","}\n","\n","display_tree({\"margin\": 10, \"node_x_size\": 160, \"node_y_size\": 28, \"node_x_offset\": 180, \"node_y_offset\": 33, \"font_size\": 10, \"edge_rounding\": 20, \"node_padding\": 2, \"show_plot_bounding_box\": false}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.05017951072889705, 0.10478416965851214, 0.07138682474743258, 0.061033647824997914, 0.026717875928863655, 0.0011689070718877848, 0.007681389329548301, 0.05468815229189279, 0.04558737580362361, 0.08716707021791767, 0.049344577106120065, 0.014527845036319613, 0.012023044167988646, 0.043834015195791935, 0.03423227853385656, 0.01469483176087501, 0.04107873424062787, 0.0154462720213743, 0.03272939801285798, 0.01636469900642899, 0.0384904400100192, 0.032144944476914086, 0.001085413709610086, 0.01001920347332387, 0.011605577356600151, 0.03565166569257744, 0.016030725557318194, 0.0010019203473323871, 0.007180429155882107, 0.0013358937964431828, 0.011188110545211656, 0.013609418051264924, 0.002087334056942473, 0.0017533606078316774, 0.0009184269850546882, 0.004091174751607247, 0.0003339734491107957, 0.0006679468982215914, 0.0004174668113884946, 0.003256241128830258, 0.0012524004341654838, 8.349336227769892e-05, 0.0006679468982215914, 0.00016698672455539785, 0.0005844535359438924, 0.009935710111046173, 8.349336227769892e-05, 0.003172747766552559, 0.0005009601736661936, 0.0009184269850546882, 0.00016698672455539785, 0.0002504800868330968, 0.0007514402604992904, 0.0002504800868330968, 0.0, 0.001085413709610086, 0.0, 0.0004174668113884946, 0.0003339734491107957, 0.0, 0.0, 8.349336227769892e-05, 0.00016698672455539785, 0.0, 0.0003339734491107957, 0.0, 0.0, 0.0002504800868330968, 0.0, 8.349336227769892e-05, 0.00016698672455539785, 0.00016698672455539785, 0.0, 8.349336227769892e-05, 0.0, 0.0005009601736661936], \"num_examples\": 11977.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.35\", \"threshold\": 0.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.041199129124099815, 0.08172835370959639, 0.08122592530564395, 0.07904873555518338, 0.03600736894992464, 0.0011723329425556857, 0.007033997655334115, 0.034667559872718134, 0.04622341316362418, 0.08993468430748619, 0.04639088929827499, 0.0066990453860324905, 0.019092279350192597, 0.03935689164294088, 0.035337464411321386, 0.016580137330430414, 0.053592363088259924, 0.018254898676938535, 0.030983084910400267, 0.017417518003684476, 0.044046223413163624, 0.028638419025288898, 0.0016747613465081226, 0.015240328253223915, 0.010718472617651985, 0.029308323563892145, 0.016580137330430414, 0.0008373806732540613, 0.010550996483001172, 0.0008373806732540613, 0.013733043041366605, 0.01691508959973204, 0.0016747613465081226, 0.0023446658851113715, 0.0015072852118573103, 0.0016747613465081226, 0.0005024284039524368, 0.0005024284039524368, 0.0003349522693016245, 0.0030145704237146205, 0.000669904538603249, 0.0, 0.0003349522693016245, 0.0, 0.00016747613465081226, 0.008038854463238989, 0.00016747613465081226, 0.002679618154412996, 0.0003349522693016245, 0.0005024284039524368, 0.0, 0.0, 0.0003349522693016245, 0.00016747613465081226, 0.0, 0.0010048568079048736, 0.0, 0.000669904538603249, 0.0005024284039524368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000669904538603249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003349522693016245, 0.0, 0.00016747613465081226, 0.0, 0.000669904538603249], \"num_examples\": 5971.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.38\", \"threshold\": 0.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.029543994861913937, 0.06037251123956326, 0.0783558124598587, 0.08670520231213873, 0.046885035324341684, 0.0, 0.007064868336544637, 0.01605651894669236, 0.04110468850353243, 0.0899165061014772, 0.025048169556840076, 0.0032113037893384713, 0.033397559409120106, 0.03596660244059088, 0.03018625561978163, 0.01798330122029544, 0.08734746307000642, 0.014129736673089274, 0.03018625561978163, 0.011560693641618497, 0.054592164418754016, 0.01798330122029544, 0.0019267822736030828, 0.016698779704560053, 0.012845215157353885, 0.035324341682723186, 0.02697495183044316, 0.0, 0.014771997430956968, 0.0, 0.014129736673089274, 0.02569043031470777, 0.0, 0.007064868336544637, 0.0019267822736030828, 0.0006422607578676942, 0.0, 0.0012845215157353885, 0.0012845215157353885, 0.00449582530507386, 0.0006422607578676942, 0.0, 0.0, 0.0, 0.0, 0.011560693641618497, 0.0, 0.0019267822736030828, 0.0006422607578676942, 0.0012845215157353885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0012845215157353885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"num_examples\": 1557.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.15\", \"threshold\": 2.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.03043170559094126, 0.059447983014861996, 0.07855626326963906, 0.08563340410474168, 0.04670912951167728, 0.0, 0.005661712668082095, 0.017692852087756547, 0.044585987261146494, 0.09483368719037509, 0.02689313517338995, 0.003538570417551309, 0.036093418259023353, 0.03821656050955414, 0.027600849256900213, 0.019815994338287332, 0.08634111818825195, 0.01556970983722576, 0.02689313517338995, 0.012031139419674451, 0.05803255484784147, 0.017692852087756547, 0.0, 0.012031139419674451, 0.009200283085633405, 0.038924274593064405, 0.029016277423920735, 0.0, 0.013446567586694975, 0.0, 0.010615711252653927, 0.01910828025477707, 0.0, 0.006369426751592357, 0.0021231422505307855, 0.0007077140835102619, 0.0, 0.0014154281670205238, 0.0014154281670205238, 0.004953998584571833, 0.0007077140835102619, 0.0, 0.0, 0.0, 0.0, 0.012031139419674451, 0.0, 0.0021231422505307855, 0.0007077140835102619, 0.0014154281670205238, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0014154281670205238, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"num_examples\": 1413.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.40\", \"threshold\": 378.0}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.020833333333333332, 0.06944444444444445, 0.0763888888888889, 0.09722222222222222, 0.04861111111111111, 0.0, 0.020833333333333332, 0.0, 0.006944444444444444, 0.041666666666666664, 0.006944444444444444, 0.0, 0.006944444444444444, 0.013888888888888888, 0.05555555555555555, 0.0, 0.09722222222222222, 0.0, 0.0625, 0.006944444444444444, 0.020833333333333332, 0.020833333333333332, 0.020833333333333332, 0.0625, 0.04861111111111111, 0.0, 0.006944444444444444, 0.0, 0.027777777777777776, 0.0, 0.04861111111111111, 0.09027777777777778, 0.0, 0.013888888888888888, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006944444444444444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"num_examples\": 144.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.21\", \"threshold\": 1616.0}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.045310376076121435, 0.08926144086995923, 0.08223833257816039, 0.0763479836882646, 0.032170367014046214, 0.0015858631626642502, 0.007023108291798822, 0.0412324422292705, 0.04802899864068872, 0.08994109651110105, 0.053919347530584506, 0.00792931581332125, 0.014046216583597644, 0.04055278658812868, 0.03715450838241957, 0.016085183507023107, 0.04168554599003172, 0.01971001359311282, 0.031264159492523785, 0.019483461712732214, 0.04032623470774807, 0.03239691889442682, 0.0015858631626642502, 0.014725872224739466, 0.009968282736746714, 0.02718622564567286, 0.012913457181694609, 0.0011327594019030357, 0.009062075215224286, 0.0011327594019030357, 0.01359311282283643, 0.013819664703217037, 0.0022655188038060714, 0.0006796556411418215, 0.001359311282283643, 0.0020389669234254643, 0.0006796556411418215, 0.00022655188038060717, 0.0, 0.0024920706841866785, 0.0006796556411418215, 0.0, 0.00045310376076121433, 0.0, 0.00022655188038060717, 0.006796556411418215, 0.00022655188038060717, 0.0029451744449478933, 0.00022655188038060717, 0.00022655188038060717, 0.0, 0.0, 0.00045310376076121433, 0.00022655188038060717, 0.0, 0.0009062075215224287, 0.0, 0.0009062075215224287, 0.0006796556411418215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0009062075215224287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00045310376076121433, 0.0, 0.00022655188038060717, 0.0, 0.0009062075215224287], \"num_examples\": 4414.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.11\", \"threshold\": 1006.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.04641567818463126, 0.08715832903558535, 0.09489427539969056, 0.08303249097472924, 0.03403816400206292, 0.0010314595152140279, 0.005157297576070139, 0.021144920061887573, 0.04744713769984528, 0.06549767921609077, 0.036616812790097986, 0.008767405879319236, 0.018050541516245487, 0.04332129963898917, 0.04486848891181021, 0.01598762248581743, 0.042805569881382156, 0.025786487880350695, 0.03558535327488396, 0.012893243940175348, 0.040226921093347086, 0.038164002062919034, 0.0025786487880350697, 0.020113460546673543, 0.009283135636926251, 0.036616812790097986, 0.009798865394533264, 0.0, 0.007220216606498195, 0.0, 0.015471892728210418, 0.017534811758638472, 0.0020629190304280558, 0.0015471892728210418, 0.0015471892728210418, 0.0025786487880350697, 0.0, 0.0, 0.0, 0.0041258380608561115, 0.0010314595152140279, 0.0, 0.0, 0.0, 0.0, 0.008251676121712223, 0.0005157297576070139, 0.0025786487880350697, 0.0005157297576070139, 0.0005157297576070139, 0.0, 0.0, 0.0005157297576070139, 0.0005157297576070139, 0.0, 0.0, 0.0, 0.0, 0.0015471892728210418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0020629190304280558, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0005157297576070139, 0.0, 0.0020629190304280558], \"num_examples\": 1939.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.13\", \"threshold\": 3.5}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.044444444444444446, 0.09090909090909091, 0.07232323232323232, 0.07111111111111111, 0.030707070707070707, 0.00202020202020202, 0.008484848484848486, 0.05696969696969697, 0.048484848484848485, 0.10909090909090909, 0.06747474747474748, 0.007272727272727273, 0.01090909090909091, 0.03838383838383838, 0.03111111111111111, 0.01616161616161616, 0.04080808080808081, 0.01494949494949495, 0.027878787878787878, 0.024646464646464646, 0.04040404040404041, 0.027878787878787878, 0.0008080808080808081, 0.010505050505050505, 0.010505050505050505, 0.019797979797979797, 0.015353535353535354, 0.00202020202020202, 0.010505050505050505, 0.00202020202020202, 0.012121212121212121, 0.01090909090909091, 0.0024242424242424242, 0.0, 0.0012121212121212121, 0.0016161616161616162, 0.0012121212121212121, 0.00040404040404040404, 0.0, 0.0012121212121212121, 0.00040404040404040404, 0.0, 0.0008080808080808081, 0.0, 0.00040404040404040404, 0.0056565656565656566, 0.0, 0.0032323232323232323, 0.0, 0.0, 0.0, 0.0, 0.00040404040404040404, 0.0, 0.0, 0.0016161616161616162, 0.0, 0.0016161616161616162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0008080808080808081, 0.0, 0.0, 0.0, 0.0], \"num_examples\": 2475.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.0\", \"threshold\": 64.5}}]}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.059107559107559104, 0.1277056277056277, 0.06160506160506161, 0.04312354312354312, 0.017482517482517484, 0.0011655011655011655, 0.008325008325008326, 0.07459207459207459, 0.04495504495504495, 0.08441558441558442, 0.05228105228105228, 0.022311022311022312, 0.004995004995004995, 0.04828504828504829, 0.033133533133533136, 0.01282051282051282, 0.02863802863802864, 0.012654012654012654, 0.034465534465534464, 0.015318015318015318, 0.03296703296703297, 0.03563103563103563, 0.0004995004995004995, 0.004828504828504829, 0.012487512487512488, 0.04195804195804196, 0.015484515484515484, 0.0011655011655011655, 0.0038295038295038295, 0.0018315018315018315, 0.008658008658008658, 0.010323010323010324, 0.0024975024975024975, 0.0011655011655011655, 0.000333000333000333, 0.006493506493506494, 0.0001665001665001665, 0.0008325008325008325, 0.0004995004995004995, 0.0034965034965034965, 0.0018315018315018315, 0.0001665001665001665, 0.000999000999000999, 0.000333000333000333, 0.000999000999000999, 0.011821511821511822, 0.0, 0.003663003663003663, 0.000666000666000666, 0.001332001332001332, 0.000333000333000333, 0.0004995004995004995, 0.0011655011655011655, 0.000333000333000333, 0.0, 0.0011655011655011655, 0.0, 0.0001665001665001665, 0.0001665001665001665, 0.0, 0.0, 0.0001665001665001665, 0.000333000333000333, 0.0, 0.0, 0.0, 0.0, 0.0004995004995004995, 0.0, 0.0001665001665001665, 0.000333000333000333, 0.0, 0.0, 0.0, 0.0, 0.000333000333000333], \"num_examples\": 6006.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.2\", \"threshold\": 16.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.057730328192961644, 0.13424278370897588, 0.06583629893238434, 0.042902332937920125, 0.017398181099248716, 0.0011862396204033216, 0.008699090549624358, 0.0804665875840253, 0.04586793198892843, 0.08758402530644524, 0.05476472914195334, 0.023131672597864767, 0.0055357848952155, 0.05061289047054172, 0.031237643337287464, 0.014037168841439305, 0.028667457493080268, 0.01047844998022934, 0.023527085804665875, 0.008896797153024912, 0.02431791221826809, 0.03637801502570186, 0.0005931198102016608, 0.003756425464610518, 0.011862396204033215, 0.044286279161724, 0.01640964808224595, 0.0009885330170027679, 0.0039541320680110716, 0.0017793594306049821, 0.007512850929221036, 0.010676156583629894, 0.0025701858442071963, 0.001383946223803875, 0.00039541320680110717, 0.006919731119019375, 0.00019770660340055358, 0.0009885330170027679, 0.0005931198102016608, 0.003361012257809411, 0.0017793594306049821, 0.00019770660340055358, 0.0011862396204033216, 0.00039541320680110717, 0.00039541320680110717, 0.013641755634638196, 0.0, 0.0017793594306049821, 0.0007908264136022143, 0.0015816528272044287, 0.00039541320680110717, 0.0005931198102016608, 0.001383946223803875, 0.00039541320680110717, 0.0, 0.0011862396204033216, 0.0, 0.00019770660340055358, 0.00019770660340055358, 0.0, 0.0, 0.00019770660340055358, 0.00039541320680110717, 0.0, 0.0, 0.0, 0.0, 0.0005931198102016608, 0.0, 0.00019770660340055358, 0.00039541320680110717, 0.0, 0.0, 0.0, 0.0, 0.00039541320680110717], \"num_examples\": 5058.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.1\", \"threshold\": 323.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.061153174140943505, 0.13570180547466512, 0.07047175305765871, 0.04688410017472335, 0.015142690739662202, 0.00145602795573675, 0.011357018054746652, 0.08328479906814211, 0.05183459522422831, 0.07134536983110076, 0.0553290623179965, 0.0192195690157251, 0.00553290623179965, 0.05358182877111241, 0.028829353523587654, 0.017472335468841003, 0.028538147932440302, 0.00902737332556785, 0.0110658124635993, 0.007280139778683751, 0.02242283051834595, 0.039021549213744906, 0.0008736167734420501, 0.0026208503203261502, 0.011939429237041351, 0.04863133372160745, 0.017763541059988352, 0.0008736167734420501, 0.004368083867210251, 0.0011648223645894002, 0.008736167734420501, 0.0128130460104834, 0.0020384391380314504, 0.0020384391380314504, 0.0005824111822947001, 0.004368083867210251, 0.00029120559114735004, 0.0011648223645894002, 0.0008736167734420501, 0.004076878276062901, 0.0017472335468841002, 0.0, 0.0011648223645894002, 0.0005824111822947001, 0.0005824111822947001, 0.01485148514851485, 0.0, 0.0005824111822947001, 0.0008736167734420501, 0.00145602795573675, 0.0005824111822947001, 0.0, 0.0020384391380314504, 0.0005824111822947001, 0.0, 0.0011648223645894002, 0.0, 0.00029120559114735004, 0.00029120559114735004, 0.0, 0.0, 0.0, 0.0005824111822947001, 0.0, 0.0, 0.0, 0.0, 0.0008736167734420501, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0005824111822947001], \"num_examples\": 3434.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.4\", \"threshold\": 16.5}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.050492610837438424, 0.1311576354679803, 0.05603448275862069, 0.034482758620689655, 0.022167487684729065, 0.0006157635467980296, 0.003078817733990148, 0.07450738916256158, 0.0332512315270936, 0.12192118226600986, 0.05357142857142857, 0.03140394088669951, 0.005541871921182266, 0.04433497536945813, 0.03633004926108374, 0.0067733990147783255, 0.02894088669950739, 0.013546798029556651, 0.049876847290640396, 0.012315270935960592, 0.02832512315270936, 0.03078817733990148, 0.0, 0.006157635467980296, 0.011699507389162561, 0.035098522167487683, 0.013546798029556651, 0.0012315270935960591, 0.003078817733990148, 0.003078817733990148, 0.0049261083743842365, 0.006157635467980296, 0.003694581280788177, 0.0, 0.0, 0.012315270935960592, 0.0, 0.0006157635467980296, 0.0, 0.0018472906403940886, 0.0018472906403940886, 0.0006157635467980296, 0.0012315270935960591, 0.0, 0.0, 0.011083743842364532, 0.0, 0.004310344827586207, 0.0006157635467980296, 0.0018472906403940886, 0.0, 0.0018472906403940886, 0.0, 0.0, 0.0, 0.0012315270935960591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0006157635467980296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0006157635467980296, 0.0012315270935960591, 0.0, 0.0, 0.0, 0.0, 0.0], \"num_examples\": 1624.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.21\", \"threshold\": 1.5}}]}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.06645569620253164, 0.09282700421940929, 0.039029535864978905, 0.04430379746835443, 0.017932489451476793, 0.0010548523206751054, 0.006329113924050633, 0.043248945147679324, 0.04008438818565401, 0.06751054852320675, 0.039029535864978905, 0.017932489451476793, 0.002109704641350211, 0.035864978902953586, 0.043248945147679324, 0.006329113924050633, 0.028481012658227847, 0.024261603375527425, 0.09282700421940929, 0.049578059071729956, 0.07911392405063292, 0.03164556962025317, 0.0, 0.010548523206751054, 0.015822784810126583, 0.029535864978902954, 0.010548523206751054, 0.002109704641350211, 0.0031645569620253164, 0.002109704641350211, 0.014767932489451477, 0.008438818565400843, 0.002109704641350211, 0.0, 0.0, 0.004219409282700422, 0.0, 0.0, 0.0, 0.004219409282700422, 0.002109704641350211, 0.0, 0.0, 0.0, 0.004219409282700422, 0.002109704641350211, 0.0, 0.013713080168776372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0010548523206751054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"num_examples\": 948.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.2\", \"threshold\": 15.5}, \"children\": [{\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.0, 0.0, 0.0, 0.007575757575757576, 0.03787878787878788, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03787878787878788, 0.0, 0.0, 0.022727272727272728, 0.3939393939393939, 0.21212121212121213, 0.24242424242424243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007575757575757576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03787878787878788, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"num_examples\": 132.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.33\", \"threshold\": 4941.5}}, {\"value\": {\"type\": \"PROBABILITY\", \"distribution\": [0.07720588235294118, 0.10784313725490197, 0.04534313725490196, 0.05024509803921569, 0.014705882352941176, 0.0012254901960784314, 0.007352941176470588, 0.05024509803921569, 0.04656862745098039, 0.0784313725490196, 0.04534313725490196, 0.020833333333333332, 0.0024509803921568627, 0.041666666666666664, 0.04411764705882353, 0.007352941176470588, 0.03308823529411765, 0.024509803921568627, 0.04411764705882353, 0.023284313725490197, 0.05269607843137255, 0.03676470588235294, 0.0, 0.012254901960784314, 0.01838235294117647, 0.03431372549019608, 0.011029411764705883, 0.0024509803921568627, 0.003676470588235294, 0.0024509803921568627, 0.01715686274509804, 0.00980392156862745, 0.0024509803921568627, 0.0, 0.0, 0.004901960784313725, 0.0, 0.0, 0.0, 0.004901960784313725, 0.0024509803921568627, 0.0, 0.0, 0.0, 0.004901960784313725, 0.0024509803921568627, 0.0, 0.00980392156862745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0012254901960784314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"num_examples\": 816.0}, \"condition\": {\"type\": \"NUMERICAL_IS_HIGHER_THAN\", \"attribute\": \"data:0.3\", \"threshold\": 16.5}}]}]}]}, \"#tree_plot_36db0a86d0b04a998a3a203941aee493\")\n","</script>\n"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["rf_model.make_inspector().training_logs()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"vSZ06gr4ByEY","executionInfo":{"status":"ok","timestamp":1682772014091,"user_tz":-60,"elapsed":175,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"outputId":"c004a3d3-0840-4c48-b782-25fb1d925190"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[TrainLog(num_trees=1, evaluation=Evaluation(num_examples=4335, accuracy=0.08327566320645906, loss=33.04209259103601, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=11, evaluation=Evaluation(num_examples=11888, accuracy=0.0930349932705249, loss=27.632395626329046, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=21, evaluation=Evaluation(num_examples=11975, accuracy=0.10488517745302714, loss=22.877549845010726, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=31, evaluation=Evaluation(num_examples=11977, accuracy=0.11497035985639141, loss=19.430620743801718, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=41, evaluation=Evaluation(num_examples=11977, accuracy=0.11897804124572096, loss=17.053322800362576, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=51, evaluation=Evaluation(num_examples=11977, accuracy=0.12265174918593971, loss=15.091465022280556, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=61, evaluation=Evaluation(num_examples=11977, accuracy=0.12690991066210236, loss=13.594844568497146, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=69, evaluation=Evaluation(num_examples=11977, accuracy=0.12590799031476999, loss=12.66089998050769, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=79, evaluation=Evaluation(num_examples=11977, accuracy=0.1330884194706521, loss=11.683523747726305, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=89, evaluation=Evaluation(num_examples=11977, accuracy=0.13383985973115137, loss=10.846306794305843, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=99, evaluation=Evaluation(num_examples=11977, accuracy=0.1327544460215413, loss=10.182580948631486, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=109, evaluation=Evaluation(num_examples=11977, accuracy=0.13659514068631542, loss=9.670451902974062, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=119, evaluation=Evaluation(num_examples=11977, accuracy=0.13500876680303917, loss=9.183200234623772, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=129, evaluation=Evaluation(num_examples=11977, accuracy=0.13809802120731401, loss=8.822858071985923, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=139, evaluation=Evaluation(num_examples=11977, accuracy=0.14068631543792268, loss=8.484426369268652, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=149, evaluation=Evaluation(num_examples=11977, accuracy=0.14076980880020037, loss=8.189472439706106, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=159, evaluation=Evaluation(num_examples=11977, accuracy=0.14210570259664357, loss=7.919264269538129, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=169, evaluation=Evaluation(num_examples=11977, accuracy=0.14452701010269683, loss=7.642331303057417, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=179, evaluation=Evaluation(num_examples=11977, accuracy=0.1453619437254738, loss=7.412372244768473, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=189, evaluation=Evaluation(num_examples=11977, accuracy=0.14486098355180763, loss=7.21382090565941, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=199, evaluation=Evaluation(num_examples=11977, accuracy=0.14469399682725223, loss=7.070287970298044, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=209, evaluation=Evaluation(num_examples=11977, accuracy=0.14519495700091842, loss=6.886052211634134, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=219, evaluation=Evaluation(num_examples=11977, accuracy=0.1453619437254738, loss=6.74024872591899, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=229, evaluation=Evaluation(num_examples=11977, accuracy=0.14619687734825082, loss=6.573098169992889, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=239, evaluation=Evaluation(num_examples=11977, accuracy=0.1481172246806379, loss=6.428837022298792, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=249, evaluation=Evaluation(num_examples=11977, accuracy=0.1482007180429156, loss=6.2841167430212765, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=259, evaluation=Evaluation(num_examples=11977, accuracy=0.14970359856391416, loss=6.1818801848385965, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=269, evaluation=Evaluation(num_examples=11977, accuracy=0.15078901227352426, loss=6.066414041970467, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=279, evaluation=Evaluation(num_examples=11977, accuracy=0.15020455873758037, loss=5.936504778856799, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=289, evaluation=Evaluation(num_examples=11977, accuracy=0.15112298572263505, loss=5.849960387744046, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=299, evaluation=Evaluation(num_examples=11977, accuracy=0.14911914502797027, loss=5.758031810186956, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None)),\n"," TrainLog(num_trees=300, evaluation=Evaluation(num_examples=11977, accuracy=0.14911914502797027, loss=5.744823348359079, rmse=None, ndcg=None, aucs=None, auuc=None, qini=None))]"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["logs = rf_model.make_inspector().training_logs()\n","\n","plt.figure(figsize=(12, 4))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\n","plt.xlabel(\"Number of trees\")\n","plt.ylabel(\"Accuracy (out-of-bag)\")\n","\n","plt.subplot(1, 2, 2)\n","plt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])\n","plt.xlabel(\"Number of trees\")\n","plt.ylabel(\"Logloss (out-of-bag)\")\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"id":"CXX0pyoPB0ZQ","executionInfo":{"status":"ok","timestamp":1682772057054,"user_tz":-60,"elapsed":1073,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"outputId":"accce144-6aba-4706-bc9a-d7fbe7538114"},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x400 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["rf_model.save('/content/drive/MyDrive/data/rf_model')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"fzCxqxoF7J1x","executionInfo":{"status":"ok","timestamp":1682772080888,"user_tz":-60,"elapsed":10221,"user":{"displayName":"Robert O'Sullivan","userId":"06333551652984277057"}},"outputId":"f61e2b3a-21c9-4479-f72d-9af2b248d36c"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as call_get_leaves, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1AHW1MpEkMnyJGeC-XtCYfubkNuoj53j2","timestamp":1682690241776},{"file_id":"1t8CEOG31ZTzVbim6MzhEggnLMlDjEGHN","timestamp":1682265544966},{"file_id":"1ANTd2whM0Saw_rBYcnRPhKvvIi3DMsdP","timestamp":1682265505855},{"file_id":"1A1SWDJKPziM1YClileEMO2bHg5u54G5k","timestamp":1682265458889},{"file_id":"1zhoXUZXzTGXLrQtfQviBfoPYUUSObMDC","timestamp":1682265224147}]},"kernelspec":{"display_name":"venv_dl","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}