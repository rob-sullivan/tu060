{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zpot689y7vD3"
      },
      "outputs": [],
      "source": [
        "# data handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "#word cleaning\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# load numpy array from csv file\n",
        "from numpy import loadtxt\n",
        "\n",
        "#for splitting our data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#plotting performance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras.utils as ku\n",
        "import keras.backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAWX6z-WGeMW",
        "outputId": "5a714888-a90a-4a48-e3ee-8ca596fa33f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords') #to remove common words\n",
        "nltk.download('wordnet') #for WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "InPrf5mSGeMY"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade tensorflow_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "av5LNFqwGeMY"
      },
      "outputs": [],
      "source": [
        "#used for transfer learning\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ZPhIBgfXUU8g"
      },
      "outputs": [],
      "source": [
        "#get data from google drive\n",
        "from google.colab import drive, files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKZWTmGEQ5E-",
        "outputId": "db2400f6-cc9e-4835-db63-72577d21bb5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__DUkAw8GeMZ",
        "outputId": "ded1ea0b-4b4e-4197-8edb-3fddc126678b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ],
      "source": [
        "#check that we are using GPU\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nC8OLsOrGeMZ"
      },
      "source": [
        "# Data Preparation\n",
        "Custom functions to help with handling the data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6HDbNBTlGeMb"
      },
      "source": [
        "## Text Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fK8s85b1GeMb"
      },
      "outputs": [],
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text): #ref:https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17\n",
        "    \"\"\"\n",
        "      outputs a cleaned string of text from an input string of text\n",
        "    \"\"\"\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing.\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwords from text\n",
        "    lemmatizer.lemmatize(text) # reduce to root word\n",
        "    return text\n",
        "\n",
        "def encode_text(corpus): #we pass in X and set y as next word\n",
        "    tokenizer = Tokenizer()\n",
        "    ## tokenization\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "    \n",
        "    ## convert data to sequence of tokens \n",
        "    input_sequences = []\n",
        "    for line in corpus:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            n_gram_sequence = token_list[:i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "\n",
        "    max_sequence_len = 129 #max([len(x) for x in input_sequences])\n",
        "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "    \n",
        "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "    label = ku.to_categorical(label, num_classes=total_words)\n",
        "    return predictors, label, total_words, max_sequence_len, tokenizer\n",
        "\n",
        "def encode_text1(X, y, total_words, seq_len=3):\n",
        "  \"\"\"\n",
        "  Input txt and outputs tokenised text.\n",
        "  encode_type: bow = encode documents into vector where the coefficient for \n",
        "  each token is based on counting words\n",
        "  \"\"\"\n",
        "  encoder = Tokenizer()# create the tokenizer\n",
        "  encoder.fit_on_texts(X)\n",
        "\n",
        "  predictors = encoder.texts_to_sequences(X)\n",
        "  predictors = pad_sequences(predictors, padding='post', truncating='post', maxlen=seq_len)\n",
        "\n",
        "  label = encoder.texts_to_sequences(y)\n",
        "  label = pad_sequences(label, padding='post', truncating='post', maxlen=seq_len)\n",
        "\n",
        "  label = ku.to_categorical(y, num_classes=total_words)\n",
        "\n",
        "  # summarize what was learned\n",
        "  print(\"Predictors:\\n\")\n",
        "  print(predictors)\n",
        "  print(type(predictors))\n",
        "  print(len(predictors))\n",
        "  print(predictors.shape)\n",
        "  return predictors, label, encoder\n",
        "  \n",
        "def decode_text(encoder, seq):\n",
        "    seq_to_wrd=encoder.sequences_to_texts(seq)\n",
        "    print(\"Numbers to Texts:\", seq_to_wrd)\n",
        "\n",
        "def train_val_test(X_features, y_target, tc=237, pt_embed=False):\n",
        "    \"\"\"\n",
        "    Splits dataset into 10% for testting, 10% for validation and \n",
        "    the remaining 80% for training data. By first spliting data for \n",
        "    training and test data (90:10), then training with validation.\n",
        "\n",
        "    returns X_train, X_test, X_val, max_words, seq_len\n",
        "    \"\"\"\n",
        "    # Reduce word amount to speed up training\n",
        "    truncate = tc #592 #1183 #2368 #6000 # 23677 \n",
        "    mxw = 23681 #our vocab value we found during data cleaning\n",
        "    sl = truncate\n",
        "\n",
        "    X_train_set, X_test_set, y_train_set, y_test_set = train_test_split(X_features, y_target, test_size=0.1, random_state=42)\n",
        "\n",
        "    X_train_set, X_val_set, y_train_set, y_val_set = train_test_split(X_train_set, y_train_set, test_size=0.1111, random_state=42)\n",
        "\n",
        "    print(\"** Before Truncate **\")\n",
        "    print(\"Training data shape:\", X_train_set.shape)\n",
        "    print(\"Training labels shape:\", y_train_set.shape)\n",
        "    print(\"\\n\")\n",
        "    print(\"Validation data shape:\", X_val_set.shape)\n",
        "    print(\"Validation labels shape:\", y_val_set.shape)\n",
        "    print(\"\\n\")\n",
        "    print(\"Test data shape:\", X_test_set.shape)\n",
        "    print(\"Test labels shape:\", y_test_set.shape)\n",
        "\n",
        "    if(pt_embed):\n",
        "      return X_train_set, X_test_set, X_val_set, y_train_set, y_val_set, y_test_set, mxw, sl\n",
        "    else:\n",
        "      X_train_set = X_train_set[:, :truncate]\n",
        "      X_test_set = X_test_set[:, :truncate]\n",
        "      X_val_set = X_val_set[:, :truncate]\n",
        "\n",
        "      print(\"\\n\")\n",
        "      print(\"** After Truncate: \" + str(truncate) + \" **\")\n",
        "      print(\"Training data shape:\", X_train_set.shape)\n",
        "      print(\"Training labels shape:\", y_train_set.shape)\n",
        "      print(\"\\n\")\n",
        "      print(\"Validation data shape:\", X_val_set.shape)\n",
        "      print(\"Validation labels shape:\", y_val_set.shape)\n",
        "      print(\"\\n\")\n",
        "      print(\"Test data shape:\", X_test_set.shape)\n",
        "      print(\"Test labels shape:\", y_test_set.shape)\n",
        "\n",
        "      return X_train_set, X_test_set, X_val_set, y_train_set, y_val_set, y_test_set, mxw, sl"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KP1J8s8sGeMe"
      },
      "source": [
        "## Model Builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nv9ZLnlMGeMf"
      },
      "outputs": [],
      "source": [
        "def build_generative_lstm(total_words, input_len): #bodyContent: can have 0 to 59,714 per example\n",
        "    model = tf.keras.Sequential()\n",
        "    # Add Input Embedding Layer\n",
        "    model.add(layers.Embedding(total_words, 10, input_length=input_len))\n",
        "    # Add Hidden Layer 1 - LSTM Layer\n",
        "    model.add(layers.LSTM(8, return_sequences=True))\n",
        "    model.add(layers.Dropout(0.1))\n",
        "    model.add(layers.LSTM(8))\n",
        "    #output layer\n",
        "    model.add(layers.Dense(total_words, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perplexity Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def perplexity(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates perplexity metric.\n",
        "    \"\"\"\n",
        "    cross_entropy = K.sparse_categorical_crossentropy(y_true, y_pred)\n",
        "    perplexity = K.pow(2.0, K.mean(cross_entropy))\n",
        "    return perplexity"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-vzzBGpvGeMf"
      },
      "source": [
        "## Text Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "OC8qHXxBGeMf"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_string, encoder, num_generate):\n",
        "    for _ in range(num_generate):\n",
        "        token_list = encoder.texts_to_sequences([start_string])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=128, padding='pre') \n",
        "        classes = model.predict(token_list, verbose=0)\n",
        "        predicted=np.argmax(classes,axis=1)\n",
        "\n",
        "        output_word = \"\"\n",
        "        for word,index in encoder.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        start_string += \" \"+output_word\n",
        "\n",
        "    # Calculate the perplexity of the generated text\n",
        "    #true_next_words = token_list[1:]\n",
        "    #perplexity_score = perplexity(true_next_words, predicted.reshape(-1, len(encoder.word_index)))\n",
        "    #print(\"Perplexity score:\", perplexity_score)\n",
        "\n",
        "    return start_string.title()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "whb009-0IOUe"
      },
      "source": [
        "## Load prepared dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gNBEeCpbGeMg"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/data/guardian_articles_10_perc.csv') #for colab only\n",
        "#df = pd.read_csv('./data/guardian_articles_10_perc.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QtBLgmTUGeMg",
        "outputId": "61359036-3c4f-4a29-9e83-f67e9fd0fa42"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-de240edc-7656-4649-ab56-ed6f08761d05\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>webTitle</th>\n",
              "      <th>bodyContent</th>\n",
              "      <th>sectionName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Saido Berahino has right attitude but he’s not...</td>\n",
              "      <td>Tony Pulis hopes his only transfer business be...</td>\n",
              "      <td>Football</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Angelique Kerber now aims to dislodge Serena W...</td>\n",
              "      <td>Gone midnight and Angelique Kerber was conduct...</td>\n",
              "      <td>Sport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The family building a refugee haven in the sha...</td>\n",
              "      <td>On 9 June 2014 Queenslander and charity worker...</td>\n",
              "      <td>World news</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Exeter keep Saracens in their sights with bonu...</td>\n",
              "      <td>There is no need for calculators this week but...</td>\n",
              "      <td>Sport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Exposed: photography's fabulous fakes</td>\n",
              "      <td>In 1840, Hippolyte Bayard, a pioneer of early ...</td>\n",
              "      <td>Art and design</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de240edc-7656-4649-ab56-ed6f08761d05')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de240edc-7656-4649-ab56-ed6f08761d05 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de240edc-7656-4649-ab56-ed6f08761d05');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            webTitle  \\\n",
              "0  Saido Berahino has right attitude but he’s not...   \n",
              "1  Angelique Kerber now aims to dislodge Serena W...   \n",
              "2  The family building a refugee haven in the sha...   \n",
              "3  Exeter keep Saracens in their sights with bonu...   \n",
              "4              Exposed: photography's fabulous fakes   \n",
              "\n",
              "                                         bodyContent     sectionName  \n",
              "0  Tony Pulis hopes his only transfer business be...        Football  \n",
              "1  Gone midnight and Angelique Kerber was conduct...           Sport  \n",
              "2  On 9 June 2014 Queenslander and charity worker...      World news  \n",
              "3  There is no need for calculators this week but...           Sport  \n",
              "4  In 1840, Hippolyte Bayard, a pioneer of early ...  Art and design  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "f4Pj48uxGeMg"
      },
      "outputs": [],
      "source": [
        "df['webTitle'] = df['webTitle'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "q0hg6tTJGeMh"
      },
      "outputs": [],
      "source": [
        "df['bodyContent'] = df['bodyContent'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WzIP8TvqGeMh"
      },
      "outputs": [],
      "source": [
        "#drop the columns we don't need for further analysis/modelling\n",
        "df = df.drop(columns=['sectionName'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jUk4Sq9sGeMh"
      },
      "outputs": [],
      "source": [
        "df.iloc[:, 0] = df.iloc[:,0].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mi03B0PAGeMh"
      },
      "outputs": [],
      "source": [
        "df.iloc[:, 1] = df.iloc[:,1].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHWMyXYFGeMh",
        "outputId": "16584070-a706-4c7a-a3a8-2ff13bf78fd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WebTitle: 128, bodyContent: 59714\n"
          ]
        }
      ],
      "source": [
        "# Find how many words per row a.k.a the sequence length, but exclude counting spaces\n",
        "# we will use this to pad the output\n",
        "seq_len_wt = int(df.iloc[:, 0].map(len).max())\n",
        "seq_len_wt_bc = int(df.iloc[:, 1].map(len).max())\n",
        "print(\"WebTitle: \" + str(seq_len_wt) + \", bodyContent: \" + str(seq_len_wt_bc)) #max length of each example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqN1aLfzGeMi",
        "outputId": "7d7bf411-5d24-4cf9-993e-a4b98988e0ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['saido berahino right attitude hes fit says west broms pulis'\n",
            " 'angelique kerber aims dislodge serena williams world no1 spot'\n",
            " 'family building refugee shadow isis' ...\n",
            " 'whistleblowers inside un review horrific tale misogyny rape 10 000 deaths'\n",
            " 'tokyo mayoral win huge surprise candidate lately arrived belgium'\n",
            " 'marble head hercules pulled roman shipwreck site greece']\n",
            "(14983,)\n"
          ]
        }
      ],
      "source": [
        "X = df.webTitle.values #len 128\n",
        "#X = df.bodyContent.values #len 59714\n",
        "\n",
        "\n",
        "# print the array\n",
        "print(X)\n",
        "print(X.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NYgXZmHVmdci"
      },
      "source": [
        "## Tokenise Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AF5SJg0pGeMi"
      },
      "outputs": [],
      "source": [
        "predictors, label, total_words, max_sequence_len, encoder = encode_text(X) #592 #1183 #2368 #6000 # 23677 #max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPvmMKOOHe7K",
        "outputId": "87c1556c-42fd-412d-ef0f-ef1b943a0e4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(104694, 128)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictors.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfIjY7yDHhAq",
        "outputId": "79b31cfa-5645-4636-c10a-6273663924c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(104694, 23677)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vFS7f8zUN2Lc"
      },
      "source": [
        "## LSTM Text Generative Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQRAVOJbKEfv",
        "outputId": "9f87670b-a11f-4968-e5cc-17b9e01811d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 128, 10)           236770    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128, 8)            608       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128, 8)            0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 8)                 544       \n",
            "                                                                 \n",
            " dense (Dense)               (None, 23677)             213093    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451,015\n",
            "Trainable params: 451,015\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "LSTM_gen_model = build_generative_lstm(total_words, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYV8hP8mGeMi",
        "outputId": "763cb263-31bb-4f3a-8910-60e3b965d4aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3272/3272 [==============================] - 257s 77ms/step - loss: 9.3236\n",
            "Epoch 2/10\n",
            "3272/3272 [==============================] - 251s 77ms/step - loss: 8.9011\n",
            "Epoch 3/10\n",
            "3272/3272 [==============================] - 273s 83ms/step - loss: 8.7869\n",
            "Epoch 4/10\n",
            "3272/3272 [==============================] - 250s 76ms/step - loss: 8.6993\n",
            "Epoch 5/10\n",
            "3272/3272 [==============================] - 249s 76ms/step - loss: 8.6174\n",
            "Epoch 6/10\n",
            "3272/3272 [==============================] - 250s 77ms/step - loss: 8.5405\n",
            "Epoch 7/10\n",
            "3272/3272 [==============================] - 250s 76ms/step - loss: 8.4620\n",
            "Epoch 8/10\n",
            "3272/3272 [==============================] - 252s 77ms/step - loss: 8.3843\n",
            "Epoch 9/10\n",
            "3272/3272 [==============================] - 250s 77ms/step - loss: 8.3124\n",
            "Epoch 10/10\n",
            "3272/3272 [==============================] - 259s 79ms/step - loss: 8.2468\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6261a13a90>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LSTM_gen_model.fit(predictors, label, epochs=10) #total_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "x2m_xEJzXNsb"
      },
      "outputs": [],
      "source": [
        "seed_text = \"Kanye West scandal over problematic advertising campaign\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1LU8TrBFO-ti",
        "outputId": "e6c3c91a-5384-4a7d-e58a-01475031bb5d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Kanye West Scandal Over Problematic Advertising Campaign New Says John Crace Wilson Williams Crace Williams Wilson Williams'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_next_words = 10\n",
        "generate_text(LSTM_gen_model, seed_text, encoder, predict_next_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OPC2DPNL3dQ",
        "outputId": "daa2eada-8eb8-4213-c6b8-1df827cb84e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "LSTM_gen_model.save('/content/LSTM_gen_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxOWeOjWMHjN",
        "outputId": "0cc4f6ea-f67b-4b36-b099-7e1e80d2896a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: LSTM_gen_model/ (stored 0%)\n",
            "  adding: LSTM_gen_model/keras_metadata.pb (deflated 90%)\n",
            "  adding: LSTM_gen_model/assets/ (stored 0%)\n",
            "  adding: LSTM_gen_model/fingerprint.pb (stored 0%)\n",
            "  adding: LSTM_gen_model/variables/ (stored 0%)\n",
            "  adding: LSTM_gen_model/variables/variables.index (deflated 60%)\n",
            "  adding: LSTM_gen_model/variables/variables.data-00000-of-00001 (deflated 10%)\n",
            "  adding: LSTM_gen_model/saved_model.pb (deflated 91%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r LSTM_gen_model.zip LSTM_gen_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_dFNm-PdMJFY",
        "outputId": "f0811cbf-f30b-4133-ed33-76987bc7b96a"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_01f14f90-7e4a-4051-8dd7-d3d50ebccb78\", \"LSTM_gen_model.zip\", 5035178)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "files.download(\"/content/LSTM_gen_model.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
