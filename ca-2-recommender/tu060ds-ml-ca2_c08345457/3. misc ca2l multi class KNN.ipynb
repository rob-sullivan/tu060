{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21eb6be9",
   "metadata": {},
   "source": [
    "# H&M Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f518981",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f7cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working with files and memory management\n",
    "import gc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd31156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ab935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used during data exploration and model evaluation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "012b9e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working with datetime feature\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c072dea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling missing values where not dropped\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54905caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for evaluating our model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8bc2ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for dimension reduction\n",
    "from sklearn.pipeline import Pipeline # to sequence training events\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2e7fe394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad047f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to provide information to the user when running this notebook\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811fac61",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a307ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get transaction data\n",
    "transactions_train_df = pd.read_csv(\"input/transactions_train.csv\") # import the transactions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3dfedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get product meta data\n",
    "articles_df = pd.read_csv(\"input/articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35b7c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get customer meta data\n",
    "customers_df = pd.read_csv(\"input/customers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15117a70",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis & Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ddb5c6",
   "metadata": {},
   "source": [
    "In this section we first looked at what data was available, it's distribution, what was missing and what opportunities were available to reduce the number of features or dimensions in our dataset. Secondly we determined what models could work well with the data, finally we looked to fix any missing values or encoding categorical variables where needed.\n",
    "\n",
    "An exploritory data analysis was conducted already by various other kaggle contestants such as (Karpov, 2022). Their analysis was reviewed as part of this workbook in order to reduce this EDA section and allow us to focus on model building, prediction and evaluation. \n",
    "\n",
    "Data available consisted of images of every product, detailed metadata of every product, detailed metadata of every customer and purchase details for customers who bought products. These will be refered to as images,articles,customers and transactions respectively. Although it is assumed that images are an important part of how customers decide on the products they purchase, due to the data size and limited processing power, they will not be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1f07d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>663713001</td>\n",
       "      <td>0.050831</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>541518023</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>505221004</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        t_dat                                        customer_id  article_id  \\\n",
       "0  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   663713001   \n",
       "1  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   541518023   \n",
       "2  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   505221004   \n",
       "\n",
       "      price  sales_channel_id  \n",
       "0  0.050831                 2  \n",
       "1  0.030492                 2  \n",
       "2  0.015237                 2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "900f63f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t_dat                   734\n",
       "customer_id         1362281\n",
       "article_id           104547\n",
       "price                  9857\n",
       "sales_channel_id          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_train_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4909276f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>FN</th>\n",
       "      <th>Active</th>\n",
       "      <th>club_member_status</th>\n",
       "      <th>fashion_news_frequency</th>\n",
       "      <th>age</th>\n",
       "      <th>postal_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>49.0</td>\n",
       "      <td>52043ee2162cf5aa7ee79974281641c6f11a68d276429a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2973abc54daa8a5f8ccfe9362140c63247c5eee03f1d93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>64f17e6a330a85798e4998f62d0930d14db8db1c054af6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id  FN  Active  \\\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3... NaN     NaN   \n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e... NaN     NaN   \n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca... NaN     NaN   \n",
       "\n",
       "  club_member_status fashion_news_frequency   age  \\\n",
       "0             ACTIVE                   NONE  49.0   \n",
       "1             ACTIVE                   NONE  25.0   \n",
       "2             ACTIVE                   NONE  24.0   \n",
       "\n",
       "                                         postal_code  \n",
       "0  52043ee2162cf5aa7ee79974281641c6f11a68d276429a...  \n",
       "1  2973abc54daa8a5f8ccfe9362140c63247c5eee03f1d93...  \n",
       "2  64f17e6a330a85798e4998f62d0930d14db8db1c054af6...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bf0ca8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id               1371980\n",
       "FN                              1\n",
       "Active                          1\n",
       "club_member_status              3\n",
       "fashion_news_frequency          4\n",
       "age                            84\n",
       "postal_code                352899\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abe1faa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>prod_name</th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_no</th>\n",
       "      <th>graphical_appearance_name</th>\n",
       "      <th>colour_group_code</th>\n",
       "      <th>colour_group_name</th>\n",
       "      <th>...</th>\n",
       "      <th>department_name</th>\n",
       "      <th>index_code</th>\n",
       "      <th>index_name</th>\n",
       "      <th>index_group_no</th>\n",
       "      <th>index_group_name</th>\n",
       "      <th>section_no</th>\n",
       "      <th>section_name</th>\n",
       "      <th>garment_group_no</th>\n",
       "      <th>garment_group_name</th>\n",
       "      <th>detail_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108775015</td>\n",
       "      <td>108775</td>\n",
       "      <td>Strap top</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>9</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>A</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>16</td>\n",
       "      <td>Womens Everyday Basics</td>\n",
       "      <td>1002</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108775044</td>\n",
       "      <td>108775</td>\n",
       "      <td>Strap top</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>10</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>A</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>16</td>\n",
       "      <td>Womens Everyday Basics</td>\n",
       "      <td>1002</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108775051</td>\n",
       "      <td>108775</td>\n",
       "      <td>Strap top (1)</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010017</td>\n",
       "      <td>Stripe</td>\n",
       "      <td>11</td>\n",
       "      <td>Off White</td>\n",
       "      <td>...</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>A</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>16</td>\n",
       "      <td>Womens Everyday Basics</td>\n",
       "      <td>1002</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  product_code      prod_name  product_type_no product_type_name  \\\n",
       "0   108775015        108775      Strap top              253          Vest top   \n",
       "1   108775044        108775      Strap top              253          Vest top   \n",
       "2   108775051        108775  Strap top (1)              253          Vest top   \n",
       "\n",
       "   product_group_name  graphical_appearance_no graphical_appearance_name  \\\n",
       "0  Garment Upper body                  1010016                     Solid   \n",
       "1  Garment Upper body                  1010016                     Solid   \n",
       "2  Garment Upper body                  1010017                    Stripe   \n",
       "\n",
       "   colour_group_code colour_group_name  ...  department_name index_code  \\\n",
       "0                  9             Black  ...     Jersey Basic          A   \n",
       "1                 10             White  ...     Jersey Basic          A   \n",
       "2                 11         Off White  ...     Jersey Basic          A   \n",
       "\n",
       "   index_name index_group_no  index_group_name section_no  \\\n",
       "0  Ladieswear              1        Ladieswear         16   \n",
       "1  Ladieswear              1        Ladieswear         16   \n",
       "2  Ladieswear              1        Ladieswear         16   \n",
       "\n",
       "             section_name garment_group_no  garment_group_name  \\\n",
       "0  Womens Everyday Basics             1002        Jersey Basic   \n",
       "1  Womens Everyday Basics             1002        Jersey Basic   \n",
       "2  Womens Everyday Basics             1002        Jersey Basic   \n",
       "\n",
       "                               detail_desc  \n",
       "0  Jersey top with narrow shoulder straps.  \n",
       "1  Jersey top with narrow shoulder straps.  \n",
       "2  Jersey top with narrow shoulder straps.  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10f53cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id                      105542\n",
       "product_code                     47224\n",
       "prod_name                        45875\n",
       "product_type_no                    132\n",
       "product_type_name                  131\n",
       "product_group_name                  19\n",
       "graphical_appearance_no             30\n",
       "graphical_appearance_name           30\n",
       "colour_group_code                   50\n",
       "colour_group_name                   50\n",
       "perceived_colour_value_id            8\n",
       "perceived_colour_value_name          8\n",
       "perceived_colour_master_id          20\n",
       "perceived_colour_master_name        20\n",
       "department_no                      299\n",
       "department_name                    250\n",
       "index_code                          10\n",
       "index_name                          10\n",
       "index_group_no                       5\n",
       "index_group_name                     5\n",
       "section_no                          57\n",
       "section_name                        56\n",
       "garment_group_no                    21\n",
       "garment_group_name                  21\n",
       "detail_desc                      43404\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b7d33",
   "metadata": {},
   "source": [
    "There are over 31.9 million transactions and over 3gb in size. With our limited space and processing power, this made working with the dataset slow and unweidly. Instead we were only able to sample this dataset.\n",
    "\n",
    "For the customer's dataset we have 1,37 million customers from 352,899 locations, it is assumed that FN stands for whether h&m have the customers is signed up for fashion news. Several other features are also available such as post code. We will have to convert NaNs into zero values, we will do the same for Active. For Fashion news frequency we will have to encode these orginal categories. This might also determine customer quality for recommendation.\n",
    "\n",
    "105,542 products are in the articles dataset. Regarding columns in this dataset, every item had a unique identifier called the article id, but it also had a product code and a product name. The identifier and the product code were not the same, it was assumed that this was due to size differences or colour variations in H&M's clothing (e.g a v-neck polo shirt could be in a small, medium and large, as well as having two colours, black and white). \n",
    "\n",
    "The product name could probably be dropped later as the product code and name seem to match. This seems to be true for the product type name, colour group name and graphical appearance name. We could drop the names and keep the numbers. We will however keep product group name as there doesn't seem to be a corisponding type_no. We will have to encode this ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d15b5cb",
   "metadata": {},
   "source": [
    "### Making Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb1dda",
   "metadata": {},
   "source": [
    "In a perfect scenario for a recommendation system we would have a table of m users by n items, with each product given a rating r_ij by each user. However We could have hundreds of users and thousands of products. A user may not have tried every product so our table would have missing values. To solve this issue we would need to predict the value for missing cells (rhat_ij). A good prediction would mean a good recommendation to the user. Another way to make recommendations to users would be to rank the top k products for each user. This would be based on information we have available on products and users. In essence the prediction problem boils down to how we rate products.\n",
    "\n",
    "In order for us to rate products we would first need some metric to rate them by. Secondly, we would need to decide the prerequisites that a product must meet to recieve said rating. Thirdly we would then need to calculate the score for each item that satisfies the prerequisites and finally we would output a list of items in decreasing order. Unfortunately, H&M have not provided any labelling for us. W+e must make our own. This makes the problem of recommendation more difficult.\n",
    "\n",
    "In our Transaction dataset we have customers who bought products at a particular price and time. We started here, with these features to try create a simple collaborative model recommendation system. The model tried to learn from a customer's historical purchases and make predictions about their future purchases.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee67e664",
   "metadata": {},
   "source": [
    "Since we don't actual have a customer item ratings like a 1 to 5 rating per item, we will assume qty of purchase indicates customer interest in products. If we have outliers they may bias our data. In this case we can assume that 68% of customer transaction will lie within 1 standard deviation from the mean so we could take anything 3 standard deviations from the mean as rare events (1%) and remove them.\n",
    "\n",
    "We will pick a random customer with a few recent transactions and try to predict their future buying habits based on past data about them. We will configure a dataset of purchase made by the customer in the past. We will then use the meta data of the customer and the products to form a model we can use to predict if the customer will by a certain product or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89abe2c",
   "metadata": {},
   "source": [
    "### Prepare the Transaction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54790a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we will convert our date text into a panda date type.\n",
    "transactions_train_df[\"t_dat\"] = pd.to_datetime(transactions_train_df[\"t_dat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e89f19b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we convert articles to string instead of default int.\n",
    "transactions_train_df['article_id'] = transactions_train_df['article_id'].values.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dafb6c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.178832e+07</td>\n",
       "      <td>3.178832e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.782927e-02</td>\n",
       "      <td>1.704028e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.918113e-02</td>\n",
       "      <td>4.564786e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.694915e-05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.581356e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.540678e-02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.388136e-02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.915254e-01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price  sales_channel_id\n",
       "count  3.178832e+07      3.178832e+07\n",
       "mean   2.782927e-02      1.704028e+00\n",
       "std    1.918113e-02      4.564786e-01\n",
       "min    1.694915e-05      1.000000e+00\n",
       "25%    1.581356e-02      1.000000e+00\n",
       "50%    2.540678e-02      2.000000e+00\n",
       "75%    3.388136e-02      2.000000e+00\n",
       "max    5.915254e-01      2.000000e+00"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to see distributions and std dev\n",
    "transactions_train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7031a96",
   "metadata": {},
   "source": [
    "We will use a 3 week date range between 2020-09-8 and 2020-09-22 to reduce our dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c979f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (transactions_train_df['t_dat'] >= '2020-09-01') & (transactions_train_df['t_dat'] <= '2020-09-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7166890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "798269"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = transactions_train_df.loc[mask]\n",
    "features_df['customer_id'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba3bf45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df[['article_id','customer_id', 't_dat', 'price', 'sales_channel_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c777f8d",
   "metadata": {},
   "source": [
    "### Prepare Product Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "887e06e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we convert articles to string instead of default int.\n",
    "articles_df['article_id'] = articles_df['article_id'].values.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f135bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge product meta data with transactions\n",
    "features_df = features_df.merge(articles_df, left_on='article_id', right_on='article_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a984ecce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['article_id', 'customer_id', 't_dat', 'price', 'sales_channel_id',\n",
       "       'product_code', 'prod_name', 'product_type_no', 'product_type_name',\n",
       "       'product_group_name', 'graphical_appearance_no',\n",
       "       'graphical_appearance_name', 'colour_group_code', 'colour_group_name',\n",
       "       'perceived_colour_value_id', 'perceived_colour_value_name',\n",
       "       'perceived_colour_master_id', 'perceived_colour_master_name',\n",
       "       'department_no', 'department_name', 'index_code', 'index_name',\n",
       "       'index_group_no', 'index_group_name', 'section_no', 'section_name',\n",
       "       'garment_group_no', 'garment_group_name', 'detail_desc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c927a50",
   "metadata": {},
   "source": [
    "Regarding columns in the articles data set, every item had a unique identifier called the article id, but it also had a product code and a product name. The identifier and the product code were not the same, it was assumed that this was due to size differences or colour variations in H&M's clothing (e.g a v-neck polo shirt could be in a small, medium and large, as well as having two colours, black and white). \n",
    "\n",
    "The product name could probably be dropped as the product code and name seem to match. This seems to be true for the product type name, colour group name and graphical appearance name. We could drop the names and keep the numbers. We will however keep product_group_name as there doesn't seem to be a corisponding type_no. We will have to encode this ourselves.\n",
    "\n",
    "There was no missing data so we did not need to do anything like imputing missing data with sklearn SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "001e40fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>t_dat</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_no</th>\n",
       "      <th>colour_group_code</th>\n",
       "      <th>perceived_colour_value_id</th>\n",
       "      <th>perceived_colour_master_id</th>\n",
       "      <th>department_no</th>\n",
       "      <th>index_code</th>\n",
       "      <th>index_group_no</th>\n",
       "      <th>section_no</th>\n",
       "      <th>garment_group_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>777148006</td>\n",
       "      <td>0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37...</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>1</td>\n",
       "      <td>777148</td>\n",
       "      <td>252</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010010</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1626</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>777148006</td>\n",
       "      <td>5ac5e1825104ed5fe3333e75b9337eebc4b45ad761056b...</td>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>1</td>\n",
       "      <td>777148</td>\n",
       "      <td>252</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010010</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1626</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>777148006</td>\n",
       "      <td>0dcf3023ea1992a78a1fcc769b6befc956f7308186496d...</td>\n",
       "      <td>2020-09-06</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>1</td>\n",
       "      <td>777148</td>\n",
       "      <td>252</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010010</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1626</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>777148006</td>\n",
       "      <td>28b30893bbe946358103760387e3dcd09fdb7b077a942f...</td>\n",
       "      <td>2020-09-06</td>\n",
       "      <td>0.042356</td>\n",
       "      <td>2</td>\n",
       "      <td>777148</td>\n",
       "      <td>252</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010010</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1626</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>777148006</td>\n",
       "      <td>278f23c7fac720c2b96b25455d640860bdfa8bb3c867cf...</td>\n",
       "      <td>2020-09-10</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>1</td>\n",
       "      <td>777148</td>\n",
       "      <td>252</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010010</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1626</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798264</th>\n",
       "      <td>737994021</td>\n",
       "      <td>f71529889de7a28df0015fad0a043941ecc98883286ef0...</td>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>1</td>\n",
       "      <td>737994</td>\n",
       "      <td>273</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>1010023</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7917</td>\n",
       "      <td>H</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798265</th>\n",
       "      <td>533261032</td>\n",
       "      <td>f79e372e21c1359dfebc7da0bf7f321d55e47b3275c351...</td>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>2</td>\n",
       "      <td>533261</td>\n",
       "      <td>256</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>6515</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798266</th>\n",
       "      <td>865792012</td>\n",
       "      <td>f82c91decd5f9abd0a7a72eae0d4911b00ed4f5b4f04f9...</td>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>0.008458</td>\n",
       "      <td>2</td>\n",
       "      <td>865792</td>\n",
       "      <td>273</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>1010001</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6525</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798267</th>\n",
       "      <td>772659001</td>\n",
       "      <td>f96661e9e56449885d4c4b90d3227e4abea5e0d2382e2d...</td>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>1</td>\n",
       "      <td>772659</td>\n",
       "      <td>274</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1948</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798268</th>\n",
       "      <td>807775001</td>\n",
       "      <td>fd5ce8716faf00f6a83616f609e0403ac516727d4ca4aa...</td>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>2</td>\n",
       "      <td>807775</td>\n",
       "      <td>272</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5683</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798269 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id                                        customer_id  \\\n",
       "0       777148006  0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37...   \n",
       "1       777148006  5ac5e1825104ed5fe3333e75b9337eebc4b45ad761056b...   \n",
       "2       777148006  0dcf3023ea1992a78a1fcc769b6befc956f7308186496d...   \n",
       "3       777148006  28b30893bbe946358103760387e3dcd09fdb7b077a942f...   \n",
       "4       777148006  278f23c7fac720c2b96b25455d640860bdfa8bb3c867cf...   \n",
       "...           ...                                                ...   \n",
       "798264  737994021  f71529889de7a28df0015fad0a043941ecc98883286ef0...   \n",
       "798265  533261032  f79e372e21c1359dfebc7da0bf7f321d55e47b3275c351...   \n",
       "798266  865792012  f82c91decd5f9abd0a7a72eae0d4911b00ed4f5b4f04f9...   \n",
       "798267  772659001  f96661e9e56449885d4c4b90d3227e4abea5e0d2382e2d...   \n",
       "798268  807775001  fd5ce8716faf00f6a83616f609e0403ac516727d4ca4aa...   \n",
       "\n",
       "            t_dat     price  sales_channel_id  product_code  product_type_no  \\\n",
       "0      2020-09-01  0.013542                 1        777148              252   \n",
       "1      2020-09-03  0.013542                 1        777148              252   \n",
       "2      2020-09-06  0.013542                 1        777148              252   \n",
       "3      2020-09-06  0.042356                 2        777148              252   \n",
       "4      2020-09-10  0.013542                 1        777148              252   \n",
       "...           ...       ...               ...           ...              ...   \n",
       "798264 2020-09-22  0.030492                 1        737994              273   \n",
       "798265 2020-09-22  0.033881                 2        533261              256   \n",
       "798266 2020-09-22  0.008458                 2        865792              273   \n",
       "798267 2020-09-22  0.016932                 1        772659              274   \n",
       "798268 2020-09-22  0.033881                 2        807775              272   \n",
       "\n",
       "        product_group_name  graphical_appearance_no  colour_group_code  \\\n",
       "0       Garment Upper body                  1010010                 52   \n",
       "1       Garment Upper body                  1010010                 52   \n",
       "2       Garment Upper body                  1010010                 52   \n",
       "3       Garment Upper body                  1010010                 52   \n",
       "4       Garment Upper body                  1010010                 52   \n",
       "...                    ...                      ...                ...   \n",
       "798264  Garment Lower body                  1010023                 72   \n",
       "798265  Garment Upper body                  1010016                 17   \n",
       "798266  Garment Lower body                  1010001                 73   \n",
       "798267  Garment Lower body                  1010016                 33   \n",
       "798268  Garment Lower body                  1010016                  9   \n",
       "\n",
       "        perceived_colour_value_id  perceived_colour_master_id  department_no  \\\n",
       "0                               7                           4           1626   \n",
       "1                               7                           4           1626   \n",
       "2                               7                           4           1626   \n",
       "3                               7                           4           1626   \n",
       "4                               7                           4           1626   \n",
       "...                           ...                         ...            ...   \n",
       "798264                          2                           2           7917   \n",
       "798265                          2                          13           6515   \n",
       "798266                          4                           2           6525   \n",
       "798267                          4                           3           1948   \n",
       "798268                          4                           5           5683   \n",
       "\n",
       "       index_code  index_group_no  section_no  garment_group_no  \n",
       "0               A               1          15              1003  \n",
       "1               A               1          15              1003  \n",
       "2               A               1          15              1003  \n",
       "3               A               1          15              1003  \n",
       "4               A               1          15              1003  \n",
       "...           ...             ...         ...               ...  \n",
       "798264          H               4          76              1016  \n",
       "798265          G               4          44              1002  \n",
       "798266          G               4          40              1005  \n",
       "798267          A               1          18              1009  \n",
       "798268          F               3          55              1009  \n",
       "\n",
       "[798269 rows x 17 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.drop(['prod_name',\n",
    "                  'product_type_name',\n",
    "                  'graphical_appearance_name',\n",
    "                  'colour_group_name',\n",
    "                  'perceived_colour_value_name',\n",
    "                  'perceived_colour_master_name',\n",
    "                  'department_name',\n",
    "                  'index_name',\n",
    "                  'index_group_name',\n",
    "                  'section_name',\n",
    "                  'garment_group_name',\n",
    "                  'detail_desc'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a958c366",
   "metadata": {},
   "source": [
    "### Prepare Customer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34b17890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge customer meta data with transactions\n",
    "features_df = features_df.merge(customers_df, left_on='customer_id', right_on='customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd7014be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop post code as it is similar to customer_id\n",
    "features_df = features_df.drop(['postal_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11a97606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we reorganise columns\n",
    "features_df = features_df[['customer_id',#the customer\n",
    "                           'FN',#customer meta data\n",
    "                           'Active',\n",
    "                           'club_member_status', \n",
    "                           'fashion_news_frequency', \n",
    "                           'age',\n",
    "                           'product_code',#product meta data\n",
    "                           'product_type_no',\n",
    "                           'product_group_name',\n",
    "                           'graphical_appearance_no',\n",
    "                           'colour_group_code', \n",
    "                           'perceived_colour_value_id', \n",
    "                           'perceived_colour_master_id', \n",
    "                           'department_no',  \n",
    "                           'index_code', \n",
    "                           'index_group_no',  \n",
    "                           'section_no', \n",
    "                           'garment_group_no', \n",
    "                           't_dat',#transaction meta data\n",
    "                           'price',\n",
    "                           'sales_channel_id', \n",
    "                           'article_id']]#the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fefb671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert from objects and floats to categories and ints\n",
    "features_df['club_member_status'] = features_df['club_member_status'].astype('category')\n",
    "features_df['fashion_news_frequency'] = features_df['fashion_news_frequency'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70241735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missing values\n",
    "def find_missing(df):\n",
    "    missing = df.isnull().sum() # ref: https://stackoverflow.com/questions/59694988/python-pandas-dataframe-find-missing-values\n",
    "    print(df.shape)\n",
    "    print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a516208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(798269, 22)\n",
      "customer_id                        0\n",
      "FN                            443296\n",
      "Active                        448465\n",
      "club_member_status              1358\n",
      "fashion_news_frequency          1752\n",
      "age                             2931\n",
      "product_code                       0\n",
      "product_type_no                    0\n",
      "product_group_name                 0\n",
      "graphical_appearance_no            0\n",
      "colour_group_code                  0\n",
      "perceived_colour_value_id          0\n",
      "perceived_colour_master_id         0\n",
      "department_no                      0\n",
      "index_code                         0\n",
      "index_group_no                     0\n",
      "section_no                         0\n",
      "garment_group_no                   0\n",
      "t_dat                              0\n",
      "price                              0\n",
      "sales_channel_id                   0\n",
      "article_id                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "find_missing(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "261a808a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Garment Upper body'],\n",
       "       ['Garment Upper body'],\n",
       "       ['Garment Lower body'],\n",
       "       ...,\n",
       "       ['Accessories'],\n",
       "       ['Garment Full body'],\n",
       "       ['Garment Upper body']], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.iloc[:, 8:-13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1beae9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>FN</th>\n",
       "      <th>Active</th>\n",
       "      <th>club_member_status</th>\n",
       "      <th>fashion_news_frequency</th>\n",
       "      <th>age</th>\n",
       "      <th>product_code</th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_no</th>\n",
       "      <th>...</th>\n",
       "      <th>perceived_colour_master_id</th>\n",
       "      <th>department_no</th>\n",
       "      <th>index_code</th>\n",
       "      <th>index_group_no</th>\n",
       "      <th>section_no</th>\n",
       "      <th>garment_group_no</th>\n",
       "      <th>t_dat</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>Regularly</td>\n",
       "      <td>44.0</td>\n",
       "      <td>777148</td>\n",
       "      <td>252</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010010</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1626</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1003</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>1</td>\n",
       "      <td>777148006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>Regularly</td>\n",
       "      <td>44.0</td>\n",
       "      <td>835801</td>\n",
       "      <td>252</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1626</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1003</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>0.018627</td>\n",
       "      <td>1</td>\n",
       "      <td>835801001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>Regularly</td>\n",
       "      <td>44.0</td>\n",
       "      <td>923134</td>\n",
       "      <td>272</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>1636</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1005</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>1</td>\n",
       "      <td>923134005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>Regularly</td>\n",
       "      <td>44.0</td>\n",
       "      <td>865929</td>\n",
       "      <td>254</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010001</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1636</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1005</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>1</td>\n",
       "      <td>865929003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>Regularly</td>\n",
       "      <td>44.0</td>\n",
       "      <td>935858</td>\n",
       "      <td>252</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4091</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1001</td>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>1</td>\n",
       "      <td>935858001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id   FN  Active  \\\n",
       "0  0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37...  1.0     1.0   \n",
       "1  0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37...  1.0     1.0   \n",
       "2  0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37...  1.0     1.0   \n",
       "3  0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37...  1.0     1.0   \n",
       "4  0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37...  1.0     1.0   \n",
       "\n",
       "  club_member_status fashion_news_frequency   age  product_code  \\\n",
       "0             ACTIVE              Regularly  44.0        777148   \n",
       "1             ACTIVE              Regularly  44.0        835801   \n",
       "2             ACTIVE              Regularly  44.0        923134   \n",
       "3             ACTIVE              Regularly  44.0        865929   \n",
       "4             ACTIVE              Regularly  44.0        935858   \n",
       "\n",
       "   product_type_no  product_group_name  graphical_appearance_no  ...  \\\n",
       "0              252  Garment Upper body                  1010010  ...   \n",
       "1              252  Garment Upper body                  1010016  ...   \n",
       "2              272  Garment Lower body                  1010016  ...   \n",
       "3              254  Garment Upper body                  1010001  ...   \n",
       "4              252  Garment Upper body                  1010016  ...   \n",
       "\n",
       "   perceived_colour_master_id  department_no  index_code  index_group_no  \\\n",
       "0                           4           1626           A               1   \n",
       "1                           9           1626           A               1   \n",
       "2                          19           1636           A               1   \n",
       "3                          11           1636           A               1   \n",
       "4                           5           4091           D               2   \n",
       "\n",
       "  section_no  garment_group_no      t_dat     price sales_channel_id  \\\n",
       "0         15              1003 2020-09-01  0.013542                1   \n",
       "1         15              1003 2020-09-01  0.018627                1   \n",
       "2         15              1005 2020-09-01  0.012695                1   \n",
       "3         15              1005 2020-09-01  0.016932                1   \n",
       "4         50              1001 2020-09-07  0.016932                1   \n",
       "\n",
       "   article_id  \n",
       "0   777148006  \n",
       "1   835801001  \n",
       "2   923134005  \n",
       "3   865929003  \n",
       "4   935858001  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adbd9810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(798269, 22)\n",
      "customer_id                   0\n",
      "fn                            0\n",
      "active                        0\n",
      "club_member_status            0\n",
      "fashion_news_frequency        0\n",
      "age                           0\n",
      "product_code                  0\n",
      "product_type_no               0\n",
      "product_group_name            0\n",
      "graphical_appearance_no       0\n",
      "colour_group_code             0\n",
      "perceived_colour_value_id     0\n",
      "perceived_colour_master_id    0\n",
      "department_no                 0\n",
      "index_code                    0\n",
      "index_group_no                0\n",
      "section_no                    0\n",
      "garment_group_no              0\n",
      "t_dat                         0\n",
      "price                         0\n",
      "sales_channel_id              0\n",
      "article_id                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "features_df['FN'] = features_df['FN'].fillna(0)\n",
    "features_df['Active'] = features_df['Active'].fillna(0)\n",
    "\n",
    "club_member_status = features_df.iloc[:, 3:-18].values\n",
    "fashion_news_frequency = features_df.iloc[:, 4:-17].values\n",
    "age = features_df.iloc[:, 5:-16].values\n",
    "\n",
    "#ref: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "imputer_med = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imputer_mf = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "#we replace missing values with the most frequent\n",
    "imputer_mf.fit(club_member_status)\n",
    "club_member_status = imputer_mf.transform(club_member_status)\n",
    "\n",
    "imputer_mf.fit(fashion_news_frequency)\n",
    "fashion_news_frequency = imputer_mf.transform(fashion_news_frequency)\n",
    "\n",
    "#we replace any missing age values with the median age\n",
    "imputer_med.fit(age)\n",
    "age = imputer_med.transform(age)\n",
    "\n",
    "#now add corrected columns back into our main customer dataframe\n",
    "features_df.iloc[:, 3:-18] = club_member_status\n",
    "features_df.iloc[:, 4:-17] = fashion_news_frequency\n",
    "features_df.iloc[:, 5:-16] = age\n",
    "\n",
    "#replace minus sign in text and check result of dataset after imputing missing values\n",
    "features_df.columns = features_df.columns.str.replace('-', '')\n",
    "\n",
    "#lower case columns\n",
    "features_df.columns = map(str.lower, features_df.columns)\n",
    "\n",
    "find_missing(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4a1ca1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>fn</th>\n",
       "      <th>active</th>\n",
       "      <th>club_member_status</th>\n",
       "      <th>fashion_news_frequency</th>\n",
       "      <th>age</th>\n",
       "      <th>product_code</th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_no</th>\n",
       "      <th>...</th>\n",
       "      <th>perceived_colour_master_id</th>\n",
       "      <th>department_no</th>\n",
       "      <th>index_code</th>\n",
       "      <th>index_group_no</th>\n",
       "      <th>section_no</th>\n",
       "      <th>garment_group_no</th>\n",
       "      <th>t_dat</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>798264</th>\n",
       "      <td>d5013b57392ac330a87fdf6c04d439594bfb8776afe035...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>34.0</td>\n",
       "      <td>828321</td>\n",
       "      <td>265</td>\n",
       "      <td>Garment Full body</td>\n",
       "      <td>1010014</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4314</td>\n",
       "      <td>J</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1019</td>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>1</td>\n",
       "      <td>828321001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798265</th>\n",
       "      <td>d98a24c79ecfe9e1e52f9ff5d0ffc4f84740c317591530...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>Regularly</td>\n",
       "      <td>75.0</td>\n",
       "      <td>818890</td>\n",
       "      <td>76</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>1010016</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3519</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>1019</td>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>1</td>\n",
       "      <td>818890001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798266</th>\n",
       "      <td>d98a24c79ecfe9e1e52f9ff5d0ffc4f84740c317591530...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>Regularly</td>\n",
       "      <td>75.0</td>\n",
       "      <td>818890</td>\n",
       "      <td>76</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>1010016</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3519</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>1019</td>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>1</td>\n",
       "      <td>818890001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798267</th>\n",
       "      <td>e991c3fcb6730496d8ba1c521121d55fb1dfd0ab98b748...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>Regularly</td>\n",
       "      <td>21.0</td>\n",
       "      <td>930405</td>\n",
       "      <td>265</td>\n",
       "      <td>Garment Full body</td>\n",
       "      <td>1010026</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>1322</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1013</td>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>0.067780</td>\n",
       "      <td>2</td>\n",
       "      <td>930405002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798268</th>\n",
       "      <td>f1b9cf466441305d09034354ccbb6f18faf9deaa99b85b...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>28.0</td>\n",
       "      <td>790006</td>\n",
       "      <td>262</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1201</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1007</td>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>0.084729</td>\n",
       "      <td>2</td>\n",
       "      <td>790006001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_id   fn  active  \\\n",
       "798264  d5013b57392ac330a87fdf6c04d439594bfb8776afe035...  0.0     0.0   \n",
       "798265  d98a24c79ecfe9e1e52f9ff5d0ffc4f84740c317591530...  1.0     1.0   \n",
       "798266  d98a24c79ecfe9e1e52f9ff5d0ffc4f84740c317591530...  1.0     1.0   \n",
       "798267  e991c3fcb6730496d8ba1c521121d55fb1dfd0ab98b748...  1.0     1.0   \n",
       "798268  f1b9cf466441305d09034354ccbb6f18faf9deaa99b85b...  0.0     0.0   \n",
       "\n",
       "       club_member_status fashion_news_frequency   age  product_code  \\\n",
       "798264             ACTIVE                   NONE  34.0        828321   \n",
       "798265             ACTIVE              Regularly  75.0        818890   \n",
       "798266             ACTIVE              Regularly  75.0        818890   \n",
       "798267             ACTIVE              Regularly  21.0        930405   \n",
       "798268             ACTIVE                   NONE  28.0        790006   \n",
       "\n",
       "        product_type_no  product_group_name  graphical_appearance_no  ...  \\\n",
       "798264              265   Garment Full body                  1010014  ...   \n",
       "798265               76         Accessories                  1010016  ...   \n",
       "798266               76         Accessories                  1010016  ...   \n",
       "798267              265   Garment Full body                  1010026  ...   \n",
       "798268              262  Garment Upper body                  1010016  ...   \n",
       "\n",
       "        perceived_colour_master_id  department_no  index_code  index_group_no  \\\n",
       "798264                           5           4314           J               4   \n",
       "798265                           5           3519           C               1   \n",
       "798266                           5           3519           C               1   \n",
       "798267                          20           1322           A               1   \n",
       "798268                           5           1201           A               1   \n",
       "\n",
       "       section_no  garment_group_no      t_dat     price sales_channel_id  \\\n",
       "798264         43              1019 2020-09-22  0.033881                1   \n",
       "798265         65              1019 2020-09-22  0.016932                1   \n",
       "798266         65              1019 2020-09-22  0.016932                1   \n",
       "798267         15              1013 2020-09-22  0.067780                2   \n",
       "798268         19              1007 2020-09-22  0.084729                2   \n",
       "\n",
       "        article_id  \n",
       "798264   828321001  \n",
       "798265   818890001  \n",
       "798266   818890001  \n",
       "798267   930405002  \n",
       "798268   790006001  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will encode and scale after we have split our data\n",
    "features_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c1954",
   "metadata": {},
   "source": [
    "### Split Data Into Train & Test Set \n",
    "We take the past 2 weeks as training data and 1 week in the future as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5bf142be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32130"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mask = (features_df['t_dat'] >= '2020-09-21') & (features_df['t_dat'] <= '2020-09-21')\n",
    "train_df = features_df.loc[train_mask]\n",
    "train_df['customer_id'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "13717566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32866"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mask = (features_df['t_dat'] >= '2020-09-22') & (features_df['t_dat'] <= '2020-09-22')\n",
    "test_df = features_df.loc[test_mask]\n",
    "test_df['customer_id'].size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b497f4cd",
   "metadata": {},
   "source": [
    "### Encode Data (After Timesplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "260fe100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\newlo\\AppData\\Local\\Temp\\ipykernel_4848\\2122401799.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.iloc[:,3] = le.fit_transform(train_df.iloc[:,3])#club_member_status\n",
      "C:\\Users\\newlo\\AppData\\Local\\Temp\\ipykernel_4848\\2122401799.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.iloc[:,4] = le.fit_transform(train_df.iloc[:,4])#fashion_news_frequency\n",
      "C:\\Users\\newlo\\AppData\\Local\\Temp\\ipykernel_4848\\2122401799.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.iloc[:,8] = le.fit_transform(train_df.iloc[:,8])#product_group_name\n",
      "C:\\Users\\newlo\\AppData\\Local\\Temp\\ipykernel_4848\\2122401799.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.iloc[:,14] = le.fit_transform(train_df.iloc[:,14])#index_code\n",
      "C:\\Users\\newlo\\AppData\\Local\\Temp\\ipykernel_4848\\2122401799.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.iloc[:,3] = le.fit_transform(test_df.iloc[:,3])#club_member_status\n",
      "C:\\Users\\newlo\\AppData\\Local\\Temp\\ipykernel_4848\\2122401799.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.iloc[:,4] = le.fit_transform(test_df.iloc[:,4])#fashion_news_frequency\n",
      "C:\\Users\\newlo\\AppData\\Local\\Temp\\ipykernel_4848\\2122401799.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.iloc[:,8] = le.fit_transform(test_df.iloc[:,8])#product_group_name\n",
      "C:\\Users\\newlo\\AppData\\Local\\Temp\\ipykernel_4848\\2122401799.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.iloc[:,14] = le.fit_transform(test_df.iloc[:,14])#index_code\n"
     ]
    }
   ],
   "source": [
    "#we now encode any categorical variables in our training and testing data\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_df.iloc[:,3] = le.fit_transform(train_df.iloc[:,3])#club_member_status\n",
    "train_df.iloc[:,4] = le.fit_transform(train_df.iloc[:,4])#fashion_news_frequency\n",
    "train_df.iloc[:,8] = le.fit_transform(train_df.iloc[:,8])#product_group_name\n",
    "train_df.iloc[:,14] = le.fit_transform(train_df.iloc[:,14])#index_code\n",
    "\n",
    "test_df.iloc[:,3] = le.fit_transform(test_df.iloc[:,3])#club_member_status\n",
    "test_df.iloc[:,4] = le.fit_transform(test_df.iloc[:,4])#fashion_news_frequency\n",
    "test_df.iloc[:,8] = le.fit_transform(test_df.iloc[:,8])#product_group_name\n",
    "test_df.iloc[:,14] = le.fit_transform(test_df.iloc[:,14])#index_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b3bf10ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\newlo\\AppData\\Local\\Temp\\ipykernel_4848\\592797208.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['t_dat'] = train_df['t_dat'].apply(lambda x: x.toordinal())\n"
     ]
    }
   ],
   "source": [
    "#encode date as ordinal after we split our training and test data\n",
    "train_df['t_dat'] = train_df['t_dat'].apply(lambda x: x.toordinal())\n",
    "#reverse encoding. convert from ordinal to date\n",
    "#features_df['t_dat'] = features_df['t_dat'].apply(lambda x: datetime.fromordinal(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bf5eb229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\newlo\\AppData\\Local\\Temp\\ipykernel_4848\\1173125632.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['t_dat'] = test_df['t_dat'].apply(lambda x: x.toordinal())\n"
     ]
    }
   ],
   "source": [
    "#encode date as ordinal after we split our training and test data\n",
    "test_df['t_dat'] = test_df['t_dat'].apply(lambda x: x.toordinal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dab8bb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>fn</th>\n",
       "      <th>active</th>\n",
       "      <th>club_member_status</th>\n",
       "      <th>fashion_news_frequency</th>\n",
       "      <th>age</th>\n",
       "      <th>product_code</th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_no</th>\n",
       "      <th>...</th>\n",
       "      <th>perceived_colour_master_id</th>\n",
       "      <th>department_no</th>\n",
       "      <th>index_code</th>\n",
       "      <th>index_group_no</th>\n",
       "      <th>section_no</th>\n",
       "      <th>garment_group_no</th>\n",
       "      <th>t_dat</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>44cedf42ef296b66eb0842bed7234b7f83ba3bb49a45df...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>918292</td>\n",
       "      <td>273</td>\n",
       "      <td>5</td>\n",
       "      <td>1010010</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8310</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>1005</td>\n",
       "      <td>737689</td>\n",
       "      <td>0.031763</td>\n",
       "      <td>2</td>\n",
       "      <td>918292001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           customer_id   fn  active  \\\n",
       "180  44cedf42ef296b66eb0842bed7234b7f83ba3bb49a45df...  1.0     1.0   \n",
       "\n",
       "     club_member_status  fashion_news_frequency   age  product_code  \\\n",
       "180                   0                       1  31.0        918292   \n",
       "\n",
       "     product_type_no  product_group_name  graphical_appearance_no  ...  \\\n",
       "180              273                   5                  1010010  ...   \n",
       "\n",
       "     perceived_colour_master_id  department_no  index_code  index_group_no  \\\n",
       "180                           5           8310           9              26   \n",
       "\n",
       "     section_no  garment_group_no   t_dat     price  sales_channel_id  \\\n",
       "180           5              1005  737689  0.031763                 2   \n",
       "\n",
       "     article_id  \n",
       "180   918292001  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7cf6a7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>fn</th>\n",
       "      <th>active</th>\n",
       "      <th>club_member_status</th>\n",
       "      <th>fashion_news_frequency</th>\n",
       "      <th>age</th>\n",
       "      <th>product_code</th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_no</th>\n",
       "      <th>...</th>\n",
       "      <th>perceived_colour_master_id</th>\n",
       "      <th>department_no</th>\n",
       "      <th>index_code</th>\n",
       "      <th>index_group_no</th>\n",
       "      <th>section_no</th>\n",
       "      <th>garment_group_no</th>\n",
       "      <th>t_dat</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4078d35f7b2ae7a56cfdaec8c42959bf28f1f7ed742ab6...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>835801</td>\n",
       "      <td>252</td>\n",
       "      <td>4</td>\n",
       "      <td>1010016</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1003</td>\n",
       "      <td>737690</td>\n",
       "      <td>0.011847</td>\n",
       "      <td>1</td>\n",
       "      <td>835801001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          customer_id   fn  active  \\\n",
       "35  4078d35f7b2ae7a56cfdaec8c42959bf28f1f7ed742ab6...  0.0     0.0   \n",
       "\n",
       "    club_member_status  fashion_news_frequency   age  product_code  \\\n",
       "35                   0                       1  25.0        835801   \n",
       "\n",
       "    product_type_no  product_group_name  graphical_appearance_no  ...  \\\n",
       "35              252                   4                  1010016  ...   \n",
       "\n",
       "    perceived_colour_master_id  department_no  index_code  index_group_no  \\\n",
       "35                           9           1626           0               1   \n",
       "\n",
       "    section_no  garment_group_no   t_dat     price  sales_channel_id  \\\n",
       "35          15              1003  737690  0.011847                 1   \n",
       "\n",
       "    article_id  \n",
       "35   835801001  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a83a302",
   "metadata": {},
   "source": [
    "### Create Feature & Target Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f98285a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32130, 19)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are the attributes of our customers\n",
    "X_train = train_df.iloc[:, 1: 20].values\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7d671ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32130,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the product or in our case the class\n",
    "y_train = train_df.iloc[:, 21].values\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "519dd1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32866, 19)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are future customers\n",
    "X_test = test_df.iloc[:, 1: 20].values\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "50d7b02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32866,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are future products\n",
    "y_test = test_df.iloc[:, 21].values\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3acf7e5",
   "metadata": {},
   "source": [
    "### Feature Scaling: MinMax - range (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1f7ddef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4ae7ade2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 0.        , ..., 0.16666667, 0.        ,\n",
       "        0.0734004 ],\n",
       "       [1.        , 1.        , 0.        , ..., 0.83333333, 0.        ,\n",
       "        0.03818913],\n",
       "       [1.        , 1.        , 0.        , ..., 0.66666667, 0.        ,\n",
       "        0.04321932],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.08333333, 0.        ,\n",
       "        0.01002012],\n",
       "       [1.        , 1.        , 0.        , ..., 0.25      , 0.        ,\n",
       "        0.23939638],\n",
       "       [1.        , 1.        , 0.        , ..., 0.25      , 0.        ,\n",
       "        0.23939638]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cbb269a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.08333333, 0.        ,\n",
       "        0.02174204],\n",
       "       [0.        , 0.        , 0.        , ..., 0.75      , 0.        ,\n",
       "        0.02174204],\n",
       "       [1.        , 1.        , 0.        , ..., 0.04166667, 0.        ,\n",
       "        0.06529313],\n",
       "       ...,\n",
       "       [1.        , 1.        , 0.        , ..., 0.75      , 0.        ,\n",
       "        0.03179229],\n",
       "       [1.        , 1.        , 0.        , ..., 0.5       , 0.        ,\n",
       "        0.13229481],\n",
       "       [0.        , 0.        , 0.        , ..., 0.25      , 0.        ,\n",
       "        0.16579564]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = min_max_scaler.fit_transform(X_test)\n",
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81188ec",
   "metadata": {},
   "source": [
    "### Export Cleaned Data to Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "06c827ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(\"data/X_train_scaled_sample.csv\", X_train_scaled, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1469b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(\"data/y_test_scaled_sample.csv\", y_train, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ed77db",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c009a3",
   "metadata": {},
   "source": [
    "### Training the K-NN model on our Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e05428a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps = [('svd', TruncatedSVD(n_components=15)), ('knn', hm_clf)]\n",
    "# n_neighbors: number of neighbors. Default is 5\n",
    "# metric=\"minkowski\", p=2: will calculate distance as eucledian distance formula\n",
    "\n",
    "#steps = [('pca', PCA(n_components = 0.95)), ('knn', KNeighborsClassifier(n_neighbors=5, metric=\"minkowski\", p=2))]\n",
    "#steps = [('svd', TruncatedSVD(n_components=15)), ('knn', KNeighborsClassifier(n_neighbors=5, metric=\"minkowski\", p=2))]\n",
    "#steps = [('svd', TruncatedSVD(n_components=15)), ('knn', KNeighborsClassifier(n_neighbors=4, metric=\"minkowski\", p=2))]\n",
    "#steps = [('svd', TruncatedSVD(n_components=15)), ('knn', KNeighborsClassifier(n_neighbors=3, metric=\"minkowski\", p=2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe1887b",
   "metadata": {},
   "source": [
    "### Training the Kmeans model on our Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8ba6304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('pca', PCA(n_components=2)), ('km', KMeans(n_clusters=12))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "540d1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d69686d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_train_scaled, y_train) # for knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8a034e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pca', PCA(n_components=2)), ('km', KMeans(n_clusters=12))])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled) # for kmedoids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e34a325",
   "metadata": {},
   "source": [
    "### Predicting a new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e946dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classifier.predict(sc.transform([[0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37, 30,2020-09-08]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc98226",
   "metadata": {},
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b60140b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6777cfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  6, 10, ...,  1,  5,  0])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred # here we see the model predict products for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "55fb7a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32866"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d135b5",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3f3abbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of H&M KNN Classifier: 0.4259922512051178\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of H&M KNN Classifier:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "982bfb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score for H&M KNN Classifier: 0.17221084804834588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision Score for H&M KNN Classifier:\", precision_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65811a0e",
   "metadata": {},
   "source": [
    "## Results & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c03ebb",
   "metadata": {},
   "source": [
    "### Results\n",
    "TEST 1: H&M KNN Classifier Model Accuracy (k=5) was 0.00497 and Precision Score was 0.001, both less than 1% accurate.\n",
    " * We used the last 3 weeks in September 2020 from our transaction dataset to be used later for training and testing data.\n",
    " * We used Customer attributes, the full date range (YYYY-MM-DD) and transaction attributes as features to predict products.\n",
    " * We filled in missing data in our customer attributes using SimpleImputer to impute most frequent categories and median was used to impute missing ages.\n",
    " * We split our data up by time instead of random assignment. This meant 2 weeks (in the past) were used for training and 1 week (in the future) was used for testing testing\n",
    " * We encoded our categorical data using the LabelEncoder and date feature by converting the date into an ordinal number. This was after the training/test split.\n",
    " * We created our training and testing datasets and scaled them using MinMax range (0 to 1)\n",
    " * To build the KNN Classifier model, we used k=5 and our metric was minkowski p2, This meant we calculated the distance using eucledian distance formula.\n",
    " * To evaluate the model, we used accuracy as a measuring score. Which compared our predicted products to what was in the test dataset.\n",
    " \n",
    "TEST 2: H&M KNN Classifier Model (k=5) Accuracy increased to 0.432 and Precision Score increased to 0.161:\n",
    " * We included product attributes in with Customer attributes, the full date range (YYYY-MM-DD) and transaction attributes as features to predict products. This can lead to curse of dimensionality. The KNN Classifier can perform poorly with too many features. In our case the results were better but the time it took to process the data won't scale to the full transaction file.\n",
    " * For the next test we should reduce the amount of features we have. To do this we must use dimension reduction techniques such as principle component analysis (when we have lots of features) or singular value decomposition (SVD) when we have sparse data.\n",
    "\n",
    "TEST 3: H&M KNN Classifier Model (k=5) Accuracy decreased to 0.432 and Precision Score increased to 0.161:\n",
    " * we tried PCA with 95% variance kept. It didn't improve our score or our speed. We will try SVD in the next text\n",
    " \n",
    "TEST 4: H&M KNN Classifier Model (k=5) Accuracy decreased to 0.422 and Precision Score increased to 0.151:\n",
    "* SVD reduced our features down to 15 and also reduced our accuracy but sped up processing, we will try PCA to compare\n",
    "\n",
    "TEST 5: H&M KNN Classifier Model (k=5) Accuracy decreased to 0.038 and Precision Score increased to 0.0144:\n",
    "* We removed customer and tried to predict customer age with products as a test. Speed increased dramatically. The idea behind this would be to use age to select customer_id per product.\n",
    "\n",
    "TEST 6: H&M KNN Classifier Model (k=4) Accuracy decreased to 0.415 and Precision Score increased to 0.1601:\n",
    "* We tried k=4\n",
    "\n",
    "TEST 7: H&M KNN Classifier Model (k=3) Accuracy decreased to 0.426 and Precision Score increased to 0.1722:\n",
    "* We tried k=3\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc2888c",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5149e0d5",
   "metadata": {},
   "source": [
    "Overall Test 2 was the best. We tried in Test 3 to introduce PCA but it did not improve our result. We did however use SVD to reduce our number of features to 15. This reduced our score but significantly increased our processing time. This trade off was deemed acceptable to progress to a full train and test with Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa6c783",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c086e6",
   "metadata": {},
   "source": [
    "* https://www.kaggle.com/code/martandsay/knn-multi-classification-animal-classification/notebook\n",
    "* https://towardsdatascience.com/multiclass-classification-using-k-nearest-neighbours-ca5281a9ef76\n",
    "* https://analyticsindiamag.com/singular-value-decomposition-svd-application-recommender-system/\n",
    "* https://machinelearningmastery.com/singular-value-decomposition-for-dimensionality-reduction-in-python/\n",
    "* https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    "* https://www.kaggle.com/code/lichtlab/h-m-data-deep-dive-chap-1-understand-article\n",
    "* https://www.kaggle.com/code/vanguarde/h-m-eda-first-look\n",
    "* https://www.kaggle.com/code/debarshichanda/understanding-mean-average-precision\n",
    "* https://www.kaggle.com/code/paweljankiewicz/hm-create-dataset-samples\n",
    "* https://www.kaggle.com/code/souamesannis/tips-to-work-efficiently-with-the-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddd1a86",
   "metadata": {},
   "source": [
    "# Generate Kaggle Predictions File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b8678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working with files and memory management\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "#working with data\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "#working with datetime feature\n",
    "from datetime import datetime\n",
    "\n",
    "#handling missing values where not dropped\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#for evaluating our model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "\n",
    "#for dimension reduction\n",
    "from sklearn.pipeline import Pipeline # to sequence training events\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "#model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#used to provide information to the user when running this notebook\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "098bd7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "imputer_cms_mf = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imputer_fnf_mf = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imputer_age_med = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "#create encoders for categorical variables\n",
    "le_cms = preprocessing.LabelEncoder()\n",
    "le_fnf = preprocessing.LabelEncoder()\n",
    "le_pgn = preprocessing.LabelEncoder() #product group name\n",
    "le_ic = preprocessing.LabelEncoder()\n",
    "\n",
    "#create scaler\n",
    "min_max_scaler_train = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "min_max_scaler_test = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "#H&M Collaborative KNN Model Based Recommendation System\n",
    "def HmRecSys_data_prep():\n",
    "    \n",
    "    #GET DATA\n",
    "    #output message for user\n",
    "    clear_output(wait=True)\n",
    "    display('Importing Data. Please wait...')\n",
    "    \n",
    "    #get transaction data\n",
    "    transactions_train_df = pd.read_csv(\"data/transactions_train.csv\", \n",
    "                                        dtype={\"article_id\": \"str\"}) # import the transactions dataset\n",
    "\n",
    "    #get product meta data\n",
    "    articles_df = pd.read_csv(\"data/articles.csv\", dtype={\"article_id\": \"str\"})\n",
    "\n",
    "    #get customer meta data\n",
    "    customers_df = pd.read_csv(\"data/customers.csv\")\n",
    "\n",
    "    #output message for user\n",
    "    clear_output(wait=True)\n",
    "    display('Preparing Data. Please wait...')\n",
    "    \n",
    "    #PREPARE DATA\n",
    "    #prepare transactions dataset\n",
    "    features_df = transactions_train_df[['article_id',\n",
    "                                         'customer_id', \n",
    "                                         't_dat', \n",
    "                                         'price', \n",
    "                                         'sales_channel_id']]\n",
    "    \n",
    "    del transactions_train_df\n",
    "    gc.collect()\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    display('imported transactions and arranged columns...')\n",
    "    \n",
    "    #First we will convert our date text into a panda date type.\n",
    "    features_df[\"t_dat\"] = pd.to_datetime(features_df[\"t_dat\"])\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    display('converted date into datetime object...')\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display('converted article_ids to strings...')\n",
    "    \n",
    "    #merge product meta data with transactions\n",
    "    features_df = features_df.merge(articles_df, left_on='article_id', right_on='article_id')\n",
    "    \n",
    "    del articles_df\n",
    "    gc.collect()\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    display('merged articles with transactions...')\n",
    "    \n",
    "    #we drop cols we don't need from products dataset\n",
    "    features_df.drop(['prod_name',\n",
    "                      'product_type_name',\n",
    "                      'graphical_appearance_name',\n",
    "                      'colour_group_name',\n",
    "                      'perceived_colour_value_name',\n",
    "                      'perceived_colour_master_name',\n",
    "                      'department_name',\n",
    "                      'index_name',\n",
    "                      'index_group_name',\n",
    "                      'section_name',\n",
    "                      'garment_group_name',\n",
    "                      'detail_desc'], axis=1)    \n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    display('rearranged columns of features dataset for merger...')\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display('merging customers with features dataset...')\n",
    "    \n",
    "    #merge customer meta data with transactions\n",
    "    features_df = features_df.merge(customers_df, left_on='customer_id', right_on='customer_id')\n",
    "    \n",
    "    del customers_df\n",
    "    gc.collect()\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    display('rearranging customers and articles with feature dataset...')\n",
    "    \n",
    "    #we reorganise columns\n",
    "    features_df = features_df[['customer_id',#the customer\n",
    "                               'FN',#customer meta data\n",
    "                               'Active',\n",
    "                               'club_member_status', \n",
    "                               'fashion_news_frequency', \n",
    "                               'age',\n",
    "                               'product_code',#product meta data\n",
    "                               'product_type_no',\n",
    "                               'product_group_name',\n",
    "                               'graphical_appearance_no',\n",
    "                               'colour_group_code', \n",
    "                               'perceived_colour_value_id', \n",
    "                               'perceived_colour_master_id', \n",
    "                               'department_no',  \n",
    "                               'index_code', \n",
    "                               'index_group_no',  \n",
    "                               'section_no', \n",
    "                               'garment_group_no', \n",
    "                               't_dat',#transaction meta data\n",
    "                               'price',\n",
    "                               'sales_channel_id', \n",
    "                               'article_id']]#the product\n",
    "    clear_output(wait=True)\n",
    "    display('rearranged columns of features dataset...')\n",
    "    \n",
    "    #FIX MISSING DATA\n",
    "    #convert from objects and floats to categories and ints\n",
    "    features_df['club_member_status'] = features_df['club_member_status'].astype('category')\n",
    "    features_df['fashion_news_frequency'] = features_df['fashion_news_frequency'].astype('category')\n",
    "    \n",
    "    features_df['FN'] = features_df['FN'].fillna(0)\n",
    "    features_df['Active'] = features_df['Active'].fillna(0)\n",
    "\n",
    "    club_member_status = features_df.iloc[:, 3:-18].values\n",
    "    fashion_news_frequency = features_df.iloc[:, 4:-17].values\n",
    "    age = features_df.iloc[:, 5:-16].values\n",
    "\n",
    "    #we replace missing values with the most frequent\n",
    "    imputer_cms_mf.fit(club_member_status)\n",
    "    club_member_status = imputer_cms_mf.transform(club_member_status)\n",
    "\n",
    "    imputer_fnf_mf.fit(fashion_news_frequency)\n",
    "    fashion_news_frequency = imputer_fnf_mf.transform(fashion_news_frequency)\n",
    "\n",
    "    #we replace any missing age values with the median age\n",
    "    imputer_age_med.fit(age)\n",
    "    age = imputer_age_med.transform(age)\n",
    "\n",
    "    #now add corrected columns back into our main customer dataframe\n",
    "    features_df.iloc[:, 3:-18] = club_member_status\n",
    "    features_df.iloc[:, 4:-17] = fashion_news_frequency\n",
    "    features_df.iloc[:, 5:-16] = age\n",
    "\n",
    "    #replace minus sign in text and check result of dataset after imputing missing values\n",
    "    features_df.columns = features_df.columns.str.replace('-', '')\n",
    "\n",
    "    #lower case columns\n",
    "    features_df.columns = map(str.lower, features_df.columns)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display('filled in missing values and fixed column names...')\n",
    "    \n",
    "    # ENCODE DATA\n",
    "    #encode our categorical variables\n",
    "    features_df.iloc[:,3] = le_cms.fit_transform(features_df.iloc[:,3])#club_member_status\n",
    "    features_df.iloc[:,4] = le_fnf.fit_transform(features_df.iloc[:,4])#fashion_news_frequency\n",
    "    features_df.iloc[:,8] = le_pgn.fit_transform(features_df.iloc[:,8])#product_group_name\n",
    "    features_df.iloc[:,14] = le_ic.fit_transform(features_df.iloc[:,14])#index_code\n",
    "    \n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display('encoded features...')\n",
    "\n",
    "    # SPLIT DATA X FEATURES Y PREDICTOR\n",
    "    \n",
    "    train_mask = (features_df['t_dat'] >= '2020-09-21') & (features_df['t_dat'] <= '2020-09-21')\n",
    "    train_df = features_df.loc[train_mask]\n",
    "    \n",
    "    test_mask = (features_df['t_dat'] >= '2020-09-22') & (features_df['t_dat'] <= '2020-09-22')\n",
    "    test_df = features_df.loc[test_mask]\n",
    "    \n",
    "    #encode date as ordinal after we split our training and test data\n",
    "    train_df['t_dat'] = features_df['t_dat'].apply(lambda x: x.toordinal())\n",
    "    test_df['t_dat'] = features_df['t_dat'].apply(lambda x: x.toordinal())\n",
    "\n",
    "    del features_df\n",
    "    gc.collect()\n",
    "    \n",
    "    #These are the attributes of our customers for training\n",
    "    X_train = train_df.iloc[:, 1: 20].values\n",
    "    \n",
    "    # this is the product or in our case the class for training\n",
    "    y_train = train_df.iloc[:, 21].values\n",
    "\n",
    "\n",
    "    #These are the attributes of our customers for test\n",
    "    X_test = test_df.iloc[:, 1: 20].values\n",
    "    \n",
    "    # this is the product or in our case the class for test\n",
    "    y_test = test_df.iloc[:, 21].values\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    display('split data into X features and y predictor...')\n",
    "    \n",
    "    # SCALE FEATURES: MinMax - range (0,1)  \n",
    "    X_train_scaled = min_max_scaler_train.fit_transform(X_train)\n",
    "    X_test_scaled = min_max_scaler_test.fit_transform(X_test)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display('features scaling complete...')\n",
    " \n",
    "    clear_output(wait=True)\n",
    "    display('exporting X_train_scaled np array to text file...')\n",
    "    np.savetxt(\"data/X_train_scaled_sample1.csv\", X_train_scaled, delimiter=\",\")\n",
    "\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    display('exporting X_test_scaled np array to text file...')\n",
    "    np.savetxt(\"data/X_test_scaled_sample1.csv\", X_test_scaled, delimiter=\",\")  \n",
    "\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display('exporting y_train np array to text file...')\n",
    "    np.savetxt(\"data/y_train_sample1.csv\", y_train, delimiter=\",\", fmt='%s')\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    display('exporting y_test np array to text file...')\n",
    "    np.savetxt(\"data/y_test_sample1.csv\", y_test, delimiter=\",\", fmt='%s')\n",
    "    \n",
    "    del X_train\n",
    "    del y_train\n",
    "    del X_train_scaled\n",
    "    \n",
    "    del X_test\n",
    "    del y_test\n",
    "    del X_test_scaled\n",
    "    gc.collect()\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    display('Data preparation complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef511fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HmRecSys_model_train(): \n",
    "\n",
    "    #output message for user\n",
    "    clear_output(wait=True)\n",
    "    display('Importing X_train np array from text file. Please wait...')  \n",
    "    X_train_scaled = np.loadtxt('data/X_train_scaled_sample1.csv', delimiter=',')\n",
    "    \n",
    "    #output message for user\n",
    "    clear_output(wait=True)\n",
    "    display('Importing y_train df from text file. Please wait...') \n",
    "    y_train = np.loadtxt('data/y_train_sample1.csv', delimiter=',')\n",
    "    \n",
    "    \n",
    "    #output message for user\n",
    "    clear_output(wait=True)\n",
    "    display('Importing X_test np array from text file. Please wait...')  \n",
    "    X_test_scaled = np.loadtxt('data/X_test_scaled_sample1.csv', delimiter=',')\n",
    "    \n",
    "    #output message for user\n",
    "    clear_output(wait=True)\n",
    "    display('Importing y_train df from text file. Please wait...') \n",
    "    y_test = np.loadtxt('data/y_test_sample1.csv', delimiter=',')\n",
    "    \n",
    "    # CREATE PIPELINE\n",
    "    #create model pipeline\n",
    "    clear_output(wait=True)\n",
    "    display('Creating pipeline...')\n",
    "    \n",
    "    steps = [('svd', TruncatedSVD(n_components=15)), \n",
    "             ('knn', KNeighborsClassifier(n_neighbors=3, metric=\"minkowski\", p=2))]\n",
    "    \n",
    "    model = Pipeline(steps=steps)\n",
    "\n",
    "    #output message for user\n",
    "    clear_output(wait=True)\n",
    "    display('training model please wait...')\n",
    "                                 \n",
    "    #TRAIN MODEL\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    del X_train_scaled\n",
    "    del y_train\n",
    "    gc.collect()\n",
    "    \n",
    "    #output message for user\n",
    "    clear_output(wait=True)\n",
    "    display('model trained...')\n",
    "    \n",
    "    #MODEL EVALUATION\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    clear_output(wait=True)\n",
    "    display(\"Accuracy of H&M KNN Classifier:\" + str(accuracy_score(y_test, y_pred)) + \"\\nPrecision Score for H&M KNN Classifier:\" + str(precision_score(y_test, y_pred, average='macro')) + \"\\nsaving model. please wait...\")\n",
    "\n",
    "    del X_test_scaled\n",
    "    del y_test\n",
    "    del y_pred\n",
    "    gc.collect()\n",
    "    \n",
    "    pickle.dump(model, open('data/hm_knn_model.sav', 'wb'))\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55924d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HmRecSys_model_predict():\n",
    "    \n",
    "    #GET DATA\n",
    "    #output message for user\n",
    "    clear_output(wait=True)\n",
    "    display('Importing model. Please wait...')\n",
    "    \n",
    "    model = pickle.load(open('data/hm_knn_model.sav', 'rb'))\n",
    "    \n",
    "    #output message for user\n",
    "    clear_output(wait=True)\n",
    "    display('Importing Data. Please wait...')\n",
    "    \n",
    "    #get product meta data\n",
    "    articles_df = pd.read_csv(\"data/articles.csv\", dtype={\"article_id\": \"str\"})\n",
    "\n",
    "    #get customer meta data\n",
    "    customers_df = pd.read_csv(\"data/customers.csv\")\n",
    "    \n",
    "    #get transaction data\n",
    "    transactions_train_df = pd.read_csv(\"data/transactions_train.csv\", \n",
    "                                        dtype={\"article_id\": \"str\"}) # import the transactions dataset\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display('Getting price mode')\n",
    "    \n",
    "    #get popular price to pay\n",
    "    p = transactions_train_df['price'].mode()\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    display('Getting sales mode')\n",
    "    \n",
    "    #get popular sales channel to buy from\n",
    "    s = transactions_train_df['sales_channel_id'].mode()\n",
    "\n",
    "    del transactions_train_df\n",
    "    gc.collect() \n",
    "\n",
    "    #for encoding data and filling missing values\n",
    "    #ref: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "    imputer_med = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    imputer_mf = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    \n",
    "    #output message for user\n",
    "    clear_output(wait=True)\n",
    "    display('opening CSV file to start writing...')\n",
    "    \n",
    "    write_file = \"ros_predictions4.csv\"\n",
    "    with open(write_file, \"wt\", encoding=\"utf-8\") as output:\n",
    "        #add headers first\n",
    "        output.write(\"customer_id,prediction\" + '\\n')\n",
    "        \n",
    "        #now we loop through each row and write predictions to csv file\n",
    "        for index_i, cus in customers_df.iterrows():\n",
    "                \n",
    "            #create prediction csv file\n",
    "            output.write(cus.customer_id + \",\" + '\\n')\n",
    "            \n",
    "            #random sample 4 products\n",
    "            sample_4 = articles_df.sample(n=4, random_state=1)\n",
    "            \n",
    "            #predict 3 products near each 4\n",
    "            for index_j, art in sample_4.iterrows():\n",
    "                #clear_output(wait=True)\n",
    "                #display('Predicting customer: ' + str(cus.customer_id) + \" recommendations from: \" + str(art.article_id))\n",
    "\n",
    "                #get their meta data   \n",
    "                data = {'FN': [cus['FN']],\n",
    "                        'Active': [cus['Active']],\n",
    "                        'club_member_status': [cus['club_member_status']],\n",
    "                        'fashion_news_frequency': [cus['fashion_news_frequency']],\n",
    "                        'age': [cus['age']],\n",
    "                        'product_code': [art['product_code']], \n",
    "                        'product_type_no': [art['product_type_no']],\n",
    "                        'product_group_name': [art['product_group_name']],\n",
    "                        'graphical_appearance_no': [art['graphical_appearance_no']],\n",
    "                        'colour_group_code': [art['colour_group_code']], \n",
    "                        'perceived_colour_value_id': [art['perceived_colour_value_id']], \n",
    "                        'perceived_colour_master_id': [art['perceived_colour_master_id']], \n",
    "                        'department_no': [art['department_no']],  \n",
    "                        'index_code': [art['index_code']], \n",
    "                        'index_group_no': [art['index_group_no']],  \n",
    "                        'section_no': [art['section_no']], \n",
    "                        'garment_group_no': [art['garment_group_no']],\n",
    "                        'date': [['2020-09-29']],#future date in next 7 days (2020-09-29)\n",
    "                        'price': [[p]], #most popular price to pay\n",
    "                        'sales_channel_id': [[s]] #most popular way to buy (in store or online)\n",
    "                       }\n",
    "                \n",
    "                # Create DataFrame\n",
    "                features_df = pd.DataFrame(data)\n",
    "\n",
    "                #FIX MISSING DATA\n",
    "                #convert from objects and floats to categories and ints\n",
    "                #features_df['club_member_status'] = features_df['club_member_status'].astype('category')\n",
    "                #features_df['fashion_news_frequency'] = features_df['fashion_news_frequency'].astype('category')\n",
    "\n",
    "                features_df['FN'] = features_df['FN'].astype('Int16')\n",
    "                features_df['Active'] = features_df['Active'].astype('Int16')\n",
    "                features_df['age'] = features_df['age'].astype('float')\n",
    "                \n",
    "                \n",
    "                #features_df['FN'] = features_df['FN'].fillna(0)\n",
    "                #features_df['Active'] = features_df['Active'].fillna(0)\n",
    "                \n",
    "                club_member_status = features_df.iloc[:, 2:-19].values\n",
    "                fashion_news_frequency = features_df.iloc[:, 3:-18].values\n",
    "                age = features_df.iloc[:, 4:-17].values\n",
    "                #club_member_status = features_df['club_member_status'].iloc[0].values\n",
    "                #fashion_news_frequency = features_df['fashion_news_frequency'].iloc[0]\n",
    "                #age = features_df['age'].iloc[0]\n",
    "                \n",
    "                \n",
    "                features_df['date'] = pd.to_datetime(features_df['date'].iloc[0], format='%Y-%m-%d')\n",
    "                features_df['date'] = features_df['date'].apply(lambda x: x.toordinal())\n",
    "                \n",
    "                #we replace missing values with the most frequent\n",
    "                club_member_status = imputer_cms_mf.fit_transform(club_member_status)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                fashion_news_frequency = imputer_fnf_mf.fit_transform(fashion_news_frequency)\n",
    "                \n",
    "                #we replace any missing age values with the median age\n",
    "                age = imputer_age_med.fit_transform(age)\n",
    "\n",
    "\n",
    "                #now add corrected columns back into our main customer dataframe\n",
    "                features_df.iloc[:, 2] = club_member_status\n",
    "                features_df.iloc[:, 3] = fashion_news_frequency\n",
    "                features_df.iloc[:, 4] = age\n",
    "                \n",
    "                #replace minus sign in text and check result of dataset after imputing missing values\n",
    "                features_df.columns = features_df.columns.str.replace('-', '')\n",
    "\n",
    "                #lower case columns\n",
    "                features_df.columns = map(str.lower, features_df.columns)\n",
    "\n",
    "                #encode our categorical variables\n",
    "                features_df.iloc[:,2] = le_cms.fit_transform(features_df.iloc[:,3])#club_member_status\n",
    "                features_df.iloc[:,3] = le_fnf.fit_transform(features_df.iloc[:,4])#fashion_news_frequency\n",
    "                features_df.iloc[:,7] = le_pgn.fit_transform(features_df.iloc[:,8])#product_group_name\n",
    "                features_df.iloc[:,13] = le_ic.fit_transform(features_df.iloc[:,14])#index_code\n",
    "                \"\"\"\n",
    "                clear_output(wait=True)\n",
    "                display('filled in missing values and fixed column names...')\n",
    "\n",
    "                #normalise data to query customer\n",
    "                q_cus_scaled = min_max_scaler_test.transform(features_df)\n",
    "                \n",
    "                #free up memory\n",
    "                del features_df\n",
    "                gc.collect()  \n",
    "                \n",
    "                #make a prediction\n",
    "                y_pred = model.predict(q_cus_scaled)\n",
    "                \n",
    "                result = []\n",
    "                r = []\n",
    "                prediction = \"\"\n",
    "                \n",
    "                #add 3 predicted products\n",
    "                result.append(y_pred)\n",
    "            \n",
    "                for n in result:\n",
    "                    r.append(\"0\" + str(n))\n",
    "                    prediction =  ' '.join(r)\n",
    "                    \n",
    "                #write predictions to csv file\n",
    "                output.write(prediction + '\\n')\n",
    "                \n",
    "                del result\n",
    "                del r\n",
    "                del prediction\n",
    "                gc.collect()\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "701ef50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data preparation complete.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HmRecSys_data_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fc7e567",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy of H&M KNN Classifier:0.40376072536968294\\nPrecision Score for H&M KNN Classifier:0.13095032692545291\\nsaving model. please wait...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HmRecSys_model_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6155363a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'opening CSV file to start writing...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(1, 0)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mHmRecSys_model_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36mHmRecSys_model_predict\u001b[1;34m()\u001b[0m\n\u001b[0;32m    116\u001b[0m features_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m features_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mtoordinal())\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m#we replace missing values with the most frequent\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m club_member_status \u001b[38;5;241m=\u001b[39m \u001b[43mimputer_cms_mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclub_member_status\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m fashion_news_frequency \u001b[38;5;241m=\u001b[39m imputer_fnf_mf\u001b[38;5;241m.\u001b[39mfit_transform(fashion_news_frequency)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m#we replace any missing age values with the median age\u001b[39;00m\n",
      "File \u001b[1;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\sklearn\\base.py:852\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    851\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\sklearn\\impute\\_base.py:319\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit the imputer on `X`.\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;66;03m# otherwise\u001b[39;00m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\sklearn\\impute\\_base.py:287\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 287\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ve\n\u001b[0;32m    289\u001b[0m _check_inputs_dtype(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_values)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\sklearn\\impute\\_base.py:270\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    267\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_fit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not convert\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n",
      "File \u001b[1;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\sklearn\\base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:814\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    812\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m<\u001b[39m ensure_min_features:\n\u001b[1;32m--> 814\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    815\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m feature(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m a minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_features, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_features, context)\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmay_share_memory(array, array_orig):\n\u001b[0;32m    821\u001b[0m     array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(array, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(1, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "HmRecSys_model_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890aa3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
