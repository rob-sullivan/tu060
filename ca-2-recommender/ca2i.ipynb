{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21eb6be9",
   "metadata": {},
   "source": [
    "# H&M Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4acb857",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b841e259",
   "metadata": {},
   "source": [
    "H&M Group is a clothing business with 53 online markets and approximately 4,850 stores. They are concerned that customers might not quickly find what interests them or what they are looking for, and ultimately, they might not make a purchase. They want to enhance the shopping experience and help customers make the right choices. They think they can also reduce transportation emissions if they reduce customer returns. H&M want product recommendations based on data from previous transactions, as well as from customer and product meta data.\n",
    "\n",
    "Submissions will be evaluated according to the Mean Average Precision @ 12 (MAP@12). They will make purchase predictions for all customer_id values provided, regardless of whether these customers made purchases in the training data. They explain that customers who did not make any purchase during test period are excluded from the scoring.\n",
    "There is no penalty for using the full 12 predictions for a customer that ordered fewer than 12 items. They encourage to make 12 predictions for each customer.\n",
    "\n",
    "For each customer (customer_id), H&M want a prediction of up to 12 products (article_ids), which is the predicted items a customer will buy in the next 7-day period after the training time period. The file should contain a header and have the following format.\n",
    "\n",
    "H&M are expecting about 1,371,980 prediction rows, we will only have 1,362,281 because 9,699 customers have not purchased anything yet. We will also have to make predictions on these customers without knowing their transaction history. We could look for customers with similar demographics but this may be computationally expensive and a big assumption, that similar demographics purchase similar products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f518981",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbd31156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ab935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used during data exploration and model evaluation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012b9e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working with datetime feature\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c072dea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling missing values where not dropped\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54905caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for evaluating our model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bc2ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for dimension reduction\n",
    "from sklearn.pipeline import Pipeline # to sequence training events\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58599dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49a24c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to provide information to the user when running this notebook\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811fac61",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a307ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get transaction data\n",
    "transactions_train_df = pd.read_csv(\"data/transactions_train.csv\") # import the transactions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3dfedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get product meta data\n",
    "articles_df = pd.read_csv(\"data/articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35b7c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get customer meta data\n",
    "customers_df = pd.read_csv(\"data/customers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15117a70",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis & Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ddb5c6",
   "metadata": {},
   "source": [
    "In this section we first looked at what data was available, it's distribution, what was missing and what opportunities were available to reduce the number of features or dimensions in our dataset. Secondly we determined what models could work well with the data, finally we looked to fix any missing values or encoding categorical variables where needed.\n",
    "\n",
    "An exploritory data analysis was conducted already by various other kaggle contestants such as (Karpov, 2022). Their analysis was reviewed as part of this workbook in order to reduce this EDA section and allow us to focus on model building, prediction and evaluation. \n",
    "\n",
    "Data available consisted of images of every product, detailed metadata of every product, detailed metadata of every customer and purchase details for customers who bought products. These will be refered to as images,articles,customers and transactions respectively. Although it is assumed that images are an important part of how customers decide on the products they purchase, due to the data size and limited processing power, they will not be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1f07d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transactions_train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40336b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transactions_train_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4909276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#customers_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef5f3e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id               1371980\n",
       "FN                              1\n",
       "Active                          1\n",
       "club_member_status              3\n",
       "fashion_news_frequency          4\n",
       "age                            84\n",
       "postal_code                352899\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abe1faa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#articles_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "512587ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#articles_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b7d33",
   "metadata": {},
   "source": [
    "There are over 31.9 million transactions and over 3gb in size. With our limited space and processing power, this made working with the dataset slow and unweidly. Instead we were only able to sample this dataset.\n",
    "\n",
    "For the customer's dataset we have 1,37 million customers from 352,899 locations, it is assumed that FN stands for whether h&m have the customers is signed up for fashion news. Several other features are also available such as post code. We will have to convert NaNs into zero values, we will do the same for Active. For Fashion news frequency we will have to encode these orginal categories. This might also determine customer quality for recommendation.\n",
    "\n",
    "105,542 products are in the articles dataset. Regarding columns in this dataset, every item had a unique identifier called the article id, but it also had a product code and a product name. The identifier and the product code were not the same, it was assumed that this was due to size differences or colour variations in H&M's clothing (e.g a v-neck polo shirt could be in a small, medium and large, as well as having two colours, black and white). \n",
    "\n",
    "The product name could probably be dropped later as the product code and name seem to match. This seems to be true for the product type name, colour group name and graphical appearance name. We could drop the names and keep the numbers. We will however keep product group name as there doesn't seem to be a corisponding type_no. We will have to encode this ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d15b5cb",
   "metadata": {},
   "source": [
    "### Making Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb1dda",
   "metadata": {},
   "source": [
    "In a perfect scenario for a recommendation system we would have a table of m users by n items, with each product given a rating r_ij by each user. However We could have hundreds of users and thousands of products. A user may not have tried every product so our table would have missing values. To solve this issue we would need to predict the value for missing cells (rhat_ij). A good prediction would mean a good recommendation to the user. Another way to make recommendations to users would be to rank the top k products for each user. This would be based on information we have available on products and users. In essence the prediction problem boils down to how we rate products.\n",
    "\n",
    "In order for us to rate products we would first need some metric to rate them by. Secondly, we would need to decide the prerequisites that a product must meet to recieve said rating. Thirdly we would then need to calculate the score for each item that satisfies the prerequisites and finally we would output a list of items in decreasing order. Unfortunately, H&M have not provided any labelling for us. W+e must make our own. This makes the problem of recommendation more difficult.\n",
    "\n",
    "In our Transaction dataset we have customers who bought products at a particular price and time. We started here, with these features to try create a simple collaborative model recommendation system. The model tried to learn from a customer's historical purchases and make predictions about their future purchases.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee67e664",
   "metadata": {},
   "source": [
    "Since we don't actual have a customer item ratings like a 1 to 5 rating per item, we will assume qty of purchase indicates customer interest in products. If we have outliers they may bias our data. In this case we can assume that 68% of customer transaction will lie within 1 standard deviation from the mean so we could take anything 3 standard deviations from the mean as rare events (1%) and remove them.\n",
    "\n",
    "We will pick a random customer with a few recent transactions and try to predict their future buying habits based on past data about them. We will configure a dataset of purchase made by the customer in the past. We will then use the meta data of the customer and the products to form a model we can use to predict if the customer will by a certain product or not.\n",
    "\n",
    "Cus_id | Customer meta data | Date of purchase | price of purchase | store/website | product meta data | article_id\n",
    "1,151561,123,0.05,1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89abe2c",
   "metadata": {},
   "source": [
    "### Prepare the Transaction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54790a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we will convert our date text into a panda date type.\n",
    "transactions_train_df[\"t_dat\"] = pd.to_datetime(transactions_train_df[\"t_dat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0586117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we split out the date into seperate columns for day, month and year making use of python zip for memory efficiency\n",
    "days, months, years  = zip(*[(d.day, d.month, d.year) for d in transactions_train_df['t_dat']])\n",
    "transactions_train_df = transactions_train_df.assign(day=days, month=months, year=years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dda6965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we drop the t_dat column as it is no longer needed\n",
    "transactions_train_df = transactions_train_df.drop(['t_dat'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e89f19b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we convert articles to string instead of default int.\n",
    "transactions_train_df['article_id'] = transactions_train_df['article_id'].values.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dafb6c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to see distributions and std dev\n",
    "#transactions_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20108968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>663713001</td>\n",
       "      <td>0.050831</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>541518023</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>505221004</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>685687003</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>685687004</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id article_id     price  \\\n",
       "0  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  663713001  0.050831   \n",
       "1  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  541518023  0.030492   \n",
       "2  00007d2de826758b65a93dd24ce629ed66842531df6699...  505221004  0.015237   \n",
       "3  00007d2de826758b65a93dd24ce629ed66842531df6699...  685687003  0.016932   \n",
       "4  00007d2de826758b65a93dd24ce629ed66842531df6699...  685687004  0.016932   \n",
       "\n",
       "   sales_channel_id  day  month  year  \n",
       "0                 2   20      9  2018  \n",
       "1                 2   20      9  2018  \n",
       "2                 2   20      9  2018  \n",
       "3                 2   20      9  2018  \n",
       "4                 2   20      9  2018  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7031a96",
   "metadata": {},
   "source": [
    "We will use a 3 week date range between 2020-09-8 and 2020-09-22 to reduce our dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c979f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (transactions_train_df['year'] >= 2020) & (transactions_train_df['month'] >= 9) & (transactions_train_df['day'] >= 1) & (transactions_train_df['year'] <= 2020) & (transactions_train_df['month'] <= 9) & (transactions_train_df['day'] <= 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7166890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "798269"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = transactions_train_df.loc[mask]\n",
    "features_df['customer_id'].size #798269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba3bf45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df[['article_id', 'year', 'month', 'day', 'price', 'sales_channel_id', 'customer_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c777f8d",
   "metadata": {},
   "source": [
    "### Prepare Product Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "887e06e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we convert articles to string instead of default int.\n",
    "articles_df['article_id'] = articles_df['article_id'].values.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f135bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge product meta data with transactions\n",
    "features_df = features_df.merge(articles_df, left_on='article_id', right_on='article_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c927a50",
   "metadata": {},
   "source": [
    "Regarding columns in the articles data set, every item had a unique identifier called the article id, but it also had a product code and a product name. The identifier and the product code were not the same, it was assumed that this was due to size differences or colour variations in H&M's clothing (e.g a v-neck polo shirt could be in a small, medium and large, as well as having two colours, black and white). \n",
    "\n",
    "The product name could probably be dropped as the product code and name seem to match. This seems to be true for the product type name, colour group name and graphical appearance name. We could drop the names and keep the numbers. We will however keep product_group_name as there doesn't seem to be a corisponding type_no. We will have to encode this ourselves.\n",
    "\n",
    "There was no missing data so we did not need to do anything like imputing missing data with sklearn SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "001e40fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_no</th>\n",
       "      <th>colour_group_code</th>\n",
       "      <th>perceived_colour_value_id</th>\n",
       "      <th>perceived_colour_master_id</th>\n",
       "      <th>department_no</th>\n",
       "      <th>index_code</th>\n",
       "      <th>index_group_no</th>\n",
       "      <th>section_no</th>\n",
       "      <th>garment_group_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>777148006</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>1</td>\n",
       "      <td>0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37...</td>\n",
       "      <td>777148</td>\n",
       "      <td>252</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010010</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1626</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>777148006</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>1</td>\n",
       "      <td>5ac5e1825104ed5fe3333e75b9337eebc4b45ad761056b...</td>\n",
       "      <td>777148</td>\n",
       "      <td>252</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010010</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1626</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>777148006</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>1</td>\n",
       "      <td>0dcf3023ea1992a78a1fcc769b6befc956f7308186496d...</td>\n",
       "      <td>777148</td>\n",
       "      <td>252</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010010</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1626</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>777148006</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.042356</td>\n",
       "      <td>2</td>\n",
       "      <td>28b30893bbe946358103760387e3dcd09fdb7b077a942f...</td>\n",
       "      <td>777148</td>\n",
       "      <td>252</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010010</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1626</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>777148006</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>1</td>\n",
       "      <td>278f23c7fac720c2b96b25455d640860bdfa8bb3c867cf...</td>\n",
       "      <td>777148</td>\n",
       "      <td>252</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010010</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1626</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798264</th>\n",
       "      <td>737994021</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>1</td>\n",
       "      <td>f71529889de7a28df0015fad0a043941ecc98883286ef0...</td>\n",
       "      <td>737994</td>\n",
       "      <td>273</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>1010023</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7917</td>\n",
       "      <td>H</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798265</th>\n",
       "      <td>533261032</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>2</td>\n",
       "      <td>f79e372e21c1359dfebc7da0bf7f321d55e47b3275c351...</td>\n",
       "      <td>533261</td>\n",
       "      <td>256</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>6515</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798266</th>\n",
       "      <td>865792012</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>0.008458</td>\n",
       "      <td>2</td>\n",
       "      <td>f82c91decd5f9abd0a7a72eae0d4911b00ed4f5b4f04f9...</td>\n",
       "      <td>865792</td>\n",
       "      <td>273</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>1010001</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6525</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798267</th>\n",
       "      <td>772659001</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>1</td>\n",
       "      <td>f96661e9e56449885d4c4b90d3227e4abea5e0d2382e2d...</td>\n",
       "      <td>772659</td>\n",
       "      <td>274</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1948</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798268</th>\n",
       "      <td>807775001</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>2</td>\n",
       "      <td>fd5ce8716faf00f6a83616f609e0403ac516727d4ca4aa...</td>\n",
       "      <td>807775</td>\n",
       "      <td>272</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5683</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798269 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id  year  month  day     price  sales_channel_id  \\\n",
       "0       777148006  2020      9    1  0.013542                 1   \n",
       "1       777148006  2020      9    3  0.013542                 1   \n",
       "2       777148006  2020      9    6  0.013542                 1   \n",
       "3       777148006  2020      9    6  0.042356                 2   \n",
       "4       777148006  2020      9   10  0.013542                 1   \n",
       "...           ...   ...    ...  ...       ...               ...   \n",
       "798264  737994021  2020      9   22  0.030492                 1   \n",
       "798265  533261032  2020      9   22  0.033881                 2   \n",
       "798266  865792012  2020      9   22  0.008458                 2   \n",
       "798267  772659001  2020      9   22  0.016932                 1   \n",
       "798268  807775001  2020      9   22  0.033881                 2   \n",
       "\n",
       "                                              customer_id  product_code  \\\n",
       "0       0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37...        777148   \n",
       "1       5ac5e1825104ed5fe3333e75b9337eebc4b45ad761056b...        777148   \n",
       "2       0dcf3023ea1992a78a1fcc769b6befc956f7308186496d...        777148   \n",
       "3       28b30893bbe946358103760387e3dcd09fdb7b077a942f...        777148   \n",
       "4       278f23c7fac720c2b96b25455d640860bdfa8bb3c867cf...        777148   \n",
       "...                                                   ...           ...   \n",
       "798264  f71529889de7a28df0015fad0a043941ecc98883286ef0...        737994   \n",
       "798265  f79e372e21c1359dfebc7da0bf7f321d55e47b3275c351...        533261   \n",
       "798266  f82c91decd5f9abd0a7a72eae0d4911b00ed4f5b4f04f9...        865792   \n",
       "798267  f96661e9e56449885d4c4b90d3227e4abea5e0d2382e2d...        772659   \n",
       "798268  fd5ce8716faf00f6a83616f609e0403ac516727d4ca4aa...        807775   \n",
       "\n",
       "        product_type_no  product_group_name  graphical_appearance_no  \\\n",
       "0                   252  Garment Upper body                  1010010   \n",
       "1                   252  Garment Upper body                  1010010   \n",
       "2                   252  Garment Upper body                  1010010   \n",
       "3                   252  Garment Upper body                  1010010   \n",
       "4                   252  Garment Upper body                  1010010   \n",
       "...                 ...                 ...                      ...   \n",
       "798264              273  Garment Lower body                  1010023   \n",
       "798265              256  Garment Upper body                  1010016   \n",
       "798266              273  Garment Lower body                  1010001   \n",
       "798267              274  Garment Lower body                  1010016   \n",
       "798268              272  Garment Lower body                  1010016   \n",
       "\n",
       "        colour_group_code  perceived_colour_value_id  \\\n",
       "0                      52                          7   \n",
       "1                      52                          7   \n",
       "2                      52                          7   \n",
       "3                      52                          7   \n",
       "4                      52                          7   \n",
       "...                   ...                        ...   \n",
       "798264                 72                          2   \n",
       "798265                 17                          2   \n",
       "798266                 73                          4   \n",
       "798267                 33                          4   \n",
       "798268                  9                          4   \n",
       "\n",
       "        perceived_colour_master_id  department_no index_code  index_group_no  \\\n",
       "0                                4           1626          A               1   \n",
       "1                                4           1626          A               1   \n",
       "2                                4           1626          A               1   \n",
       "3                                4           1626          A               1   \n",
       "4                                4           1626          A               1   \n",
       "...                            ...            ...        ...             ...   \n",
       "798264                           2           7917          H               4   \n",
       "798265                          13           6515          G               4   \n",
       "798266                           2           6525          G               4   \n",
       "798267                           3           1948          A               1   \n",
       "798268                           5           5683          F               3   \n",
       "\n",
       "        section_no  garment_group_no  \n",
       "0               15              1003  \n",
       "1               15              1003  \n",
       "2               15              1003  \n",
       "3               15              1003  \n",
       "4               15              1003  \n",
       "...            ...               ...  \n",
       "798264          76              1016  \n",
       "798265          44              1002  \n",
       "798266          40              1005  \n",
       "798267          18              1009  \n",
       "798268          55              1009  \n",
       "\n",
       "[798269 rows x 19 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.drop(['prod_name',\n",
    "                  'product_type_name',\n",
    "                  'graphical_appearance_name',\n",
    "                  'colour_group_name',\n",
    "                  'perceived_colour_value_name',\n",
    "                  'perceived_colour_master_name',\n",
    "                  'department_name',\n",
    "                  'index_name',\n",
    "                  'index_group_name',\n",
    "                  'section_name',\n",
    "                  'garment_group_name',\n",
    "                  'detail_desc'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a958c366",
   "metadata": {},
   "source": [
    "### Prepare Customer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94eea06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge customer meta data with transactions\n",
    "features_df = features_df.merge(customers_df, left_on='customer_id', right_on='customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a984ecce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['article_id', 'year', 'month', 'day', 'price', 'sales_channel_id',\n",
       "       'customer_id', 'product_code', 'prod_name', 'product_type_no',\n",
       "       'product_type_name', 'product_group_name', 'graphical_appearance_no',\n",
       "       'graphical_appearance_name', 'colour_group_code', 'colour_group_name',\n",
       "       'perceived_colour_value_id', 'perceived_colour_value_name',\n",
       "       'perceived_colour_master_id', 'perceived_colour_master_name',\n",
       "       'department_no', 'department_name', 'index_code', 'index_name',\n",
       "       'index_group_no', 'index_group_name', 'section_no', 'section_name',\n",
       "       'garment_group_no', 'garment_group_name', 'detail_desc', 'FN', 'Active',\n",
       "       'club_member_status', 'fashion_news_frequency', 'age', 'postal_code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11a97606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we reorganise columns\n",
    "features_df = features_df.loc[:, ['article_id',#the product\n",
    "                                  #product meta data\n",
    "                                  'product_code',\n",
    "                                  'product_type_no',\n",
    "                                  'product_group_name',\n",
    "                                  'graphical_appearance_no',\n",
    "                                  'colour_group_code', \n",
    "                                  'perceived_colour_value_id', \n",
    "                                  'perceived_colour_master_id', \n",
    "                                  'department_no',  \n",
    "                                  'index_code', \n",
    "                                  'index_group_no',  \n",
    "                                  'section_no', \n",
    "                                  'garment_group_no',\n",
    "                                  #transaction meta data\n",
    "                                  'year',\n",
    "                                  'month',\n",
    "                                  'day',\n",
    "                                  'price',\n",
    "                                  #customer class\n",
    "                                  'age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70241735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missing values\n",
    "def find_missing(df):\n",
    "    missing = df.isnull().sum() # ref: https://stackoverflow.com/questions/59694988/python-pandas-dataframe-find-missing-values\n",
    "    print(df.shape)\n",
    "    print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a516208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(798269, 18)\n",
      "article_id                       0\n",
      "product_code                     0\n",
      "product_type_no                  0\n",
      "product_group_name               0\n",
      "graphical_appearance_no          0\n",
      "colour_group_code                0\n",
      "perceived_colour_value_id        0\n",
      "perceived_colour_master_id       0\n",
      "department_no                    0\n",
      "index_code                       0\n",
      "index_group_no                   0\n",
      "section_no                       0\n",
      "garment_group_no                 0\n",
      "year                             0\n",
      "month                            0\n",
      "day                              0\n",
      "price                            0\n",
      "age                           2931\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "find_missing(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "261a808a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Garment Upper body', 'Garment Upper body', 'Garment Lower body',\n",
       "       ..., 'Accessories', 'Garment Full body', 'Garment Upper body'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.iloc[:, 3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1beae9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_no</th>\n",
       "      <th>colour_group_code</th>\n",
       "      <th>perceived_colour_value_id</th>\n",
       "      <th>perceived_colour_master_id</th>\n",
       "      <th>department_no</th>\n",
       "      <th>index_code</th>\n",
       "      <th>index_group_no</th>\n",
       "      <th>section_no</th>\n",
       "      <th>garment_group_no</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>price</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>777148006</td>\n",
       "      <td>777148</td>\n",
       "      <td>252</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010010</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1626</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1003</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>835801001</td>\n",
       "      <td>835801</td>\n",
       "      <td>252</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1626</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1003</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018627</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>923134005</td>\n",
       "      <td>923134</td>\n",
       "      <td>272</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1636</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1005</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>865929003</td>\n",
       "      <td>865929</td>\n",
       "      <td>254</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010001</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1636</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1005</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>935858001</td>\n",
       "      <td>935858</td>\n",
       "      <td>252</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4091</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1001</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id  product_code  product_type_no  product_group_name  \\\n",
       "0  777148006        777148              252  Garment Upper body   \n",
       "1  835801001        835801              252  Garment Upper body   \n",
       "2  923134005        923134              272  Garment Lower body   \n",
       "3  865929003        865929              254  Garment Upper body   \n",
       "4  935858001        935858              252  Garment Upper body   \n",
       "\n",
       "   graphical_appearance_no  colour_group_code  perceived_colour_value_id  \\\n",
       "0                  1010010                 52                          7   \n",
       "1                  1010016                 11                          1   \n",
       "2                  1010016                 91                          1   \n",
       "3                  1010001                 12                          1   \n",
       "4                  1010016                  9                          4   \n",
       "\n",
       "   perceived_colour_master_id  department_no index_code  index_group_no  \\\n",
       "0                           4           1626          A               1   \n",
       "1                           9           1626          A               1   \n",
       "2                          19           1636          A               1   \n",
       "3                          11           1636          A               1   \n",
       "4                           5           4091          D               2   \n",
       "\n",
       "   section_no  garment_group_no  year  month  day     price   age  \n",
       "0          15              1003  2020      9    1  0.013542  44.0  \n",
       "1          15              1003  2020      9    1  0.018627  44.0  \n",
       "2          15              1005  2020      9    1  0.012695  44.0  \n",
       "3          15              1005  2020      9    1  0.016932  44.0  \n",
       "4          50              1001  2020      9    7  0.016932  44.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b497f4cd",
   "metadata": {},
   "source": [
    "### Encode Data (After Timesplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b1c2c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we now encode any categorical variables in our training and testing data\n",
    "le = preprocessing.LabelEncoder()\n",
    "features_df.iloc[:, 3] = le.fit_transform(features_df.iloc[:,3])#product_group_name\n",
    "features_df.iloc[:, 9] = le.fit_transform(features_df.iloc[:,9])#index_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df48d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "imputer_med = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "age = features_df.iloc[:, 17:18].values\n",
    "\n",
    "#we replace any missing age values with the median age\n",
    "imputer_med.fit(age)\n",
    "age = imputer_med.transform(age)\n",
    "\n",
    "#now add corrected column back into our main customer dataframe\n",
    "features_df.iloc[:, -1] = age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c858cd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(798269, 18)\n",
      "article_id                    0\n",
      "product_code                  0\n",
      "product_type_no               0\n",
      "product_group_name            0\n",
      "graphical_appearance_no       0\n",
      "colour_group_code             0\n",
      "perceived_colour_value_id     0\n",
      "perceived_colour_master_id    0\n",
      "department_no                 0\n",
      "index_code                    0\n",
      "index_group_no                0\n",
      "section_no                    0\n",
      "garment_group_no              0\n",
      "year                          0\n",
      "month                         0\n",
      "day                           0\n",
      "price                         0\n",
      "age                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "find_missing(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adbd9810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace minus sign in text and check result of dataset after imputing missing values\n",
    "features_df.columns = features_df.columns.str.replace('-', '')\n",
    "\n",
    "#lower case columns\n",
    "features_df.columns = map(str.lower, features_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4a1ca1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_no</th>\n",
       "      <th>colour_group_code</th>\n",
       "      <th>perceived_colour_value_id</th>\n",
       "      <th>perceived_colour_master_id</th>\n",
       "      <th>department_no</th>\n",
       "      <th>index_code</th>\n",
       "      <th>index_group_no</th>\n",
       "      <th>section_no</th>\n",
       "      <th>garment_group_no</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>price</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>798264</th>\n",
       "      <td>828321001</td>\n",
       "      <td>828321</td>\n",
       "      <td>265</td>\n",
       "      <td>4</td>\n",
       "      <td>1010014</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4314</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1019</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798265</th>\n",
       "      <td>818890001</td>\n",
       "      <td>818890</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>1010016</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3519</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>1019</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798266</th>\n",
       "      <td>818890001</td>\n",
       "      <td>818890</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>1010016</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3519</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>1019</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798267</th>\n",
       "      <td>930405002</td>\n",
       "      <td>930405</td>\n",
       "      <td>265</td>\n",
       "      <td>4</td>\n",
       "      <td>1010026</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1322</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1013</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>0.067780</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798268</th>\n",
       "      <td>790006001</td>\n",
       "      <td>790006</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>1010016</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1201</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1007</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>0.084729</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id  product_code  product_type_no  product_group_name  \\\n",
       "798264  828321001        828321              265                   4   \n",
       "798265  818890001        818890               76                   0   \n",
       "798266  818890001        818890               76                   0   \n",
       "798267  930405002        930405              265                   4   \n",
       "798268  790006001        790006              262                   6   \n",
       "\n",
       "        graphical_appearance_no  colour_group_code  perceived_colour_value_id  \\\n",
       "798264                  1010014                  9                          4   \n",
       "798265                  1010016                  9                          4   \n",
       "798266                  1010016                  9                          4   \n",
       "798267                  1010026                 92                          2   \n",
       "798268                  1010016                  9                          4   \n",
       "\n",
       "        perceived_colour_master_id  department_no  index_code  index_group_no  \\\n",
       "798264                           5           4314           8               4   \n",
       "798265                           5           3519           2               1   \n",
       "798266                           5           3519           2               1   \n",
       "798267                          20           1322           0               1   \n",
       "798268                           5           1201           0               1   \n",
       "\n",
       "        section_no  garment_group_no  year  month  day     price   age  \n",
       "798264          43              1019  2020      9   22  0.033881  34.0  \n",
       "798265          65              1019  2020      9   22  0.016932  75.0  \n",
       "798266          65              1019  2020      9   22  0.016932  75.0  \n",
       "798267          15              1013  2020      9   22  0.067780  21.0  \n",
       "798268          19              1007  2020      9   22  0.084729  28.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will encode and scale after we have split our data\n",
    "features_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c1954",
   "metadata": {},
   "source": [
    "\n",
    "### Split Data Into Train & Test Set \n",
    "We take the past 2 weeks as training data and 1 week in the future as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54e0fe8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(798269, 18)\n",
      "article_id                    0\n",
      "product_code                  0\n",
      "product_type_no               0\n",
      "product_group_name            0\n",
      "graphical_appearance_no       0\n",
      "colour_group_code             0\n",
      "perceived_colour_value_id     0\n",
      "perceived_colour_master_id    0\n",
      "department_no                 0\n",
      "index_code                    0\n",
      "index_group_no                0\n",
      "section_no                    0\n",
      "garment_group_no              0\n",
      "year                          0\n",
      "month                         0\n",
      "day                           0\n",
      "price                         0\n",
      "age                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "find_missing(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5bf142be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531905"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mask = (features_df['year'] >= 2020) & (features_df['month'] >= 9) & (features_df['day'] >= 1) & (features_df['year'] <= 2020) & (features_df['month'] <= 9) & (features_df['day'] <= 14)\n",
    "train_df = features_df.loc[train_mask]\n",
    "train_df['article_id'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13717566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266364"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mask = (features_df['year'] >= 2020) & (features_df['month'] >= 9) & (features_df['day'] >= 15) & (features_df['year'] <= 2020) & (features_df['month'] <= 9) & (features_df['day'] <= 22)\n",
    "test_df = features_df.loc[test_mask]\n",
    "test_df['article_id'].size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a83a302",
   "metadata": {},
   "source": [
    "### Create Feature & Target Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f98285a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(531905, 15)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are the attributes of our customers\n",
    "X_train = train_df.iloc[:, 1: 16].values\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d671ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(531905,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the product or in our case the class\n",
    "y_train = train_df.iloc[:, 17].values\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "519dd1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266364, 15)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are future customers\n",
    "X_test = test_df.iloc[:, 1: 16].values\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "50d7b02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266364,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are future products\n",
    "y_test = test_df.iloc[:, 17].values\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3acf7e5",
   "metadata": {},
   "source": [
    "### Feature Scaling: MinMax - range (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f7ddef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ae7ade2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78869468, 0.33158585, 0.375     , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.8579065 , 0.33158585, 0.375     , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.96096134, 0.35779817, 0.3125    , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.69736926, 0.40498034, 0.375     , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.83697055, 0.34076016, 0.375     , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.63056823, 0.12450852, 0.625     , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0b7a32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266364, 15)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = min_max_scaler.fit_transform(X_test)\n",
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ed77db",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c009a3",
   "metadata": {},
   "source": [
    "### Training the K-NN model on our Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e05428a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps = [('svd', TruncatedSVD(n_components=15)), ('knn', hm_clf)]\n",
    "# n_neighbors: number of neighbors. Default is 5\n",
    "# metric=\"minkowski\", p=2: will calculate distance as eucledian distance formula\n",
    "#PCA 95% of variance\n",
    "steps = [('pca', PCA(n_components = 0.95)), ('knn', KNeighborsClassifier(n_neighbors=5, metric=\"minkowski\", p=2))]\n",
    "model = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d69686d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pca', PCA(n_components=0.95)),\n",
       "                ('knn', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e34a325",
   "metadata": {},
   "source": [
    "### Predicting a new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e946dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classifier.predict(sc.transform([[0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37, 30,2020-09-08]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc98226",
   "metadata": {},
   "source": [
    "### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b60140b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6777cfe2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43my_pred\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred # here we see the model predict products for the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d135b5",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3abbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of H&M KNN Classifier:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982bfb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score for H&M KNN Classifier:\", precision_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65811a0e",
   "metadata": {},
   "source": [
    "## Results & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c03ebb",
   "metadata": {},
   "source": [
    "First H&M KNN Classifier Model Accuracy was 0.00497 and Precision Score was 0.001, both less than 1% accurate.\n",
    " * We used the last 3 weeks in September 2020 from our transaction dataset to be used later for training and testing data.\n",
    " * We used Customer attributes, the full date range (YYYY-MM-DD) and transaction attributes as features to predict products.\n",
    " * We filled in missing data in our customer attributes using SimpleImputer to impute most frequent categories and median was used to impute missing ages.\n",
    " * We split our data up by time instead of random assignment. This meant 2 weeks (in the past) were used for training and 1 week (in the future) was used for testing testing\n",
    " * We encoded our categorical data using the LabelEncoder and date feature by converting the date into an ordinal number. This was after the training/test split.\n",
    " * We created our training and testing datasets and scaled them using MinMax range (0 to 1)\n",
    " * To build the KNN Classifier model, we used k=5 and our metric was minkowski p2, This meant we calculated the distance using eucledian distance formula.\n",
    " * To evaluate the model, we used accuracy as a measuring score. Which compared our predicted products to what was in the test dataset.\n",
    " \n",
    "Second H&M KNN Classifier Model Accuracy increased to 0.432 and Precision Score increased to 0.161:\n",
    " * We included product attributes in with Customer attributes, the full date range (YYYY-MM-DD) and transaction attributes as features to predict products. This lead to curse of dimensionality. The KNN Classifier performs poorly with too many features. For the next test we should reduce the amount of features we have. To do this we must use dimension reduction techniques such as principle component analysis (when we have lots of features) or singular value decomposition (SVD) when we have sparse data.\n",
    " \n",
    "Third H&M KNN Classifier Model Accuracy increased to 0.422 and Precision Score increased to 0.151:\n",
    "* SVD reduced our features down to 15 and also reduced our accuracy but sped up processing, we will try PCA to compare\n",
    "\n",
    "Fourth H&M KNN Classifier Model Accuracy increased to 0.038 and Precision Score increased to 0.0144:\n",
    "* We removed customer and tried to predict customer age\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa6c783",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c086e6",
   "metadata": {},
   "source": [
    "* https://www.kaggle.com/code/martandsay/knn-multi-classification-animal-classification/notebook\n",
    "* https://towardsdatascience.com/multiclass-classification-using-k-nearest-neighbours-ca5281a9ef76\n",
    "* https://analyticsindiamag.com/singular-value-decomposition-svd-application-recommender-system/\n",
    "* https://machinelearningmastery.com/singular-value-decomposition-for-dimensionality-reduction-in-python/\n",
    "* https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    "* https://www.kaggle.com/code/lichtlab/h-m-data-deep-dive-chap-1-understand-article\n",
    "* https://www.kaggle.com/code/vanguarde/h-m-eda-first-look\n",
    "* https://www.mikulskibartosz.name/pca-how-to-choose-the-number-of-components/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddd1a86",
   "metadata": {},
   "source": [
    "# Generate Kaggle Predictions File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32632014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#H&M Collaborative KNN Model Based Recommendation System\n",
    "def hm_rec_sys(t_df, c_df, a_df, write_file):\n",
    "    \n",
    "    #output message for user\n",
    "    clear_output(wait=True)\n",
    "    display('preparing data...')\n",
    "    \n",
    "    #DATA PREPARATION   \n",
    "    features_df = t_df[['article_id','customer_id', 't_dat', 'price', 'sales_channel_id']]\n",
    "    \n",
    "    #First we will convert our date text into a panda date type.\n",
    "    features_df[\"t_dat\"] = pd.to_datetime(features_df[\"t_dat\"])\n",
    "    \n",
    "    #we convert articles to string instead of default int.\n",
    "    features_df['article_id'] = features_df['article_id'].values.astype(str)\n",
    "    \n",
    "    #merge product meta data with transactions\n",
    "    features_df = features_df.merge(a_df, left_on='article_id', right_on='article_id')\n",
    "    \n",
    "    #we drop cols we don't need from products dataset\n",
    "    features_df.drop(['prod_name',\n",
    "                      'product_type_name',\n",
    "                      'graphical_appearance_name',\n",
    "                      'colour_group_name',\n",
    "                      'perceived_colour_value_name',\n",
    "                      'perceived_colour_master_name',\n",
    "                      'department_name',\n",
    "                      'index_name',\n",
    "                      'index_group_name',\n",
    "                      'section_name',\n",
    "                      'garment_group_name',\n",
    "                      'detail_desc'], axis=1)    \n",
    "    \n",
    "    #merge customer meta data with transactions\n",
    "    features_df = features_df.merge(c_df, left_on='customer_id', right_on='customer_id')\n",
    "    \n",
    "    #drop post code as it is similar to customer_id\n",
    "    features_df = features_df.drop(['postal_code'], axis=1)\n",
    "    \n",
    "    #we reorganise columns\n",
    "    features_df = features_df.loc[:, ['customer_id',#the customer\n",
    "                                      'FN',#customer meta data\n",
    "                                      'Active',\n",
    "                                      'club_member_status', \n",
    "                                      'fashion_news_frequency', \n",
    "                                      'age',\n",
    "                                      'product_code',#product meta data\n",
    "                                      'product_type_no',\n",
    "                                      'product_group_name',\n",
    "                                      'graphical_appearance_no',\n",
    "                                      'colour_group_code', \n",
    "                                      'perceived_colour_value_id', \n",
    "                                      'perceived_colour_master_id', \n",
    "                                      'department_no',  \n",
    "                                      'index_code', \n",
    "                                      'index_group_no',  \n",
    "                                      'section_no', \n",
    "                                      'garment_group_no', \n",
    "                                      't_dat',#transaction meta data\n",
    "                                      'price',\n",
    "                                      'sales_channel_id', \n",
    "                                      'article_id']]#the product\n",
    "    \n",
    "    #convert from objects and floats to categories and ints\n",
    "    features_df['club_member_status'] = features_df['club_member_status'].astype('category')\n",
    "    features_df['fashion_news_frequency'] = features_df['fashion_news_frequency'].astype('category')\n",
    "    \n",
    "    features_df['FN'] = features_df['FN'].fillna(0)\n",
    "    features_df['Active'] = features_df['Active'].fillna(0)\n",
    "\n",
    "    club_member_status = features_df.iloc[:, 3:-18].values\n",
    "    fashion_news_frequency = features_df.iloc[:, 4:-17].values\n",
    "    age = features_df.iloc[:, 5:-16].values\n",
    "\n",
    "    #ref: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "    imputer_med = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    imputer_mf = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "    #we replace missing values with the most frequent\n",
    "    imputer_mf.fit(club_member_status)\n",
    "    club_member_status = imputer_mf.transform(club_member_status)\n",
    "\n",
    "    imputer_mf.fit(fashion_news_frequency)\n",
    "    fashion_news_frequency = imputer_mf.transform(fashion_news_frequency)\n",
    "\n",
    "    #we replace any missing age values with the median age\n",
    "    imputer_med.fit(age)\n",
    "    age = imputer_med.transform(age)\n",
    "\n",
    "    #now add corrected columns back into our main customer dataframe\n",
    "    features_df.iloc[:, 3:-18] = club_member_status\n",
    "    features_df.iloc[:, 4:-17] = fashion_news_frequency\n",
    "    features_df.iloc[:, 5:-16] = age\n",
    "\n",
    "    #replace minus sign in text and check result of dataset after imputing missing values\n",
    "    features_df.columns = features_df.columns.str.replace('-', '')\n",
    "\n",
    "    #lower case columns\n",
    "    features_df.columns = map(str.lower, features_df.columns)\n",
    "    \n",
    "    #encode our categorical variables\n",
    "    features_df.iloc[:,3] = le.fit_transform(features_df.iloc[:,3])#club_member_status\n",
    "    features_df.iloc[:,4] = le.fit_transform(features_df.iloc[:,4])#fashion_news_frequency\n",
    "    features_df.iloc[:,8] = le.fit_transform(features_df.iloc[:,8])#product_group_name\n",
    "    features_df.iloc[:,14] = le.fit_transform(features_df.iloc[:,14])#index_code\n",
    "    \n",
    "    #encode date as ordinal after we split our training and test data\n",
    "    train_df['t_dat'] = train_df['t_dat'].apply(lambda x: x.toordinal())\n",
    "\n",
    "    #These are the attributes of our customers\n",
    "    X_train = features_df.iloc[:, 1: 20].values\n",
    "    \n",
    "    # this is the product or in our case the class\n",
    "    y_train = features_df.iloc[:, 21].values\n",
    "    \n",
    "    # FEATURE SCALING: MinMax - range (0,1)\n",
    "    X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
    "    \n",
    "    #create model pipeline\n",
    "    steps = [('pca', PCA(.95)), ('knn', KNeighborsClassifier(n_neighbors=5, metric=\"minkowski\", p=2)]\n",
    "    model = Pipeline(steps=steps)\n",
    "\n",
    "    #output message for user\n",
    "    clear_output(wait=True)\n",
    "    display('training model please wait...')\n",
    "                                 \n",
    "    #TRAIN MODEL\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "    #output message for user\n",
    "    clear_output(wait=True)\n",
    "    display('making predictions...')\n",
    "\n",
    "    #predict in next 7 days from 2020-09-29\n",
    "    date = {'date': ['2020-09-29']}\n",
    "    d_df = pd.DataFrame(values)\n",
    "    d_df['date'] = pd.to_datetime(df['date'], format='%Y-%m%-d')\n",
    "    d_df['date'] = d_df['date'].apply(lambda x: x.toordinal())\n",
    "    d = d_df['date'].iloc[:].values\n",
    "                                 \n",
    "    #write_file = \"predictions.csv\"\n",
    "    with open(write_file, \"wt\", encoding=\"utf-8\") as output:\n",
    "        #add headers first\n",
    "        output.write(\"customer_id,prediction\" + '\\n')\n",
    "        \n",
    "        #now we loop through each row and write predictions to csv file\n",
    "        for index_i, cus in c_df.iterrows():\n",
    "            #get past price\n",
    "            #get past sales channel\n",
    "            p = t_df['price'].mode()\n",
    "            s = t_df['sales_channel_id'].mode()\n",
    "            \n",
    "            #we keep trying different products until we make a hit then we add it to the list\n",
    "            for index_j, art in a_df.iterrows():\n",
    "                #get their meta data   \n",
    "                features_df = [cus['FN'], \n",
    "                               cus['Active'], \n",
    "                               cus['club_member_status'], \n",
    "                               cus['fashion_news_frequency'],\n",
    "                               cus['age'],\n",
    "                               art['product_code'], \n",
    "                               art['product_type_no'],\n",
    "                               art['product_group_name'],\n",
    "                               art['graphical_appearance_no'],\n",
    "                               art['colour_group_code'], \n",
    "                               art['perceived_colour_value_id'], \n",
    "                               art['perceived_colour_master_id'], \n",
    "                               art['department_no'],  \n",
    "                               art['index_code'], \n",
    "                               art['index_group_no'],  \n",
    "                               art['section_no'], \n",
    "                               art['garment_group_no'],\n",
    "                               d,\n",
    "                               p,\n",
    "                               s]\n",
    "\n",
    "                #normalise data\n",
    "                q_cus_scaled = min_max_scaler.fit_transform(features_df)\n",
    "\n",
    "                #make a prediction\n",
    "                y_pred = model.predict(q_cus_scaled)\n",
    "                result.append(y_pred)\n",
    " \n",
    "                #create prediction csv file\n",
    "                r = []\n",
    "                r.append(cus.customer_id + \",\")\n",
    "                for n in result:\n",
    "                    p = names.iloc[n]\n",
    "                    r.append(str(p))\n",
    "                    prediction =  ' '.join(r)\n",
    "                #write predictions to csv file\n",
    "                output.write(prediction + '\\n')\n",
    "                clear_output(wait=True)\n",
    "                display('Processed Row: ' + str(index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
