{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82866eef",
   "metadata": {},
   "source": [
    "# Requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7127d743",
   "metadata": {},
   "source": [
    "For each customer (customer_id), H&M want a prediction of up to 12 products (article_ids), which is the predicted items a customer will buy in the next 7-day period after the training time period. The file should contain a header and have the following format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbd31156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working with files and memory management\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#used during data exploration\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "#handling missing values where not dropped\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811fac61",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a307ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get transaction data\n",
    "transactions_train_df = pd.read_csv(\"data/transactions_train.csv\",\n",
    "                                    index_col=['article_id'],\n",
    "                                    usecols=['article_id', \n",
    "                                             't_dat', \n",
    "                                             'price', \n",
    "                                             'customer_id'],\n",
    "                                    parse_dates=[\"t_dat\"]) # import the transactions dataset dtype={'article_id': 'str'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3d2e1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>663713001</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0.050831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541518023</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0.030492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505221004</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0.015237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685687003</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0.016932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685687004</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0.016932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                t_dat                                        customer_id  \\\n",
       "article_id                                                                 \n",
       "663713001  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
       "541518023  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
       "505221004  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   \n",
       "685687003  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   \n",
       "685687004  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   \n",
       "\n",
       "               price  \n",
       "article_id            \n",
       "663713001   0.050831  \n",
       "541518023   0.030492  \n",
       "505221004   0.015237  \n",
       "685687003   0.016932  \n",
       "685687004   0.016932  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3dfedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get product meta data\n",
    "articles_df = pd.read_csv('data/articles.csv',\n",
    "                          index_col=['article_id'],\n",
    "                          usecols=['article_id',\n",
    "                                   'product_type_no', #e.g Scarf\n",
    "                                   'graphical_appearance_no', # e.g stripe\n",
    "                                   'colour_group_code', #e.g white\n",
    "                                   'index_group_no',#e.g ladies wear\n",
    "                                   'detail_desc'],\n",
    "                          dtype={'article_id': 'str'}) # drop text, no clothing size available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b21edcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>graphical_appearance_no</th>\n",
       "      <th>colour_group_code</th>\n",
       "      <th>index_group_no</th>\n",
       "      <th>detail_desc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0108775015</th>\n",
       "      <td>253</td>\n",
       "      <td>1010016</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0108775044</th>\n",
       "      <td>253</td>\n",
       "      <td>1010016</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0108775051</th>\n",
       "      <td>253</td>\n",
       "      <td>1010017</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0110065001</th>\n",
       "      <td>306</td>\n",
       "      <td>1010016</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0110065002</th>\n",
       "      <td>306</td>\n",
       "      <td>1010016</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            product_type_no  graphical_appearance_no  colour_group_code  \\\n",
       "article_id                                                                \n",
       "0108775015              253                  1010016                  9   \n",
       "0108775044              253                  1010016                 10   \n",
       "0108775051              253                  1010017                 11   \n",
       "0110065001              306                  1010016                  9   \n",
       "0110065002              306                  1010016                 10   \n",
       "\n",
       "            index_group_no                                        detail_desc  \n",
       "article_id                                                                     \n",
       "0108775015               1            Jersey top with narrow shoulder straps.  \n",
       "0108775044               1            Jersey top with narrow shoulder straps.  \n",
       "0108775051               1            Jersey top with narrow shoulder straps.  \n",
       "0110065001               1  Microfibre T-shirt bra with underwired, moulde...  \n",
       "0110065002               1  Microfibre T-shirt bra with underwired, moulde...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35b7c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get customer meta data\n",
    "customers_df = pd.read_csv('data/customers.csv',\n",
    "                           usecols=['customer_id'])#just import customer ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "159e55e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1371980 entries, 0 to 1371979\n",
      "Data columns (total 1 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   customer_id  1371980 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 10.5+ MB\n"
     ]
    }
   ],
   "source": [
    "customers_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89abe2c",
   "metadata": {},
   "source": [
    "# Prepare the Transaction Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e43ad3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "798269"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will use a 3 week date range between 2020-09-8 and 2020-09-22 to reduce our dataset size.\n",
    "mask = (transactions_train_df['t_dat'] >= '2020-09-01') & (transactions_train_df['t_dat'] <= '2020-09-22')\n",
    "transactions_train_df = transactions_train_df.loc[mask]\n",
    "transactions_train_df['customer_id'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dafb6c0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#merge product meta data with transactions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m transactions_train_df \u001b[38;5;241m=\u001b[39m \u001b[43mtransactions_train_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticles_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marticle_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marticle_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\pandas\\core\\frame.py:9345\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   9326\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   9327\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m   9328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9341\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   9342\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   9343\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[1;32m-> 9345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9346\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9354\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9355\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 107\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:704\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    696\u001b[0m (\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m    700\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 704\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1257\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[0;32m   1252\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   1253\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1254\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1255\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1256\u001b[0m     ):\n\u001b[1;32m-> 1257\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "#merge product meta data with transactions\n",
    "transactions_train_df = transactions_train_df.merge(articles_df, left_on='article_id', right_on='article_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7de6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we split out the date into seperate columns for day, month and year making use of python zip for memory efficiency\n",
    "days, months, years  = zip(*[(d.day, d.month, d.year) for d in transactions_train_df['t_dat']])\n",
    "transactions_train_df = transactions_train_df.assign(day=days, month=months, year=years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92ffa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8c0923",
   "metadata": {},
   "source": [
    "## Split Data Into Train & Test Set \n",
    "We take the past 2 weeks as training data and 1 week in the future as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247dd9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = (transactions_train_df['t_dat'] >= '2020-09-01') & (transactions_train_df['t_dat'] <= '2020-09-14')\n",
    "train_df = transactions_train_df.loc[train_mask]\n",
    "train_df['customer_id'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1094df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['day'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd769aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mask = (transactions_train_df['t_dat'] >= '2020-09-15') & (transactions_train_df['t_dat'] <= '2020-09-22')\n",
    "test_df = transactions_train_df.loc[test_mask]\n",
    "test_df['customer_id'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ebd227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store features as numpy array Xy\n",
    "#names = ts_train_df.index\n",
    "names = train_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2016b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c58084",
   "metadata": {},
   "source": [
    "# Plot Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d20501",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_type = train_df['product_type_no'].values # x\n",
    "colour = train_df['colour_group_code'].values # y\n",
    "\n",
    "q_product_type = test_df['product_type_no'].values[1] # x\n",
    "q_colour = test_df['colour_group_code'].values[1]\n",
    "\n",
    "#place day/price points on graph\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(product_type, colour, color='green')\n",
    "\n",
    "#place query on graph\n",
    "plt.scatter(q_product_type, q_colour,color='black')\n",
    "plt.annotate('q',(q_product_type+0.2, q_colour))\n",
    "\n",
    "#label graph\n",
    "plt.title(\"H&M\")\n",
    "plt.xlabel(\"Product Type\")\n",
    "plt.ylabel(\"Colour\")\n",
    "\n",
    "#display graph\n",
    "plt.grid()\n",
    "\n",
    "#populate product names on the graph\n",
    "#for i, txt in enumerate(names):\n",
    "#    plt.annotate(txt, (days[i]+0.09, prices[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792591b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.iloc[:, np.r_[3, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57d33e3",
   "metadata": {},
   "source": [
    "# Normalise the Sample Transaction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f6ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = min_max_scaler.fit_transform(train_df.iloc[:, np.r_[3, 5]])\n",
    "\n",
    "#scaler = preprocessing.StandardScaler().fit(train_df.iloc[:, np.r_[3, 4]])  #need a handle on the scaler to apply to training and test data\n",
    "#X_scaled = scaler.fit_transform(train_df.iloc[:, np.r_[3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d72aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q_scaled = scaler.fit_transform([[test_df['product_type_no'].values[1], test_df['colour_group_code'].values[1]]])\n",
    "q_scaled = min_max_scaler.transform([[test_df['product_type_no'].values[550], test_df['colour_group_code'].values[550]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a96085",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f230ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_scaled[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213225d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check new scale\n",
    "product_type = X_scaled[:,0] # x\n",
    "colour = X_scaled[:,1] # y\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(product_type, colour, color='green')\n",
    "\n",
    "plt.scatter(q_scaled[:,0],q_scaled[:,1],color='black')\n",
    "plt.annotate('q',(q_scaled[:, 0]+0.03,q_scaled[:, 1]))\n",
    "\n",
    "plt.title(\"H&M\")\n",
    "plt.xlabel(\"Product Type\")\n",
    "plt.ylabel(\"Colour\")\n",
    "plt.grid()\n",
    "#plt.legend(handles=[red_patch, blue_patch],loc=4)\n",
    "#for i, txt in enumerate(names):\n",
    "#    plt.annotate(txt, (days[i]+0.09, prices[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3879d8c3",
   "metadata": {},
   "source": [
    "# Train a KNN Model on Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98212e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = NearestNeighbors(n_neighbors=12, radius=0.4)\n",
    "knn_model.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af34d34f",
   "metadata": {},
   "source": [
    "# Predict with KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get neighbours' names where k=12\n",
    "result = knn_model.kneighbors(q_scaled, 12)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3976a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for n in result:\n",
    "#    i = names[n]\n",
    "#    print(str(n))\n",
    "names[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ca07169",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3369\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Input \u001b[0;32mIn [49]\u001b[0m in \u001b[0;35m<cell line: 2>\u001b[0m\n    item = articles_df.query('index == ' + str(p))\n",
      "  File \u001b[0;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\pandas\\core\\frame.py:4111\u001b[0m in \u001b[0;35mquery\u001b[0m\n    res = self.eval(expr, **kwargs)\n",
      "  File \u001b[0;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\pandas\\core\\frame.py:4240\u001b[0m in \u001b[0;35meval\u001b[0m\n    return _eval(expr, inplace=inplace, **kwargs)\n",
      "  File \u001b[0;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\pandas\\core\\computation\\eval.py:350\u001b[0m in \u001b[0;35meval\u001b[0m\n    parsed_expr = Expr(expr, engine=engine, parser=parser, env=env)\n",
      "  File \u001b[0;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\pandas\\core\\computation\\expr.py:811\u001b[0m in \u001b[0;35m__init__\u001b[0m\n    self.terms = self.parse()\n",
      "  File \u001b[0;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\pandas\\core\\computation\\expr.py:830\u001b[0m in \u001b[0;35mparse\u001b[0m\n    return self._visitor.visit(self.expr)\n",
      "  File \u001b[0;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\pandas\\core\\computation\\expr.py:411\u001b[0m in \u001b[0;35mvisit\u001b[0m\n    raise e\n",
      "  File \u001b[0;32md:\\projects\\tudublin\\tu060\\machine learning\\venv\\lib\\site-packages\\pandas\\core\\computation\\expr.py:407\u001b[0m in \u001b[0;35mvisit\u001b[0m\n    node = ast.fix_missing_locations(ast.parse(clean))\n",
      "\u001b[1;36m  File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\ast.py:47\u001b[1;36m in \u001b[1;35mparse\u001b[1;36m\u001b[0m\n\u001b[1;33m    return compile(source, filename, mode, flags,\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m<unknown>:1\u001b[1;36m\u001b[0m\n\u001b[1;33m    index ==0 882759006\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# result contains the 'index' of the nearest neighbours\n",
    "for n in result:\n",
    "    p = names[n]\n",
    "    item = articles_df.query('index == ' + str(p))\n",
    "    print(\"PRODUCT: \" + str(p))\n",
    "    print(item.iloc[0][4])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2329201",
   "metadata": {},
   "source": [
    "# Evaluate Model on Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c71e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(test_query[:,3:5])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "035fdf55",
   "metadata": {},
   "source": [
    "for i,p in enumerate(predicted):\n",
    "    if p in actual and p not in predicted[:i]:\n",
    "        num_hits += 1.0\n",
    "        score += num_hits / (i+1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f14e26",
   "metadata": {},
   "source": [
    "# Generate Predictions File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d53eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#H&M Collaborative KNN Model Based Recommendation System\n",
    "def hm_rec_sys(r_model, cus_df, write_file):  \n",
    "    \n",
    "    #write_file = \"ros_predictions.csv\"\n",
    "    with open(write_file, \"wt\", encoding=\"utf-8\") as output:\n",
    "        #add headers first\n",
    "        output.write(\"customer_id,prediction\" + '\\n')\n",
    "        \n",
    "        #now we loop through each row and write predictions to csv file\n",
    "        for index, cus in cus_df.iterrows():\n",
    "            #select day and price and convert them to np array\n",
    "            q_cus = np.array([cus['day'],cus['price']], dtype=float) #cus[3:5]\n",
    "            \n",
    "            #normalise data\n",
    "            q_cus_scaled = scaler.transform([q_cus])\n",
    "\n",
    "            #get neighbours' names where k=12\n",
    "            result = r_model.kneighbors(q_cus_scaled, 12)[1][0]\n",
    "            \n",
    "            #create prediction csv file\n",
    "            r = []\n",
    "            r.append(cus.customer_id + \",\")\n",
    "            for n in result:\n",
    "                p = names.iloc[n]\n",
    "                r.append(\"0\" + str(p))\n",
    "                prediction =  ' '.join(r)\n",
    "            #write predictions to csv file\n",
    "            output.write(prediction + '\\n')\n",
    "            clear_output(wait=True)\n",
    "            display('Processed Row: ' + str(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062928c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we now generate our intial predictions list and save it as a csv file\n",
    "hm_rec_sys(knn_model, cus_pred_df, \"data/ros_predictions3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de051749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect our prediction data\n",
    "predictions_df = pd.read_csv(\"data/ros_predictions3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe27ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1925033",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['customer_id'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543922c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
