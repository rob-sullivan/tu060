{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "Example taken from *Introduction to Machine Learning with Python* by Muller and Guido.  \n",
    "You will need to install `mglearn` (`pip install mglearn`)  \n",
    "mglearn github repo: https://github.com/amueller/mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hotel Review Data\n",
    "Neural Network with 20 units in the hidden layer manages to perfectly learn this dataset.  \n",
    "Accuracy on training set is 100%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "HR = pd.read_csv('data/HotelRevHelpfulness.csv')\n",
    "HR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HR.pop('hotelId')\n",
    "y = HR.pop('reviewHelpfulness').values\n",
    "scaler = preprocessing.StandardScaler().fit(HR)\n",
    "X_scaled = scaler.transform(HR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=2000, random_state=2,\n",
    "                    hidden_layer_sizes=[20])\n",
    "mlp.fit(X_scaled, y)\n",
    "acc = mlp.score(X_scaled, y)\n",
    "print(\"Accuracy on training set: {:.2f}\".format(acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the weights in a heatmap, it seems some features are not influential, e.g. `completeness3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = HR.columns\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.imshow(mlp.coefs_[0], interpolation='none', cmap='YlGnBu')\n",
    "plt.yticks(range(len(features)), features)\n",
    "plt.xlabel(\"Columns in weight matrix\")\n",
    "plt.ylabel(\"Input feature\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout testing\n",
    "- Divide the data into train and test splits\n",
    "- Build multiple models with different stopping conditions (iterations)\n",
    "- Overfitting increases with training\n",
    "- Regularization (set alpha to e.g. 5) stops overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = HR.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 1/3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs',random_state=0, max_iter=100)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_range = range(10,200,10)\n",
    "tr_scores = []\n",
    "ts_scores = []\n",
    "\n",
    "# alpha = 0.15 shows overfitting\n",
    "# alpha = 5 provides good regularization (little overfitting)\n",
    "for i in eval_range:\n",
    "    mlp = MLPClassifier(random_state=0, alpha = .15, max_iter=i)\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "#    print(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "#    print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test))) \n",
    "    tr_scores.append(mlp.score(X_train_scaled, y_train))\n",
    "    ts_scores.append(mlp.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Train': tr_scores, 'Test': ts_scores}, index = eval_range) \n",
    "ax = df.plot(lw=2, title='Train & Test Accuracy')\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_ylim(0.5,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Two Moons dataset\n",
    "Using synthetic data generated using `make_moons` - two dimensions, 100 samples.  \n",
    "Default MLPClassifier parameters:\n",
    "- 1 hidden layer, 100 units\n",
    "- learning_rate_init = 0.001\n",
    "- max_iter = 200\n",
    "- momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mglearn\n",
    "\n",
    "X, y = make_moons(n_samples=100, noise=0.25, random_state=3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                        random_state=42)\n",
    "mlp = MLPClassifier(solver='lbfgs', random_state=0).fit(X_train, y_train)\n",
    "mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the default parameters. \n",
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the number of units in the hidden layer to 3 - a much simpler model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', random_state=0, hidden_layer_sizes=[3])\n",
    "mlp.fit(X_train, y_train)\n",
    "mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using two hidden layers, with 10 units each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', random_state=0,\n",
    "                        hidden_layer_sizes=[10, 10])\n",
    "mlp.fit(X_train, y_train)\n",
    "mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different learning rates and different structures - 2 hidden layers with 10 or 100 nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(20, 8)) \n",
    "for axx, n_hidden_nodes in zip(axes, [10, 100]):\n",
    "    for ax, lr in zip(axx, [0.01, 0.1, 0.5, 1]):\n",
    "        mlp = MLPClassifier(solver='sgd', random_state=0,\n",
    "                                hidden_layer_sizes=[n_hidden_nodes, n_hidden_nodes],\n",
    "                                max_iter = 2000, learning_rate_init=lr)\n",
    "        mlp.fit(X_train, y_train)\n",
    "        mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3, ax=ax) \n",
    "        mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train, ax=ax) \n",
    "        ax.set_title(\"n_hidden=[{}, {}]\\n learning_rate={:.4f}\".format(\n",
    "                          n_hidden_nodes, n_hidden_nodes, lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different random initialisations will also produce quite different models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(20, 8)) \n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "        mlp = MLPClassifier(solver='lbfgs', random_state=i,\n",
    "                            hidden_layer_sizes=[100, 100])\n",
    "        mlp.fit(X_train, y_train)\n",
    "        mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3, ax=ax)\n",
    "        mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Diabetes data\n",
    "This analaysis on the diabetes data is included to show that the overfitting is not just a problem with the Hotel Review data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "diabetesDF = pd.read_csv('data/diabetes.csv')\n",
    "diabetesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diabetesDF.pop('neg_pos').values\n",
    "X = diabetesDF.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 1/3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs',random_state=0,max_iter=100)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_range = range(20,500,20)\n",
    "tr_scores = []\n",
    "ts_scores = []\n",
    "\n",
    "for i in eval_range:\n",
    "    mlp = MLPClassifier(random_state=0, alpha =0.15 ,max_iter=i)\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "#    print(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "#    print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test))) \n",
    "    tr_scores.append(mlp.score(X_train_scaled, y_train))\n",
    "    ts_scores.append(mlp.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Train': tr_scores, 'Test': ts_scores}, index = eval_range) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Train': tr_scores, 'Test': ts_scores}, index = eval_range) \n",
    "ax = df.plot(lw=2, title='Overfitting')\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_ylim(0.7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.imshow(mlp.coefs_[0], interpolation='none', cmap='YlGnBu')\n",
    "plt.yticks(range(len(diabetesDF.columns)), diabetesDF.columns)\n",
    "plt.xlabel(\"Columns in weight matrix\")\n",
    "plt.ylabel(\"Input feature\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
