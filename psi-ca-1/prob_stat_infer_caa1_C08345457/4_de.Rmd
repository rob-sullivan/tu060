---
title: "4. Data Exploration"
output:
  html_document:
    df_print: paged
---
```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(VIM)
library(tidyverse)
library(pastecs) #For creating descriptive statistic summaries
library(ggplot2) #For creating histograms with more detail than plot
library(psych) # Some useful descriptive functions
library(moments) #For skewness and kurtosis semTools package doesn't work
library(FSA) #For percentage
library(car) # For Levene's test for homogeneity of variance 
library(effectsize) #To calculate effect size for t-test
library(coin)# For Wilcox test (non-parametric)
library(rstatix)# For calculating effect size
library(dplyr)
```

## Variable Selected: Maths Students
We selected 14 variables of interest for math students during data description. We will now use these variables to answer our questions: What levels indicate, in a subset of attributes, that a student requires early intervention before exam failure?
```{r, echo=FALSE}
#These are our variables of interest - the nine continuous variables
# Import Dataset
students <- read.csv(file = 'dataset.csv', header=TRUE)
varsint<-c("school",
           "age", 
           "Pstatus", 
           "guardian.m", 
           "traveltime.m",
           "failures.m", 
           "schoolsup.m" , 
           "romantic.m",
           "goout.m",
           "Dalc.m",
           "Walc.m",
           "health.m",
           "mG3"
           )

smath <- students[varsint]#subset with our variables
#characters to factors
for (i in colnames(smath)){
  if(class(smath[[i]])=="character"){
    smath[[i]] <- as.factor(smath[[i]])
  }
}

# Data Encoding
#for (i in colnames(smath)){
#  if(class(smath[[i]])=="factor"){
#    smath[[i]] <- sapply(smath[[i]], unclass)
#  }
#}

summary(smath) #Get our summary statistics
```

## Q1: Do math students that are in a romantic relationship drink more at the weekend?
The purpose of this test is to see if romantic relationships and alcohol consumption are related and if they affect grades. 

We will use a two sampled paired t-test if we find the difference in standard deviation between the two is greater than 2 standard deviations we will deem this a non-parametric test and use a Wilcoxon’s rank sum test instead. We are comparing 'relationship' which is a nominal categorical variable with level of alcohol consumption, an ordinal categorical variable. 

We state our hypothesis:
h0: mu_1 = mu_2
h1: mu_1 != mu_2

### Descriptive statistics of variables
* We get descriptive statistics by group to show a matrix of alcohol consumption by those in a relationship and those that are not.
```{r, echo=FALSE}
psych::describeBy(smath$Walc.m, smath$romantic.m, mat=TRUE)
```
* Mean of those in a relationship that drink is a little larger than those that are not, we want to now test if this is statistically significant. Standard deviations are less than 2 so we can use a student t-test. Both are positively skewed with a platykurtic distribution (Moderately Spread Out).

### Levene's test for homogeneity of variance
* We conduct Levene's test for homogeneity of variance. The null hypothesis is that variances in romantic relationships and weekend alcohol consumption are equal so to assume homogeneity we would expect probability to not be statistically significant. This test will only work for categorical variables with numeric variables.
```{r, echo=FALSE}
car::leveneTest(smath$Walc.m, smath$romantic.m, center=mean)
```
* our probability Pr(>F) is greater than 0.05 so it is not statistically significant so we can assume homogeneity.

### Student T-Test
```{r, echo=FALSE}
stats::t.test(Walc.m~romantic.m,var.equal=TRUE,data=smath)
# If p-value was less than 0.05 we would deem it not normally distributed and require a non-parametric test such as Wilcoxon’s rank sum test
#stats::wilcox.test(Walc.m~romantic.m, data=smath)

# No statistically significant difference was found so we do not reject the null hypothesis. We cannot say with a 95% confidence level that math students in a relationship drink more at the  weekend than those that do not.
```
```{r, echo=FALSE}
### Cohen's d
# We can calculate Cohen's d value to see the size of our statistically significance of difference (if any)
#romantic.m_num <- sapply(smath$romantic.m, as.numeric)
#effectsize::t_to_d(t = smath$Walc.m, romantic.m_num)
```
### Result
* *No statistically significant difference* was found so we do not reject the null hypothesis. We cannot say with a 95% confidence level that math students in a relationship drink more at the  weekend than those that do not.

## Q2: Do math students that are in a relationship get bad grades?
The purpose of this test is to

We will use a two sampled paired t-test if we find the difference in standard deviation between the two is greater than 2 standard deviations we will deem this a non-parametric test and use a Wilcoxon’s rank sum test instead. We are comparing 'relationship' which is a nominal categorical variable with level of grade level, a numeric variable.

We state our hypothesis:
h0: mu_1 = mu_2
h1: mu_1 != mu_2

### Descriptive statistics of variables
* We get descriptive statistics by group to show a matrix of grades by those in a relationship and those that are not. Grades that are 10 to 11 are deemed sufficient or a D in Ireland (i.e a pass)
```{r, echo=FALSE}
psych::describeBy(smath$mG3, smath$romantic.m, mat=TRUE)
```
* Mean of those not in a relationship is greater than those in a relationship, we need to test if this is statistically significant. Standard deviations are less than 2 so we can use a student t-test. Both are negativelyskewed with a platykurtic distribution(Moderately Spread Out).

### Levene's test for homogeneity of variance
* We conduct Levene's test for homogeneity of variance. The null hypothesis is that variances in relationship and grades are equal so to assume homogeneity we would expect probability to not be statistically significant.
```{r, echo=FALSE}
car::leveneTest(smath$mG3 ~ smath$romantic.m, center=mean)
```
* our probability Pr(>F) is greater than 0.05 so it is not statistically significant so we can assume homogeneity.

### Student T-Test
```{r, echo=FALSE}
stats::t.test(mG3~romantic.m,var.equal=TRUE,data=smath)
# If Pr(>F) was less we would assume not normally distributed and Non-parametric
#stats::wilcox.test(mG3~romantic.m, data=smath)
```
```{r, echo=FALSE}
## Cohen's d
#We can calculate Cohen's d value to see the size of our statistically significance of difference (if any)
#romantic.m_num <- sapply(smath$romantic.m, as.numeric)
#effectsize::t_to_d(t = smath$mG3, romantic.m_num)
```

### Result
* The P value is less than 0.05. There is some statistically significance of a difference. We reject the null hypothesis. We can say with a 95% confidence level that there *is a statistically significance* in math students in a relationship getting poor grades.




## Q3: Do math students of a certain age group perform worse on final their maths exam than other groups?
We will chose a one way Anova because we are testing against different groups from the same school. We assume that students from GT school were randomly sampled from a normally distributed population.

We also state our hypothesis:
H0: The means between age groups are identical
Ha: At least, the mean of one age group is different

school: GT (all students are from the same school)
age group: 15, 16 and 17
mG3: maths grade performance

### Data Preparation
```{r}
gp_smath <- smath[which(smath$school=='GP'),]
varsint<-c("school",
           "age",
           "mG3"
           )

#subset with our variables
gp_smath <- gp_smath[varsint]

#we configure the age variable
gp_smath_ages <- subset(gp_smath, gp_smath$age < 18) %>%
  select(age, mG3) %>% 
  mutate(age = factor(gp_smath_ages$age, ordered = TRUE))

# we check our dataframe creation worked
glimpse(gp_smath_ages) 

# we check we have 3 levels for age group
levels(gp_smath_ages$age) 


# we get Desc stats of ages and score
gp_smath_ages %>%
	group_by(age) %>%
	summarise(
		count_ages = n(),
		mean_score = mean(mG3, na.rm = TRUE),
		sd_score = sd(mG3, na.rm = TRUE)
	)

# We can visually check for difference in distribution between age groups
ggplot(gp_smath_ages, aes(x = age, y = mG3, fill = age)) +
    geom_boxplot() +
    geom_jitter(shape = 15,
        color = "steelblue",
        position = position_jitter(0.21)) +
    theme_classic()
```

### One-Way ANOVA Test
```{r}
#We conduct oneway ANOVA using the dplyr library
#We use Tukey as the post-hoc test option if group variances are the same and Games-Howell if they are not
anova_one_way <- aov(mG3~age, data = gp_smath_ages)
print("One Way ANOVA:")
summary(anova_one_way)

```

```{r}
# we cannot tell which mean is different so we use Tukey
print("Tukey:")
TukeyHSD(anova_one_way)
```
### Result
Pr(>F) value is greater than 0.05. There is *no statistical difference* between the age groups. There is a slight difference in means between 15 year olds and 17 year olds but nothing that is statistical significant (p adj>0.05).

## Q4: Do math students with bad health get bad grades?
### Data Preparation
```{r}
gp_smath <- smath[which(smath$school=='GP'),]
varsint<-c("school",
           "guardian.m",
           "health.m",
           "mG3"
           )

#subset with our variables
gp_smath <- gp_smath[varsint]

#we configure the guardian variable
gp_smath %>%
  select(guardian.m, health.m, mG3) %>% 
  mutate(guardian.m = factor(gp_smath$guardian.m, ordered = TRUE))


# We can visually check for difference in distribution between age groups and health groups
ggplot(gp_smath, aes(x = guardian.m, y = mG3, fill = health.m)) +
    geom_boxplot() +
    geom_jitter(shape = 15,
        color = "steelblue",
        position = position_jitter(0.21)) +
    theme_classic()
```
### Two-way ANOVA Test
```{r}
anova_two_way <- aov(mG3~guardian.m+health.m, data = gp_smath)
summary(anova_two_way)
```
### Result
Pr(>F) values for health and guadianship status are greater than 0.05. There is *no statistical difference* between the these groups. There is a slight difference in means between health and guadianship but nothing that is statistical significant (p adj>0.05).
## Q5: Do math students in the care of someone other than their mother get more school support?
Here we will perform a chi-square test of independence on school support and guardianship. We first check that both categorical variable are factor.

### Variable Class View
```{r}
sapply(smath, class) # yes both are factors
```
### Chi-Square Test
```{r}
chisq_test <- chisq.test(table(smath$guardian.m, smath$schoolsup))
chisq_test # we get Chi-squared approximation may be incorrect, so we try a fisher's test
```

```{r}
fisher_test <- fisher.test(table(smath$guardian.m, smath$schoolsup))
fisher_test
```