# we check we have more than 3 levels for mothers education group
levels(smath$Medu)
# we get Desc stats of ages and score
smath %>%
group_by(Medu) %>%
summarise(
count_medu = n(),
mean_score = mean(mG3, na.rm = TRUE),
sd_score = sd(mG3, na.rm = TRUE)
)
# We can visually check for difference in distribution between age groups
ggplot(smath, aes(x = Medu, y = mG3, fill = Medu)) +
geom_boxplot() +
geom_jitter(shape = 15,
color = "steelblue",
position = position_jitter(0.21)) +
theme_classic()
# we check our dataframe creation worked
smath$Medu <- as.factor(smath$Medu)
levels(smath$Medu) <- c("None", "Primary", "5th-9th Grade", "Secondary", "Higher Level")
#glimpse(smath)
# we check we have more than 3 levels for mothers education group
levels(smath$Medu)
# we get Desc stats of ages and score
smath %>%
group_by(Medu) %>%
summarise(
count_medu = n(),
mean_score = mean(mG3, na.rm = TRUE),
sd_score = sd(mG3, na.rm = TRUE)
)
# We can visually check for difference in distribution between age groups
ggplot(smath, aes(x = Medu, y = mG3, fill = Medu)) +
xlab('Mother\'s Education (Medu)') +
ylab('Final Grade Score (mG3)') +
geom_boxplot() +
geom_jitter(shape = 15,
color = "steelblue",
position = position_jitter(0.21)) +
theme_classic()
anova_one_way <- aov(mG3~Medu, data = smath)
print("One Way ANOVA:")
summary(anova_one_way)
print("Tukey:")
TukeyHSD(anova_one_way)
# we check our dataframe creation worked
smath$Medu <- as.factor(smath$Medu)
levels(smath$Medu) <- c("None", "Primary", "5th-9th Grade", "Secondary", "Higher Level")
smath$Fedu <- as.factor(smath$Medu)
levels(smath$Fedu) <- c("None", "Primary", "5th-9th Grade", "Secondary", "Higher Level")
#glimpse(smath)
# we check we have more than 3 levels for mothers education group
levels(smath$Medu)
levels(smath$Fedu)
# we get Desc stats of ages and score
smath %>%
group_by(mG3) %>%
summarise(
count_medu = n(),
mean_score = mean(mG3, na.rm = TRUE),
sd_score = sd(mG3, na.rm = TRUE)
)
# We can visually check for difference in distribution between age groups
ggplot(smath, aes(x = Medu+Fedu, y = mG3, fill = Medu)) +
xlab('Mother\'s Education (Medu)') +
ylab('Final Grade Score (mG3)') +
geom_boxplot() +
geom_jitter(shape = 15,
color = "steelblue",
position = position_jitter(0.21)) +
theme_classic()
anova_one_way <- aov(mG3~Medu+Fedu, data = smath)
print("One Way ANOVA:")
summary(anova_one_way)
# we check our dataframe creation worked
smath$Medu <- as.factor(smath$Medu)
levels(smath$Medu) <- c("None", "Primary", "5th-9th Grade", "Secondary", "Higher Level")
#glimpse(smath)
# we check we have more than 3 levels for mothers education group
levels(smath$Medu)
# we get Desc stats of ages and score
smath %>%
group_by(Medu) %>%
summarise(
count_medu = n(),
mean_score = mean(mG3, na.rm = TRUE),
sd_score = sd(mG3, na.rm = TRUE)
)
# We can visually check for difference in distribution between age groups
ggplot(smath, aes(x = Medu, y = mG3, fill = Medu)) +
xlab('Mother\'s Education (Medu)') +
ylab('Final Grade Score (mG3)') +
geom_boxplot() +
geom_jitter(shape = 15,
color = "steelblue",
position = position_jitter(0.21)) +
theme_classic()
anova_one_way <- aov(mG3~Medu, data = smath)
print("One Way ANOVA:")
summary(anova_one_way)
print("Tukey:")
TukeyHSD(anova_one_way) #Games-Howell in userfriendlyscience which is depreciated on CRAN
#gp_smath <- smath[which(smath$school=='GP'),]
varsint<-c("age",
"traveltime.m",
"failures.m",
"mG3"
)
#subset with our variables
smath_f <- smath[varsint]
#we configure the guardian variable
smath_f %>%
select(age, traveltime.m, failures.m, mG3) %>%
mutate(traveltime.m = factor(smath_f$traveltime.m, ordered = TRUE))
head(smath_f)
# We can visually check for difference in distribution between going out group and failure group
ggplot(smath_f, aes(x = failures.m, y = mG3 , fill=traveltime.m)) +
geom_boxplot() +
geom_jitter(shape = 15,
color = "red",
position = position_jitter(0.21)) +
theme_classic()
smath$traveltime.m <- as.factor(smath$traveltime.m)
levels(smath$traveltime.m) <- c("<15m", "15m-30m", "30m-1hr", ">1hr")
smath$failures.m <- as.factor(smath$failures.m)
levels(smath$failures.m) <- c("0", "1", "2", "3", "4")
#we configure the guardian variable
smath %>%
select(traveltime.m, failures.m, mG3) %>%
mutate(traveltime.m = factor(smath$traveltime.m, ordered = TRUE))
head(smath)
# We can visually check for difference in distribution between going out group and failure group
ggplot(smath, aes(x = failures.m, y = mG3 , fill=traveltime.m)) +
geom_boxplot() +
geom_jitter(shape = 15,
color = "red",
position = position_jitter(0.21)) +
theme_classic()
smath$traveltime.m <- as.factor(smath$traveltime.m)
levels(smath$traveltime.m) <- c("<15m", "15m-30m", "30m-1hr", ">1hr")
smath$failures.m <- as.factor(smath$failures.m)
levels(smath$failures.m) <- c("0", "1", "2", "3", "4")
#we configure the guardian variable
smath %>%
select(traveltime.m, failures.m, mG3) %>%
mutate(traveltime.m = factor(smath$traveltime.m, ordered = TRUE))
head(smath)
# We can visually check for difference in distribution between going out group and failure group
ggplot(smath, aes(x = failures.m, y = mG3 , fill=traveltime.m)) +
geom_boxplot() +
theme_classic()
smath$traveltime.m <- as.factor(smath$traveltime.m)
levels(smath$traveltime.m) <- c("<15m", "15m-30m", "30m-1hr", ">1hr")
smath$failures.m <- as.factor(smath$failures.m)
levels(smath$failures.m) <- c("0", "1", "2", "3", "4")
#we configure the guardian variable
smath %>%
select(failures.m, traveltime.m, mG3) %>%
mutate(failures.m = factor(smath$failures.m, ordered = TRUE))
head(smath)
# We can visually check for difference in distribution between going out group and failure group
ggplot(smath, aes(x = traveltime.m, y = mG3 , fill=failures.m)) +
geom_boxplot() +
theme_classic()
anova_two_way <- aov(mG3~traveltime.m+failures.m, data = smath)
summary(anova_two_way)
anova_two_way <- aov(mG3~traveltime.m+failures.m, data = smath)
summary(anova_two_way)
print("Tukey:")
TukeyHSD(anova_one_way) #Games-Howell in userfriendlyscience which is depreciated on CRAN
anova_two_way <- aov(mG3~traveltime.m+failures.m, data = smath)
summary(anova_two_way)
print("Tukey:")
TukeyHSD(anova_two_way) #Games-Howell in userfriendlyscience which is depreciated on CRAN
smath$mG1 <- as.factor(smath$mG1)
smath$mG2 <- as.factor(smath$mG2)
head(smath)
# We can visually check for difference in distribution between going out group and failure group
ggplot(smath, aes(x = mG1, y = mG3 , fill=mG2)) +
geom_boxplot() +
theme_classic()
smath$mG1 <- as.factor(smath$mG1)
smath$mG2 <- as.factor(smath$mG2)
head(smath)
# We can visually check for difference in distribution between going out group and failure group
ggplot(smath, aes(x = mG2, y = mG3 , fill=mG2)) +
geom_boxplot() +
theme_classic()
smath$mG1 <- as.factor(smath$mG1)
smath$mG2 <- as.factor(smath$mG2)
head(smath)
# We can visually check for difference in distribution between going out group and failure group
ggplot(smath, aes(x = mG2, y = mG3 , fill=mG2)) +
geom_boxplot() +
theme_classic()
anova_one_way <- aov(mG3~mG1, data = smath)
print("One Way ANOVA (mG1):")
summary(anova_one_way)
anova_one_way <- aov(mG3~mG2, data = smath)
print("One Way ANOVA (mG2):")
summary(anova_one_way)
anova_one_way <- aov(mG3~mG1, data = smath)
print("One Way ANOVA (mG1):")
summary(anova_one_way)
print("Tukey (mG1):")
TukeyHSD(anova_one_way) #Games-Howell in userfriendlyscience which is depreciated on CRAN
anova_one_way <- aov(mG3~mG2, data = smath)
print("One Way ANOVA (mG2):")
summary(anova_one_way)
print("Tukey (mG2):")
TukeyHSD(anova_one_way) #Games-Howell in userfriendlyscience which is depreciated on CRAN
anova_one_way <- aov(mG3~mG1, data = smath)
print("One Way ANOVA (mG1):")
summary(anova_one_way)
print("Tukey (mG1):")
head(TukeyHSD(anova_one_way)) #Games-Howell in userfriendlyscience which is depreciated on CRAN
anova_one_way <- aov(mG3~mG2, data = smath)
print("One Way ANOVA (mG2):")
summary(anova_one_way)
print("Tukey (mG2):")
head(TukeyHSD(anova_one_way)) #Games-Howell in userfriendlyscience which is depreciated on CRAN
anova_one_way <- aov(mG3~mG1, data = smath)
print("One Way ANOVA (mG1):")
summary(anova_one_way)
anova_one_way <- aov(mG3~mG2, data = smath)
print("One Way ANOVA (mG2):")
summary(anova_one_way)
anova_one_way <- aov(mG3~mG1, data = smath)
print("One Way ANOVA (mG1):")
summary(anova_one_way)
anova_one_way <- aov(mG3~mG2, data = smath)
print("One Way ANOVA (mG2):")
summary(anova_one_way)
#These are our variables of interest - the nine continuous variables
# Import Dataset
library(stats)
library(ggplot2)
library(foreign) #To work with SPSS data
library(lm.beta) #Will allow us to isolate the beta co-efficients
library(stargazer)#For formatting outputs/tables
library(semTools)
library(lmtest)
library(nnet)#Multinomial regression
library(reshape2)
library(DescTools)
install.packages(DescTools)
install.packages('DescTools')
#These are our variables of interest - the nine continuous variables
# Import Dataset
library(stats)
library(ggplot2)
library(foreign) #To work with SPSS data
library(lm.beta) #Will allow us to isolate the beta co-efficients
library(stargazer)#For formatting outputs/tables
library(semTools)
library(lmtest)
library(nnet)#Multinomial regression
library(reshape2)
library(DescTools)
library(generalhoslem)#For test of fit for logistic regression
install.packages('generalhoslem')
#These are our variables of interest - the nine continuous variables
# Import Dataset
library(stats)
library(ggplot2)
library(foreign) #To work with SPSS data
library(lm.beta) #Will allow us to isolate the beta co-efficients
library(stargazer)#For formatting outputs/tables
library(semTools)
library(lmtest)
library(nnet)#Multinomial regression
library(reshape2)
library(DescTools)
library(generalhoslem)#For test of fit for logistic regression
#Read in the file
students <- read.csv(file = 'dataset.csv', header=TRUE)
varsint<-c("Medu",
"higher.m",
"failures.m",
"mG1",
"mG2",
"mG3"
)
regression <- students[varsint]#subset with our variables
summary(regression)
regression$Medu <- as.factor(smath$Medu)
regression$Medu <- as.factor(regression$Medu)
regression$higher.m <- as.factor(regression$higher.m)
regression$failures.m <- as.factor(regression$failures.m)
#Note: R automatically recodes categorical to be dummy variable 0 = reference (boy), 1 category of interest (girl)
model2<-lm(regression$mG3~regression$mG2+regression$mG1+regression$failures.m+regression$higher.m+regression$Medu)
anova(model2)
summary(model2)
stargazer(model2, type="text") #Tidy output of all the required stats
lm.beta(model2)
stargazer(model1, model2, type="text") #Quick model comparison
#Note: R automatically recodes categorical to be dummy variable 0 = reference (boy), 1 category of interest (girl)
model2<-lm(regression$mG3~regression$mG2+regression$mG1+regression$failures.m+regression$higher.m)
anova(model2)
summary(model2)
stargazer(model2, type="text") #Tidy output of all the required stats
lm.beta(model2)
stargazer(model1, model2, type="text") #Quick model comparison
#Note: R automatically recodes categorical to be dummy variable 0 = reference (boy), 1 category of interest (girl)
model2<-lm(regression$mG3~regression$mG2+regression$mG1+regression$failures.m)
anova(model2)
summary(model2)
stargazer(model2, type="text") #Tidy output of all the required stats
lm.beta(model2)
stargazer(model1, model2, type="text") #Quick model comparison
#Note: R automatically recodes categorical to be dummy variable 0 = reference (boy), 1 category of interest (girl)
model2<-lm(regression$mG3~regression$mG2+regression$mG1+regression$higher.m)
anova(model2)
summary(model2)
stargazer(model2, type="text") #Tidy output of all the required stats
lm.beta(model2)
stargazer(model1, model2, type="text") #Quick model comparison
#Note: R automatically recodes categorical to be dummy variable 0 = reference (boy), 1 category of interest (girl)
model2<-lm(regression$mG3~regression$mG2+regression$mG1+regression$Medu)
anova(model2)
summary(model2)
stargazer(model2, type="text") #Tidy output of all the required stats
lm.beta(model2)
stargazer(model1, model2, type="text") #Quick model comparison
#Note: R automatically recodes categorical to be dummy variable 0 = reference (boy), 1 category of interest (girl)
model2<-lm(regression$mG3~regression$mG2+regression$mG1+regression$failures.m+regression$higher.m+regression$Medu)
anova(model2)
summary(model2)
stargazer(model2, type="text") #Tidy output of all the required stats
lm.beta(model2)
stargazer(model1, model2, type="text") #Quick model comparison
#split dataset into training and test set
set.seed(123)
split = sample.split(regression SplitRatio = 0.8) #40 training # 10% in test
#split dataset into training and test set
set.seed(123)
split = sample.split(regression, SplitRatio = 0.8) #40 training # 10% in test
regression$Medu <- as.factor(regression$Medu)
regression$higher.m <- as.factor(regression$higher.m)
regression$failures.m <- as.factor(regression$failures.m)
#Note: R automatically recodes categorical to be dummy variable 0 = reference (boy), 1 category of interest (girl)
model<-lm(regression$mG3~regression$mG2+regression$mG1+regression$failures.m+regression$higher.m+regression$Medu)
summary(model)
stargazer(model, type="text") #Tidy output of all the required stats
lm.beta(model)
regression$Medu <- as.factor(regression$Medu)
regression$higher.m <- as.factor(regression$higher.m)
regression$failures.m <- as.factor(regression$failures.m)
regression$mG1 <- as.factor(regression$mG1)
regression$mG2 <- as.factor(regression$mG2)
#Note: R automatically recodes categorical to be dummy variable 0 = reference (boy), 1 category of interest (girl)
model<-lm(regression$mG3~regression$mG2+regression$mG1+regression$failures.m+regression$higher.m+regression$Medu)
summary(model)
stargazer(model, type="text") #Tidy output of all the required stats
lm.beta(model)
#Read in the file
students <- read.csv(file = 'dataset.csv', header=TRUE)
varsint<-c("Medu",
"higher.m",
"failures.m",
"mG1",
"mG2",
"mG3"
)
regression <- students[varsint]#subset with our variables
summary(regression)
regression$Medu <- as.factor(regression$Medu)
regression$higher.m <- as.factor(regression$higher.m)
regression$failures.m <- as.factor(regression$failures.m)
#Note: R automatically recodes categorical to be dummy variable 0 = reference (boy), 1 category of interest (girl)
model<-lm(regression$mG3~regression$mG2+regression$mG1)
summary(model)
stargazer(model, type="text") #Tidy output of all the required stats
lm.beta(model)
regression$Medu <- as.factor(regression$Medu)
regression$higher.m <- as.factor(regression$higher.m)
regression$failures.m <- as.factor(regression$failures.m)
regression <- regression[which(smath$mG2>0),]
summary(regression)
regression$Medu <- as.factor(regression$Medu)
regression$higher.m <- as.factor(regression$higher.m)
regression$failures.m <- as.factor(regression$failures.m)
regression <- regression[which(regression$mG2>0),]
summary(regression)
#Read in the file
students <- read.csv(file = 'dataset.csv', header=TRUE)
varsint<-c("Medu",
"higher.m",
"failures.m",
"mG1",
"mG2",
"mG3"
)
regression <- students[varsint]#subset with our variables
summary(regression)
regression$Medu <- as.factor(regression$Medu)
regression$higher.m <- as.factor(regression$higher.m)
regression$failures.m <- as.factor(regression$failures.m)
regression <- regression[which(regression$mG2>0.0),]
summary(regression)
regression$Medu <- as.factor(regression$Medu)
regression$higher.m <- as.factor(regression$higher.m)
regression$failures.m <- as.factor(regression$failures.m)
regression <- regression[which(regression$mG2>0.0),]
regression <- regression[which(regression$mG3>0.0),]
summary(regression)
#Note: R automatically recodes categorical to be dummy variable 0 = reference (boy), 1 category of interest (girl)
model<-lm(regression$mG3~regression$mG2+regression$mG1+regression$failures.m+regression$higher.m+regression$Medu)
summary(model)
stargazer(model, type="text") #Tidy output of all the required stats
lm.beta(model)
logreg_data <- regression
summary(logreg_data)
model <- glm(mG3 ~ mG2 + mG1 + failures.m + higher.m + Medu, data=logreg_data, family="binomial")
logreg_data <- regression
# Adding column based on other column (0-9 = fail):
logreg_data %>%
mutate(pass = case_when(
mG3>10 ~ 1,
mG3<10 ~ 0
))
summary(logreg_data)
logreg_data <- regression
# Adding column based on other column (0-9 = fail):
logreg_data %>%
mutate(pass = case_when(
mG3 %% >10 ~ 1,
logreg_data <- regression
# Adding column based on other column (0-9 = fail):
logreg_data %>%
mutate(Pass = case_when(
mG3>10 ~ 1,
mG3<10 ~ 0
))
summary(logreg_data)
logreg_data <- regression
# Adding column based on other column (0-9 = fail):
logreg_data %>%
mutate(Pass = case_when(
mG3>=10 ~ 1,
mG3<10 ~ 0
))
summary(logreg_data)
model <- glm(Pass ~ mG2 + mG1 + failures.m + higher.m + Medu, data=logreg_data, family="binomial")
logreg_data <- regression
# Adding column based on other column (0-9 = fail):
logreg_data <-logreg_data %>%
mutate(Pass = case_when(
mG3>=10 ~ 1,
mG3<10 ~ 0
))
summary(logreg_data)
model <- glm(Pass ~ mG2 + mG1 + failures.m + higher.m + Medu, data=logreg_data, family="binomial")
summary(model)
model <- glm(Pass ~ mG2 + mG1 + failures.m + higher.m + Medu, data=logreg_data, family="binomial")
summary(model)
setwd("~/projects/tu060/week-9/PSIWeek9 data + R")
library(lmtest)
library(DescTools)
library(nnet)#Multinomial regression
library(foreign)
library(reshape2)
library(ggplot2)
library(DescTools)
library(generalhoslem)#For test of fit for logistic regression
ldata <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
#Data on admission to graduate programme
#admit- whether admitted or not
#gre - score on GRE test
#gpa - grade point average @ undergraduate degree
#rank - academic ranking of school where student took undergraduate degree
names(ldata)
summary(ldata)
ldata$rank <- factor(ldata$rank)# Make sure that R treats this as a categorical variable
#We have FOUR categories of ranking
summary(ldata$rank)
model <- glm(admit ~ gre + gpa + rank, data=ldata, family="binomial")
summary(model)
model <- glm(admit ~ gre + gpa + rank, data=ldata, family="binomial")
summary(model)
# interpret logistic regression results,  transform the coefficients to odds ratios by raising e to the power of the coefficients.
# Store coefficients in another object
coefs <- coef(model)
# Show the coefficients, just for fun
coefs
#Raise e to the power of the coefficients to get the odds ratios
exp(coefs)
#We can do an additional transformation by taking the odds ratio, subtract 1, and multiply by 100 to get the percent change in the odds for a one unit increase in the independent variable.
# Doing the full transformation, all in one line
(exp(coefs)-1)*100
#multinom package does not include p-value calculation for the regression coefficients, so we calculate p-values using Wald tests (here z-tests).
z <- summary(model2)$coefficients/summary(model2)$standard.errors
z
p <- (1 - pnorm(abs(z), 0, 1)) * 2
p
#Chi-square plus significance
lmtest::lrtest(model2)
#Pseudo Rsquared
DescTools::PseudoR2(model2, which="CoxSnell")
DescTools::PseudoR2(model2, which="Nagelkerke")
#Check the assumption of linearity of independent variables and log odds using a Hosmer-Lemeshow test, if this is not statsitically significant we are ok
generalhoslem::logitgof(mdata$prog, fitted(model2))
#Collinearity
vifmodel<-car::vif(model2)#You can ignore the warning messages, GVIF^(1/(2*Df)) is the value of interest
vifmodel
#Tolerance
1/vifmodel
# interpret logistic regression results,  transform the coefficients to odds ratios by raising e to the power of the coefficients.
## extract the coefficients from the model and exponentiate
exp(coef(model2))
setwd("~/projects/tu060/psi-ca-1/prob_stat_infer_caa1_C08345457")
psych::describeBy(smath$mG3, smath$higher.m, mat=TRUE)
