{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining Deep Q-Learning Experience Replay with SHapley Additive exPlanations\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\repos\\tu060\\venv_research\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "#https://gymnasium.farama.org/environments/atari/\n",
    "#pip install gymnasium[atari]\n",
    "#pip install gymnasium[accept-rom-license]\n",
    "#pip install moviepy\n",
    "#https://www.youtube.com/watch?v=hCeJeq8U0lo&t=447s\n",
    "import datetime\n",
    "\n",
    "#test environments\n",
    "import hrl_gym #simulate addiction\n",
    "import gymnasium as gym\n",
    "\n",
    "#image preprocessing\n",
    "from PIL import Image\n",
    "from gymnasium.core import ObservationWrapper\n",
    "from gymnasium.spaces.box import Box\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff() #prevent plots from being displayed automatically in the notebook\n",
    "\n",
    "#n-step experience replay\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "#deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from gymnasium.wrappers import RecordVideo #enviornment monitoring\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split #for splitting memory into training and testing\n",
    "import pandas as pd\n",
    "\n",
    "import shap # explaining deep q learning model\n",
    "from shap.plots._image import image as image_plotter\n",
    "from shap.plots import colors\n",
    "import math\n",
    "import datetime #logging experiment time\n",
    "\n",
    "from PIL import Image #converting state test images into shap inputs\n",
    "import matplotlib.gridspec as gridspec #displaying shap graphs with states and q values\n",
    "\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.multicomp as mc\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda:0')\n",
    "  print('Running on the GPU')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "  print('Running on the CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q-Learning Agent\n",
    "A learning agent that can control from vector input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):  \n",
    "    def __init__(self, input_size, nb_action):\n",
    "        #ref: https://discuss.pytorch.org/t/super-model-in-init/97426\n",
    "        #super(Network, self).__init__()\n",
    "        super().__init__() #pytorch's NN model\n",
    "        self.input_size = input_size\n",
    "        self.nb_action = nb_action\n",
    "        self.fc1 = nn.Linear(input_size, 30)#arbitrarily chose 30 hidden layers\n",
    "        self.fc2 = nn.Linear(30, nb_action)\n",
    "    \n",
    "    #base pytorch NN model runs and we override the\n",
    "    #forward function with our own relu activation function\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        q_values = self.fc2(x)\n",
    "        return q_values\n",
    "    \n",
    "# This model is used for training our DQN model. It stores the transitions that the agent observes, \n",
    "# allowing us to reuse this data later. By sampling from it randomly, the transitions that build up a \n",
    "# batch are decorrelated. It has been shown that this greatly stabilizes and improves the DQN training procedure.\n",
    "class ReplayMemory(): \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "    \n",
    "    def push(self, event):\n",
    "        self.memory.append(event)\n",
    "        if len(self.memory) > self.capacity:\n",
    "            del self.memory[0] #forget first transition\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        samples = zip(*random.sample(self.memory, batch_size)) \n",
    "        return map(lambda x: Variable(torch.cat(x, 0)), samples) #tensor and gradient.\n",
    "        #this contains sample of memory. get random sample from memory with given size\n",
    "        # before list = [[state,action,reward], [state,action,reward]] zip*=> [[state], [action], [reward]]\n",
    "        #the * operator unpacks a list and applies it to a function\n",
    "        #a pytorch variable contains a tensor and a gradient. in order for pytorch to differenciate with respect to a tensor, we need a tensor and gradient\n",
    "        # For each batch within a sample, we then have to concatenate it to the first dimension because \n",
    "        # everything needs to be aligned so state action and reward align to same time t\n",
    "        # Lambda is used to do a short computation inline without def and if, etc.\n",
    "\n",
    "\n",
    "#Comprised of a neural network model and a memory model. \n",
    "#* The NN takes in observation of sensor data (brain chemicals) and chooses actions based on the relu activation function. \n",
    "#* The agent will sample some of the sensor data and store in long term memory to be reused later for training. \n",
    "#* We also use the Adam Optimisation algorithm. This is an extension to stocastic gradient desent to update weights of the neural network. \n",
    "class Dqn():\n",
    "    def __init__(self, input_size, nb_action, gamma, capacity=100000, learning=0.001, temperature=100, sample_rate=100, random_episodes):\n",
    "        self.gamma = gamma\n",
    "        self.reward_window = []\n",
    "        self.cumulative_rewards = []\n",
    "        self.model = Network(input_size, nb_action)\n",
    "        self.memory = ReplayMemory(capacity) #100k\n",
    "        self.sample_rate = sample_rate\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr = learning)\n",
    "        self.last_state = torch.Tensor(input_size).unsqueeze(0)\n",
    "        self.last_action = 0\n",
    "        self.last_reward = 0\n",
    "        self.temp = temperature\n",
    "        self.random_episodes = random_episodes\n",
    "        self.explainer = None #used to calculate shap values\n",
    "        self.shap_values = [] #store collected shap values\n",
    "\n",
    "        #create table for memory data collection\n",
    "        self.df_shap = pd.DataFrame(columns=['batch_state', 'batch_next_state', 'batch_action', 'batch_reward'])\n",
    "\n",
    "    # select action for x duration\n",
    "    def select_action(self, state):\n",
    "        #softmax converts numbers into probabilities\n",
    "        #Q values are the output of the neural network\n",
    "            #view q values\n",
    "        q_value_tensor = self.model(Variable(state, volatile = True)) \n",
    "        q_values = [q_value.detach().numpy() for q_value in q_value_tensor]\n",
    "            #print(q_values)\n",
    "            #viz q value for each action, (T value by user choice)\n",
    "            #pie chart 0/1 #seperate action\n",
    "        # Temperature value = 100. closer to zero the less sure the NN will be to taking the action\n",
    "        probs = F.softmax(self.model(Variable(state, volatile = True))*self.temp) # T=100\n",
    "        \n",
    "        action_prob = [prob.detach().numpy() for prob in probs]\n",
    "\n",
    "        action = probs.multinomial(num_samples=1) # action taken\n",
    "        #q_values[0][action] #quality of taking action in state\n",
    "        #action_prob[0][action] #probability of taking action\n",
    "\n",
    "        #return the action taken, q values and probabilities of taking action given state.\n",
    "        #return action.data[0,0], q_values[0][action], action_prob[0][action]\n",
    "        return action.data[0,0], q_values, action_prob\n",
    "    \n",
    "    #When ai reaches a new state we update everything\n",
    "    #update action, last action becomes the new action but also the last state becomes the new state and last reward becomes the new state\n",
    "    # we then get this new transition and update our reward window to track training progress and exploration\n",
    "    def update(self, reward, new_signal, episode):\n",
    "        new_state = torch.Tensor(new_signal).float().unsqueeze(0)\n",
    "        self.memory.push((self.last_state, new_state, torch.LongTensor([int(self.last_action)]), torch.Tensor([self.last_reward])))\n",
    "        action, q, p = self.select_action(new_state)\n",
    "\n",
    "        # Initialize an empty list to store the sampled inputs for SHAP Explainer\n",
    "        sampling_episode = []\n",
    "        sampled_inputs = []\n",
    "        sampled_targets = []\n",
    "        episode_sampled = False\n",
    "        if len(self.memory.memory) > self.sample_rate: #100\n",
    "            batch_state, batch_next_state, batch_action, batch_reward = self.memory.sample(self.sample_rate)\n",
    "\n",
    "            #first converting tensors to numpy arrays\n",
    "            batch_state_np = batch_state.numpy()\n",
    "            batch_next_state_np = batch_next_state.numpy()\n",
    "            batch_action_np = batch_action.numpy()\n",
    "            batch_reward_np = batch_reward.numpy()\n",
    "\n",
    "\n",
    "            #%%\n",
    "            #We take some training samples for shap.deepxplainer to create heatmap images or we use them for training. Not both!\n",
    "            if episode in self.random_episodes and not episode_sampled:\n",
    "                sampling_episode.append(episode) #record when sample was taken\n",
    "                sampled_inputs.append(inputs)\n",
    "                sampled_targets.append(targets)\n",
    "                episode_sampled = True # Set the flag to True\n",
    "            else:\n",
    "                #we convert them to tensor variables\n",
    "                inputs, targets = Variable(inputs), Variable(targets)\n",
    "                #like during eligibility_trace we get predicted q values from the cnn model\n",
    "                predictions = cnn(inputs)\n",
    "                loss_error = loss(predictions, targets)\n",
    "                optimizer.zero_grad()\n",
    "                loss_error.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                episode_sampled = False # Reset the flag for the next iteration\n",
    "            #%%\n",
    "            # Split the data into training and testing sets\n",
    "            state_train, state_test, next_state_train, next_state_test, action_train, action_test, reward_train, reward_test = train_test_split(\n",
    "                batch_state_np, batch_next_state_np, batch_action_np, batch_reward_np, test_size=0.1, random_state=42)\n",
    "            \n",
    "            # Convert back to tensors\n",
    "            state_train = torch.tensor(state_train)\n",
    "            next_state_train = torch.tensor(next_state_train)\n",
    "            reward_train = torch.tensor(reward_train)\n",
    "            action_train = torch.tensor(action_train)\n",
    "\n",
    "            state_test = torch.tensor(state_test)\n",
    "            next_state_test = torch.tensor(next_state_test)\n",
    "            reward_test = torch.tensor(reward_test)\n",
    "            action_test = torch.tensor(action_test)\n",
    "\n",
    "            #use test for SHAP\n",
    "            self.df_shap.loc[len(self.df)] = [state_test, next_state_test, reward_test, action_test]\n",
    "\n",
    "            #now train the DQN\n",
    "            self.learn(state_train, next_state_train, reward_train, action_train)\n",
    "            #self.learn(batch_state, batch_next_state, batch_reward, batch_action)\n",
    "            #X=batch_state and y=batch_next_state\n",
    "        self.last_action = action\n",
    "        self.last_state = new_state\n",
    "        self.last_reward = reward\n",
    "        self.reward_window.append(reward)\n",
    "        self.cumulative_rewards.append(sum(self.reward_window))\n",
    "        #if len(self.reward_window) > 1000:\n",
    "        #    del self.reward_window[0]\n",
    "        return action, q, p\n",
    "    \n",
    "    #to train our AI\n",
    "    #forward propagation then backproagation\n",
    "    # get our output, target, compare our output to the target to compute the loss error\n",
    "    # backproagate loss error into the nn and use stochastic gradient descent we update the weights according to how much they contributed to the loss error\n",
    "    def learn(self, batch_state, batch_next_state, batch_reward, batch_action):\n",
    "        #when we pass in batch state the output will be all possible actions\n",
    "        # we use gather passing in 1 and batch action because we only want the chosen action\n",
    "        # however batch_state has a fake dimention from unsqueeze in __init__ of NN and batch action doesn't\n",
    "        outputs = self.model(batch_state).gather(1, batch_action.unsqueeze(1)).squeeze(1) #pass state into neural network input layer., gather outputs a new tensor. input dimension\n",
    "        #gets the q values for all the next states with respect to action (i.e 1) then get the max\n",
    "        next_outputs = self.model(batch_next_state).detach().max(1)[0]\n",
    "        target = self.gamma*next_outputs + batch_reward\n",
    "        td_loss = F.smooth_l1_loss(outputs, target)\n",
    "        self.optimizer.zero_grad()\n",
    "        td_loss.backward(retain_graph = True)\n",
    "        self.optimizer.step()\n",
    "    \n",
    "    def score(self):\n",
    "        \"\"\" Current sum of all values in the reward window \"\"\"\n",
    "        return sum(self.reward_window)\n",
    "    \n",
    "    def cumulative_reward(self):\n",
    "        \"\"\" Sum of all values in the reward window at step/time\"\"\"\n",
    "        return self.cumulative_rewards\n",
    "    \n",
    "    def rewards(self):\n",
    "        \"\"\" current value in the reward window at step/time\"\"\"\n",
    "        return self.reward_window"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Convelutional Q-Learning Agent\n",
    "A learning agent that can control from pixel input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convelutional Neural Network\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, number_actions):\n",
    "        super(CNN, self).__init__() # call nn module init\n",
    "        #define what each layer in CNN is\n",
    "        self.convolution1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5)\n",
    "        self.convolution2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
    "        self.convolution3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=2)\n",
    "\n",
    "        #pass image through convolution layers and get neurons in a flatten layer to pass into a neural network\n",
    "        self.fc1 = nn.Linear(in_features=self.count_neurons((1, 80, 80)), out_features=40) #1 is number of channels so black and white images, 80 80 is width and height\n",
    "        self.fc2 = nn.Linear(in_features=40, out_features=number_actions)\n",
    "\n",
    "    def count_neurons(self, image_dim):#image_dim for example 80px x 80px in size\n",
    "        \"\"\"Will give us the number of neurons after convolutions are applied\"\"\"\n",
    "        #we need to first create a fake image (1 batch, 80px x 80px in size), * allows image_dim to be passed as a list\n",
    "        fake_image = Variable(torch.rand(1, *image_dim))\n",
    "\n",
    "        #pass image into first layer and max pool result then activate all neurons in max pool layer\n",
    "        x = F.relu(F.max_pool2d(self.convolution1(fake_image), 3, 2)) #kernal size is 3, #stride is 2\n",
    "\n",
    "        #pass image into second layer and max pool result then activate all neurons in max pool layer\n",
    "        x = F.relu(F.max_pool2d(self.convolution2(x), 3, 2)) #kernal size is 3, #stride is 2\n",
    "\n",
    "        #pass image into third layer and max pool result then activate all neurons in max pool layer\n",
    "        x = F.relu(F.max_pool2d(self.convolution3(x), 3, 2)) #kernal size is 3, #stride is 2\n",
    "        \n",
    "        #now we get all pixels in third layer and flatten it. we get the data, view what's inside it then we get all the pixels and put it into 1 dimension\n",
    "        return x.data.view(1, -1).size(1)\n",
    "    \n",
    "    def forward(self, x):       \n",
    "        x = F.relu(F.max_pool2d(self.convolution1(x), 3, 2))\n",
    "        x = F.relu(F.max_pool2d(self.convolution2(x), 3, 2))\n",
    "        x = F.relu(F.max_pool2d(self.convolution3(x), 3, 2))\n",
    "        #propagate data from convolutional layers to hidden layers by first flattening convolutional layers\n",
    "        #flatten third layer by taking all pixels and all channels in third layer and arrange one after another\n",
    "        x = x.view(x.size(0), -1) #RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x49 and 3136x40)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "### Softmax Policy\n",
    "class SoftmaxPolicy(nn.Module):\n",
    "    \"\"\"data from the CNN is passed to softmax to play an action.\n",
    "    Temperature (often denoted as τ or tau) is a hyperparameter that controls the level of randomness or exploration in the action selection process. \n",
    "    - High T values (e.g., > 5): A high temperature encourages a high level of exploration and randomness in action selection. This can be useful when you want the agent to explore a wide range of actions to discover their effects and learn about the environment.\n",
    "    - Moderate T values (e.g., 1 - 5): A moderate temperature strikes a balance between exploration and exploitation. It allows the agent to favor actions with higher Q-values while still exploring other options. \n",
    "    - Low T values (e.g., < 1): A low temperature reduces the randomness in action selection, making the agent more deterministic and focused on exploiting actions with higher Q-values. This can be useful when the agent has learned a relatively good policy and you want to minimize unnecessary exploration.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, T=10):\n",
    "        super(SoftmaxPolicy, self).__init__()\n",
    "        self.T = T\n",
    "\n",
    "    def forward(self, outputs, number_actions=1):\n",
    "        probs = F.softmax(outputs * self.T, dim=1)\n",
    "        actions = probs.multinomial(num_samples=number_actions)\n",
    "        return actions\n",
    "\n",
    "### Agent (DCQ Learning System )\n",
    "class DCQ():\n",
    "    def __init__(self, CNN, SoftmaxPolicy):\n",
    "        self.cnn = CNN\n",
    "        self.softmax = SoftmaxPolicy\n",
    "\n",
    "    def __call__(self, inputs):#comes from NStepProgress -> np.array([state])\n",
    "        \"\"\"similar to init function but it allows this AI class \n",
    "        instance to be treated like a function, not modifying the initial instance\"\"\"\n",
    "        #receive images from the game by converting image into a numpy array then into a torch tensor, then put a torch tensor into a torch variable with a gradient\n",
    "        input = Variable(torch.from_numpy(np.array(inputs, dtype = np.float32)))\n",
    "        output = self.cnn(input)\n",
    "        actions = self.softmax(output)\n",
    "        return actions.data.numpy()\n",
    "\n",
    "### Experience Replay\n",
    "#### N-Step\n",
    "class NStepProgress:\n",
    "    \"\"\"This class allows the AI to progress on several (n_step) steps\"\"\"\n",
    "    def __init__(self, env, ai, n_step):\n",
    "        self.ai = ai\n",
    "        self.rewards = []\n",
    "        self.env = env\n",
    "        self.n_step = n_step\n",
    "        self.step = namedtuple('Step', ['state', 'action', 'reward', 'done']) #Defining one Step\n",
    "    def __iter__(self):\n",
    "        \"\"\"Repeats but only incrementing parent loop when yield is called\"\"\"\n",
    "        state, info = self.env.reset()\n",
    "        history = deque()\n",
    "        reward = 0.0\n",
    "        while True: #go on forever until parent flag in ReplayMemory.runstep triggered\n",
    "            #select an action\n",
    "            action = self.ai(np.array([state]))[0][0] #agent.update\n",
    "            #get reward and next state\n",
    "            next_state, r, terminated, truncated, info = self.env.step(action)\n",
    "            done = terminated or truncated #if  game has some kind of max_steps or timeout, read 'truncated' with 'terminated'\n",
    "            reward += r #sum reward for every step\n",
    "            #add to stacked frame\n",
    "            history.append(self.step(state=state, action=action, reward=r, done=done))\n",
    "            while len(history) > self.n_step +1: #Always keep it n-steps e.g 10\n",
    "                history.popleft()\n",
    "            if len(history) == self.n_step + 1:#create our stacked tuple when finished\n",
    "                yield tuple(history)\n",
    "            state = next_state\n",
    "            if done: #either terminated or truncated signaling that the game has ended\n",
    "                if len(history) > self.n_step + 1:\n",
    "                    history.popleft()\n",
    "                while len(history) >= 1:\n",
    "                    yield tuple(history)\n",
    "                    history.popleft()\n",
    "                self.rewards.append(reward) #save accumulated reward per done\n",
    "                reward = 0.0\n",
    "                state, info  = self.env.reset()\n",
    "                history.clear()\n",
    "    \n",
    "    def rewards_steps(self):\n",
    "        \"\"\"stores total reward accumulated from start to done trigger\"\"\"\n",
    "        rewards_steps = self.rewards\n",
    "        self.rewards = []\n",
    "        return rewards_steps\n",
    "\n",
    "#### Replay Memory\n",
    "class ReplayMemory:\n",
    "    \"\"\"This class is modified to do n-step learning\"\"\"\n",
    "    def __init__(self, n_steps, capacity = 10000):\n",
    "        self.capacity = capacity # https://github.com/juliuskunze/nevermind/blob/master/nevermind/configurations.py\n",
    "        self.n_steps = n_steps\n",
    "        self.n_steps_iter = iter(n_steps) #creates an object that can be accessed one element at a time using __next__()\n",
    "        self.buffer = deque()\n",
    "\n",
    "    def sample_batch(self, batch_size): # creates an iterator that returns random batches\n",
    "        ofs = 0 #we use an offset to keep track of starting index for each batch\n",
    "        #we get samples from experience replay\n",
    "        vals = list(self.buffer)\n",
    "        #then randomly suffle them\n",
    "        np.random.shuffle(vals)\n",
    "        #now we check to see if we have enough samples in the buffer to make a batch if not we wait.\n",
    "        while (ofs+1)*batch_size <= len(self.buffer):\n",
    "            yield vals[ofs*batch_size:(ofs+1)*batch_size] #we slice from the offset position to the e.g 128 to 256\n",
    "            ofs += 1\n",
    "\n",
    "    def run_steps(self, steps):\n",
    "        \"\"\"Runs environment wait 10 consecutive steps of (state, action, reward, done) then save to buffer\n",
    "        until n sample steps are saved in buffer. Does not iterate until n_steps_iter collects 10 steps\"\"\"\n",
    "\n",
    "        while steps > 0:\n",
    "            entry = next(self.n_steps_iter) # run subtask as many times as it takes to return 10 consecutive steps of (state, action, reward, done)\n",
    "            self.buffer.append(entry) # we put e.g 200 n-step samples for the current episode, e.g 200 samples x 10 steps = 2,000 steps per episode\n",
    "            steps -= 1\n",
    "\n",
    "        while len(self.buffer) > self.capacity: # we accumulate no more than the capacity (e.g 10,000)\n",
    "            self.buffer.popleft()\n",
    "            \n",
    "### N-Step Q-Learning\n",
    "def eligibility_trace(batch, cnn, g=0.99):#batch is a sample of 128 10-steps where each step is ['state', 'action', 'reward', 'done'] so 1,280 transitions from memory\n",
    "    \"\"\"Asynchronous N-Step Q-Learning\n",
    "    learns the cumulative rewards and cumulative targets\n",
    "    on n-steps instead of one step like DQL\"\"\"\n",
    "    gamma = g\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for series in batch: #series of 10 transitions in our batch\n",
    "        #get the first and last image as the input. Convert fron numpy to torch variable\n",
    "        input = Variable(torch.from_numpy(np.array([series[0].state, series[-1].state], dtype=np.float32)))\n",
    "        output = cnn(input) #this is the prediction from the ai\n",
    "\n",
    "        #if the last transition of the series is not done we get the max q values\n",
    "        cumulative_reward = 0.0 if series[-1].done else output[1].data.max()\n",
    "\n",
    "        #start with the last step and go backwards to the first step\n",
    "        for step in reversed(series[:-1]):#reversed goes backwards \n",
    "            state = series[0].state # first state we need. This is where we started\n",
    "            target = output[0].data # this is the q value of the input state of the first step. This is what we thought we would get being in this state\n",
    "\n",
    "            # what new reward did we actually get\n",
    "            cumulative_reward = step.reward + gamma * cumulative_reward \n",
    "            target[series[0].action] = cumulative_reward # this is the q value we actually got\n",
    "\n",
    "            inputs.append(state) # we append our first state\n",
    "            targets.append(target) #we append the actual target q value for the first state\n",
    "\n",
    "            #output the input and the target after being processed through eligibility_trace\n",
    "            #we now have the first state and the target q values for the first state over 10 steps\n",
    "            return torch.from_numpy(np.array(inputs, dtype=np.float32)), torch.stack(targets)#we stack targets together\n",
    "\n",
    "### Image Preprocessing\n",
    "class ImagePreprocessor(ObservationWrapper):\n",
    "    \"\"\"Custom Image Preprocessor similar to Atari standard in gymnasium\"\"\"\n",
    "    def __init__(self, env, height = 64, width = 64, grayscale = True, crop = lambda img: img):\n",
    "        super(ImagePreprocessor, self).__init__(env)\n",
    "        self.img_size = (height, width)\n",
    "        self.grayscale = grayscale\n",
    "        self.crop = crop\n",
    "        n_colors = 1 if self.grayscale else 3\n",
    "        self.observation_space = Box(0.0, 1.0, [n_colors, height, width])\n",
    "\n",
    "    def observation(self, img):\n",
    "        img = self.crop(img)\n",
    "        img = Image.fromarray(img)\n",
    "        img = img.resize(self.img_size)\n",
    "        if self.grayscale:\n",
    "            img = img.convert('L')  # Convert to grayscale\n",
    "        else:\n",
    "            img = img.convert('RGB')  # Convert to RGB if necessary\n",
    "\n",
    "        #view preprocessed image\n",
    "        #plt.imshow(img)\n",
    "        #plt.show()\n",
    "\n",
    "        img = np.array(img)\n",
    "        #adds a new dimension to the array to represent the single color channel, resulting in the desired shape\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "        \n",
    "        #if img.ndim == 2:  # Add channel dimension if missing\n",
    "        #    img = np.expand_dims(img, axis=2)\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        img = img.astype('float32') / 255\n",
    "\n",
    "        #check dim of new image\n",
    "        #print(\"image was preprocessed to: \" + str(\"greyscale\" if self.grayscale else \"RGB\") + \" with shape \" + str(img.shape))\n",
    "        return img\n",
    "\n",
    "### Moving Average Reward (for evaluation) on n-steps\n",
    "class MA:\n",
    "    def __init__(self, size):\n",
    "        self.list_of_rewards = []\n",
    "        self.size = size\n",
    "    def add(self, rewards):\n",
    "        \"\"\"adds step rewards until nth step then removes oldest rewardm leaving 100 steps of reward saved per episode\"\"\"\n",
    "        if isinstance(rewards, list):\n",
    "            self.list_of_rewards += rewards\n",
    "        else:\n",
    "            self.list_of_rewards.append(rewards)\n",
    "        while len(self.list_of_rewards) > self.size:\n",
    "            del self.list_of_rewards[0]\n",
    "    def average(self):\n",
    "        \"\"\"gets the average reward per nth step\"\"\"\n",
    "        if len(self.list_of_rewards) > 0:\n",
    "            return np.mean(self.list_of_rewards)\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "class CustomMask(Dataset): \n",
    "    \"\"\" Defines a custom dataset mask for SHAP Deep Explainer\"\"\"\n",
    "    #ref: https://blog.paperspace.com/deep-learning-model-interpretability-with-shap/\n",
    "    def __init__(self, data, transforms=None):\n",
    "        self.data = data\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        if self.transforms!=None:\n",
    "            image = self.transforms(image)\n",
    "        return image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALE_SPACEINVADERS-V5 EXPERIMENT 0: Date-Time: 2023-08-21 06:49:23, Capacity: 1M\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 1000000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 135.0\n",
      "Episode: 4, Reward: 90.0\n",
      "Episode: 5, Reward: 90.0\n",
      "Episode: 6, Reward: 90.0\n",
      "Episode: 7, Reward: 110.0\n",
      "Episode: 8, Reward: 110.0\n",
      "Episode: 9, Reward: 110.0\n",
      "Episode: 10, Reward: 110.0\n",
      "Episode: 11, Reward: 197.5\n",
      "Episode: 12, Reward: 197.5\n",
      "Episode: 13, Reward: 197.5\n",
      "Episode: 14, Reward: 201.0\n",
      "Episode: 15, Reward: 201.0\n",
      "Episode: 16, Reward: 201.0\n",
      "Episode: 17, Reward: 201.0\n",
      "Episode: 18, Reward: 208.33\n",
      "Episode: 19, Reward: 208.33\n",
      "Episode: 20, Reward: 208.33\n",
      "Episode: 21, Reward: 212.14\n",
      "Episode: 22, Reward: 212.14\n",
      "Episode: 23, Reward: 212.14\n",
      "Episode: 24, Reward: 204.38\n",
      "Episode: 25, Reward: 204.38\n",
      "Episode: 26, Reward: 204.38\n",
      "Episode: 27, Reward: 197.78\n",
      "Episode: 28, Reward: 197.78\n",
      "Episode: 29, Reward: 197.78\n",
      "Episode: 30, Reward: 197.78\n",
      "Episode: 31, Reward: 197.78\n",
      "Episode: 32, Reward: 197.78\n",
      "Episode: 33, Reward: 189.0\n",
      "Episode: 34, Reward: 189.0\n",
      "Episode: 35, Reward: 175.5\n",
      "Episode: 36, Reward: 175.5\n",
      "Episode: 37, Reward: 175.5\n",
      "Episode: 38, Reward: 192.0\n",
      "Episode: 39, Reward: 192.0\n",
      "Episode: 40, Reward: 196.5\n",
      "Episode: 41, Reward: 196.5\n",
      "Episode: 42, Reward: 196.5\n",
      "Episode: 43, Reward: 196.5\n",
      "Episode: 44, Reward: 175.5\n",
      "Episode: 45, Reward: 175.5\n",
      "Episode: 46, Reward: 175.5\n",
      "Episode: 47, Reward: 175.5\n",
      "Episode: 48, Reward: 154.0\n",
      "Episode: 49, Reward: 154.0\n",
      "Episode: 50, Reward: 154.0\n",
      "Episode: 51, Reward: 129.5\n",
      "Episode: 52, Reward: 129.5\n",
      "Episode: 53, Reward: 129.5\n",
      "Episode: 54, Reward: 129.5\n",
      "Episode: 55, Reward: 129.5\n",
      "Episode: 56, Reward: 114.5\n",
      "Episode: 57, Reward: 114.5\n",
      "Episode: 58, Reward: 114.5\n",
      "Episode: 59, Reward: 99.5\n",
      "Episode: 60, Reward: 99.5\n",
      "Episode: 61, Reward: 99.5\n",
      "Episode: 62, Reward: 93.0\n",
      "Episode: 63, Reward: 93.0\n",
      "Episode: 64, Reward: 93.0\n",
      "Episode: 65, Reward: 93.0\n",
      "Episode: 66, Reward: 93.0\n",
      "Episode: 67, Reward: 93.0\n",
      "Episode: 68, Reward: 93.0\n",
      "Episode: 69, Reward: 103.5\n",
      "Episode: 70, Reward: 103.5\n",
      "Episode: 71, Reward: 103.5\n",
      "Episode: 72, Reward: 103.5\n",
      "Episode: 73, Reward: 103.5\n",
      "Episode: 74, Reward: 103.5\n",
      "Episode: 75, Reward: 103.5\n",
      "Episode: 76, Reward: 87.5\n",
      "Episode: 77, Reward: 87.5\n",
      "Episode: 78, Reward: 78.5\n",
      "Episode: 79, Reward: 78.5\n",
      "Episode: 80, Reward: 78.5\n",
      "Episode: 81, Reward: 78.5\n",
      "Episode: 82, Reward: 79.5\n",
      "Episode: 83, Reward: 79.5\n",
      "Episode: 84, Reward: 106.5\n",
      "Episode: 85, Reward: 106.5\n",
      "Episode: 86, Reward: 106.5\n",
      "Episode: 87, Reward: 131.5\n",
      "Episode: 88, Reward: 131.5\n",
      "Episode: 89, Reward: 131.5\n",
      "Episode: 90, Reward: 147.0\n",
      "Episode: 91, Reward: 147.0\n",
      "Episode: 92, Reward: 147.0\n",
      "Episode: 93, Reward: 147.0\n",
      "Episode: 94, Reward: 171.0\n",
      "Episode: 95, Reward: 171.0\n",
      "Episode: 96, Reward: 163.0\n",
      "Episode: 97, Reward: 163.0\n",
      "Episode: 98, Reward: 141.5\n",
      "Episode: 99, Reward: 141.5\n",
      "Episode: 100, Reward: 141.5\n",
      "Episode: 101, Reward: 141.5\n",
      "Episode: 102, Reward: 147.0\n",
      "Episode: 103, Reward: 147.0\n",
      "Episode: 104, Reward: 147.0\n",
      "Episode: 105, Reward: 144.0\n",
      "Episode: 106, Reward: 144.0\n",
      "Episode: 107, Reward: 144.0\n",
      "Episode: 108, Reward: 144.0\n",
      "Episode: 109, Reward: 134.5\n",
      "Episode: 110, Reward: 134.5\n",
      "Episode: 111, Reward: 134.5\n",
      "Episode: 112, Reward: 113.0\n",
      "Episode: 113, Reward: 113.0\n",
      "Episode: 114, Reward: 88.0\n",
      "Episode: 115, Reward: 88.0\n",
      "Episode: 116, Reward: 88.0\n",
      "Episode: 117, Reward: 88.0\n",
      "Episode: 118, Reward: 88.0\n",
      "Episode: 119, Reward: 88.0\n",
      "Episode: 120, Reward: 88.0\n",
      "Episode: 121, Reward: 102.0\n",
      "Episode: 122, Reward: 102.0\n",
      "Episode: 123, Reward: 84.0\n",
      "Episode: 124, Reward: 84.0\n",
      "Episode: 125, Reward: 100.5\n",
      "Episode: 126, Reward: 100.5\n",
      "Episode: 127, Reward: 100.5\n",
      "Episode: 128, Reward: 100.5\n",
      "Episode: 129, Reward: 100.5\n",
      "Episode: 130, Reward: 100.5\n",
      "Episode: 131, Reward: 152.5\n",
      "Episode: 132, Reward: 152.5\n",
      "Episode: 133, Reward: 152.5\n",
      "Episode: 134, Reward: 152.5\n",
      "Episode: 135, Reward: 152.5\n",
      "Episode: 136, Reward: 152.5\n",
      "Episode: 137, Reward: 200.0\n",
      "Episode: 138, Reward: 200.0\n",
      "Episode: 139, Reward: 200.0\n",
      "Episode: 140, Reward: 200.0\n",
      "Episode: 141, Reward: 200.0\n",
      "Episode: 142, Reward: 200.0\n",
      "Episode: 143, Reward: 226.5\n",
      "Episode: 144, Reward: 226.5\n",
      "Episode: 145, Reward: 226.5\n",
      "Episode: 146, Reward: 226.5\n",
      "Episode: 147, Reward: 245.5\n",
      "Episode: 148, Reward: 245.5\n",
      "Episode: 149, Reward: 245.5\n",
      "Episode: 150, Reward: 243.5\n",
      "Episode: 151, Reward: 243.5\n",
      "Episode: 152, Reward: 243.5\n",
      "Episode: 153, Reward: 251.5\n",
      "Episode: 154, Reward: 251.5\n",
      "Episode: 155, Reward: 251.5\n",
      "Episode: 156, Reward: 251.5\n",
      "Episode: 157, Reward: 285.5\n",
      "Episode: 158, Reward: 285.5\n",
      "Episode: 159, Reward: 285.5\n",
      "Episode: 160, Reward: 285.5\n",
      "Episode: 161, Reward: 285.5\n",
      "Episode: 162, Reward: 290.5\n",
      "Episode: 163, Reward: 290.5\n",
      "Episode: 164, Reward: 309.5\n",
      "Episode: 165, Reward: 309.5\n",
      "Episode: 166, Reward: 309.5\n",
      "Episode: 167, Reward: 309.5\n",
      "Episode: 168, Reward: 300.5\n",
      "Episode: 169, Reward: 300.5\n",
      "Episode: 170, Reward: 300.5\n",
      "Episode: 171, Reward: 300.5\n",
      "Episode: 172, Reward: 300.5\n",
      "Episode: 173, Reward: 269.0\n",
      "Episode: 174, Reward: 269.0\n",
      "Episode: 175, Reward: 269.0\n",
      "Episode: 176, Reward: 232.0\n",
      "Episode: 177, Reward: 232.0\n",
      "Episode: 178, Reward: 232.0\n",
      "Episode: 179, Reward: 232.0\n",
      "Episode: 180, Reward: 223.5\n",
      "Episode: 181, Reward: 223.5\n",
      "Episode: 182, Reward: 223.5\n",
      "Episode: 183, Reward: 204.5\n",
      "Episode: 184, Reward: 204.5\n",
      "Episode: 185, Reward: 204.5\n",
      "Episode: 186, Reward: 204.5\n",
      "Episode: 187, Reward: 199.0\n",
      "Episode: 188, Reward: 199.0\n",
      "Episode: 189, Reward: 199.0\n",
      "Episode: 190, Reward: 214.0\n",
      "Episode: 191, Reward: 214.0\n",
      "Episode: 192, Reward: 214.0\n",
      "Episode: 193, Reward: 214.0\n",
      "Episode: 194, Reward: 214.0\n",
      "Episode: 195, Reward: 214.0\n",
      "Episode: 196, Reward: 214.0\n",
      "Episode: 197, Reward: 214.0\n",
      "Episode: 198, Reward: 221.5\n",
      "Episode: 199, Reward: 221.5\n",
      "END - Date-Time: 2023-08-21 06:57:08\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[5, 6, 10, 11, 15, 30, 31, 32, 37, 44, 55, 56, 59, 70, 74, 76, 83, 84, 85, 86, 93, 94, 97, 100, 107, 125, 134, 143, 147, 154, 156, 158, 159, 163, 168, 169, 171, 174, 188, 189]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALE_SPACEINVADERS-V5 EXPERIMENT 1: Date-Time: 2023-08-21 06:58:03, Capacity: 500k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 500000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 45.0\n",
      "Episode: 2, Reward: 45.0\n",
      "Episode: 3, Reward: 50.0\n",
      "Episode: 4, Reward: 50.0\n",
      "Episode: 5, Reward: 53.33\n",
      "Episode: 6, Reward: 53.33\n",
      "Episode: 7, Reward: 73.75\n",
      "Episode: 8, Reward: 73.75\n",
      "Episode: 9, Reward: 73.75\n",
      "Episode: 10, Reward: 103.0\n",
      "Episode: 11, Reward: 103.0\n",
      "Episode: 12, Reward: 86.67\n",
      "Episode: 13, Reward: 86.67\n",
      "Episode: 14, Reward: 86.67\n",
      "Episode: 15, Reward: 74.29\n",
      "Episode: 16, Reward: 74.29\n",
      "Episode: 17, Reward: 74.29\n",
      "Episode: 18, Reward: 99.38\n",
      "Episode: 19, Reward: 99.38\n",
      "Episode: 20, Reward: 99.38\n",
      "Episode: 21, Reward: 111.67\n",
      "Episode: 22, Reward: 111.67\n",
      "Episode: 23, Reward: 111.67\n",
      "Episode: 24, Reward: 111.67\n",
      "Episode: 25, Reward: 100.5\n",
      "Episode: 26, Reward: 100.5\n",
      "Episode: 27, Reward: 96.0\n",
      "Episode: 28, Reward: 96.0\n",
      "Episode: 29, Reward: 96.0\n",
      "Episode: 30, Reward: 96.0\n",
      "Episode: 31, Reward: 95.5\n",
      "Episode: 32, Reward: 95.5\n",
      "Episode: 33, Reward: 95.5\n",
      "Episode: 34, Reward: 107.5\n",
      "Episode: 35, Reward: 107.5\n",
      "Episode: 36, Reward: 107.5\n",
      "Episode: 37, Reward: 107.5\n",
      "Episode: 38, Reward: 102.0\n",
      "Episode: 39, Reward: 102.0\n",
      "Episode: 40, Reward: 102.0\n",
      "Episode: 41, Reward: 102.0\n",
      "Episode: 42, Reward: 102.0\n",
      "Episode: 43, Reward: 100.0\n",
      "Episode: 44, Reward: 100.0\n",
      "Episode: 45, Reward: 100.0\n",
      "Episode: 46, Reward: 100.0\n",
      "Episode: 47, Reward: 100.0\n",
      "Episode: 48, Reward: 125.5\n",
      "Episode: 49, Reward: 125.5\n",
      "Episode: 50, Reward: 125.5\n",
      "Episode: 51, Reward: 125.5\n",
      "Episode: 52, Reward: 125.5\n",
      "Episode: 53, Reward: 125.5\n",
      "Episode: 54, Reward: 125.5\n",
      "Episode: 55, Reward: 125.5\n",
      "Episode: 56, Reward: 125.5\n",
      "Episode: 57, Reward: 109.5\n",
      "Episode: 58, Reward: 109.5\n",
      "Episode: 59, Reward: 99.0\n",
      "Episode: 60, Reward: 99.0\n",
      "Episode: 61, Reward: 99.0\n",
      "Episode: 62, Reward: 99.0\n",
      "Episode: 63, Reward: 127.5\n",
      "Episode: 64, Reward: 127.5\n",
      "Episode: 65, Reward: 127.5\n",
      "Episode: 66, Reward: 127.5\n",
      "Episode: 67, Reward: 151.5\n",
      "Episode: 68, Reward: 151.5\n",
      "Episode: 69, Reward: 151.5\n",
      "Episode: 70, Reward: 164.5\n",
      "Episode: 71, Reward: 164.5\n",
      "Episode: 72, Reward: 164.5\n",
      "Episode: 73, Reward: 164.5\n",
      "Episode: 74, Reward: 175.0\n",
      "Episode: 75, Reward: 175.0\n",
      "Episode: 76, Reward: 175.0\n",
      "Episode: 77, Reward: 175.0\n",
      "Episode: 78, Reward: 177.5\n",
      "Episode: 79, Reward: 177.5\n",
      "Episode: 80, Reward: 177.5\n",
      "Episode: 81, Reward: 165.0\n",
      "Episode: 82, Reward: 165.0\n",
      "Episode: 83, Reward: 165.0\n",
      "Episode: 84, Reward: 154.5\n",
      "Episode: 85, Reward: 154.5\n",
      "Episode: 86, Reward: 154.5\n",
      "Episode: 87, Reward: 172.5\n",
      "Episode: 88, Reward: 172.5\n",
      "Episode: 89, Reward: 172.5\n",
      "Episode: 90, Reward: 183.5\n",
      "Episode: 91, Reward: 183.5\n",
      "Episode: 92, Reward: 183.5\n",
      "Episode: 93, Reward: 191.0\n",
      "Episode: 94, Reward: 191.0\n",
      "Episode: 95, Reward: 191.0\n",
      "Episode: 96, Reward: 196.0\n",
      "Episode: 97, Reward: 196.0\n",
      "Episode: 98, Reward: 196.0\n",
      "Episode: 99, Reward: 190.0\n",
      "Episode: 100, Reward: 190.0\n",
      "Episode: 101, Reward: 190.0\n",
      "Episode: 102, Reward: 190.0\n",
      "Episode: 103, Reward: 199.5\n",
      "Episode: 104, Reward: 199.5\n",
      "Episode: 105, Reward: 199.5\n",
      "Episode: 106, Reward: 182.5\n",
      "Episode: 107, Reward: 182.5\n",
      "Episode: 108, Reward: 182.5\n",
      "Episode: 109, Reward: 182.5\n",
      "Episode: 110, Reward: 175.5\n",
      "Episode: 111, Reward: 175.5\n",
      "Episode: 112, Reward: 175.5\n",
      "Episode: 113, Reward: 188.0\n",
      "Episode: 114, Reward: 188.0\n",
      "Episode: 115, Reward: 176.5\n",
      "Episode: 116, Reward: 176.5\n",
      "Episode: 117, Reward: 176.5\n",
      "Episode: 118, Reward: 167.5\n",
      "Episode: 119, Reward: 167.5\n",
      "Episode: 120, Reward: 167.5\n",
      "Episode: 121, Reward: 173.5\n",
      "Episode: 122, Reward: 173.5\n",
      "Episode: 123, Reward: 173.5\n",
      "Episode: 124, Reward: 173.5\n",
      "Episode: 125, Reward: 173.5\n",
      "Episode: 126, Reward: 173.5\n",
      "Episode: 127, Reward: 173.0\n",
      "Episode: 128, Reward: 173.0\n",
      "Episode: 129, Reward: 173.0\n",
      "Episode: 130, Reward: 173.0\n",
      "Episode: 131, Reward: 173.0\n",
      "Episode: 132, Reward: 161.0\n",
      "Episode: 133, Reward: 161.0\n",
      "Episode: 134, Reward: 161.5\n",
      "Episode: 135, Reward: 161.5\n",
      "Episode: 136, Reward: 161.5\n",
      "Episode: 137, Reward: 161.5\n",
      "Episode: 138, Reward: 180.5\n",
      "Episode: 139, Reward: 180.5\n",
      "Episode: 140, Reward: 180.5\n",
      "Episode: 141, Reward: 180.5\n",
      "Episode: 142, Reward: 232.5\n",
      "Episode: 143, Reward: 232.5\n",
      "Episode: 144, Reward: 232.5\n",
      "Episode: 145, Reward: 222.5\n",
      "Episode: 146, Reward: 222.5\n",
      "Episode: 147, Reward: 222.5\n",
      "Episode: 148, Reward: 222.5\n",
      "Episode: 149, Reward: 222.5\n",
      "Episode: 150, Reward: 222.5\n",
      "Episode: 151, Reward: 227.5\n",
      "Episode: 152, Reward: 227.5\n",
      "Episode: 153, Reward: 214.0\n",
      "Episode: 154, Reward: 214.0\n",
      "Episode: 155, Reward: 214.0\n",
      "Episode: 156, Reward: 203.0\n",
      "Episode: 157, Reward: 203.0\n",
      "Episode: 158, Reward: 203.0\n",
      "Episode: 159, Reward: 198.0\n",
      "Episode: 160, Reward: 198.0\n",
      "Episode: 161, Reward: 198.0\n",
      "Episode: 162, Reward: 198.0\n",
      "Episode: 163, Reward: 198.0\n",
      "Episode: 164, Reward: 198.0\n",
      "Episode: 165, Reward: 191.5\n",
      "Episode: 166, Reward: 191.5\n",
      "Episode: 167, Reward: 176.0\n",
      "Episode: 168, Reward: 176.0\n",
      "Episode: 169, Reward: 176.0\n",
      "Episode: 170, Reward: 164.0\n",
      "Episode: 171, Reward: 164.0\n",
      "Episode: 172, Reward: 134.5\n",
      "Episode: 173, Reward: 82.0\n",
      "Episode: 174, Reward: 82.0\n",
      "Episode: 175, Reward: 82.0\n",
      "Episode: 176, Reward: 82.0\n",
      "Episode: 177, Reward: 64.0\n",
      "Episode: 178, Reward: 64.0\n",
      "Episode: 179, Reward: 77.5\n",
      "Episode: 180, Reward: 77.5\n",
      "Episode: 181, Reward: 77.5\n",
      "Episode: 182, Reward: 77.5\n",
      "Episode: 183, Reward: 77.5\n",
      "Episode: 184, Reward: 67.5\n",
      "Episode: 185, Reward: 67.5\n",
      "Episode: 186, Reward: 39.5\n",
      "Episode: 187, Reward: 39.5\n",
      "Episode: 188, Reward: 32.5\n",
      "Episode: 189, Reward: 32.5\n",
      "Episode: 190, Reward: 32.5\n",
      "Episode: 191, Reward: 32.5\n",
      "Episode: 192, Reward: 32.5\n",
      "Episode: 193, Reward: 54.0\n",
      "Episode: 194, Reward: 54.0\n",
      "Episode: 195, Reward: 54.0\n",
      "Episode: 196, Reward: 79.0\n",
      "Episode: 197, Reward: 79.0\n",
      "Episode: 198, Reward: 79.0\n",
      "Episode: 199, Reward: 90.0\n",
      "END - Date-Time: 2023-08-21 07:05:11\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[1, 7, 18, 31, 37, 40, 41, 46, 53, 62, 65, 68, 73, 76, 79, 82, 83, 84, 87, 97, 101, 108, 110, 124, 126, 129, 131, 138, 142, 146, 158, 159, 160, 168, 171, 180, 186, 191, 194, 199]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_SPACEINVADERS-V5 EXPERIMENT 2: Date-Time: 2023-08-21 07:05:31, Capacity: 100k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 100000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 260.0\n",
      "Episode: 4, Reward: 260.0\n",
      "Episode: 5, Reward: 160.0\n",
      "Episode: 6, Reward: 160.0\n",
      "Episode: 7, Reward: 160.0\n",
      "Episode: 8, Reward: 120.0\n",
      "Episode: 9, Reward: 120.0\n",
      "Episode: 10, Reward: 120.0\n",
      "Episode: 11, Reward: 135.0\n",
      "Episode: 12, Reward: 135.0\n",
      "Episode: 13, Reward: 135.0\n",
      "Episode: 14, Reward: 135.0\n",
      "Episode: 15, Reward: 165.0\n",
      "Episode: 16, Reward: 165.0\n",
      "Episode: 17, Reward: 165.0\n",
      "Episode: 18, Reward: 155.0\n",
      "Episode: 19, Reward: 155.0\n",
      "Episode: 20, Reward: 155.0\n",
      "Episode: 21, Reward: 132.86\n",
      "Episode: 22, Reward: 132.86\n",
      "Episode: 23, Reward: 132.86\n",
      "Episode: 24, Reward: 132.86\n",
      "Episode: 25, Reward: 142.5\n",
      "Episode: 26, Reward: 142.5\n",
      "Episode: 27, Reward: 142.5\n",
      "Episode: 28, Reward: 142.5\n",
      "Episode: 29, Reward: 142.5\n",
      "Episode: 30, Reward: 140.0\n",
      "Episode: 31, Reward: 140.0\n",
      "Episode: 32, Reward: 140.0\n",
      "Episode: 33, Reward: 140.0\n",
      "Episode: 34, Reward: 140.0\n",
      "Episode: 35, Reward: 142.5\n",
      "Episode: 36, Reward: 142.5\n",
      "Episode: 37, Reward: 142.5\n",
      "Episode: 38, Reward: 142.5\n",
      "Episode: 39, Reward: 142.5\n",
      "Episode: 40, Reward: 142.5\n",
      "Episode: 41, Reward: 133.5\n",
      "Episode: 42, Reward: 133.5\n",
      "Episode: 43, Reward: 133.5\n",
      "Episode: 44, Reward: 127.5\n",
      "Episode: 45, Reward: 127.5\n",
      "Episode: 46, Reward: 128.0\n",
      "Episode: 47, Reward: 128.0\n",
      "Episode: 48, Reward: 126.0\n",
      "Episode: 49, Reward: 126.0\n",
      "Episode: 50, Reward: 126.0\n",
      "Episode: 51, Reward: 126.0\n",
      "Episode: 52, Reward: 108.0\n",
      "Episode: 53, Reward: 108.0\n",
      "Episode: 54, Reward: 108.0\n",
      "Episode: 55, Reward: 108.0\n",
      "Episode: 56, Reward: 97.5\n",
      "Episode: 57, Reward: 97.5\n",
      "Episode: 58, Reward: 97.5\n",
      "Episode: 59, Reward: 97.5\n",
      "Episode: 60, Reward: 97.5\n",
      "Episode: 61, Reward: 85.5\n",
      "Episode: 62, Reward: 85.5\n",
      "Episode: 63, Reward: 85.5\n",
      "Episode: 64, Reward: 85.5\n",
      "Episode: 65, Reward: 85.5\n",
      "Episode: 66, Reward: 85.5\n",
      "Episode: 67, Reward: 85.5\n",
      "Episode: 68, Reward: 92.5\n",
      "Episode: 69, Reward: 92.5\n",
      "Episode: 70, Reward: 92.5\n",
      "Episode: 71, Reward: 83.5\n",
      "Episode: 72, Reward: 83.5\n",
      "Episode: 73, Reward: 83.5\n",
      "Episode: 74, Reward: 83.5\n",
      "Episode: 75, Reward: 83.5\n",
      "Episode: 76, Reward: 83.5\n",
      "Episode: 77, Reward: 81.0\n",
      "Episode: 78, Reward: 81.0\n",
      "Episode: 79, Reward: 81.0\n",
      "Episode: 80, Reward: 81.0\n",
      "Episode: 81, Reward: 81.0\n",
      "Episode: 82, Reward: 86.5\n",
      "Episode: 83, Reward: 86.5\n",
      "Episode: 84, Reward: 86.5\n",
      "Episode: 85, Reward: 70.5\n",
      "Episode: 86, Reward: 70.5\n",
      "Episode: 87, Reward: 70.5\n",
      "Episode: 88, Reward: 70.5\n",
      "Episode: 89, Reward: 62.5\n",
      "Episode: 90, Reward: 62.5\n",
      "Episode: 91, Reward: 62.5\n",
      "Episode: 92, Reward: 73.0\n",
      "Episode: 93, Reward: 73.0\n",
      "Episode: 94, Reward: 73.0\n",
      "Episode: 95, Reward: 73.0\n",
      "Episode: 96, Reward: 73.0\n",
      "Episode: 97, Reward: 73.0\n",
      "Episode: 98, Reward: 73.0\n",
      "Episode: 99, Reward: 85.0\n",
      "Episode: 100, Reward: 85.0\n",
      "Episode: 101, Reward: 85.0\n",
      "Episode: 102, Reward: 73.5\n",
      "Episode: 103, Reward: 73.5\n",
      "Episode: 104, Reward: 73.5\n",
      "Episode: 105, Reward: 76.5\n",
      "Episode: 106, Reward: 76.5\n",
      "Episode: 107, Reward: 76.5\n",
      "Episode: 108, Reward: 76.5\n",
      "Episode: 109, Reward: 76.5\n",
      "Episode: 110, Reward: 71.0\n",
      "Episode: 111, Reward: 71.0\n",
      "Episode: 112, Reward: 74.0\n",
      "Episode: 113, Reward: 74.0\n",
      "Episode: 114, Reward: 74.0\n",
      "Episode: 115, Reward: 64.5\n",
      "Episode: 116, Reward: 64.5\n",
      "Episode: 117, Reward: 64.5\n",
      "Episode: 118, Reward: 74.0\n",
      "Episode: 119, Reward: 74.0\n",
      "Episode: 120, Reward: 74.0\n",
      "Episode: 121, Reward: 96.5\n",
      "Episode: 122, Reward: 96.5\n",
      "Episode: 123, Reward: 96.5\n",
      "Episode: 124, Reward: 107.0\n",
      "Episode: 125, Reward: 107.0\n",
      "Episode: 126, Reward: 107.0\n",
      "Episode: 127, Reward: 107.0\n",
      "Episode: 128, Reward: 107.0\n",
      "Episode: 129, Reward: 144.0\n",
      "Episode: 130, Reward: 144.0\n",
      "Episode: 131, Reward: 144.0\n",
      "Episode: 132, Reward: 137.0\n",
      "Episode: 133, Reward: 137.0\n",
      "Episode: 134, Reward: 137.0\n",
      "Episode: 135, Reward: 140.0\n",
      "Episode: 136, Reward: 140.0\n",
      "Episode: 137, Reward: 134.0\n",
      "Episode: 138, Reward: 134.0\n",
      "Episode: 139, Reward: 138.0\n",
      "Episode: 140, Reward: 138.0\n",
      "Episode: 141, Reward: 138.0\n",
      "Episode: 142, Reward: 138.0\n",
      "Episode: 143, Reward: 145.5\n",
      "Episode: 144, Reward: 145.5\n",
      "Episode: 145, Reward: 145.5\n",
      "Episode: 146, Reward: 145.5\n",
      "Episode: 147, Reward: 145.5\n",
      "Episode: 148, Reward: 159.0\n",
      "Episode: 149, Reward: 159.0\n",
      "Episode: 150, Reward: 162.5\n",
      "Episode: 151, Reward: 162.5\n",
      "Episode: 152, Reward: 162.5\n",
      "Episode: 153, Reward: 162.5\n",
      "Episode: 154, Reward: 162.5\n",
      "Episode: 155, Reward: 162.5\n",
      "Episode: 156, Reward: 162.5\n",
      "Episode: 157, Reward: 149.5\n",
      "Episode: 158, Reward: 149.5\n",
      "Episode: 159, Reward: 149.5\n",
      "Episode: 160, Reward: 149.5\n",
      "Episode: 161, Reward: 136.0\n",
      "Episode: 162, Reward: 136.0\n",
      "Episode: 163, Reward: 136.0\n",
      "Episode: 164, Reward: 108.0\n",
      "Episode: 165, Reward: 108.0\n",
      "Episode: 166, Reward: 108.0\n",
      "Episode: 167, Reward: 97.0\n",
      "Episode: 168, Reward: 97.0\n",
      "Episode: 169, Reward: 115.0\n",
      "Episode: 170, Reward: 115.0\n",
      "Episode: 171, Reward: 115.0\n",
      "Episode: 172, Reward: 115.0\n",
      "Episode: 173, Reward: 131.5\n",
      "Episode: 174, Reward: 131.5\n",
      "Episode: 175, Reward: 131.5\n",
      "Episode: 176, Reward: 131.5\n",
      "Episode: 177, Reward: 131.5\n",
      "Episode: 178, Reward: 130.0\n",
      "Episode: 179, Reward: 130.0\n",
      "Episode: 180, Reward: 130.0\n",
      "Episode: 181, Reward: 130.0\n",
      "Episode: 182, Reward: 140.5\n",
      "Episode: 183, Reward: 140.5\n",
      "Episode: 184, Reward: 140.5\n",
      "Episode: 185, Reward: 140.0\n",
      "Episode: 186, Reward: 140.0\n",
      "Episode: 187, Reward: 140.0\n",
      "Episode: 188, Reward: 140.0\n",
      "Episode: 189, Reward: 155.5\n",
      "Episode: 190, Reward: 155.5\n",
      "Episode: 191, Reward: 155.5\n",
      "Episode: 192, Reward: 156.5\n",
      "Episode: 193, Reward: 156.5\n",
      "Episode: 194, Reward: 156.5\n",
      "Episode: 195, Reward: 170.0\n",
      "Episode: 196, Reward: 170.0\n",
      "Episode: 197, Reward: 170.0\n",
      "Episode: 198, Reward: 166.0\n",
      "Episode: 199, Reward: 166.0\n",
      "END - Date-Time: 2023-08-21 07:12:36\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[1, 3, 15, 17, 19, 21, 29, 32, 34, 51, 55, 56, 62, 66, 69, 81, 83, 86, 95, 100, 102, 107, 109, 110, 111, 125, 130, 132, 134, 143, 146, 149, 155, 156, 176, 178, 179, 188, 191, 197]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_SPACEINVADERS-V5 EXPERIMENT 3: Date-Time: 2023-08-21 07:12:56, Capacity: 50k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 50000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 90.0\n",
      "Episode: 2, Reward: 90.0\n",
      "Episode: 3, Reward: 90.0\n",
      "Episode: 4, Reward: 165.0\n",
      "Episode: 5, Reward: 165.0\n",
      "Episode: 6, Reward: 135.0\n",
      "Episode: 7, Reward: 135.0\n",
      "Episode: 8, Reward: 116.25\n",
      "Episode: 9, Reward: 116.25\n",
      "Episode: 10, Reward: 116.25\n",
      "Episode: 11, Reward: 105.0\n",
      "Episode: 12, Reward: 105.0\n",
      "Episode: 13, Reward: 107.5\n",
      "Episode: 14, Reward: 107.5\n",
      "Episode: 15, Reward: 107.5\n",
      "Episode: 16, Reward: 107.5\n",
      "Episode: 17, Reward: 129.29\n",
      "Episode: 18, Reward: 129.29\n",
      "Episode: 19, Reward: 129.29\n",
      "Episode: 20, Reward: 129.29\n",
      "Episode: 21, Reward: 126.88\n",
      "Episode: 22, Reward: 126.88\n",
      "Episode: 23, Reward: 129.44\n",
      "Episode: 24, Reward: 129.44\n",
      "Episode: 25, Reward: 129.44\n",
      "Episode: 26, Reward: 124.0\n",
      "Episode: 27, Reward: 124.0\n",
      "Episode: 28, Reward: 125.5\n",
      "Episode: 29, Reward: 125.5\n",
      "Episode: 30, Reward: 125.5\n",
      "Episode: 31, Reward: 125.5\n",
      "Episode: 32, Reward: 130.0\n",
      "Episode: 33, Reward: 130.0\n",
      "Episode: 34, Reward: 130.0\n",
      "Episode: 35, Reward: 143.5\n",
      "Episode: 36, Reward: 143.5\n",
      "Episode: 37, Reward: 143.5\n",
      "Episode: 38, Reward: 148.0\n",
      "Episode: 39, Reward: 148.0\n",
      "Episode: 40, Reward: 148.0\n",
      "Episode: 41, Reward: 148.0\n",
      "Episode: 42, Reward: 152.5\n",
      "Episode: 43, Reward: 152.5\n",
      "Episode: 44, Reward: 152.5\n",
      "Episode: 45, Reward: 140.5\n",
      "Episode: 46, Reward: 140.5\n",
      "Episode: 47, Reward: 140.5\n",
      "Episode: 48, Reward: 123.0\n",
      "Episode: 49, Reward: 123.0\n",
      "Episode: 50, Reward: 123.0\n",
      "Episode: 51, Reward: 134.0\n",
      "Episode: 52, Reward: 134.0\n",
      "Episode: 53, Reward: 146.0\n",
      "Episode: 54, Reward: 146.0\n",
      "Episode: 55, Reward: 146.0\n",
      "Episode: 56, Reward: 147.5\n",
      "Episode: 57, Reward: 147.5\n",
      "Episode: 58, Reward: 147.5\n",
      "Episode: 59, Reward: 147.5\n",
      "Episode: 60, Reward: 147.5\n",
      "Episode: 61, Reward: 147.5\n",
      "Episode: 62, Reward: 147.5\n",
      "Episode: 63, Reward: 147.5\n",
      "Episode: 64, Reward: 147.5\n",
      "Episode: 65, Reward: 133.5\n",
      "Episode: 66, Reward: 133.5\n",
      "Episode: 67, Reward: 133.5\n",
      "Episode: 68, Reward: 135.0\n",
      "Episode: 69, Reward: 135.0\n",
      "Episode: 70, Reward: 135.0\n",
      "Episode: 71, Reward: 135.0\n",
      "Episode: 72, Reward: 124.5\n",
      "Episode: 73, Reward: 124.5\n",
      "Episode: 74, Reward: 124.5\n",
      "Episode: 75, Reward: 120.5\n",
      "Episode: 76, Reward: 120.5\n",
      "Episode: 77, Reward: 122.0\n",
      "Episode: 78, Reward: 122.0\n",
      "Episode: 79, Reward: 113.5\n",
      "Episode: 80, Reward: 113.5\n",
      "Episode: 81, Reward: 113.5\n",
      "Episode: 82, Reward: 99.0\n",
      "Episode: 83, Reward: 99.0\n",
      "Episode: 84, Reward: 99.0\n",
      "Episode: 85, Reward: 87.5\n",
      "Episode: 86, Reward: 87.5\n",
      "Episode: 87, Reward: 87.5\n",
      "Episode: 88, Reward: 83.5\n",
      "Episode: 89, Reward: 83.5\n",
      "Episode: 90, Reward: 83.5\n",
      "Episode: 91, Reward: 73.0\n",
      "Episode: 92, Reward: 73.0\n",
      "Episode: 93, Reward: 73.0\n",
      "Episode: 94, Reward: 73.0\n",
      "Episode: 95, Reward: 58.5\n",
      "Episode: 96, Reward: 36.0\n",
      "Episode: 97, Reward: 36.0\n",
      "Episode: 98, Reward: 36.0\n",
      "Episode: 99, Reward: 47.0\n",
      "Episode: 100, Reward: 47.0\n",
      "Episode: 101, Reward: 47.0\n",
      "Episode: 102, Reward: 47.0\n",
      "Episode: 103, Reward: 52.5\n",
      "Episode: 104, Reward: 52.5\n",
      "Episode: 105, Reward: 52.5\n",
      "Episode: 106, Reward: 63.0\n",
      "Episode: 107, Reward: 63.0\n",
      "Episode: 108, Reward: 63.0\n",
      "Episode: 109, Reward: 84.0\n",
      "Episode: 110, Reward: 84.0\n",
      "Episode: 111, Reward: 84.0\n",
      "Episode: 112, Reward: 84.0\n",
      "Episode: 113, Reward: 84.0\n",
      "Episode: 114, Reward: 87.0\n",
      "Episode: 115, Reward: 87.0\n",
      "Episode: 116, Reward: 87.0\n",
      "Episode: 117, Reward: 85.5\n",
      "Episode: 118, Reward: 85.5\n",
      "Episode: 119, Reward: 85.5\n",
      "Episode: 120, Reward: 96.0\n",
      "Episode: 121, Reward: 96.0\n",
      "Episode: 122, Reward: 96.0\n",
      "Episode: 123, Reward: 96.0\n",
      "Episode: 124, Reward: 96.0\n",
      "Episode: 125, Reward: 118.5\n",
      "Episode: 126, Reward: 118.5\n",
      "Episode: 127, Reward: 130.0\n",
      "Episode: 128, Reward: 130.0\n",
      "Episode: 129, Reward: 130.0\n",
      "Episode: 130, Reward: 130.0\n",
      "Episode: 131, Reward: 143.5\n",
      "Episode: 132, Reward: 143.5\n",
      "Episode: 133, Reward: 143.5\n",
      "Episode: 134, Reward: 143.5\n",
      "Episode: 135, Reward: 143.5\n",
      "Episode: 136, Reward: 153.5\n",
      "Episode: 137, Reward: 153.5\n",
      "Episode: 138, Reward: 153.5\n",
      "Episode: 139, Reward: 159.5\n",
      "Episode: 140, Reward: 159.5\n",
      "Episode: 141, Reward: 159.5\n",
      "Episode: 142, Reward: 159.5\n",
      "Episode: 143, Reward: 165.5\n",
      "Episode: 144, Reward: 165.5\n",
      "Episode: 145, Reward: 154.0\n",
      "Episode: 146, Reward: 154.0\n",
      "Episode: 147, Reward: 154.0\n",
      "Episode: 148, Reward: 150.0\n",
      "Episode: 149, Reward: 150.0\n",
      "Episode: 150, Reward: 146.5\n",
      "Episode: 151, Reward: 146.5\n",
      "Episode: 152, Reward: 142.0\n",
      "Episode: 153, Reward: 142.0\n",
      "Episode: 154, Reward: 142.0\n",
      "Episode: 155, Reward: 142.0\n",
      "Episode: 156, Reward: 140.5\n",
      "Episode: 157, Reward: 140.5\n",
      "Episode: 158, Reward: 140.5\n",
      "Episode: 159, Reward: 140.5\n",
      "Episode: 160, Reward: 157.5\n",
      "Episode: 161, Reward: 157.5\n",
      "Episode: 162, Reward: 157.5\n",
      "Episode: 163, Reward: 159.5\n",
      "Episode: 164, Reward: 159.5\n",
      "Episode: 165, Reward: 142.0\n",
      "Episode: 166, Reward: 132.5\n",
      "Episode: 167, Reward: 132.5\n",
      "Episode: 168, Reward: 124.0\n",
      "Episode: 169, Reward: 124.0\n",
      "Episode: 170, Reward: 122.5\n",
      "Episode: 171, Reward: 122.5\n",
      "Episode: 172, Reward: 122.5\n",
      "Episode: 173, Reward: 128.0\n",
      "Episode: 174, Reward: 128.0\n",
      "Episode: 175, Reward: 135.5\n",
      "Episode: 176, Reward: 135.5\n",
      "Episode: 177, Reward: 135.5\n",
      "Episode: 178, Reward: 135.5\n",
      "Episode: 179, Reward: 135.5\n",
      "Episode: 180, Reward: 163.5\n",
      "Episode: 181, Reward: 163.5\n",
      "Episode: 182, Reward: 163.5\n",
      "Episode: 183, Reward: 185.5\n",
      "Episode: 184, Reward: 185.5\n",
      "Episode: 185, Reward: 185.5\n",
      "Episode: 186, Reward: 185.5\n",
      "Episode: 187, Reward: 185.5\n",
      "Episode: 188, Reward: 195.5\n",
      "Episode: 189, Reward: 186.5\n",
      "Episode: 190, Reward: 186.5\n",
      "Episode: 191, Reward: 187.5\n",
      "Episode: 192, Reward: 187.5\n",
      "Episode: 193, Reward: 192.0\n",
      "Episode: 194, Reward: 192.0\n",
      "Episode: 195, Reward: 192.0\n",
      "Episode: 196, Reward: 194.5\n",
      "Episode: 197, Reward: 194.5\n",
      "Episode: 198, Reward: 193.0\n",
      "Episode: 199, Reward: 193.0\n",
      "END - Date-Time: 2023-08-21 07:20:10\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[8, 9, 11, 12, 17, 21, 25, 30, 38, 46, 52, 53, 56, 60, 61, 63, 65, 69, 80, 86, 87, 102, 110, 117, 119, 123, 125, 146, 147, 148, 149, 151, 155, 156, 170, 182, 185, 189, 195, 196]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_SPACEINVADERS-V5 EXPERIMENT 4: Date-Time: 2023-08-21 07:20:30, Capacity: 10k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 10000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 110.0\n",
      "Episode: 3, Reward: 110.0\n",
      "Episode: 4, Reward: 70.0\n",
      "Episode: 5, Reward: 70.0\n",
      "Episode: 6, Reward: 108.33\n",
      "Episode: 7, Reward: 108.33\n",
      "Episode: 8, Reward: 108.33\n",
      "Episode: 9, Reward: 133.75\n",
      "Episode: 10, Reward: 133.75\n",
      "Episode: 11, Reward: 133.75\n",
      "Episode: 12, Reward: 133.75\n",
      "Episode: 13, Reward: 107.0\n",
      "Episode: 14, Reward: 107.0\n",
      "Episode: 15, Reward: 91.67\n",
      "Episode: 16, Reward: 91.67\n",
      "Episode: 17, Reward: 91.67\n",
      "Episode: 18, Reward: 91.67\n",
      "Episode: 19, Reward: 137.86\n",
      "Episode: 20, Reward: 137.86\n",
      "Episode: 21, Reward: 137.86\n",
      "Episode: 22, Reward: 137.86\n",
      "Episode: 23, Reward: 137.86\n",
      "Episode: 24, Reward: 137.86\n",
      "Episode: 25, Reward: 159.38\n",
      "Episode: 26, Reward: 159.38\n",
      "Episode: 27, Reward: 150.0\n",
      "Episode: 28, Reward: 150.0\n",
      "Episode: 29, Reward: 150.0\n",
      "Episode: 30, Reward: 150.0\n",
      "Episode: 31, Reward: 138.0\n",
      "Episode: 32, Reward: 138.0\n",
      "Episode: 33, Reward: 138.0\n",
      "Episode: 34, Reward: 148.0\n",
      "Episode: 35, Reward: 148.0\n",
      "Episode: 36, Reward: 148.0\n",
      "Episode: 37, Reward: 155.5\n",
      "Episode: 38, Reward: 155.5\n",
      "Episode: 39, Reward: 141.5\n",
      "Episode: 40, Reward: 141.5\n",
      "Episode: 41, Reward: 141.5\n",
      "Episode: 42, Reward: 141.5\n",
      "Episode: 43, Reward: 132.0\n",
      "Episode: 44, Reward: 132.0\n",
      "Episode: 45, Reward: 132.0\n",
      "Episode: 46, Reward: 132.0\n",
      "Episode: 47, Reward: 165.5\n",
      "Episode: 48, Reward: 165.5\n",
      "Episode: 49, Reward: 165.5\n",
      "Episode: 50, Reward: 175.5\n",
      "Episode: 51, Reward: 175.5\n",
      "Episode: 52, Reward: 175.5\n",
      "Episode: 53, Reward: 135.0\n",
      "Episode: 54, Reward: 135.0\n",
      "Episode: 55, Reward: 135.0\n",
      "Episode: 56, Reward: 104.0\n",
      "Episode: 57, Reward: 104.0\n",
      "Episode: 58, Reward: 104.0\n",
      "Episode: 59, Reward: 96.5\n",
      "Episode: 60, Reward: 96.5\n",
      "Episode: 61, Reward: 96.5\n",
      "Episode: 62, Reward: 93.5\n",
      "Episode: 63, Reward: 93.5\n",
      "Episode: 64, Reward: 93.5\n",
      "Episode: 65, Reward: 84.5\n",
      "Episode: 66, Reward: 84.5\n",
      "Episode: 67, Reward: 84.5\n",
      "Episode: 68, Reward: 84.5\n",
      "Episode: 69, Reward: 102.5\n",
      "Episode: 70, Reward: 102.5\n",
      "Episode: 71, Reward: 102.5\n",
      "Episode: 72, Reward: 102.5\n",
      "Episode: 73, Reward: 102.5\n",
      "Episode: 74, Reward: 102.5\n",
      "Episode: 75, Reward: 116.0\n",
      "Episode: 76, Reward: 116.0\n",
      "Episode: 77, Reward: 104.5\n",
      "Episode: 78, Reward: 104.5\n",
      "Episode: 79, Reward: 71.0\n",
      "Episode: 80, Reward: 71.0\n",
      "Episode: 81, Reward: 71.0\n",
      "Episode: 82, Reward: 88.0\n",
      "Episode: 83, Reward: 88.0\n",
      "Episode: 84, Reward: 88.0\n",
      "Episode: 85, Reward: 97.5\n",
      "Episode: 86, Reward: 97.5\n",
      "Episode: 87, Reward: 97.5\n",
      "Episode: 88, Reward: 97.5\n",
      "Episode: 89, Reward: 97.5\n",
      "Episode: 90, Reward: 97.5\n",
      "Episode: 91, Reward: 151.5\n",
      "Episode: 92, Reward: 151.5\n",
      "Episode: 93, Reward: 151.5\n",
      "Episode: 94, Reward: 151.5\n",
      "Episode: 95, Reward: 151.5\n",
      "Episode: 96, Reward: 151.5\n",
      "Episode: 97, Reward: 151.5\n",
      "Episode: 98, Reward: 154.0\n",
      "Episode: 99, Reward: 154.0\n",
      "Episode: 100, Reward: 154.0\n",
      "Episode: 101, Reward: 142.0\n",
      "Episode: 102, Reward: 142.0\n",
      "Episode: 103, Reward: 142.0\n",
      "Episode: 104, Reward: 142.0\n",
      "Episode: 105, Reward: 113.5\n",
      "Episode: 106, Reward: 113.5\n",
      "Episode: 107, Reward: 113.5\n",
      "Episode: 108, Reward: 109.0\n",
      "Episode: 109, Reward: 109.0\n",
      "Episode: 110, Reward: 109.0\n",
      "Episode: 111, Reward: 109.0\n",
      "Episode: 112, Reward: 109.0\n",
      "Episode: 113, Reward: 109.0\n",
      "Episode: 114, Reward: 109.0\n",
      "Episode: 115, Reward: 109.0\n",
      "Episode: 116, Reward: 109.0\n",
      "Episode: 117, Reward: 109.0\n",
      "Episode: 118, Reward: 109.0\n",
      "Episode: 119, Reward: 83.0\n",
      "Episode: 120, Reward: 83.0\n",
      "Episode: 121, Reward: 79.5\n",
      "Episode: 122, Reward: 79.5\n",
      "Episode: 123, Reward: 25.5\n",
      "Episode: 124, Reward: 25.5\n",
      "Episode: 125, Reward: 25.5\n",
      "Episode: 126, Reward: 25.5\n",
      "Episode: 127, Reward: 23.0\n",
      "Episode: 128, Reward: 23.0\n",
      "Episode: 129, Reward: 23.0\n",
      "Episode: 130, Reward: 23.0\n",
      "Episode: 131, Reward: 23.0\n",
      "Episode: 132, Reward: 23.0\n",
      "Episode: 133, Reward: 9.5\n",
      "Episode: 134, Reward: 9.5\n",
      "Episode: 135, Reward: 21.5\n",
      "Episode: 136, Reward: 21.5\n",
      "Episode: 137, Reward: 21.5\n",
      "Episode: 138, Reward: 21.5\n",
      "Episode: 139, Reward: 50.0\n",
      "Episode: 140, Reward: 50.0\n",
      "Episode: 141, Reward: 50.0\n",
      "Episode: 142, Reward: 65.5\n",
      "Episode: 143, Reward: 65.5\n",
      "Episode: 144, Reward: 65.5\n",
      "Episode: 145, Reward: 65.5\n",
      "Episode: 146, Reward: 87.0\n",
      "Episode: 147, Reward: 87.0\n",
      "Episode: 148, Reward: 87.0\n",
      "Episode: 149, Reward: 87.0\n",
      "Episode: 150, Reward: 115.5\n",
      "Episode: 151, Reward: 115.5\n",
      "Episode: 152, Reward: 115.5\n",
      "Episode: 153, Reward: 131.0\n",
      "Episode: 154, Reward: 131.0\n",
      "Episode: 155, Reward: 131.0\n",
      "Episode: 156, Reward: 131.0\n",
      "Episode: 157, Reward: 131.0\n",
      "Episode: 158, Reward: 131.0\n",
      "Episode: 159, Reward: 131.0\n",
      "Episode: 160, Reward: 132.5\n",
      "Episode: 161, Reward: 132.5\n",
      "Episode: 162, Reward: 132.5\n",
      "Episode: 163, Reward: 161.0\n",
      "Episode: 164, Reward: 161.0\n",
      "Episode: 165, Reward: 161.0\n",
      "Episode: 166, Reward: 161.0\n",
      "Episode: 167, Reward: 189.5\n",
      "Episode: 168, Reward: 189.5\n",
      "Episode: 169, Reward: 189.5\n",
      "Episode: 170, Reward: 189.5\n",
      "Episode: 171, Reward: 206.0\n",
      "Episode: 172, Reward: 206.0\n",
      "Episode: 173, Reward: 206.0\n",
      "Episode: 174, Reward: 177.5\n",
      "Episode: 175, Reward: 177.5\n",
      "Episode: 176, Reward: 177.5\n",
      "Episode: 177, Reward: 177.5\n",
      "Episode: 178, Reward: 159.5\n",
      "Episode: 179, Reward: 159.5\n",
      "Episode: 180, Reward: 159.5\n",
      "Episode: 181, Reward: 131.0\n",
      "Episode: 182, Reward: 131.0\n",
      "Episode: 183, Reward: 131.0\n",
      "Episode: 184, Reward: 131.0\n",
      "Episode: 185, Reward: 102.5\n",
      "Episode: 186, Reward: 102.5\n",
      "Episode: 187, Reward: 102.5\n",
      "Episode: 188, Reward: 87.0\n",
      "Episode: 189, Reward: 87.0\n",
      "Episode: 190, Reward: 87.0\n",
      "Episode: 191, Reward: 87.0\n",
      "Episode: 192, Reward: 87.0\n",
      "Episode: 193, Reward: 85.5\n",
      "Episode: 194, Reward: 85.5\n",
      "Episode: 195, Reward: 57.0\n",
      "Episode: 196, Reward: 57.0\n",
      "Episode: 197, Reward: 57.0\n",
      "Episode: 198, Reward: 41.5\n",
      "Episode: 199, Reward: 41.5\n",
      "END - Date-Time: 2023-08-21 07:24:51\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[0, 4, 14, 16, 19, 24, 28, 30, 34, 46, 51, 55, 66, 69, 83, 89, 105, 111, 112, 113, 118, 119, 122, 126, 135, 143, 149, 150, 152, 163, 164, 171, 173, 175, 179, 180, 183, 186, 193, 198]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_SPACEINVADERS-V5 EXPERIMENT 5: Date-Time: 2023-08-21 07:25:11, Capacity: 5k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 5000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 410.0\n",
      "Episode: 4, Reward: 410.0\n",
      "Episode: 5, Reward: 272.5\n",
      "Episode: 6, Reward: 272.5\n",
      "Episode: 7, Reward: 272.5\n",
      "Episode: 8, Reward: 240.0\n",
      "Episode: 9, Reward: 240.0\n",
      "Episode: 10, Reward: 240.0\n",
      "Episode: 11, Reward: 210.0\n",
      "Episode: 12, Reward: 210.0\n",
      "Episode: 13, Reward: 210.0\n",
      "Episode: 14, Reward: 210.0\n",
      "Episode: 15, Reward: 178.0\n",
      "Episode: 16, Reward: 178.0\n",
      "Episode: 17, Reward: 178.0\n",
      "Episode: 18, Reward: 160.83\n",
      "Episode: 19, Reward: 160.83\n",
      "Episode: 20, Reward: 160.83\n",
      "Episode: 21, Reward: 160.83\n",
      "Episode: 22, Reward: 160.83\n",
      "Episode: 23, Reward: 152.86\n",
      "Episode: 24, Reward: 152.86\n",
      "Episode: 25, Reward: 152.86\n",
      "Episode: 26, Reward: 149.38\n",
      "Episode: 27, Reward: 149.38\n",
      "Episode: 28, Reward: 144.44\n",
      "Episode: 29, Reward: 144.44\n",
      "Episode: 30, Reward: 144.44\n",
      "Episode: 31, Reward: 144.44\n",
      "Episode: 32, Reward: 148.0\n",
      "Episode: 33, Reward: 148.0\n",
      "Episode: 34, Reward: 130.5\n",
      "Episode: 35, Reward: 130.5\n",
      "Episode: 36, Reward: 130.5\n",
      "Episode: 37, Reward: 130.5\n",
      "Episode: 38, Reward: 152.0\n",
      "Episode: 39, Reward: 152.0\n",
      "Episode: 40, Reward: 152.0\n",
      "Episode: 41, Reward: 145.0\n",
      "Episode: 42, Reward: 145.0\n",
      "Episode: 43, Reward: 145.0\n",
      "Episode: 44, Reward: 145.0\n",
      "Episode: 45, Reward: 142.0\n",
      "Episode: 46, Reward: 142.0\n",
      "Episode: 47, Reward: 147.5\n",
      "Episode: 48, Reward: 147.5\n",
      "Episode: 49, Reward: 147.5\n",
      "Episode: 50, Reward: 140.0\n",
      "Episode: 51, Reward: 140.0\n",
      "Episode: 52, Reward: 140.0\n",
      "Episode: 53, Reward: 129.5\n",
      "Episode: 54, Reward: 129.5\n",
      "Episode: 55, Reward: 117.0\n",
      "Episode: 56, Reward: 117.0\n",
      "Episode: 57, Reward: 117.5\n",
      "Episode: 58, Reward: 117.5\n",
      "Episode: 59, Reward: 117.5\n",
      "Episode: 60, Reward: 126.5\n",
      "Episode: 61, Reward: 126.5\n",
      "Episode: 62, Reward: 126.5\n",
      "Episode: 63, Reward: 125.5\n",
      "Episode: 64, Reward: 125.5\n",
      "Episode: 65, Reward: 125.5\n",
      "Episode: 66, Reward: 125.5\n",
      "Episode: 67, Reward: 101.0\n",
      "Episode: 68, Reward: 101.0\n",
      "Episode: 69, Reward: 101.0\n",
      "Episode: 70, Reward: 101.0\n",
      "Episode: 71, Reward: 122.5\n",
      "Episode: 72, Reward: 122.5\n",
      "Episode: 73, Reward: 122.5\n",
      "Episode: 74, Reward: 137.0\n",
      "Episode: 75, Reward: 137.0\n",
      "Episode: 76, Reward: 137.0\n",
      "Episode: 77, Reward: 155.0\n",
      "Episode: 78, Reward: 155.0\n",
      "Episode: 79, Reward: 155.0\n",
      "Episode: 80, Reward: 155.0\n",
      "Episode: 81, Reward: 183.5\n",
      "Episode: 82, Reward: 183.5\n",
      "Episode: 83, Reward: 183.5\n",
      "Episode: 84, Reward: 183.5\n",
      "Episode: 85, Reward: 183.5\n",
      "Episode: 86, Reward: 194.0\n",
      "Episode: 87, Reward: 194.0\n",
      "Episode: 88, Reward: 194.0\n",
      "Episode: 89, Reward: 194.0\n",
      "Episode: 90, Reward: 194.0\n",
      "Episode: 91, Reward: 194.0\n",
      "Episode: 92, Reward: 194.0\n",
      "Episode: 93, Reward: 188.0\n",
      "Episode: 94, Reward: 188.0\n",
      "Episode: 95, Reward: 188.0\n",
      "Episode: 96, Reward: 188.0\n",
      "Episode: 97, Reward: 188.0\n",
      "Episode: 98, Reward: 182.5\n",
      "Episode: 99, Reward: 182.5\n",
      "Episode: 100, Reward: 187.0\n",
      "Episode: 101, Reward: 187.0\n",
      "Episode: 102, Reward: 187.0\n",
      "Episode: 103, Reward: 187.0\n",
      "Episode: 104, Reward: 188.5\n",
      "Episode: 105, Reward: 188.5\n",
      "Episode: 106, Reward: 188.5\n",
      "Episode: 107, Reward: 156.5\n",
      "Episode: 108, Reward: 156.5\n",
      "Episode: 109, Reward: 156.5\n",
      "Episode: 110, Reward: 156.5\n",
      "Episode: 111, Reward: 155.0\n",
      "Episode: 112, Reward: 155.0\n",
      "Episode: 113, Reward: 155.0\n",
      "Episode: 114, Reward: 155.0\n",
      "Episode: 115, Reward: 155.0\n",
      "Episode: 116, Reward: 155.0\n",
      "Episode: 117, Reward: 155.0\n",
      "Episode: 118, Reward: 137.0\n",
      "Episode: 119, Reward: 137.0\n",
      "Episode: 120, Reward: 137.0\n",
      "Episode: 121, Reward: 126.5\n",
      "Episode: 122, Reward: 126.5\n",
      "Episode: 123, Reward: 126.5\n",
      "Episode: 124, Reward: 126.5\n",
      "Episode: 125, Reward: 126.5\n",
      "Episode: 126, Reward: 126.5\n",
      "Episode: 127, Reward: 150.0\n",
      "Episode: 128, Reward: 150.0\n",
      "Episode: 129, Reward: 150.0\n",
      "Episode: 130, Reward: 150.0\n",
      "Episode: 131, Reward: 140.5\n",
      "Episode: 132, Reward: 140.5\n",
      "Episode: 133, Reward: 140.5\n",
      "Episode: 134, Reward: 113.5\n",
      "Episode: 135, Reward: 113.5\n",
      "Episode: 136, Reward: 113.5\n",
      "Episode: 137, Reward: 113.5\n",
      "Episode: 138, Reward: 101.5\n",
      "Episode: 139, Reward: 101.5\n",
      "Episode: 140, Reward: 101.5\n",
      "Episode: 141, Reward: 101.5\n",
      "Episode: 142, Reward: 101.5\n",
      "Episode: 143, Reward: 101.5\n",
      "Episode: 144, Reward: 101.5\n",
      "Episode: 145, Reward: 79.5\n",
      "Episode: 146, Reward: 79.5\n",
      "Episode: 147, Reward: 51.0\n",
      "Episode: 148, Reward: 51.0\n",
      "Episode: 149, Reward: 40.5\n",
      "Episode: 150, Reward: 40.5\n",
      "Episode: 151, Reward: 40.5\n",
      "Episode: 152, Reward: 40.5\n",
      "Episode: 153, Reward: 40.5\n",
      "Episode: 154, Reward: 69.0\n",
      "Episode: 155, Reward: 69.0\n",
      "Episode: 156, Reward: 69.0\n",
      "Episode: 157, Reward: 69.0\n",
      "Episode: 158, Reward: 69.0\n",
      "Episode: 159, Reward: 76.5\n",
      "Episode: 160, Reward: 76.5\n",
      "Episode: 161, Reward: 76.5\n",
      "Episode: 162, Reward: 91.5\n",
      "Episode: 163, Reward: 91.5\n",
      "Episode: 164, Reward: 91.5\n",
      "Episode: 165, Reward: 91.5\n",
      "Episode: 166, Reward: 91.5\n",
      "Episode: 167, Reward: 91.5\n",
      "Episode: 168, Reward: 123.5\n",
      "Episode: 169, Reward: 123.5\n",
      "Episode: 170, Reward: 123.5\n",
      "Episode: 171, Reward: 177.5\n",
      "Episode: 172, Reward: 177.5\n",
      "Episode: 173, Reward: 177.5\n",
      "Episode: 174, Reward: 177.5\n",
      "Episode: 175, Reward: 177.5\n",
      "Episode: 176, Reward: 177.5\n",
      "Episode: 177, Reward: 177.5\n",
      "Episode: 178, Reward: 177.5\n",
      "Episode: 179, Reward: 177.5\n",
      "Episode: 180, Reward: 177.5\n",
      "Episode: 181, Reward: 177.5\n",
      "Episode: 182, Reward: 177.5\n",
      "Episode: 183, Reward: 177.5\n",
      "Episode: 184, Reward: 177.5\n",
      "Episode: 185, Reward: 177.5\n",
      "Episode: 186, Reward: 177.5\n",
      "Episode: 187, Reward: 177.5\n",
      "Episode: 188, Reward: 177.5\n",
      "Episode: 189, Reward: 177.5\n",
      "Episode: 190, Reward: 177.5\n",
      "Episode: 191, Reward: 230.5\n",
      "Episode: 192, Reward: 230.5\n",
      "Episode: 193, Reward: 212.5\n",
      "Episode: 194, Reward: 212.5\n",
      "Episode: 195, Reward: 212.5\n",
      "Episode: 196, Reward: 176.5\n",
      "Episode: 197, Reward: 176.5\n",
      "Episode: 198, Reward: 149.5\n",
      "Episode: 199, Reward: 149.5\n",
      "END - Date-Time: 2023-08-21 07:28:34\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[0, 12, 13, 17, 22, 23, 30, 44, 45, 60, 61, 66, 67, 72, 75, 80, 84, 87, 88, 110, 112, 114, 119, 122, 127, 139, 142, 149, 157, 161, 164, 165, 169, 171, 175, 185, 189, 192, 193, 197]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_SPACEINVADERS-V5 EXPERIMENT 6: Date-Time: 2023-08-21 07:28:55, Capacity: 1k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 1000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 50.0\n",
      "Episode: 2, Reward: 50.0\n",
      "Episode: 3, Reward: 80.0\n",
      "Episode: 4, Reward: 80.0\n",
      "Episode: 5, Reward: 93.33\n",
      "Episode: 6, Reward: 93.33\n",
      "Episode: 7, Reward: 93.33\n",
      "Episode: 8, Reward: 91.25\n",
      "Episode: 9, Reward: 91.25\n",
      "Episode: 10, Reward: 91.25\n",
      "Episode: 11, Reward: 104.0\n",
      "Episode: 12, Reward: 104.0\n",
      "Episode: 13, Reward: 104.0\n",
      "Episode: 14, Reward: 121.67\n",
      "Episode: 15, Reward: 121.67\n",
      "Episode: 16, Reward: 121.67\n",
      "Episode: 17, Reward: 113.57\n",
      "Episode: 18, Reward: 113.57\n",
      "Episode: 19, Reward: 108.75\n",
      "Episode: 20, Reward: 108.75\n",
      "Episode: 21, Reward: 108.75\n",
      "Episode: 22, Reward: 108.75\n",
      "Episode: 23, Reward: 146.11\n",
      "Episode: 24, Reward: 146.11\n",
      "Episode: 25, Reward: 146.11\n",
      "Episode: 26, Reward: 131.5\n",
      "Episode: 27, Reward: 131.5\n",
      "Episode: 28, Reward: 131.5\n",
      "Episode: 29, Reward: 131.5\n",
      "Episode: 30, Reward: 126.5\n",
      "Episode: 31, Reward: 126.5\n",
      "Episode: 32, Reward: 126.5\n",
      "Episode: 33, Reward: 115.5\n",
      "Episode: 34, Reward: 115.5\n",
      "Episode: 35, Reward: 115.5\n",
      "Episode: 36, Reward: 115.5\n",
      "Episode: 37, Reward: 104.0\n",
      "Episode: 38, Reward: 104.0\n",
      "Episode: 39, Reward: 104.0\n",
      "Episode: 40, Reward: 96.0\n",
      "Episode: 41, Reward: 96.0\n",
      "Episode: 42, Reward: 96.0\n",
      "Episode: 43, Reward: 88.0\n",
      "Episode: 44, Reward: 88.0\n",
      "Episode: 45, Reward: 88.0\n",
      "Episode: 46, Reward: 93.0\n",
      "Episode: 47, Reward: 93.0\n",
      "Episode: 48, Reward: 93.0\n",
      "Episode: 49, Reward: 93.0\n",
      "Episode: 50, Reward: 104.5\n",
      "Episode: 51, Reward: 104.5\n",
      "Episode: 52, Reward: 104.5\n",
      "Episode: 53, Reward: 123.0\n",
      "Episode: 54, Reward: 123.0\n",
      "Episode: 55, Reward: 123.0\n",
      "Episode: 56, Reward: 123.0\n",
      "Episode: 57, Reward: 99.5\n",
      "Episode: 58, Reward: 99.5\n",
      "Episode: 59, Reward: 99.5\n",
      "Episode: 60, Reward: 115.0\n",
      "Episode: 61, Reward: 115.0\n",
      "Episode: 62, Reward: 115.0\n",
      "Episode: 63, Reward: 115.0\n",
      "Episode: 64, Reward: 115.0\n",
      "Episode: 65, Reward: 174.0\n",
      "Episode: 66, Reward: 174.0\n",
      "Episode: 67, Reward: 174.0\n",
      "Episode: 68, Reward: 174.0\n",
      "Episode: 69, Reward: 207.5\n",
      "Episode: 70, Reward: 207.5\n",
      "Episode: 71, Reward: 207.5\n",
      "Episode: 72, Reward: 225.0\n",
      "Episode: 73, Reward: 225.0\n",
      "Episode: 74, Reward: 225.0\n",
      "Episode: 75, Reward: 242.5\n",
      "Episode: 76, Reward: 242.5\n",
      "Episode: 77, Reward: 242.5\n",
      "Episode: 78, Reward: 242.5\n",
      "Episode: 79, Reward: 263.5\n",
      "Episode: 80, Reward: 263.5\n",
      "Episode: 81, Reward: 263.5\n",
      "Episode: 82, Reward: 263.5\n",
      "Episode: 83, Reward: 266.0\n",
      "Episode: 84, Reward: 266.0\n",
      "Episode: 85, Reward: 266.0\n",
      "Episode: 86, Reward: 276.5\n",
      "Episode: 87, Reward: 276.5\n",
      "Episode: 88, Reward: 276.5\n",
      "Episode: 89, Reward: 276.5\n",
      "Episode: 90, Reward: 279.0\n",
      "Episode: 91, Reward: 279.0\n",
      "Episode: 92, Reward: 279.0\n",
      "Episode: 93, Reward: 286.5\n",
      "Episode: 94, Reward: 286.5\n",
      "Episode: 95, Reward: 286.5\n",
      "Episode: 96, Reward: 286.5\n",
      "Episode: 97, Reward: 299.5\n",
      "Episode: 98, Reward: 299.5\n",
      "Episode: 99, Reward: 299.5\n",
      "Episode: 100, Reward: 299.5\n",
      "Episode: 101, Reward: 269.0\n",
      "Episode: 102, Reward: 269.0\n",
      "Episode: 103, Reward: 269.0\n",
      "Episode: 104, Reward: 264.0\n",
      "Episode: 105, Reward: 264.0\n",
      "Episode: 106, Reward: 264.0\n",
      "Episode: 107, Reward: 264.0\n",
      "Episode: 108, Reward: 274.5\n",
      "Episode: 109, Reward: 274.5\n",
      "Episode: 110, Reward: 274.5\n",
      "Episode: 111, Reward: 274.5\n",
      "Episode: 112, Reward: 285.0\n",
      "Episode: 113, Reward: 285.0\n",
      "Episode: 114, Reward: 285.0\n",
      "Episode: 115, Reward: 274.5\n",
      "Episode: 116, Reward: 274.5\n",
      "Episode: 117, Reward: 274.5\n",
      "Episode: 118, Reward: 264.0\n",
      "Episode: 119, Reward: 264.0\n",
      "Episode: 120, Reward: 240.0\n",
      "Episode: 121, Reward: 240.0\n",
      "Episode: 122, Reward: 240.0\n",
      "Episode: 123, Reward: 241.5\n",
      "Episode: 124, Reward: 241.5\n",
      "Episode: 125, Reward: 241.5\n",
      "Episode: 126, Reward: 241.5\n",
      "Episode: 127, Reward: 246.0\n",
      "Episode: 128, Reward: 246.0\n",
      "Episode: 129, Reward: 246.0\n",
      "Episode: 130, Reward: 238.5\n",
      "Episode: 131, Reward: 238.5\n",
      "Episode: 132, Reward: 238.5\n",
      "Episode: 133, Reward: 238.5\n",
      "Episode: 134, Reward: 226.0\n",
      "Episode: 135, Reward: 226.0\n",
      "Episode: 136, Reward: 207.0\n",
      "Episode: 137, Reward: 207.0\n",
      "Episode: 138, Reward: 207.0\n",
      "Episode: 139, Reward: 210.0\n",
      "Episode: 140, Reward: 210.0\n",
      "Episode: 141, Reward: 210.0\n",
      "Episode: 142, Reward: 197.0\n",
      "Episode: 143, Reward: 197.0\n",
      "Episode: 144, Reward: 197.0\n",
      "Episode: 145, Reward: 183.5\n",
      "Episode: 146, Reward: 183.5\n",
      "Episode: 147, Reward: 183.5\n",
      "Episode: 148, Reward: 191.5\n",
      "Episode: 149, Reward: 191.5\n",
      "Episode: 150, Reward: 191.5\n",
      "Episode: 151, Reward: 205.0\n",
      "Episode: 152, Reward: 205.0\n",
      "Episode: 153, Reward: 205.0\n",
      "Episode: 154, Reward: 182.0\n",
      "Episode: 155, Reward: 151.0\n",
      "Episode: 156, Reward: 151.0\n",
      "Episode: 157, Reward: 151.0\n",
      "Episode: 158, Reward: 151.0\n",
      "Episode: 159, Reward: 170.0\n",
      "Episode: 160, Reward: 170.0\n",
      "Episode: 161, Reward: 170.0\n",
      "Episode: 162, Reward: 186.0\n",
      "Episode: 163, Reward: 186.0\n",
      "Episode: 164, Reward: 186.0\n",
      "Episode: 165, Reward: 186.0\n",
      "Episode: 166, Reward: 192.5\n",
      "Episode: 167, Reward: 192.5\n",
      "Episode: 168, Reward: 168.5\n",
      "Episode: 169, Reward: 168.5\n",
      "Episode: 170, Reward: 168.5\n",
      "Episode: 171, Reward: 174.0\n",
      "Episode: 172, Reward: 174.0\n",
      "Episode: 173, Reward: 174.0\n",
      "Episode: 174, Reward: 195.5\n",
      "Episode: 175, Reward: 195.5\n",
      "Episode: 176, Reward: 195.5\n",
      "Episode: 177, Reward: 195.5\n",
      "Episode: 178, Reward: 187.5\n",
      "Episode: 179, Reward: 187.5\n",
      "Episode: 180, Reward: 172.5\n",
      "Episode: 181, Reward: 172.5\n",
      "Episode: 182, Reward: 172.5\n",
      "Episode: 183, Reward: 170.5\n",
      "Episode: 184, Reward: 170.5\n",
      "Episode: 185, Reward: 170.5\n",
      "Episode: 186, Reward: 204.0\n",
      "Episode: 187, Reward: 204.0\n",
      "Episode: 188, Reward: 204.0\n",
      "Episode: 189, Reward: 182.0\n",
      "Episode: 190, Reward: 182.0\n",
      "Episode: 191, Reward: 182.0\n",
      "Episode: 192, Reward: 182.0\n",
      "Episode: 193, Reward: 171.0\n",
      "Episode: 194, Reward: 171.0\n",
      "Episode: 195, Reward: 171.0\n",
      "Episode: 196, Reward: 171.0\n",
      "Episode: 197, Reward: 171.0\n",
      "Episode: 198, Reward: 171.0\n",
      "Episode: 199, Reward: 181.5\n",
      "END - Date-Time: 2023-08-21 07:31:31\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[3, 6, 7, 8, 12, 13, 34, 37, 48, 56, 59, 69, 74, 78, 80, 82, 91, 107, 109, 112, 137, 142, 144, 145, 146, 147, 148, 150, 158, 159, 163, 167, 168, 170, 173, 178, 180, 184, 194, 198]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_SPACEINVADERS-V5 EXPERIMENT 7: Date-Time: 2023-08-21 07:31:51, Capacity: 500\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 500\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 110.0\n",
      "Episode: 3, Reward: 110.0\n",
      "Episode: 4, Reward: 110.0\n",
      "Episode: 5, Reward: 160.0\n",
      "Episode: 6, Reward: 160.0\n",
      "Episode: 7, Reward: 160.0\n",
      "Episode: 8, Reward: 153.33\n",
      "Episode: 9, Reward: 153.33\n",
      "Episode: 10, Reward: 142.5\n",
      "Episode: 11, Reward: 142.5\n",
      "Episode: 12, Reward: 142.5\n",
      "Episode: 13, Reward: 127.0\n",
      "Episode: 14, Reward: 127.0\n",
      "Episode: 15, Reward: 109.17\n",
      "Episode: 16, Reward: 109.17\n",
      "Episode: 17, Reward: 109.17\n",
      "Episode: 18, Reward: 109.17\n",
      "Episode: 19, Reward: 121.43\n",
      "Episode: 20, Reward: 121.43\n",
      "Episode: 21, Reward: 120.62\n",
      "Episode: 22, Reward: 120.62\n",
      "Episode: 23, Reward: 111.11\n",
      "Episode: 24, Reward: 111.11\n",
      "Episode: 25, Reward: 111.11\n",
      "Episode: 26, Reward: 111.11\n",
      "Episode: 27, Reward: 146.5\n",
      "Episode: 28, Reward: 146.5\n",
      "Episode: 29, Reward: 146.5\n",
      "Episode: 30, Reward: 146.5\n",
      "Episode: 31, Reward: 152.5\n",
      "Episode: 32, Reward: 152.5\n",
      "Episode: 33, Reward: 152.5\n",
      "Episode: 34, Reward: 152.5\n",
      "Episode: 35, Reward: 152.5\n",
      "Episode: 36, Reward: 152.5\n",
      "Episode: 37, Reward: 210.0\n",
      "Episode: 38, Reward: 210.0\n",
      "Episode: 39, Reward: 210.0\n",
      "Episode: 40, Reward: 210.0\n",
      "Episode: 41, Reward: 217.5\n",
      "Episode: 42, Reward: 217.5\n",
      "Episode: 43, Reward: 221.5\n",
      "Episode: 44, Reward: 221.5\n",
      "Episode: 45, Reward: 235.5\n",
      "Episode: 46, Reward: 235.5\n",
      "Episode: 47, Reward: 235.5\n",
      "Episode: 48, Reward: 235.5\n",
      "Episode: 49, Reward: 235.5\n",
      "Episode: 50, Reward: 274.0\n",
      "Episode: 51, Reward: 274.0\n",
      "Episode: 52, Reward: 274.0\n",
      "Episode: 53, Reward: 274.0\n",
      "Episode: 54, Reward: 296.0\n",
      "Episode: 55, Reward: 296.0\n",
      "Episode: 56, Reward: 300.5\n",
      "Episode: 57, Reward: 300.5\n",
      "Episode: 58, Reward: 300.5\n",
      "Episode: 59, Reward: 300.5\n",
      "Episode: 60, Reward: 300.5\n",
      "Episode: 61, Reward: 336.0\n",
      "Episode: 62, Reward: 336.0\n",
      "Episode: 63, Reward: 336.0\n",
      "Episode: 64, Reward: 320.0\n",
      "Episode: 65, Reward: 320.0\n",
      "Episode: 66, Reward: 320.0\n",
      "Episode: 67, Reward: 316.5\n",
      "Episode: 68, Reward: 316.5\n",
      "Episode: 69, Reward: 251.0\n",
      "Episode: 70, Reward: 251.0\n",
      "Episode: 71, Reward: 243.5\n",
      "Episode: 72, Reward: 243.5\n",
      "Episode: 73, Reward: 243.5\n",
      "Episode: 74, Reward: 255.0\n",
      "Episode: 75, Reward: 255.0\n",
      "Episode: 76, Reward: 255.0\n",
      "Episode: 77, Reward: 255.0\n",
      "Episode: 78, Reward: 261.5\n",
      "Episode: 79, Reward: 261.5\n",
      "Episode: 80, Reward: 261.5\n",
      "Episode: 81, Reward: 261.5\n",
      "Episode: 82, Reward: 242.0\n",
      "Episode: 83, Reward: 242.0\n",
      "Episode: 84, Reward: 242.0\n",
      "Episode: 85, Reward: 242.0\n",
      "Episode: 86, Reward: 242.0\n",
      "Episode: 87, Reward: 242.0\n",
      "Episode: 88, Reward: 242.0\n",
      "Episode: 89, Reward: 242.0\n",
      "Episode: 90, Reward: 264.5\n",
      "Episode: 91, Reward: 264.5\n",
      "Episode: 92, Reward: 264.5\n",
      "Episode: 93, Reward: 245.0\n",
      "Episode: 94, Reward: 245.0\n",
      "Episode: 95, Reward: 234.0\n",
      "Episode: 96, Reward: 234.0\n",
      "Episode: 97, Reward: 234.0\n",
      "Episode: 98, Reward: 252.5\n",
      "Episode: 99, Reward: 252.5\n",
      "Episode: 100, Reward: 252.5\n",
      "Episode: 101, Reward: 252.5\n",
      "Episode: 102, Reward: 302.0\n",
      "Episode: 103, Reward: 302.0\n",
      "Episode: 104, Reward: 304.0\n",
      "Episode: 105, Reward: 304.0\n",
      "Episode: 106, Reward: 304.0\n",
      "Episode: 107, Reward: 304.0\n",
      "Episode: 108, Reward: 304.0\n",
      "Episode: 109, Reward: 297.0\n",
      "Episode: 110, Reward: 297.0\n",
      "Episode: 111, Reward: 297.0\n",
      "Episode: 112, Reward: 294.5\n",
      "Episode: 113, Reward: 294.5\n",
      "Episode: 114, Reward: 294.5\n",
      "Episode: 115, Reward: 294.5\n",
      "Episode: 116, Reward: 294.5\n",
      "Episode: 117, Reward: 294.5\n",
      "Episode: 118, Reward: 294.5\n",
      "Episode: 119, Reward: 294.5\n",
      "Episode: 120, Reward: 289.5\n",
      "Episode: 121, Reward: 289.5\n",
      "Episode: 122, Reward: 255.0\n",
      "Episode: 123, Reward: 255.0\n",
      "Episode: 124, Reward: 242.0\n",
      "Episode: 125, Reward: 242.0\n",
      "Episode: 126, Reward: 230.5\n",
      "Episode: 127, Reward: 230.5\n",
      "Episode: 128, Reward: 209.5\n",
      "Episode: 129, Reward: 209.5\n",
      "Episode: 130, Reward: 209.5\n",
      "Episode: 131, Reward: 161.0\n",
      "Episode: 132, Reward: 161.0\n",
      "Episode: 133, Reward: 151.0\n",
      "Episode: 134, Reward: 151.0\n",
      "Episode: 135, Reward: 151.0\n",
      "Episode: 136, Reward: 151.0\n",
      "Episode: 137, Reward: 151.0\n",
      "Episode: 138, Reward: 151.0\n",
      "Episode: 139, Reward: 151.0\n",
      "Episode: 140, Reward: 164.5\n",
      "Episode: 141, Reward: 146.0\n",
      "Episode: 142, Reward: 146.0\n",
      "Episode: 143, Reward: 112.5\n",
      "Episode: 144, Reward: 112.5\n",
      "Episode: 145, Reward: 118.0\n",
      "Episode: 146, Reward: 118.0\n",
      "Episode: 147, Reward: 112.5\n",
      "Episode: 148, Reward: 108.0\n",
      "Episode: 149, Reward: 108.0\n",
      "Episode: 150, Reward: 108.0\n",
      "Episode: 151, Reward: 108.5\n",
      "Episode: 152, Reward: 108.5\n",
      "Episode: 153, Reward: 111.0\n",
      "Episode: 154, Reward: 111.0\n",
      "Episode: 155, Reward: 111.0\n",
      "Episode: 156, Reward: 116.0\n",
      "Episode: 157, Reward: 116.0\n",
      "Episode: 158, Reward: 116.0\n",
      "Episode: 159, Reward: 113.0\n",
      "Episode: 160, Reward: 113.0\n",
      "Episode: 161, Reward: 89.0\n",
      "Episode: 162, Reward: 87.5\n",
      "Episode: 163, Reward: 87.5\n",
      "Episode: 164, Reward: 87.5\n",
      "Episode: 165, Reward: 96.5\n",
      "Episode: 166, Reward: 96.5\n",
      "Episode: 167, Reward: 96.5\n",
      "Episode: 168, Reward: 98.0\n",
      "Episode: 169, Reward: 98.0\n",
      "Episode: 170, Reward: 108.0\n",
      "Episode: 171, Reward: 108.0\n",
      "Episode: 172, Reward: 108.0\n",
      "Episode: 173, Reward: 108.0\n",
      "Episode: 174, Reward: 150.5\n",
      "Episode: 175, Reward: 150.5\n",
      "Episode: 176, Reward: 148.5\n",
      "Episode: 177, Reward: 148.5\n",
      "Episode: 178, Reward: 148.5\n",
      "Episode: 179, Reward: 148.5\n",
      "Episode: 180, Reward: 145.0\n",
      "Episode: 181, Reward: 145.0\n",
      "Episode: 182, Reward: 144.5\n",
      "Episode: 183, Reward: 144.5\n",
      "Episode: 184, Reward: 143.0\n",
      "Episode: 185, Reward: 143.0\n",
      "Episode: 186, Reward: 132.0\n",
      "Episode: 187, Reward: 131.5\n",
      "Episode: 188, Reward: 131.5\n",
      "Episode: 189, Reward: 131.5\n",
      "Episode: 190, Reward: 134.5\n",
      "Episode: 191, Reward: 134.5\n",
      "Episode: 192, Reward: 130.0\n",
      "Episode: 193, Reward: 130.0\n",
      "Episode: 194, Reward: 127.5\n",
      "Episode: 195, Reward: 127.5\n",
      "Episode: 196, Reward: 98.5\n",
      "Episode: 197, Reward: 98.5\n",
      "Episode: 198, Reward: 96.5\n",
      "Episode: 199, Reward: 96.5\n",
      "END - Date-Time: 2023-08-21 07:34:20\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[3, 4, 18, 19, 27, 34, 45, 52, 67, 81, 85, 87, 94, 96, 100, 101, 105, 111, 114, 120, 125, 127, 143, 147, 148, 151, 152, 155, 156, 157, 158, 161, 165, 173, 180, 185, 189, 193, 195, 196]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "Saving rewards to csv\n",
      "Saving boxplot of results\n",
      "Average Accumulated Reward: 237180.0\n",
      "ALE_VENTURE-V5 EXPERIMENT 0: Date-Time: 2023-08-21 07:34:42, Capacity: 1M\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 1000000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 0.0\n",
      "Episode: 8, Reward: 0.0\n",
      "Episode: 9, Reward: 0.0\n",
      "Episode: 10, Reward: 0.0\n",
      "Episode: 11, Reward: 0.0\n",
      "Episode: 12, Reward: 0.0\n",
      "Episode: 13, Reward: 0.0\n",
      "Episode: 14, Reward: 0.0\n",
      "Episode: 15, Reward: 0.0\n",
      "Episode: 16, Reward: 0.0\n",
      "Episode: 17, Reward: 0.0\n",
      "Episode: 18, Reward: 0.0\n",
      "Episode: 19, Reward: 0.0\n",
      "Episode: 20, Reward: 0.0\n",
      "Episode: 21, Reward: 0.0\n",
      "Episode: 22, Reward: 0.0\n",
      "Episode: 23, Reward: 0.0\n",
      "Episode: 24, Reward: 0.0\n",
      "Episode: 25, Reward: 0.0\n",
      "Episode: 26, Reward: 0.0\n",
      "Episode: 27, Reward: 0.0\n",
      "Episode: 28, Reward: 0.0\n",
      "Episode: 29, Reward: 0.0\n",
      "Episode: 30, Reward: 0.0\n",
      "Episode: 31, Reward: 0.0\n",
      "Episode: 32, Reward: 0.0\n",
      "Episode: 33, Reward: 0.0\n",
      "Episode: 34, Reward: 0.0\n",
      "Episode: 35, Reward: 0.0\n",
      "Episode: 36, Reward: 0.0\n",
      "Episode: 37, Reward: 0.0\n",
      "Episode: 38, Reward: 0.0\n",
      "Episode: 39, Reward: 0.0\n",
      "Episode: 40, Reward: 0.0\n",
      "Episode: 41, Reward: 0.0\n",
      "Episode: 42, Reward: 0.0\n",
      "Episode: 43, Reward: 0.0\n",
      "Episode: 44, Reward: 0.0\n",
      "Episode: 45, Reward: 0.0\n",
      "Episode: 46, Reward: 0.0\n",
      "Episode: 47, Reward: 0.0\n",
      "Episode: 48, Reward: 0.0\n",
      "Episode: 49, Reward: 0.0\n",
      "Episode: 50, Reward: 0.0\n",
      "Episode: 51, Reward: 0.0\n",
      "Episode: 52, Reward: 0.0\n",
      "Episode: 53, Reward: 0.0\n",
      "Episode: 54, Reward: 0.0\n",
      "Episode: 55, Reward: 0.0\n",
      "Episode: 56, Reward: 0.0\n",
      "Episode: 57, Reward: 0.0\n",
      "Episode: 58, Reward: 0.0\n",
      "Episode: 59, Reward: 0.0\n",
      "Episode: 60, Reward: 0.0\n",
      "Episode: 61, Reward: 0.0\n",
      "Episode: 62, Reward: 0.0\n",
      "Episode: 63, Reward: 0.0\n",
      "Episode: 64, Reward: 0.0\n",
      "Episode: 65, Reward: 0.0\n",
      "Episode: 66, Reward: 0.0\n",
      "Episode: 67, Reward: 0.0\n",
      "Episode: 68, Reward: 0.0\n",
      "Episode: 69, Reward: 0.0\n",
      "Episode: 70, Reward: 0.0\n",
      "Episode: 71, Reward: 0.0\n",
      "Episode: 72, Reward: 0.0\n",
      "Episode: 73, Reward: 0.0\n",
      "Episode: 74, Reward: 0.0\n",
      "Episode: 75, Reward: 0.0\n",
      "Episode: 76, Reward: 0.0\n",
      "Episode: 77, Reward: 0.0\n",
      "Episode: 78, Reward: 0.0\n",
      "Episode: 79, Reward: 0.0\n",
      "Episode: 80, Reward: 0.0\n",
      "Episode: 81, Reward: 0.0\n",
      "Episode: 82, Reward: 0.0\n",
      "Episode: 83, Reward: 0.0\n",
      "Episode: 84, Reward: 0.0\n",
      "Episode: 85, Reward: 0.0\n",
      "Episode: 86, Reward: 0.0\n",
      "Episode: 87, Reward: 0.0\n",
      "Episode: 88, Reward: 0.0\n",
      "Episode: 89, Reward: 0.0\n",
      "Episode: 90, Reward: 0.0\n",
      "Episode: 91, Reward: 0.0\n",
      "Episode: 92, Reward: 0.0\n",
      "Episode: 93, Reward: 0.0\n",
      "Episode: 94, Reward: 0.0\n",
      "Episode: 95, Reward: 0.0\n",
      "Episode: 96, Reward: 0.0\n",
      "Episode: 97, Reward: 0.0\n",
      "Episode: 98, Reward: 0.0\n",
      "Episode: 99, Reward: 0.0\n",
      "Episode: 100, Reward: 0.0\n",
      "Episode: 101, Reward: 0.0\n",
      "Episode: 102, Reward: 0.0\n",
      "Episode: 103, Reward: 0.0\n",
      "Episode: 104, Reward: 0.0\n",
      "Episode: 105, Reward: 0.0\n",
      "Episode: 106, Reward: 0.0\n",
      "Episode: 107, Reward: 0.0\n",
      "Episode: 108, Reward: 0.0\n",
      "Episode: 109, Reward: 0.0\n",
      "Episode: 110, Reward: 0.0\n",
      "Episode: 111, Reward: 0.0\n",
      "Episode: 112, Reward: 0.0\n",
      "Episode: 113, Reward: 0.0\n",
      "Episode: 114, Reward: 0.0\n",
      "Episode: 115, Reward: 0.0\n",
      "Episode: 116, Reward: 0.0\n",
      "Episode: 117, Reward: 0.0\n",
      "Episode: 118, Reward: 0.0\n",
      "Episode: 119, Reward: 0.0\n",
      "Episode: 120, Reward: 0.0\n",
      "Episode: 121, Reward: 0.0\n",
      "Episode: 122, Reward: 0.0\n",
      "Episode: 123, Reward: 0.0\n",
      "Episode: 124, Reward: 0.0\n",
      "Episode: 125, Reward: 0.0\n",
      "Episode: 126, Reward: 0.0\n",
      "Episode: 127, Reward: 0.0\n",
      "Episode: 128, Reward: 0.0\n",
      "Episode: 129, Reward: 0.0\n",
      "Episode: 130, Reward: 0.0\n",
      "Episode: 131, Reward: 0.0\n",
      "Episode: 132, Reward: 0.0\n",
      "Episode: 133, Reward: 0.0\n",
      "Episode: 134, Reward: 0.0\n",
      "Episode: 135, Reward: 0.0\n",
      "Episode: 136, Reward: 0.0\n",
      "Episode: 137, Reward: 0.0\n",
      "Episode: 138, Reward: 0.0\n",
      "Episode: 139, Reward: 0.0\n",
      "Episode: 140, Reward: 0.0\n",
      "Episode: 141, Reward: 0.0\n",
      "Episode: 142, Reward: 0.0\n",
      "Episode: 143, Reward: 0.0\n",
      "Episode: 144, Reward: 0.0\n",
      "Episode: 145, Reward: 0.0\n",
      "Episode: 146, Reward: 0.0\n",
      "Episode: 147, Reward: 0.0\n",
      "Episode: 148, Reward: 0.0\n",
      "Episode: 149, Reward: 0.0\n",
      "Episode: 150, Reward: 0.0\n",
      "Episode: 151, Reward: 0.0\n",
      "Episode: 152, Reward: 0.0\n",
      "Episode: 153, Reward: 0.0\n",
      "Episode: 154, Reward: 0.0\n",
      "Episode: 155, Reward: 0.0\n",
      "Episode: 156, Reward: 0.0\n",
      "Episode: 157, Reward: 0.0\n",
      "Episode: 158, Reward: 0.0\n",
      "Episode: 159, Reward: 0.0\n",
      "Episode: 160, Reward: 0.0\n",
      "Episode: 161, Reward: 0.0\n",
      "Episode: 162, Reward: 0.0\n",
      "Episode: 163, Reward: 0.0\n",
      "Episode: 164, Reward: 0.0\n",
      "Episode: 165, Reward: 0.0\n",
      "Episode: 166, Reward: 0.0\n",
      "Episode: 167, Reward: 0.0\n",
      "Episode: 168, Reward: 0.0\n",
      "Episode: 169, Reward: 0.0\n",
      "Episode: 170, Reward: 0.0\n",
      "Episode: 171, Reward: 0.0\n",
      "Episode: 172, Reward: 0.0\n",
      "Episode: 173, Reward: 0.0\n",
      "Episode: 174, Reward: 0.0\n",
      "Episode: 175, Reward: 0.0\n",
      "Episode: 176, Reward: 0.0\n",
      "Episode: 177, Reward: 0.0\n",
      "Episode: 178, Reward: 0.0\n",
      "Episode: 179, Reward: 0.0\n",
      "Episode: 180, Reward: 0.0\n",
      "Episode: 181, Reward: 0.0\n",
      "Episode: 182, Reward: 0.0\n",
      "Episode: 183, Reward: 0.0\n",
      "Episode: 184, Reward: 0.0\n",
      "Episode: 185, Reward: 0.0\n",
      "Episode: 186, Reward: 0.0\n",
      "Episode: 187, Reward: 0.0\n",
      "Episode: 188, Reward: 0.0\n",
      "Episode: 189, Reward: 0.0\n",
      "Episode: 190, Reward: 0.0\n",
      "Episode: 191, Reward: 0.0\n",
      "Episode: 192, Reward: 0.0\n",
      "Episode: 193, Reward: 0.0\n",
      "Episode: 194, Reward: 0.0\n",
      "Episode: 195, Reward: 0.0\n",
      "Episode: 196, Reward: 0.0\n",
      "Episode: 197, Reward: 0.0\n",
      "Episode: 198, Reward: 0.0\n",
      "Episode: 199, Reward: 0.0\n",
      "END - Date-Time: 2023-08-21 07:42:28\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[15, 17, 28, 31, 44, 52, 63, 67, 72, 76, 80, 82, 83, 90, 103, 104, 106, 107, 115, 119, 120, 124, 125, 126, 127, 131, 147, 148, 156, 158, 165, 178, 180, 182, 188, 193, 196, 197, 198, 199]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_VENTURE-V5 EXPERIMENT 1: Date-Time: 2023-08-21 07:42:54, Capacity: 500k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 500000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 0.0\n",
      "Episode: 8, Reward: 0.0\n",
      "Episode: 9, Reward: 0.0\n",
      "Episode: 10, Reward: 0.0\n",
      "Episode: 11, Reward: 0.0\n",
      "Episode: 12, Reward: 0.0\n",
      "Episode: 13, Reward: 0.0\n",
      "Episode: 14, Reward: 0.0\n",
      "Episode: 15, Reward: 0.0\n",
      "Episode: 16, Reward: 0.0\n",
      "Episode: 17, Reward: 0.0\n",
      "Episode: 18, Reward: 0.0\n",
      "Episode: 19, Reward: 0.0\n",
      "Episode: 20, Reward: 0.0\n",
      "Episode: 21, Reward: 0.0\n",
      "Episode: 22, Reward: 0.0\n",
      "Episode: 23, Reward: 0.0\n",
      "Episode: 24, Reward: 0.0\n",
      "Episode: 25, Reward: 0.0\n",
      "Episode: 26, Reward: 0.0\n",
      "Episode: 27, Reward: 0.0\n",
      "Episode: 28, Reward: 0.0\n",
      "Episode: 29, Reward: 0.0\n",
      "Episode: 30, Reward: 0.0\n",
      "Episode: 31, Reward: 0.0\n",
      "Episode: 32, Reward: 0.0\n",
      "Episode: 33, Reward: 0.0\n",
      "Episode: 34, Reward: 0.0\n",
      "Episode: 35, Reward: 0.0\n",
      "Episode: 36, Reward: 0.0\n",
      "Episode: 37, Reward: 0.0\n",
      "Episode: 38, Reward: 0.0\n",
      "Episode: 39, Reward: 0.0\n",
      "Episode: 40, Reward: 0.0\n",
      "Episode: 41, Reward: 0.0\n",
      "Episode: 42, Reward: 0.0\n",
      "Episode: 43, Reward: 0.0\n",
      "Episode: 44, Reward: 0.0\n",
      "Episode: 45, Reward: 0.0\n",
      "Episode: 46, Reward: 0.0\n",
      "Episode: 47, Reward: 0.0\n",
      "Episode: 48, Reward: 0.0\n",
      "Episode: 49, Reward: 0.0\n",
      "Episode: 50, Reward: 0.0\n",
      "Episode: 51, Reward: 0.0\n",
      "Episode: 52, Reward: 0.0\n",
      "Episode: 53, Reward: 0.0\n",
      "Episode: 54, Reward: 0.0\n",
      "Episode: 55, Reward: 0.0\n",
      "Episode: 56, Reward: 0.0\n",
      "Episode: 57, Reward: 0.0\n",
      "Episode: 58, Reward: 0.0\n",
      "Episode: 59, Reward: 0.0\n",
      "Episode: 60, Reward: 0.0\n",
      "Episode: 61, Reward: 0.0\n",
      "Episode: 62, Reward: 0.0\n",
      "Episode: 63, Reward: 0.0\n",
      "Episode: 64, Reward: 0.0\n",
      "Episode: 65, Reward: 0.0\n",
      "Episode: 66, Reward: 0.0\n",
      "Episode: 67, Reward: 0.0\n",
      "Episode: 68, Reward: 0.0\n",
      "Episode: 69, Reward: 0.0\n",
      "Episode: 70, Reward: 0.0\n",
      "Episode: 71, Reward: 0.0\n",
      "Episode: 72, Reward: 0.0\n",
      "Episode: 73, Reward: 0.0\n",
      "Episode: 74, Reward: 0.0\n",
      "Episode: 75, Reward: 0.0\n",
      "Episode: 76, Reward: 0.0\n",
      "Episode: 77, Reward: 0.0\n",
      "Episode: 78, Reward: 0.0\n",
      "Episode: 79, Reward: 0.0\n",
      "Episode: 80, Reward: 0.0\n",
      "Episode: 81, Reward: 0.0\n",
      "Episode: 82, Reward: 0.0\n",
      "Episode: 83, Reward: 0.0\n",
      "Episode: 84, Reward: 0.0\n",
      "Episode: 85, Reward: 0.0\n",
      "Episode: 86, Reward: 0.0\n",
      "Episode: 87, Reward: 0.0\n",
      "Episode: 88, Reward: 0.0\n",
      "Episode: 89, Reward: 0.0\n",
      "Episode: 90, Reward: 0.0\n",
      "Episode: 91, Reward: 0.0\n",
      "Episode: 92, Reward: 0.0\n",
      "Episode: 93, Reward: 0.0\n",
      "Episode: 94, Reward: 0.0\n",
      "Episode: 95, Reward: 0.0\n",
      "Episode: 96, Reward: 0.0\n",
      "Episode: 97, Reward: 0.0\n",
      "Episode: 98, Reward: 0.0\n",
      "Episode: 99, Reward: 0.0\n",
      "Episode: 100, Reward: 0.0\n",
      "Episode: 101, Reward: 0.0\n",
      "Episode: 102, Reward: 0.0\n",
      "Episode: 103, Reward: 0.0\n",
      "Episode: 104, Reward: 0.0\n",
      "Episode: 105, Reward: 0.0\n",
      "Episode: 106, Reward: 0.0\n",
      "Episode: 107, Reward: 0.0\n",
      "Episode: 108, Reward: 0.0\n",
      "Episode: 109, Reward: 0.0\n",
      "Episode: 110, Reward: 0.0\n",
      "Episode: 111, Reward: 0.0\n",
      "Episode: 112, Reward: 0.0\n",
      "Episode: 113, Reward: 0.0\n",
      "Episode: 114, Reward: 0.0\n",
      "Episode: 115, Reward: 0.0\n",
      "Episode: 116, Reward: 0.0\n",
      "Episode: 117, Reward: 0.0\n",
      "Episode: 118, Reward: 0.0\n",
      "Episode: 119, Reward: 0.0\n",
      "Episode: 120, Reward: 0.0\n",
      "Episode: 121, Reward: 0.0\n",
      "Episode: 122, Reward: 0.0\n",
      "Episode: 123, Reward: 0.0\n",
      "Episode: 124, Reward: 0.0\n",
      "Episode: 125, Reward: 0.0\n",
      "Episode: 126, Reward: 0.0\n",
      "Episode: 127, Reward: 0.0\n",
      "Episode: 128, Reward: 0.0\n",
      "Episode: 129, Reward: 0.0\n",
      "Episode: 130, Reward: 0.0\n",
      "Episode: 131, Reward: 0.0\n",
      "Episode: 132, Reward: 0.0\n",
      "Episode: 133, Reward: 0.0\n",
      "Episode: 134, Reward: 0.0\n",
      "Episode: 135, Reward: 0.0\n",
      "Episode: 136, Reward: 0.0\n",
      "Episode: 137, Reward: 0.0\n",
      "Episode: 138, Reward: 0.0\n",
      "Episode: 139, Reward: 0.0\n",
      "Episode: 140, Reward: 0.0\n",
      "Episode: 141, Reward: 0.0\n",
      "Episode: 142, Reward: 0.0\n",
      "Episode: 143, Reward: 0.0\n",
      "Episode: 144, Reward: 0.0\n",
      "Episode: 145, Reward: 0.0\n",
      "Episode: 146, Reward: 0.0\n",
      "Episode: 147, Reward: 0.0\n",
      "Episode: 148, Reward: 0.0\n",
      "Episode: 149, Reward: 0.0\n",
      "Episode: 150, Reward: 0.0\n",
      "Episode: 151, Reward: 0.0\n",
      "Episode: 152, Reward: 0.0\n",
      "Episode: 153, Reward: 0.0\n",
      "Episode: 154, Reward: 0.0\n",
      "Episode: 155, Reward: 0.0\n",
      "Episode: 156, Reward: 0.0\n",
      "Episode: 157, Reward: 0.0\n",
      "Episode: 158, Reward: 0.0\n",
      "Episode: 159, Reward: 0.0\n",
      "Episode: 160, Reward: 0.0\n",
      "Episode: 161, Reward: 0.0\n",
      "Episode: 162, Reward: 0.0\n",
      "Episode: 163, Reward: 0.0\n",
      "Episode: 164, Reward: 0.0\n",
      "Episode: 165, Reward: 0.0\n",
      "Episode: 166, Reward: 0.0\n",
      "Episode: 167, Reward: 0.0\n",
      "Episode: 168, Reward: 0.0\n",
      "Episode: 169, Reward: 0.0\n",
      "Episode: 170, Reward: 0.0\n",
      "Episode: 171, Reward: 0.0\n",
      "Episode: 172, Reward: 0.0\n",
      "Episode: 173, Reward: 0.0\n",
      "Episode: 174, Reward: 0.0\n",
      "Episode: 175, Reward: 0.0\n",
      "Episode: 176, Reward: 0.0\n",
      "Episode: 177, Reward: 0.0\n",
      "Episode: 178, Reward: 0.0\n",
      "Episode: 179, Reward: 0.0\n",
      "Episode: 180, Reward: 0.0\n",
      "Episode: 181, Reward: 0.0\n",
      "Episode: 182, Reward: 0.0\n",
      "Episode: 183, Reward: 0.0\n",
      "Episode: 184, Reward: 0.0\n",
      "Episode: 185, Reward: 0.0\n",
      "Episode: 186, Reward: 0.0\n",
      "Episode: 187, Reward: 0.0\n",
      "Episode: 188, Reward: 0.0\n",
      "Episode: 189, Reward: 0.0\n",
      "Episode: 190, Reward: 0.0\n",
      "Episode: 191, Reward: 0.0\n",
      "Episode: 192, Reward: 0.0\n",
      "Episode: 193, Reward: 0.0\n",
      "Episode: 194, Reward: 0.0\n",
      "Episode: 195, Reward: 0.0\n",
      "Episode: 196, Reward: 0.0\n",
      "Episode: 197, Reward: 0.0\n",
      "Episode: 198, Reward: 0.0\n",
      "Episode: 199, Reward: 0.0\n",
      "END - Date-Time: 2023-08-21 07:51:15\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[2, 5, 15, 16, 17, 21, 22, 33, 39, 45, 54, 59, 72, 74, 75, 78, 83, 84, 85, 86, 101, 103, 107, 116, 128, 131, 134, 139, 140, 143, 144, 146, 150, 170, 174, 185, 189, 194, 196, 198]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_VENTURE-V5 EXPERIMENT 2: Date-Time: 2023-08-21 07:51:41, Capacity: 100k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 100000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 0.0\n",
      "Episode: 8, Reward: 0.0\n",
      "Episode: 9, Reward: 0.0\n",
      "Episode: 10, Reward: 0.0\n",
      "Episode: 11, Reward: 0.0\n",
      "Episode: 12, Reward: 0.0\n",
      "Episode: 13, Reward: 0.0\n",
      "Episode: 14, Reward: 0.0\n",
      "Episode: 15, Reward: 0.0\n",
      "Episode: 16, Reward: 0.0\n",
      "Episode: 17, Reward: 0.0\n",
      "Episode: 18, Reward: 0.0\n",
      "Episode: 19, Reward: 0.0\n",
      "Episode: 20, Reward: 0.0\n",
      "Episode: 21, Reward: 0.0\n",
      "Episode: 22, Reward: 0.0\n",
      "Episode: 23, Reward: 0.0\n",
      "Episode: 24, Reward: 0.0\n",
      "Episode: 25, Reward: 0.0\n",
      "Episode: 26, Reward: 0.0\n",
      "Episode: 27, Reward: 0.0\n",
      "Episode: 28, Reward: 0.0\n",
      "Episode: 29, Reward: 0.0\n",
      "Episode: 30, Reward: 0.0\n",
      "Episode: 31, Reward: 0.0\n",
      "Episode: 32, Reward: 0.0\n",
      "Episode: 33, Reward: 0.0\n",
      "Episode: 34, Reward: 0.0\n",
      "Episode: 35, Reward: 0.0\n",
      "Episode: 36, Reward: 0.0\n",
      "Episode: 37, Reward: 0.0\n",
      "Episode: 38, Reward: 0.0\n",
      "Episode: 39, Reward: 0.0\n",
      "Episode: 40, Reward: 0.0\n",
      "Episode: 41, Reward: 0.0\n",
      "Episode: 42, Reward: 0.0\n",
      "Episode: 43, Reward: 0.0\n",
      "Episode: 44, Reward: 0.0\n",
      "Episode: 45, Reward: 0.0\n",
      "Episode: 46, Reward: 0.0\n",
      "Episode: 47, Reward: 0.0\n",
      "Episode: 48, Reward: 0.0\n",
      "Episode: 49, Reward: 0.0\n",
      "Episode: 50, Reward: 0.0\n",
      "Episode: 51, Reward: 0.0\n",
      "Episode: 52, Reward: 0.0\n",
      "Episode: 53, Reward: 0.0\n",
      "Episode: 54, Reward: 0.0\n",
      "Episode: 55, Reward: 0.0\n",
      "Episode: 56, Reward: 0.0\n",
      "Episode: 57, Reward: 0.0\n",
      "Episode: 58, Reward: 0.0\n",
      "Episode: 59, Reward: 0.0\n",
      "Episode: 60, Reward: 0.0\n",
      "Episode: 61, Reward: 0.0\n",
      "Episode: 62, Reward: 0.0\n",
      "Episode: 63, Reward: 0.0\n",
      "Episode: 64, Reward: 0.0\n",
      "Episode: 65, Reward: 0.0\n",
      "Episode: 66, Reward: 0.0\n",
      "Episode: 67, Reward: 0.0\n",
      "Episode: 68, Reward: 0.0\n",
      "Episode: 69, Reward: 0.0\n",
      "Episode: 70, Reward: 0.0\n",
      "Episode: 71, Reward: 0.0\n",
      "Episode: 72, Reward: 0.0\n",
      "Episode: 73, Reward: 0.0\n",
      "Episode: 74, Reward: 0.0\n",
      "Episode: 75, Reward: 0.0\n",
      "Episode: 76, Reward: 0.0\n",
      "Episode: 77, Reward: 0.0\n",
      "Episode: 78, Reward: 0.0\n",
      "Episode: 79, Reward: 0.0\n",
      "Episode: 80, Reward: 0.0\n",
      "Episode: 81, Reward: 0.0\n",
      "Episode: 82, Reward: 0.0\n",
      "Episode: 83, Reward: 0.0\n",
      "Episode: 84, Reward: 0.0\n",
      "Episode: 85, Reward: 0.0\n",
      "Episode: 86, Reward: 0.0\n",
      "Episode: 87, Reward: 0.0\n",
      "Episode: 88, Reward: 0.0\n",
      "Episode: 89, Reward: 0.0\n",
      "Episode: 90, Reward: 0.0\n",
      "Episode: 91, Reward: 0.0\n",
      "Episode: 92, Reward: 0.0\n",
      "Episode: 93, Reward: 0.0\n",
      "Episode: 94, Reward: 0.0\n",
      "Episode: 95, Reward: 0.0\n",
      "Episode: 96, Reward: 0.0\n",
      "Episode: 97, Reward: 0.0\n",
      "Episode: 98, Reward: 0.0\n",
      "Episode: 99, Reward: 0.0\n",
      "Episode: 100, Reward: 0.0\n",
      "Episode: 101, Reward: 0.0\n",
      "Episode: 102, Reward: 0.0\n",
      "Episode: 103, Reward: 0.0\n",
      "Episode: 104, Reward: 0.0\n",
      "Episode: 105, Reward: 0.0\n",
      "Episode: 106, Reward: 0.0\n",
      "Episode: 107, Reward: 0.0\n",
      "Episode: 108, Reward: 0.0\n",
      "Episode: 109, Reward: 0.0\n",
      "Episode: 110, Reward: 0.0\n",
      "Episode: 111, Reward: 0.0\n",
      "Episode: 112, Reward: 0.0\n",
      "Episode: 113, Reward: 0.0\n",
      "Episode: 114, Reward: 0.0\n",
      "Episode: 115, Reward: 0.0\n",
      "Episode: 116, Reward: 0.0\n",
      "Episode: 117, Reward: 0.0\n",
      "Episode: 118, Reward: 0.0\n",
      "Episode: 119, Reward: 0.0\n",
      "Episode: 120, Reward: 0.0\n",
      "Episode: 121, Reward: 0.0\n",
      "Episode: 122, Reward: 0.0\n",
      "Episode: 123, Reward: 0.0\n",
      "Episode: 124, Reward: 0.0\n",
      "Episode: 125, Reward: 0.0\n",
      "Episode: 126, Reward: 0.0\n",
      "Episode: 127, Reward: 0.0\n",
      "Episode: 128, Reward: 0.0\n",
      "Episode: 129, Reward: 0.0\n",
      "Episode: 130, Reward: 0.0\n",
      "Episode: 131, Reward: 0.0\n",
      "Episode: 132, Reward: 0.0\n",
      "Episode: 133, Reward: 0.0\n",
      "Episode: 134, Reward: 0.0\n",
      "Episode: 135, Reward: 0.0\n",
      "Episode: 136, Reward: 0.0\n",
      "Episode: 137, Reward: 0.0\n",
      "Episode: 138, Reward: 0.0\n",
      "Episode: 139, Reward: 0.0\n",
      "Episode: 140, Reward: 0.0\n",
      "Episode: 141, Reward: 0.0\n",
      "Episode: 142, Reward: 0.0\n",
      "Episode: 143, Reward: 0.0\n",
      "Episode: 144, Reward: 0.0\n",
      "Episode: 145, Reward: 0.0\n",
      "Episode: 146, Reward: 0.0\n",
      "Episode: 147, Reward: 0.0\n",
      "Episode: 148, Reward: 0.0\n",
      "Episode: 149, Reward: 0.0\n",
      "Episode: 150, Reward: 0.0\n",
      "Episode: 151, Reward: 0.0\n",
      "Episode: 152, Reward: 0.0\n",
      "Episode: 153, Reward: 0.0\n",
      "Episode: 154, Reward: 0.0\n",
      "Episode: 155, Reward: 0.0\n",
      "Episode: 156, Reward: 0.0\n",
      "Episode: 157, Reward: 0.0\n",
      "Episode: 158, Reward: 0.0\n",
      "Episode: 159, Reward: 0.0\n",
      "Episode: 160, Reward: 0.0\n",
      "Episode: 161, Reward: 0.0\n",
      "Episode: 162, Reward: 0.0\n",
      "Episode: 163, Reward: 0.0\n",
      "Episode: 164, Reward: 0.0\n",
      "Episode: 165, Reward: 0.0\n",
      "Episode: 166, Reward: 0.0\n",
      "Episode: 167, Reward: 0.0\n",
      "Episode: 168, Reward: 0.0\n",
      "Episode: 169, Reward: 0.0\n",
      "Episode: 170, Reward: 0.0\n",
      "Episode: 171, Reward: 0.0\n",
      "Episode: 172, Reward: 0.0\n",
      "Episode: 173, Reward: 0.0\n",
      "Episode: 174, Reward: 0.0\n",
      "Episode: 175, Reward: 0.0\n",
      "Episode: 176, Reward: 0.0\n",
      "Episode: 177, Reward: 0.0\n",
      "Episode: 178, Reward: 0.0\n",
      "Episode: 179, Reward: 0.0\n",
      "Episode: 180, Reward: 0.0\n",
      "Episode: 181, Reward: 0.0\n",
      "Episode: 182, Reward: 0.0\n",
      "Episode: 183, Reward: 0.0\n",
      "Episode: 184, Reward: 0.0\n",
      "Episode: 185, Reward: 0.0\n",
      "Episode: 186, Reward: 0.0\n",
      "Episode: 187, Reward: 0.0\n",
      "Episode: 188, Reward: 0.0\n",
      "Episode: 189, Reward: 0.0\n",
      "Episode: 190, Reward: 0.0\n",
      "Episode: 191, Reward: 0.0\n",
      "Episode: 192, Reward: 0.0\n",
      "Episode: 193, Reward: 0.0\n",
      "Episode: 194, Reward: 0.0\n",
      "Episode: 195, Reward: 0.0\n",
      "Episode: 196, Reward: 0.0\n",
      "Episode: 197, Reward: 0.0\n",
      "Episode: 198, Reward: 0.0\n",
      "Episode: 199, Reward: 0.0\n",
      "END - Date-Time: 2023-08-21 08:00:14\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[1, 5, 10, 16, 17, 43, 45, 50, 59, 60, 71, 74, 75, 80, 83, 93, 103, 105, 106, 107, 109, 110, 113, 115, 118, 119, 120, 121, 123, 129, 131, 134, 137, 141, 146, 163, 175, 177, 178, 197]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_VENTURE-V5 EXPERIMENT 3: Date-Time: 2023-08-21 08:00:39, Capacity: 50k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 50000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 0.0\n",
      "Episode: 8, Reward: 0.0\n",
      "Episode: 9, Reward: 0.0\n",
      "Episode: 10, Reward: 0.0\n",
      "Episode: 11, Reward: 0.0\n",
      "Episode: 12, Reward: 0.0\n",
      "Episode: 13, Reward: 0.0\n",
      "Episode: 14, Reward: 0.0\n",
      "Episode: 15, Reward: 0.0\n",
      "Episode: 16, Reward: 0.0\n",
      "Episode: 17, Reward: 0.0\n",
      "Episode: 18, Reward: 0.0\n",
      "Episode: 19, Reward: 0.0\n",
      "Episode: 20, Reward: 0.0\n",
      "Episode: 21, Reward: 0.0\n",
      "Episode: 22, Reward: 0.0\n",
      "Episode: 23, Reward: 0.0\n",
      "Episode: 24, Reward: 0.0\n",
      "Episode: 25, Reward: 0.0\n",
      "Episode: 26, Reward: 0.0\n",
      "Episode: 27, Reward: 0.0\n",
      "Episode: 28, Reward: 0.0\n",
      "Episode: 29, Reward: 0.0\n",
      "Episode: 30, Reward: 0.0\n",
      "Episode: 31, Reward: 0.0\n",
      "Episode: 32, Reward: 0.0\n",
      "Episode: 33, Reward: 0.0\n",
      "Episode: 34, Reward: 0.0\n",
      "Episode: 35, Reward: 0.0\n",
      "Episode: 36, Reward: 0.0\n",
      "Episode: 37, Reward: 0.0\n",
      "Episode: 38, Reward: 0.0\n",
      "Episode: 39, Reward: 0.0\n",
      "Episode: 40, Reward: 0.0\n",
      "Episode: 41, Reward: 0.0\n",
      "Episode: 42, Reward: 0.0\n",
      "Episode: 43, Reward: 0.0\n",
      "Episode: 44, Reward: 0.0\n",
      "Episode: 45, Reward: 0.0\n",
      "Episode: 46, Reward: 0.0\n",
      "Episode: 47, Reward: 0.0\n",
      "Episode: 48, Reward: 0.0\n",
      "Episode: 49, Reward: 0.0\n",
      "Episode: 50, Reward: 0.0\n",
      "Episode: 51, Reward: 0.0\n",
      "Episode: 52, Reward: 0.0\n",
      "Episode: 53, Reward: 0.0\n",
      "Episode: 54, Reward: 0.0\n",
      "Episode: 55, Reward: 0.0\n",
      "Episode: 56, Reward: 0.0\n",
      "Episode: 57, Reward: 0.0\n",
      "Episode: 58, Reward: 0.0\n",
      "Episode: 59, Reward: 0.0\n",
      "Episode: 60, Reward: 0.0\n",
      "Episode: 61, Reward: 0.0\n",
      "Episode: 62, Reward: 0.0\n",
      "Episode: 63, Reward: 0.0\n",
      "Episode: 64, Reward: 0.0\n",
      "Episode: 65, Reward: 0.0\n",
      "Episode: 66, Reward: 0.0\n",
      "Episode: 67, Reward: 0.0\n",
      "Episode: 68, Reward: 0.0\n",
      "Episode: 69, Reward: 0.0\n",
      "Episode: 70, Reward: 0.0\n",
      "Episode: 71, Reward: 0.0\n",
      "Episode: 72, Reward: 0.0\n",
      "Episode: 73, Reward: 0.0\n",
      "Episode: 74, Reward: 0.0\n",
      "Episode: 75, Reward: 0.0\n",
      "Episode: 76, Reward: 0.0\n",
      "Episode: 77, Reward: 0.0\n",
      "Episode: 78, Reward: 0.0\n",
      "Episode: 79, Reward: 0.0\n",
      "Episode: 80, Reward: 0.0\n",
      "Episode: 81, Reward: 0.0\n",
      "Episode: 82, Reward: 0.0\n",
      "Episode: 83, Reward: 0.0\n",
      "Episode: 84, Reward: 0.0\n",
      "Episode: 85, Reward: 0.0\n",
      "Episode: 86, Reward: 0.0\n",
      "Episode: 87, Reward: 0.0\n",
      "Episode: 88, Reward: 0.0\n",
      "Episode: 89, Reward: 0.0\n",
      "Episode: 90, Reward: 0.0\n",
      "Episode: 91, Reward: 0.0\n",
      "Episode: 92, Reward: 0.0\n",
      "Episode: 93, Reward: 0.0\n",
      "Episode: 94, Reward: 0.0\n",
      "Episode: 95, Reward: 0.0\n",
      "Episode: 96, Reward: 0.0\n",
      "Episode: 97, Reward: 0.0\n",
      "Episode: 98, Reward: 0.0\n",
      "Episode: 99, Reward: 0.0\n",
      "Episode: 100, Reward: 0.0\n",
      "Episode: 101, Reward: 0.0\n",
      "Episode: 102, Reward: 0.0\n",
      "Episode: 103, Reward: 0.0\n",
      "Episode: 104, Reward: 0.0\n",
      "Episode: 105, Reward: 0.0\n",
      "Episode: 106, Reward: 0.0\n",
      "Episode: 107, Reward: 0.0\n",
      "Episode: 108, Reward: 0.0\n",
      "Episode: 109, Reward: 0.0\n",
      "Episode: 110, Reward: 0.0\n",
      "Episode: 111, Reward: 0.0\n",
      "Episode: 112, Reward: 0.0\n",
      "Episode: 113, Reward: 0.0\n",
      "Episode: 114, Reward: 0.0\n",
      "Episode: 115, Reward: 0.0\n",
      "Episode: 116, Reward: 0.0\n",
      "Episode: 117, Reward: 0.0\n",
      "Episode: 118, Reward: 0.0\n",
      "Episode: 119, Reward: 0.0\n",
      "Episode: 120, Reward: 0.0\n",
      "Episode: 121, Reward: 0.0\n",
      "Episode: 122, Reward: 0.0\n",
      "Episode: 123, Reward: 0.0\n",
      "Episode: 124, Reward: 0.0\n",
      "Episode: 125, Reward: 0.0\n",
      "Episode: 126, Reward: 0.0\n",
      "Episode: 127, Reward: 0.0\n",
      "Episode: 128, Reward: 0.0\n",
      "Episode: 129, Reward: 0.0\n",
      "Episode: 130, Reward: 0.0\n",
      "Episode: 131, Reward: 0.0\n",
      "Episode: 132, Reward: 0.0\n",
      "Episode: 133, Reward: 0.0\n",
      "Episode: 134, Reward: 0.0\n",
      "Episode: 135, Reward: 0.0\n",
      "Episode: 136, Reward: 0.0\n",
      "Episode: 137, Reward: 0.0\n",
      "Episode: 138, Reward: 0.0\n",
      "Episode: 139, Reward: 0.0\n",
      "Episode: 140, Reward: 0.0\n",
      "Episode: 141, Reward: 0.0\n",
      "Episode: 142, Reward: 0.0\n",
      "Episode: 143, Reward: 0.0\n",
      "Episode: 144, Reward: 0.0\n",
      "Episode: 145, Reward: 0.0\n",
      "Episode: 146, Reward: 0.0\n",
      "Episode: 147, Reward: 0.0\n",
      "Episode: 148, Reward: 0.0\n",
      "Episode: 149, Reward: 0.0\n",
      "Episode: 150, Reward: 0.0\n",
      "Episode: 151, Reward: 0.0\n",
      "Episode: 152, Reward: 0.0\n",
      "Episode: 153, Reward: 0.0\n",
      "Episode: 154, Reward: 0.0\n",
      "Episode: 155, Reward: 0.0\n",
      "Episode: 156, Reward: 0.0\n",
      "Episode: 157, Reward: 0.0\n",
      "Episode: 158, Reward: 0.0\n",
      "Episode: 159, Reward: 0.0\n",
      "Episode: 160, Reward: 0.0\n",
      "Episode: 161, Reward: 0.0\n",
      "Episode: 162, Reward: 0.0\n",
      "Episode: 163, Reward: 0.0\n",
      "Episode: 164, Reward: 0.0\n",
      "Episode: 165, Reward: 0.0\n",
      "Episode: 166, Reward: 0.0\n",
      "Episode: 167, Reward: 0.0\n",
      "Episode: 168, Reward: 0.0\n",
      "Episode: 169, Reward: 0.0\n",
      "Episode: 170, Reward: 0.0\n",
      "Episode: 171, Reward: 0.0\n",
      "Episode: 172, Reward: 0.0\n",
      "Episode: 173, Reward: 0.0\n",
      "Episode: 174, Reward: 0.0\n",
      "Episode: 175, Reward: 0.0\n",
      "Episode: 176, Reward: 0.0\n",
      "Episode: 177, Reward: 0.0\n",
      "Episode: 178, Reward: 0.0\n",
      "Episode: 179, Reward: 0.0\n",
      "Episode: 180, Reward: 0.0\n",
      "Episode: 181, Reward: 0.0\n",
      "Episode: 182, Reward: 0.0\n",
      "Episode: 183, Reward: 0.0\n",
      "Episode: 184, Reward: 0.0\n",
      "Episode: 185, Reward: 0.0\n",
      "Episode: 186, Reward: 0.0\n",
      "Episode: 187, Reward: 0.0\n",
      "Episode: 188, Reward: 0.0\n",
      "Episode: 189, Reward: 0.0\n",
      "Episode: 190, Reward: 0.0\n",
      "Episode: 191, Reward: 0.0\n",
      "Episode: 192, Reward: 0.0\n",
      "Episode: 193, Reward: 0.0\n",
      "Episode: 194, Reward: 0.0\n",
      "Episode: 195, Reward: 0.0\n",
      "Episode: 196, Reward: 0.0\n",
      "Episode: 197, Reward: 0.0\n",
      "Episode: 198, Reward: 0.0\n",
      "Episode: 199, Reward: 0.0\n",
      "END - Date-Time: 2023-08-21 08:09:59\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[13, 15, 17, 19, 31, 34, 37, 38, 39, 47, 49, 50, 52, 59, 62, 63, 64, 71, 75, 77, 79, 88, 89, 96, 110, 114, 117, 119, 122, 131, 132, 147, 152, 153, 156, 181, 183, 187, 188, 196]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_VENTURE-V5 EXPERIMENT 4: Date-Time: 2023-08-21 08:10:26, Capacity: 10k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 10000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 0.0\n",
      "Episode: 8, Reward: 0.0\n",
      "Episode: 9, Reward: 0.0\n",
      "Episode: 10, Reward: 0.0\n",
      "Episode: 11, Reward: 0.0\n",
      "Episode: 12, Reward: 0.0\n",
      "Episode: 13, Reward: 0.0\n",
      "Episode: 14, Reward: 0.0\n",
      "Episode: 15, Reward: 0.0\n",
      "Episode: 16, Reward: 0.0\n",
      "Episode: 17, Reward: 0.0\n",
      "Episode: 18, Reward: 0.0\n",
      "Episode: 19, Reward: 0.0\n",
      "Episode: 20, Reward: 0.0\n",
      "Episode: 21, Reward: 0.0\n",
      "Episode: 22, Reward: 0.0\n",
      "Episode: 23, Reward: 0.0\n",
      "Episode: 24, Reward: 0.0\n",
      "Episode: 25, Reward: 0.0\n",
      "Episode: 26, Reward: 0.0\n",
      "Episode: 27, Reward: 0.0\n",
      "Episode: 28, Reward: 0.0\n",
      "Episode: 29, Reward: 0.0\n",
      "Episode: 30, Reward: 0.0\n",
      "Episode: 31, Reward: 0.0\n",
      "Episode: 32, Reward: 0.0\n",
      "Episode: 33, Reward: 0.0\n",
      "Episode: 34, Reward: 0.0\n",
      "Episode: 35, Reward: 0.0\n",
      "Episode: 36, Reward: 0.0\n",
      "Episode: 37, Reward: 0.0\n",
      "Episode: 38, Reward: 0.0\n",
      "Episode: 39, Reward: 0.0\n",
      "Episode: 40, Reward: 0.0\n",
      "Episode: 41, Reward: 0.0\n",
      "Episode: 42, Reward: 0.0\n",
      "Episode: 43, Reward: 0.0\n",
      "Episode: 44, Reward: 0.0\n",
      "Episode: 45, Reward: 0.0\n",
      "Episode: 46, Reward: 0.0\n",
      "Episode: 47, Reward: 0.0\n",
      "Episode: 48, Reward: 0.0\n",
      "Episode: 49, Reward: 0.0\n",
      "Episode: 50, Reward: 0.0\n",
      "Episode: 51, Reward: 0.0\n",
      "Episode: 52, Reward: 0.0\n",
      "Episode: 53, Reward: 0.0\n",
      "Episode: 54, Reward: 0.0\n",
      "Episode: 55, Reward: 0.0\n",
      "Episode: 56, Reward: 0.0\n",
      "Episode: 57, Reward: 0.0\n",
      "Episode: 58, Reward: 0.0\n",
      "Episode: 59, Reward: 0.0\n",
      "Episode: 60, Reward: 0.0\n",
      "Episode: 61, Reward: 0.0\n",
      "Episode: 62, Reward: 0.0\n",
      "Episode: 63, Reward: 0.0\n",
      "Episode: 64, Reward: 0.0\n",
      "Episode: 65, Reward: 0.0\n",
      "Episode: 66, Reward: 0.0\n",
      "Episode: 67, Reward: 0.0\n",
      "Episode: 68, Reward: 0.0\n",
      "Episode: 69, Reward: 0.0\n",
      "Episode: 70, Reward: 0.0\n",
      "Episode: 71, Reward: 0.0\n",
      "Episode: 72, Reward: 0.0\n",
      "Episode: 73, Reward: 0.0\n",
      "Episode: 74, Reward: 0.0\n",
      "Episode: 75, Reward: 0.0\n",
      "Episode: 76, Reward: 0.0\n",
      "Episode: 77, Reward: 0.0\n",
      "Episode: 78, Reward: 0.0\n",
      "Episode: 79, Reward: 0.0\n",
      "Episode: 80, Reward: 0.0\n",
      "Episode: 81, Reward: 0.0\n",
      "Episode: 82, Reward: 0.0\n",
      "Episode: 83, Reward: 0.0\n",
      "Episode: 84, Reward: 0.0\n",
      "Episode: 85, Reward: 0.0\n",
      "Episode: 86, Reward: 0.0\n",
      "Episode: 87, Reward: 0.0\n",
      "Episode: 88, Reward: 0.0\n",
      "Episode: 89, Reward: 0.0\n",
      "Episode: 90, Reward: 0.0\n",
      "Episode: 91, Reward: 0.0\n",
      "Episode: 92, Reward: 0.0\n",
      "Episode: 93, Reward: 0.0\n",
      "Episode: 94, Reward: 0.0\n",
      "Episode: 95, Reward: 0.0\n",
      "Episode: 96, Reward: 0.0\n",
      "Episode: 97, Reward: 0.0\n",
      "Episode: 98, Reward: 0.0\n",
      "Episode: 99, Reward: 0.0\n",
      "Episode: 100, Reward: 0.0\n",
      "Episode: 101, Reward: 0.0\n",
      "Episode: 102, Reward: 0.0\n",
      "Episode: 103, Reward: 0.0\n",
      "Episode: 104, Reward: 0.0\n",
      "Episode: 105, Reward: 0.0\n",
      "Episode: 106, Reward: 0.0\n",
      "Episode: 107, Reward: 0.0\n",
      "Episode: 108, Reward: 0.0\n",
      "Episode: 109, Reward: 0.0\n",
      "Episode: 110, Reward: 0.0\n",
      "Episode: 111, Reward: 0.0\n",
      "Episode: 112, Reward: 0.0\n",
      "Episode: 113, Reward: 0.0\n",
      "Episode: 114, Reward: 0.0\n",
      "Episode: 115, Reward: 0.0\n",
      "Episode: 116, Reward: 0.0\n",
      "Episode: 117, Reward: 0.0\n",
      "Episode: 118, Reward: 0.0\n",
      "Episode: 119, Reward: 0.0\n",
      "Episode: 120, Reward: 0.0\n",
      "Episode: 121, Reward: 0.0\n",
      "Episode: 122, Reward: 0.0\n",
      "Episode: 123, Reward: 0.0\n",
      "Episode: 124, Reward: 0.0\n",
      "Episode: 125, Reward: 0.0\n",
      "Episode: 126, Reward: 0.0\n",
      "Episode: 127, Reward: 0.0\n",
      "Episode: 128, Reward: 0.0\n",
      "Episode: 129, Reward: 0.0\n",
      "Episode: 130, Reward: 0.0\n",
      "Episode: 131, Reward: 0.0\n",
      "Episode: 132, Reward: 0.0\n",
      "Episode: 133, Reward: 0.0\n",
      "Episode: 134, Reward: 0.0\n",
      "Episode: 135, Reward: 0.0\n",
      "Episode: 136, Reward: 0.0\n",
      "Episode: 137, Reward: 0.0\n",
      "Episode: 138, Reward: 0.0\n",
      "Episode: 139, Reward: 0.0\n",
      "Episode: 140, Reward: 0.0\n",
      "Episode: 141, Reward: 0.0\n",
      "Episode: 142, Reward: 0.0\n",
      "Episode: 143, Reward: 0.0\n",
      "Episode: 144, Reward: 0.0\n",
      "Episode: 145, Reward: 0.0\n",
      "Episode: 146, Reward: 0.0\n",
      "Episode: 147, Reward: 0.0\n",
      "Episode: 148, Reward: 0.0\n",
      "Episode: 149, Reward: 0.0\n",
      "Episode: 150, Reward: 0.0\n",
      "Episode: 151, Reward: 0.0\n",
      "Episode: 152, Reward: 0.0\n",
      "Episode: 153, Reward: 0.0\n",
      "Episode: 154, Reward: 0.0\n",
      "Episode: 155, Reward: 0.0\n",
      "Episode: 156, Reward: 0.0\n",
      "Episode: 157, Reward: 0.0\n",
      "Episode: 158, Reward: 0.0\n",
      "Episode: 159, Reward: 0.0\n",
      "Episode: 160, Reward: 0.0\n",
      "Episode: 161, Reward: 0.0\n",
      "Episode: 162, Reward: 0.0\n",
      "Episode: 163, Reward: 0.0\n",
      "Episode: 164, Reward: 0.0\n",
      "Episode: 165, Reward: 0.0\n",
      "Episode: 166, Reward: 0.0\n",
      "Episode: 167, Reward: 0.0\n",
      "Episode: 168, Reward: 0.0\n",
      "Episode: 169, Reward: 0.0\n",
      "Episode: 170, Reward: 0.0\n",
      "Episode: 171, Reward: 0.0\n",
      "Episode: 172, Reward: 0.0\n",
      "Episode: 173, Reward: 0.0\n",
      "Episode: 174, Reward: 0.0\n",
      "Episode: 175, Reward: 0.0\n",
      "Episode: 176, Reward: 0.0\n",
      "Episode: 177, Reward: 0.0\n",
      "Episode: 178, Reward: 0.0\n",
      "Episode: 179, Reward: 0.0\n",
      "Episode: 180, Reward: 0.0\n",
      "Episode: 181, Reward: 0.0\n",
      "Episode: 182, Reward: 0.0\n",
      "Episode: 183, Reward: 0.0\n",
      "Episode: 184, Reward: 0.0\n",
      "Episode: 185, Reward: 0.0\n",
      "Episode: 186, Reward: 0.0\n",
      "Episode: 187, Reward: 0.0\n",
      "Episode: 188, Reward: 0.0\n",
      "Episode: 189, Reward: 0.0\n",
      "Episode: 190, Reward: 0.0\n",
      "Episode: 191, Reward: 0.0\n",
      "Episode: 192, Reward: 0.0\n",
      "Episode: 193, Reward: 0.0\n",
      "Episode: 194, Reward: 0.0\n",
      "Episode: 195, Reward: 0.0\n",
      "Episode: 196, Reward: 0.0\n",
      "Episode: 197, Reward: 0.0\n",
      "Episode: 198, Reward: 0.0\n",
      "Episode: 199, Reward: 0.0\n",
      "END - Date-Time: 2023-08-21 08:16:18\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[15, 17, 18, 20, 21, 28, 37, 45, 46, 60, 67, 69, 71, 74, 76, 78, 82, 85, 91, 94, 95, 96, 97, 103, 115, 119, 130, 131, 133, 137, 138, 148, 172, 173, 174, 177, 180, 183, 191, 193]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_VENTURE-V5 EXPERIMENT 5: Date-Time: 2023-08-21 08:16:44, Capacity: 5k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 5000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 0.0\n",
      "Episode: 8, Reward: 0.0\n",
      "Episode: 9, Reward: 0.0\n",
      "Episode: 10, Reward: 0.0\n",
      "Episode: 11, Reward: 0.0\n",
      "Episode: 12, Reward: 0.0\n",
      "Episode: 13, Reward: 0.0\n",
      "Episode: 14, Reward: 0.0\n",
      "Episode: 15, Reward: 0.0\n",
      "Episode: 16, Reward: 0.0\n",
      "Episode: 17, Reward: 0.0\n",
      "Episode: 18, Reward: 0.0\n",
      "Episode: 19, Reward: 0.0\n",
      "Episode: 20, Reward: 0.0\n",
      "Episode: 21, Reward: 0.0\n",
      "Episode: 22, Reward: 0.0\n",
      "Episode: 23, Reward: 0.0\n",
      "Episode: 24, Reward: 0.0\n",
      "Episode: 25, Reward: 0.0\n",
      "Episode: 26, Reward: 0.0\n",
      "Episode: 27, Reward: 0.0\n",
      "Episode: 28, Reward: 0.0\n",
      "Episode: 29, Reward: 0.0\n",
      "Episode: 30, Reward: 0.0\n",
      "Episode: 31, Reward: 0.0\n",
      "Episode: 32, Reward: 0.0\n",
      "Episode: 33, Reward: 0.0\n",
      "Episode: 34, Reward: 0.0\n",
      "Episode: 35, Reward: 0.0\n",
      "Episode: 36, Reward: 0.0\n",
      "Episode: 37, Reward: 0.0\n",
      "Episode: 38, Reward: 0.0\n",
      "Episode: 39, Reward: 0.0\n",
      "Episode: 40, Reward: 0.0\n",
      "Episode: 41, Reward: 0.0\n",
      "Episode: 42, Reward: 0.0\n",
      "Episode: 43, Reward: 0.0\n",
      "Episode: 44, Reward: 0.0\n",
      "Episode: 45, Reward: 0.0\n",
      "Episode: 46, Reward: 0.0\n",
      "Episode: 47, Reward: 0.0\n",
      "Episode: 48, Reward: 0.0\n",
      "Episode: 49, Reward: 0.0\n",
      "Episode: 50, Reward: 0.0\n",
      "Episode: 51, Reward: 0.0\n",
      "Episode: 52, Reward: 0.0\n",
      "Episode: 53, Reward: 0.0\n",
      "Episode: 54, Reward: 0.0\n",
      "Episode: 55, Reward: 0.0\n",
      "Episode: 56, Reward: 0.0\n",
      "Episode: 57, Reward: 0.0\n",
      "Episode: 58, Reward: 0.0\n",
      "Episode: 59, Reward: 0.0\n",
      "Episode: 60, Reward: 0.0\n",
      "Episode: 61, Reward: 0.0\n",
      "Episode: 62, Reward: 0.0\n",
      "Episode: 63, Reward: 0.0\n",
      "Episode: 64, Reward: 0.0\n",
      "Episode: 65, Reward: 0.0\n",
      "Episode: 66, Reward: 0.0\n",
      "Episode: 67, Reward: 0.0\n",
      "Episode: 68, Reward: 0.0\n",
      "Episode: 69, Reward: 0.0\n",
      "Episode: 70, Reward: 0.0\n",
      "Episode: 71, Reward: 0.0\n",
      "Episode: 72, Reward: 0.0\n",
      "Episode: 73, Reward: 0.0\n",
      "Episode: 74, Reward: 0.0\n",
      "Episode: 75, Reward: 0.0\n",
      "Episode: 76, Reward: 0.0\n",
      "Episode: 77, Reward: 0.0\n",
      "Episode: 78, Reward: 0.0\n",
      "Episode: 79, Reward: 0.0\n",
      "Episode: 80, Reward: 0.0\n",
      "Episode: 81, Reward: 0.0\n",
      "Episode: 82, Reward: 0.0\n",
      "Episode: 83, Reward: 0.0\n",
      "Episode: 84, Reward: 0.0\n",
      "Episode: 85, Reward: 0.0\n",
      "Episode: 86, Reward: 0.0\n",
      "Episode: 87, Reward: 0.0\n",
      "Episode: 88, Reward: 0.0\n",
      "Episode: 89, Reward: 0.0\n",
      "Episode: 90, Reward: 0.0\n",
      "Episode: 91, Reward: 0.0\n",
      "Episode: 92, Reward: 0.0\n",
      "Episode: 93, Reward: 0.0\n",
      "Episode: 94, Reward: 0.0\n",
      "Episode: 95, Reward: 0.0\n",
      "Episode: 96, Reward: 0.0\n",
      "Episode: 97, Reward: 0.0\n",
      "Episode: 98, Reward: 0.0\n",
      "Episode: 99, Reward: 0.0\n",
      "Episode: 100, Reward: 0.0\n",
      "Episode: 101, Reward: 0.0\n",
      "Episode: 102, Reward: 0.0\n",
      "Episode: 103, Reward: 0.0\n",
      "Episode: 104, Reward: 0.0\n",
      "Episode: 105, Reward: 0.0\n",
      "Episode: 106, Reward: 0.0\n",
      "Episode: 107, Reward: 0.0\n",
      "Episode: 108, Reward: 0.0\n",
      "Episode: 109, Reward: 0.0\n",
      "Episode: 110, Reward: 0.0\n",
      "Episode: 111, Reward: 0.0\n",
      "Episode: 112, Reward: 0.0\n",
      "Episode: 113, Reward: 0.0\n",
      "Episode: 114, Reward: 0.0\n",
      "Episode: 115, Reward: 0.0\n",
      "Episode: 116, Reward: 0.0\n",
      "Episode: 117, Reward: 0.0\n",
      "Episode: 118, Reward: 0.0\n",
      "Episode: 119, Reward: 0.0\n",
      "Episode: 120, Reward: 0.0\n",
      "Episode: 121, Reward: 0.0\n",
      "Episode: 122, Reward: 0.0\n",
      "Episode: 123, Reward: 0.0\n",
      "Episode: 124, Reward: 0.0\n",
      "Episode: 125, Reward: 0.0\n",
      "Episode: 126, Reward: 0.0\n",
      "Episode: 127, Reward: 0.0\n",
      "Episode: 128, Reward: 0.0\n",
      "Episode: 129, Reward: 0.0\n",
      "Episode: 130, Reward: 0.0\n",
      "Episode: 131, Reward: 0.0\n",
      "Episode: 132, Reward: 0.0\n",
      "Episode: 133, Reward: 0.0\n",
      "Episode: 134, Reward: 0.0\n",
      "Episode: 135, Reward: 0.0\n",
      "Episode: 136, Reward: 0.0\n",
      "Episode: 137, Reward: 0.0\n",
      "Episode: 138, Reward: 0.0\n",
      "Episode: 139, Reward: 0.0\n",
      "Episode: 140, Reward: 0.0\n",
      "Episode: 141, Reward: 0.0\n",
      "Episode: 142, Reward: 0.0\n",
      "Episode: 143, Reward: 0.0\n",
      "Episode: 144, Reward: 0.0\n",
      "Episode: 145, Reward: 0.0\n",
      "Episode: 146, Reward: 0.0\n",
      "Episode: 147, Reward: 0.0\n",
      "Episode: 148, Reward: 0.0\n",
      "Episode: 149, Reward: 0.0\n",
      "Episode: 150, Reward: 0.0\n",
      "Episode: 151, Reward: 0.0\n",
      "Episode: 152, Reward: 0.0\n",
      "Episode: 153, Reward: 0.0\n",
      "Episode: 154, Reward: 0.0\n",
      "Episode: 155, Reward: 0.0\n",
      "Episode: 156, Reward: 0.0\n",
      "Episode: 157, Reward: 0.0\n",
      "Episode: 158, Reward: 0.0\n",
      "Episode: 159, Reward: 0.0\n",
      "Episode: 160, Reward: 0.0\n",
      "Episode: 161, Reward: 0.0\n",
      "Episode: 162, Reward: 0.0\n",
      "Episode: 163, Reward: 0.0\n",
      "Episode: 164, Reward: 0.0\n",
      "Episode: 165, Reward: 0.0\n",
      "Episode: 166, Reward: 0.0\n",
      "Episode: 167, Reward: 0.0\n",
      "Episode: 168, Reward: 0.0\n",
      "Episode: 169, Reward: 0.0\n",
      "Episode: 170, Reward: 0.0\n",
      "Episode: 171, Reward: 0.0\n",
      "Episode: 172, Reward: 0.0\n",
      "Episode: 173, Reward: 0.0\n",
      "Episode: 174, Reward: 0.0\n",
      "Episode: 175, Reward: 0.0\n",
      "Episode: 176, Reward: 0.0\n",
      "Episode: 177, Reward: 0.0\n",
      "Episode: 178, Reward: 0.0\n",
      "Episode: 179, Reward: 0.0\n",
      "Episode: 180, Reward: 0.0\n",
      "Episode: 181, Reward: 0.0\n",
      "Episode: 182, Reward: 0.0\n",
      "Episode: 183, Reward: 0.0\n",
      "Episode: 184, Reward: 0.0\n",
      "Episode: 185, Reward: 0.0\n",
      "Episode: 186, Reward: 0.0\n",
      "Episode: 187, Reward: 0.0\n",
      "Episode: 188, Reward: 0.0\n",
      "Episode: 189, Reward: 0.0\n",
      "Episode: 190, Reward: 0.0\n",
      "Episode: 191, Reward: 0.0\n",
      "Episode: 192, Reward: 0.0\n",
      "Episode: 193, Reward: 0.0\n",
      "Episode: 194, Reward: 0.0\n",
      "Episode: 195, Reward: 0.0\n",
      "Episode: 196, Reward: 0.0\n",
      "Episode: 197, Reward: 0.0\n",
      "Episode: 198, Reward: 0.0\n",
      "Episode: 199, Reward: 0.0\n",
      "END - Date-Time: 2023-08-21 08:21:51\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[3, 6, 7, 12, 16, 27, 39, 47, 49, 50, 58, 65, 67, 68, 87, 95, 97, 98, 106, 109, 116, 117, 120, 130, 134, 137, 141, 153, 157, 167, 172, 174, 175, 177, 180, 182, 183, 185, 187, 199]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_VENTURE-V5 EXPERIMENT 6: Date-Time: 2023-08-21 08:22:18, Capacity: 1k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 1000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 0.0\n",
      "Episode: 8, Reward: 0.0\n",
      "Episode: 9, Reward: 0.0\n",
      "Episode: 10, Reward: 0.0\n",
      "Episode: 11, Reward: 0.0\n",
      "Episode: 12, Reward: 0.0\n",
      "Episode: 13, Reward: 0.0\n",
      "Episode: 14, Reward: 0.0\n",
      "Episode: 15, Reward: 0.0\n",
      "Episode: 16, Reward: 0.0\n",
      "Episode: 17, Reward: 0.0\n",
      "Episode: 18, Reward: 0.0\n",
      "Episode: 19, Reward: 0.0\n",
      "Episode: 20, Reward: 0.0\n",
      "Episode: 21, Reward: 0.0\n",
      "Episode: 22, Reward: 0.0\n",
      "Episode: 23, Reward: 0.0\n",
      "Episode: 24, Reward: 0.0\n",
      "Episode: 25, Reward: 0.0\n",
      "Episode: 26, Reward: 0.0\n",
      "Episode: 27, Reward: 0.0\n",
      "Episode: 28, Reward: 0.0\n",
      "Episode: 29, Reward: 0.0\n",
      "Episode: 30, Reward: 0.0\n",
      "Episode: 31, Reward: 0.0\n",
      "Episode: 32, Reward: 0.0\n",
      "Episode: 33, Reward: 0.0\n",
      "Episode: 34, Reward: 0.0\n",
      "Episode: 35, Reward: 0.0\n",
      "Episode: 36, Reward: 0.0\n",
      "Episode: 37, Reward: 0.0\n",
      "Episode: 38, Reward: 0.0\n",
      "Episode: 39, Reward: 0.0\n",
      "Episode: 40, Reward: 0.0\n",
      "Episode: 41, Reward: 0.0\n",
      "Episode: 42, Reward: 0.0\n",
      "Episode: 43, Reward: 0.0\n",
      "Episode: 44, Reward: 0.0\n",
      "Episode: 45, Reward: 0.0\n",
      "Episode: 46, Reward: 0.0\n",
      "Episode: 47, Reward: 0.0\n",
      "Episode: 48, Reward: 0.0\n",
      "Episode: 49, Reward: 0.0\n",
      "Episode: 50, Reward: 0.0\n",
      "Episode: 51, Reward: 0.0\n",
      "Episode: 52, Reward: 0.0\n",
      "Episode: 53, Reward: 0.0\n",
      "Episode: 54, Reward: 0.0\n",
      "Episode: 55, Reward: 0.0\n",
      "Episode: 56, Reward: 0.0\n",
      "Episode: 57, Reward: 0.0\n",
      "Episode: 58, Reward: 0.0\n",
      "Episode: 59, Reward: 0.0\n",
      "Episode: 60, Reward: 0.0\n",
      "Episode: 61, Reward: 0.0\n",
      "Episode: 62, Reward: 0.0\n",
      "Episode: 63, Reward: 0.0\n",
      "Episode: 64, Reward: 0.0\n",
      "Episode: 65, Reward: 0.0\n",
      "Episode: 66, Reward: 0.0\n",
      "Episode: 67, Reward: 0.0\n",
      "Episode: 68, Reward: 0.0\n",
      "Episode: 69, Reward: 0.0\n",
      "Episode: 70, Reward: 0.0\n",
      "Episode: 71, Reward: 0.0\n",
      "Episode: 72, Reward: 0.0\n",
      "Episode: 73, Reward: 0.0\n",
      "Episode: 74, Reward: 0.0\n",
      "Episode: 75, Reward: 0.0\n",
      "Episode: 76, Reward: 0.0\n",
      "Episode: 77, Reward: 0.0\n",
      "Episode: 78, Reward: 0.0\n",
      "Episode: 79, Reward: 0.0\n",
      "Episode: 80, Reward: 0.0\n",
      "Episode: 81, Reward: 0.0\n",
      "Episode: 82, Reward: 0.0\n",
      "Episode: 83, Reward: 0.0\n",
      "Episode: 84, Reward: 0.0\n",
      "Episode: 85, Reward: 0.0\n",
      "Episode: 86, Reward: 0.0\n",
      "Episode: 87, Reward: 0.0\n",
      "Episode: 88, Reward: 0.0\n",
      "Episode: 89, Reward: 0.0\n",
      "Episode: 90, Reward: 0.0\n",
      "Episode: 91, Reward: 0.0\n",
      "Episode: 92, Reward: 0.0\n",
      "Episode: 93, Reward: 0.0\n",
      "Episode: 94, Reward: 0.0\n",
      "Episode: 95, Reward: 0.0\n",
      "Episode: 96, Reward: 0.0\n",
      "Episode: 97, Reward: 0.0\n",
      "Episode: 98, Reward: 0.0\n",
      "Episode: 99, Reward: 0.0\n",
      "Episode: 100, Reward: 0.0\n",
      "Episode: 101, Reward: 0.0\n",
      "Episode: 102, Reward: 0.0\n",
      "Episode: 103, Reward: 0.0\n",
      "Episode: 104, Reward: 0.0\n",
      "Episode: 105, Reward: 0.0\n",
      "Episode: 106, Reward: 0.0\n",
      "Episode: 107, Reward: 0.0\n",
      "Episode: 108, Reward: 0.0\n",
      "Episode: 109, Reward: 0.0\n",
      "Episode: 110, Reward: 0.0\n",
      "Episode: 111, Reward: 0.0\n",
      "Episode: 112, Reward: 0.0\n",
      "Episode: 113, Reward: 0.0\n",
      "Episode: 114, Reward: 0.0\n",
      "Episode: 115, Reward: 0.0\n",
      "Episode: 116, Reward: 0.0\n",
      "Episode: 117, Reward: 0.0\n",
      "Episode: 118, Reward: 0.0\n",
      "Episode: 119, Reward: 0.0\n",
      "Episode: 120, Reward: 0.0\n",
      "Episode: 121, Reward: 0.0\n",
      "Episode: 122, Reward: 0.0\n",
      "Episode: 123, Reward: 0.0\n",
      "Episode: 124, Reward: 0.0\n",
      "Episode: 125, Reward: 0.0\n",
      "Episode: 126, Reward: 0.0\n",
      "Episode: 127, Reward: 0.0\n",
      "Episode: 128, Reward: 0.0\n",
      "Episode: 129, Reward: 0.0\n",
      "Episode: 130, Reward: 0.0\n",
      "Episode: 131, Reward: 0.0\n",
      "Episode: 132, Reward: 0.0\n",
      "Episode: 133, Reward: 0.0\n",
      "Episode: 134, Reward: 0.0\n",
      "Episode: 135, Reward: 0.0\n",
      "Episode: 136, Reward: 0.0\n",
      "Episode: 137, Reward: 0.0\n",
      "Episode: 138, Reward: 0.0\n",
      "Episode: 139, Reward: 0.0\n",
      "Episode: 140, Reward: 0.0\n",
      "Episode: 141, Reward: 0.0\n",
      "Episode: 142, Reward: 0.0\n",
      "Episode: 143, Reward: 0.0\n",
      "Episode: 144, Reward: 0.0\n",
      "Episode: 145, Reward: 0.0\n",
      "Episode: 146, Reward: 0.0\n",
      "Episode: 147, Reward: 0.0\n",
      "Episode: 148, Reward: 0.0\n",
      "Episode: 149, Reward: 0.0\n",
      "Episode: 150, Reward: 0.0\n",
      "Episode: 151, Reward: 0.0\n",
      "Episode: 152, Reward: 0.0\n",
      "Episode: 153, Reward: 0.0\n",
      "Episode: 154, Reward: 0.0\n",
      "Episode: 155, Reward: 0.0\n",
      "Episode: 156, Reward: 0.0\n",
      "Episode: 157, Reward: 0.0\n",
      "Episode: 158, Reward: 0.0\n",
      "Episode: 159, Reward: 0.0\n",
      "Episode: 160, Reward: 0.0\n",
      "Episode: 161, Reward: 0.0\n",
      "Episode: 162, Reward: 0.0\n",
      "Episode: 163, Reward: 0.0\n",
      "Episode: 164, Reward: 0.0\n",
      "Episode: 165, Reward: 0.0\n",
      "Episode: 166, Reward: 0.0\n",
      "Episode: 167, Reward: 0.0\n",
      "Episode: 168, Reward: 0.0\n",
      "Episode: 169, Reward: 0.0\n",
      "Episode: 170, Reward: 0.0\n",
      "Episode: 171, Reward: 0.0\n",
      "Episode: 172, Reward: 0.0\n",
      "Episode: 173, Reward: 0.0\n",
      "Episode: 174, Reward: 0.0\n",
      "Episode: 175, Reward: 0.0\n",
      "Episode: 176, Reward: 0.0\n",
      "Episode: 177, Reward: 0.0\n",
      "Episode: 178, Reward: 0.0\n",
      "Episode: 179, Reward: 0.0\n",
      "Episode: 180, Reward: 0.0\n",
      "Episode: 181, Reward: 0.0\n",
      "Episode: 182, Reward: 0.0\n",
      "Episode: 183, Reward: 0.0\n",
      "Episode: 184, Reward: 0.0\n",
      "Episode: 185, Reward: 0.0\n",
      "Episode: 186, Reward: 0.0\n",
      "Episode: 187, Reward: 0.0\n",
      "Episode: 188, Reward: 0.0\n",
      "Episode: 189, Reward: 0.0\n",
      "Episode: 190, Reward: 0.0\n",
      "Episode: 191, Reward: 0.0\n",
      "Episode: 192, Reward: 0.0\n",
      "Episode: 193, Reward: 0.0\n",
      "Episode: 194, Reward: 0.0\n",
      "Episode: 195, Reward: 0.0\n",
      "Episode: 196, Reward: 0.0\n",
      "Episode: 197, Reward: 0.0\n",
      "Episode: 198, Reward: 0.0\n",
      "Episode: 199, Reward: 0.0\n",
      "END - Date-Time: 2023-08-21 08:26:20\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[1, 7, 9, 17, 20, 22, 24, 27, 43, 46, 52, 54, 57, 61, 67, 78, 83, 85, 98, 99, 100, 101, 106, 108, 131, 134, 139, 141, 144, 156, 158, 164, 170, 172, 173, 183, 184, 185, 186, 191]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_VENTURE-V5 EXPERIMENT 7: Date-Time: 2023-08-21 08:26:47, Capacity: 500\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 500\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 0.0\n",
      "Episode: 8, Reward: 0.0\n",
      "Episode: 9, Reward: 0.0\n",
      "Episode: 10, Reward: 0.0\n",
      "Episode: 11, Reward: 0.0\n",
      "Episode: 12, Reward: 0.0\n",
      "Episode: 13, Reward: 0.0\n",
      "Episode: 14, Reward: 0.0\n",
      "Episode: 15, Reward: 0.0\n",
      "Episode: 16, Reward: 0.0\n",
      "Episode: 17, Reward: 0.0\n",
      "Episode: 18, Reward: 0.0\n",
      "Episode: 19, Reward: 0.0\n",
      "Episode: 20, Reward: 0.0\n",
      "Episode: 21, Reward: 0.0\n",
      "Episode: 22, Reward: 0.0\n",
      "Episode: 23, Reward: 0.0\n",
      "Episode: 24, Reward: 0.0\n",
      "Episode: 25, Reward: 0.0\n",
      "Episode: 26, Reward: 0.0\n",
      "Episode: 27, Reward: 0.0\n",
      "Episode: 28, Reward: 0.0\n",
      "Episode: 29, Reward: 0.0\n",
      "Episode: 30, Reward: 0.0\n",
      "Episode: 31, Reward: 0.0\n",
      "Episode: 32, Reward: 0.0\n",
      "Episode: 33, Reward: 0.0\n",
      "Episode: 34, Reward: 0.0\n",
      "Episode: 35, Reward: 0.0\n",
      "Episode: 36, Reward: 0.0\n",
      "Episode: 37, Reward: 0.0\n",
      "Episode: 38, Reward: 0.0\n",
      "Episode: 39, Reward: 0.0\n",
      "Episode: 40, Reward: 0.0\n",
      "Episode: 41, Reward: 0.0\n",
      "Episode: 42, Reward: 0.0\n",
      "Episode: 43, Reward: 0.0\n",
      "Episode: 44, Reward: 0.0\n",
      "Episode: 45, Reward: 0.0\n",
      "Episode: 46, Reward: 0.0\n",
      "Episode: 47, Reward: 0.0\n",
      "Episode: 48, Reward: 0.0\n",
      "Episode: 49, Reward: 0.0\n",
      "Episode: 50, Reward: 0.0\n",
      "Episode: 51, Reward: 0.0\n",
      "Episode: 52, Reward: 0.0\n",
      "Episode: 53, Reward: 0.0\n",
      "Episode: 54, Reward: 0.0\n",
      "Episode: 55, Reward: 0.0\n",
      "Episode: 56, Reward: 0.0\n",
      "Episode: 57, Reward: 0.0\n",
      "Episode: 58, Reward: 0.0\n",
      "Episode: 59, Reward: 0.0\n",
      "Episode: 60, Reward: 0.0\n",
      "Episode: 61, Reward: 0.0\n",
      "Episode: 62, Reward: 0.0\n",
      "Episode: 63, Reward: 0.0\n",
      "Episode: 64, Reward: 0.0\n",
      "Episode: 65, Reward: 0.0\n",
      "Episode: 66, Reward: 0.0\n",
      "Episode: 67, Reward: 0.0\n",
      "Episode: 68, Reward: 0.0\n",
      "Episode: 69, Reward: 0.0\n",
      "Episode: 70, Reward: 0.0\n",
      "Episode: 71, Reward: 0.0\n",
      "Episode: 72, Reward: 0.0\n",
      "Episode: 73, Reward: 0.0\n",
      "Episode: 74, Reward: 0.0\n",
      "Episode: 75, Reward: 0.0\n",
      "Episode: 76, Reward: 0.0\n",
      "Episode: 77, Reward: 0.0\n",
      "Episode: 78, Reward: 0.0\n",
      "Episode: 79, Reward: 0.0\n",
      "Episode: 80, Reward: 0.0\n",
      "Episode: 81, Reward: 0.0\n",
      "Episode: 82, Reward: 0.0\n",
      "Episode: 83, Reward: 0.0\n",
      "Episode: 84, Reward: 0.0\n",
      "Episode: 85, Reward: 0.0\n",
      "Episode: 86, Reward: 0.0\n",
      "Episode: 87, Reward: 0.0\n",
      "Episode: 88, Reward: 0.0\n",
      "Episode: 89, Reward: 0.0\n",
      "Episode: 90, Reward: 0.0\n",
      "Episode: 91, Reward: 0.0\n",
      "Episode: 92, Reward: 0.0\n",
      "Episode: 93, Reward: 0.0\n",
      "Episode: 94, Reward: 0.0\n",
      "Episode: 95, Reward: 0.0\n",
      "Episode: 96, Reward: 0.0\n",
      "Episode: 97, Reward: 0.0\n",
      "Episode: 98, Reward: 0.0\n",
      "Episode: 99, Reward: 0.0\n",
      "Episode: 100, Reward: 0.0\n",
      "Episode: 101, Reward: 0.0\n",
      "Episode: 102, Reward: 0.0\n",
      "Episode: 103, Reward: 0.0\n",
      "Episode: 104, Reward: 0.0\n",
      "Episode: 105, Reward: 0.0\n",
      "Episode: 106, Reward: 0.0\n",
      "Episode: 107, Reward: 0.0\n",
      "Episode: 108, Reward: 0.0\n",
      "Episode: 109, Reward: 0.0\n",
      "Episode: 110, Reward: 0.0\n",
      "Episode: 111, Reward: 0.0\n",
      "Episode: 112, Reward: 0.0\n",
      "Episode: 113, Reward: 0.0\n",
      "Episode: 114, Reward: 0.0\n",
      "Episode: 115, Reward: 0.0\n",
      "Episode: 116, Reward: 0.0\n",
      "Episode: 117, Reward: 0.0\n",
      "Episode: 118, Reward: 0.0\n",
      "Episode: 119, Reward: 0.0\n",
      "Episode: 120, Reward: 0.0\n",
      "Episode: 121, Reward: 0.0\n",
      "Episode: 122, Reward: 0.0\n",
      "Episode: 123, Reward: 0.0\n",
      "Episode: 124, Reward: 0.0\n",
      "Episode: 125, Reward: 0.0\n",
      "Episode: 126, Reward: 0.0\n",
      "Episode: 127, Reward: 0.0\n",
      "Episode: 128, Reward: 0.0\n",
      "Episode: 129, Reward: 0.0\n",
      "Episode: 130, Reward: 0.0\n",
      "Episode: 131, Reward: 0.0\n",
      "Episode: 132, Reward: 0.0\n",
      "Episode: 133, Reward: 0.0\n",
      "Episode: 134, Reward: 0.0\n",
      "Episode: 135, Reward: 0.0\n",
      "Episode: 136, Reward: 0.0\n",
      "Episode: 137, Reward: 0.0\n",
      "Episode: 138, Reward: 0.0\n",
      "Episode: 139, Reward: 0.0\n",
      "Episode: 140, Reward: 0.0\n",
      "Episode: 141, Reward: 0.0\n",
      "Episode: 142, Reward: 0.0\n",
      "Episode: 143, Reward: 0.0\n",
      "Episode: 144, Reward: 0.0\n",
      "Episode: 145, Reward: 0.0\n",
      "Episode: 146, Reward: 0.0\n",
      "Episode: 147, Reward: 0.0\n",
      "Episode: 148, Reward: 0.0\n",
      "Episode: 149, Reward: 0.0\n",
      "Episode: 150, Reward: 0.0\n",
      "Episode: 151, Reward: 0.0\n",
      "Episode: 152, Reward: 0.0\n",
      "Episode: 153, Reward: 0.0\n",
      "Episode: 154, Reward: 0.0\n",
      "Episode: 155, Reward: 0.0\n",
      "Episode: 156, Reward: 0.0\n",
      "Episode: 157, Reward: 0.0\n",
      "Episode: 158, Reward: 0.0\n",
      "Episode: 159, Reward: 0.0\n",
      "Episode: 160, Reward: 0.0\n",
      "Episode: 161, Reward: 0.0\n",
      "Episode: 162, Reward: 0.0\n",
      "Episode: 163, Reward: 0.0\n",
      "Episode: 164, Reward: 0.0\n",
      "Episode: 165, Reward: 0.0\n",
      "Episode: 166, Reward: 0.0\n",
      "Episode: 167, Reward: 0.0\n",
      "Episode: 168, Reward: 0.0\n",
      "Episode: 169, Reward: 0.0\n",
      "Episode: 170, Reward: 0.0\n",
      "Episode: 171, Reward: 0.0\n",
      "Episode: 172, Reward: 0.0\n",
      "Episode: 173, Reward: 0.0\n",
      "Episode: 174, Reward: 0.0\n",
      "Episode: 175, Reward: 0.0\n",
      "Episode: 176, Reward: 0.0\n",
      "Episode: 177, Reward: 0.0\n",
      "Episode: 178, Reward: 0.0\n",
      "Episode: 179, Reward: 0.0\n",
      "Episode: 180, Reward: 0.0\n",
      "Episode: 181, Reward: 0.0\n",
      "Episode: 182, Reward: 0.0\n",
      "Episode: 183, Reward: 0.0\n",
      "Episode: 184, Reward: 0.0\n",
      "Episode: 185, Reward: 0.0\n",
      "Episode: 186, Reward: 0.0\n",
      "Episode: 187, Reward: 0.0\n",
      "Episode: 188, Reward: 0.0\n",
      "Episode: 189, Reward: 0.0\n",
      "Episode: 190, Reward: 0.0\n",
      "Episode: 191, Reward: 0.0\n",
      "Episode: 192, Reward: 0.0\n",
      "Episode: 193, Reward: 0.0\n",
      "Episode: 194, Reward: 0.0\n",
      "Episode: 195, Reward: 0.0\n",
      "Episode: 196, Reward: 0.0\n",
      "Episode: 197, Reward: 0.0\n",
      "Episode: 198, Reward: 0.0\n",
      "Episode: 199, Reward: 0.0\n",
      "END - Date-Time: 2023-08-21 08:30:53\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[6, 15, 18, 27, 30, 36, 38, 39, 40, 41, 51, 54, 61, 64, 71, 72, 82, 83, 104, 105, 107, 108, 114, 116, 119, 124, 126, 134, 141, 148, 149, 151, 152, 171, 172, 182, 183, 184, 185, 187]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "Saving rewards to csv\n",
      "Saving boxplot of results\n",
      "Average Accumulated Reward: 0.0\n",
      "ALE_WIZARDOFWOR-V5 EXPERIMENT 0: Date-Time: 2023-08-21 08:31:23, Capacity: 1M\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 1000000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 400.0\n",
      "Episode: 6, Reward: 400.0\n",
      "Episode: 7, Reward: 400.0\n",
      "Episode: 8, Reward: 250.0\n",
      "Episode: 9, Reward: 250.0\n",
      "Episode: 10, Reward: 166.67\n",
      "Episode: 11, Reward: 125.0\n",
      "Episode: 12, Reward: 125.0\n",
      "Episode: 13, Reward: 125.0\n",
      "Episode: 14, Reward: 100.0\n",
      "Episode: 15, Reward: 100.0\n",
      "Episode: 16, Reward: 100.0\n",
      "Episode: 17, Reward: 100.0\n",
      "Episode: 18, Reward: 100.0\n",
      "Episode: 19, Reward: 133.33\n",
      "Episode: 20, Reward: 133.33\n",
      "Episode: 21, Reward: 133.33\n",
      "Episode: 22, Reward: 133.33\n",
      "Episode: 23, Reward: 128.57\n",
      "Episode: 24, Reward: 128.57\n",
      "Episode: 25, Reward: 112.5\n",
      "Episode: 26, Reward: 112.5\n",
      "Episode: 27, Reward: 112.5\n",
      "Episode: 28, Reward: 112.5\n",
      "Episode: 29, Reward: 112.5\n",
      "Episode: 30, Reward: 133.33\n",
      "Episode: 31, Reward: 133.33\n",
      "Episode: 32, Reward: 133.33\n",
      "Episode: 33, Reward: 133.33\n",
      "Episode: 34, Reward: 130.0\n",
      "Episode: 35, Reward: 130.0\n",
      "Episode: 36, Reward: 90.0\n",
      "Episode: 37, Reward: 90.0\n",
      "Episode: 38, Reward: 100.0\n",
      "Episode: 39, Reward: 100.0\n",
      "Episode: 40, Reward: 100.0\n",
      "Episode: 41, Reward: 100.0\n",
      "Episode: 42, Reward: 100.0\n",
      "Episode: 43, Reward: 100.0\n",
      "Episode: 44, Reward: 120.0\n",
      "Episode: 45, Reward: 120.0\n",
      "Episode: 46, Reward: 120.0\n",
      "Episode: 47, Reward: 120.0\n",
      "Episode: 48, Reward: 140.0\n",
      "Episode: 49, Reward: 140.0\n",
      "Episode: 50, Reward: 140.0\n",
      "Episode: 51, Reward: 140.0\n",
      "Episode: 52, Reward: 160.0\n",
      "Episode: 53, Reward: 160.0\n",
      "Episode: 54, Reward: 160.0\n",
      "Episode: 55, Reward: 130.0\n",
      "Episode: 56, Reward: 130.0\n",
      "Episode: 57, Reward: 130.0\n",
      "Episode: 58, Reward: 140.0\n",
      "Episode: 59, Reward: 140.0\n",
      "Episode: 60, Reward: 140.0\n",
      "Episode: 61, Reward: 140.0\n",
      "Episode: 62, Reward: 140.0\n",
      "Episode: 63, Reward: 110.0\n",
      "Episode: 64, Reward: 110.0\n",
      "Episode: 65, Reward: 110.0\n",
      "Episode: 66, Reward: 100.0\n",
      "Episode: 67, Reward: 100.0\n",
      "Episode: 68, Reward: 100.0\n",
      "Episode: 69, Reward: 80.0\n",
      "Episode: 70, Reward: 80.0\n",
      "Episode: 71, Reward: 60.0\n",
      "Episode: 72, Reward: 60.0\n",
      "Episode: 73, Reward: 60.0\n",
      "Episode: 74, Reward: 60.0\n",
      "Episode: 75, Reward: 60.0\n",
      "Episode: 76, Reward: 60.0\n",
      "Episode: 77, Reward: 50.0\n",
      "Episode: 78, Reward: 50.0\n",
      "Episode: 79, Reward: 50.0\n",
      "Episode: 80, Reward: 50.0\n",
      "Episode: 81, Reward: 30.0\n",
      "Episode: 82, Reward: 30.0\n",
      "Episode: 83, Reward: 30.0\n",
      "Episode: 84, Reward: 30.0\n",
      "Episode: 85, Reward: 50.0\n",
      "Episode: 86, Reward: 50.0\n",
      "Episode: 87, Reward: 50.0\n",
      "Episode: 88, Reward: 60.0\n",
      "Episode: 89, Reward: 60.0\n",
      "Episode: 90, Reward: 60.0\n",
      "Episode: 91, Reward: 60.0\n",
      "Episode: 92, Reward: 60.0\n",
      "Episode: 93, Reward: 60.0\n",
      "Episode: 94, Reward: 80.0\n",
      "Episode: 95, Reward: 80.0\n",
      "Episode: 96, Reward: 90.0\n",
      "Episode: 97, Reward: 90.0\n",
      "Episode: 98, Reward: 90.0\n",
      "Episode: 99, Reward: 90.0\n",
      "Episode: 100, Reward: 90.0\n",
      "Episode: 101, Reward: 70.0\n",
      "Episode: 102, Reward: 60.0\n",
      "Episode: 103, Reward: 60.0\n",
      "Episode: 104, Reward: 60.0\n",
      "Episode: 105, Reward: 60.0\n",
      "Episode: 106, Reward: 60.0\n",
      "Episode: 107, Reward: 60.0\n",
      "Episode: 108, Reward: 60.0\n",
      "Episode: 109, Reward: 60.0\n",
      "Episode: 110, Reward: 90.0\n",
      "Episode: 111, Reward: 70.0\n",
      "Episode: 112, Reward: 70.0\n",
      "Episode: 113, Reward: 70.0\n",
      "Episode: 114, Reward: 70.0\n",
      "Episode: 115, Reward: 70.0\n",
      "Episode: 116, Reward: 70.0\n",
      "Episode: 117, Reward: 60.0\n",
      "Episode: 118, Reward: 60.0\n",
      "Episode: 119, Reward: 60.0\n",
      "Episode: 120, Reward: 60.0\n",
      "Episode: 121, Reward: 60.0\n",
      "Episode: 122, Reward: 70.0\n",
      "Episode: 123, Reward: 70.0\n",
      "Episode: 124, Reward: 70.0\n",
      "Episode: 125, Reward: 70.0\n",
      "Episode: 126, Reward: 80.0\n",
      "Episode: 127, Reward: 80.0\n",
      "Episode: 128, Reward: 80.0\n",
      "Episode: 129, Reward: 80.0\n",
      "Episode: 130, Reward: 80.0\n",
      "Episode: 131, Reward: 80.0\n",
      "Episode: 132, Reward: 80.0\n",
      "Episode: 133, Reward: 80.0\n",
      "Episode: 134, Reward: 100.0\n",
      "Episode: 135, Reward: 100.0\n",
      "Episode: 136, Reward: 100.0\n",
      "Episode: 137, Reward: 100.0\n",
      "Episode: 138, Reward: 100.0\n",
      "Episode: 139, Reward: 100.0\n",
      "Episode: 140, Reward: 100.0\n",
      "Episode: 141, Reward: 70.0\n",
      "Episode: 142, Reward: 70.0\n",
      "Episode: 143, Reward: 70.0\n",
      "Episode: 144, Reward: 70.0\n",
      "Episode: 145, Reward: 70.0\n",
      "Episode: 146, Reward: 70.0\n",
      "Episode: 147, Reward: 70.0\n",
      "Episode: 148, Reward: 70.0\n",
      "Episode: 149, Reward: 70.0\n",
      "Episode: 150, Reward: 60.0\n",
      "Episode: 151, Reward: 60.0\n",
      "Episode: 152, Reward: 60.0\n",
      "Episode: 153, Reward: 60.0\n",
      "Episode: 154, Reward: 60.0\n",
      "Episode: 155, Reward: 70.0\n",
      "Episode: 156, Reward: 70.0\n",
      "Episode: 157, Reward: 70.0\n",
      "Episode: 158, Reward: 70.0\n",
      "Episode: 159, Reward: 90.0\n",
      "Episode: 160, Reward: 90.0\n",
      "Episode: 161, Reward: 90.0\n",
      "Episode: 162, Reward: 90.0\n",
      "Episode: 163, Reward: 100.0\n",
      "Episode: 164, Reward: 90.0\n",
      "Episode: 165, Reward: 90.0\n",
      "Episode: 166, Reward: 90.0\n",
      "Episode: 167, Reward: 90.0\n",
      "Episode: 168, Reward: 90.0\n",
      "Episode: 169, Reward: 90.0\n",
      "Episode: 170, Reward: 120.0\n",
      "Episode: 171, Reward: 120.0\n",
      "Episode: 172, Reward: 140.0\n",
      "Episode: 173, Reward: 140.0\n",
      "Episode: 174, Reward: 140.0\n",
      "Episode: 175, Reward: 140.0\n",
      "Episode: 176, Reward: 140.0\n",
      "Episode: 177, Reward: 160.0\n",
      "Episode: 178, Reward: 160.0\n",
      "Episode: 179, Reward: 160.0\n",
      "Episode: 180, Reward: 160.0\n",
      "Episode: 181, Reward: 190.0\n",
      "Episode: 182, Reward: 190.0\n",
      "Episode: 183, Reward: 190.0\n",
      "Episode: 184, Reward: 190.0\n",
      "Episode: 185, Reward: 190.0\n",
      "Episode: 186, Reward: 190.0\n",
      "Episode: 187, Reward: 190.0\n",
      "Episode: 188, Reward: 190.0\n",
      "Episode: 189, Reward: 190.0\n",
      "Episode: 190, Reward: 190.0\n",
      "Episode: 191, Reward: 190.0\n",
      "Episode: 192, Reward: 200.0\n",
      "Episode: 193, Reward: 200.0\n",
      "Episode: 194, Reward: 190.0\n",
      "Episode: 195, Reward: 190.0\n",
      "Episode: 196, Reward: 190.0\n",
      "Episode: 197, Reward: 190.0\n",
      "Episode: 198, Reward: 190.0\n",
      "Episode: 199, Reward: 180.0\n",
      "END - Date-Time: 2023-08-21 08:45:05\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[10, 11, 18, 24, 38, 41, 49, 55, 59, 61, 72, 74, 75, 80, 83, 85, 100, 105, 110, 111, 115, 118, 119, 122, 124, 136, 139, 144, 146, 147, 154, 155, 158, 161, 162, 167, 170, 183, 186, 192]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_WIZARDOFWOR-V5 EXPERIMENT 1: Date-Time: 2023-08-21 08:45:31, Capacity: 500k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 500000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 0.0\n",
      "Episode: 8, Reward: 0.0\n",
      "Episode: 9, Reward: 0.0\n",
      "Episode: 10, Reward: 0.0\n",
      "Episode: 11, Reward: 500.0\n",
      "Episode: 12, Reward: 300.0\n",
      "Episode: 13, Reward: 300.0\n",
      "Episode: 14, Reward: 233.33\n",
      "Episode: 15, Reward: 233.33\n",
      "Episode: 16, Reward: 175.0\n",
      "Episode: 17, Reward: 140.0\n",
      "Episode: 18, Reward: 140.0\n",
      "Episode: 19, Reward: 116.67\n",
      "Episode: 20, Reward: 100.0\n",
      "Episode: 21, Reward: 100.0\n",
      "Episode: 22, Reward: 87.5\n",
      "Episode: 23, Reward: 87.5\n",
      "Episode: 24, Reward: 87.5\n",
      "Episode: 25, Reward: 87.5\n",
      "Episode: 26, Reward: 88.89\n",
      "Episode: 27, Reward: 88.89\n",
      "Episode: 28, Reward: 88.89\n",
      "Episode: 29, Reward: 88.89\n",
      "Episode: 30, Reward: 88.89\n",
      "Episode: 31, Reward: 110.0\n",
      "Episode: 32, Reward: 110.0\n",
      "Episode: 33, Reward: 110.0\n",
      "Episode: 34, Reward: 110.0\n",
      "Episode: 35, Reward: 80.0\n",
      "Episode: 36, Reward: 80.0\n",
      "Episode: 37, Reward: 70.0\n",
      "Episode: 38, Reward: 70.0\n",
      "Episode: 39, Reward: 70.0\n",
      "Episode: 40, Reward: 70.0\n",
      "Episode: 41, Reward: 70.0\n",
      "Episode: 42, Reward: 80.0\n",
      "Episode: 43, Reward: 80.0\n",
      "Episode: 44, Reward: 80.0\n",
      "Episode: 45, Reward: 80.0\n",
      "Episode: 46, Reward: 80.0\n",
      "Episode: 47, Reward: 110.0\n",
      "Episode: 48, Reward: 110.0\n",
      "Episode: 49, Reward: 110.0\n",
      "Episode: 50, Reward: 110.0\n",
      "Episode: 51, Reward: 110.0\n",
      "Episode: 52, Reward: 110.0\n",
      "Episode: 53, Reward: 110.0\n",
      "Episode: 54, Reward: 110.0\n",
      "Episode: 55, Reward: 110.0\n",
      "Episode: 56, Reward: 120.0\n",
      "Episode: 57, Reward: 120.0\n",
      "Episode: 58, Reward: 120.0\n",
      "Episode: 59, Reward: 120.0\n",
      "Episode: 60, Reward: 110.0\n",
      "Episode: 61, Reward: 110.0\n",
      "Episode: 62, Reward: 110.0\n",
      "Episode: 63, Reward: 90.0\n",
      "Episode: 64, Reward: 90.0\n",
      "Episode: 65, Reward: 90.0\n",
      "Episode: 66, Reward: 90.0\n",
      "Episode: 67, Reward: 90.0\n",
      "Episode: 68, Reward: 80.0\n",
      "Episode: 69, Reward: 80.0\n",
      "Episode: 70, Reward: 80.0\n",
      "Episode: 71, Reward: 80.0\n",
      "Episode: 72, Reward: 100.0\n",
      "Episode: 73, Reward: 100.0\n",
      "Episode: 74, Reward: 80.0\n",
      "Episode: 75, Reward: 80.0\n",
      "Episode: 76, Reward: 50.0\n",
      "Episode: 77, Reward: 50.0\n",
      "Episode: 78, Reward: 50.0\n",
      "Episode: 79, Reward: 50.0\n",
      "Episode: 80, Reward: 50.0\n",
      "Episode: 81, Reward: 50.0\n",
      "Episode: 82, Reward: 60.0\n",
      "Episode: 83, Reward: 60.0\n",
      "Episode: 84, Reward: 60.0\n",
      "Episode: 85, Reward: 50.0\n",
      "Episode: 86, Reward: 50.0\n",
      "Episode: 87, Reward: 50.0\n",
      "Episode: 88, Reward: 50.0\n",
      "Episode: 89, Reward: 80.0\n",
      "Episode: 90, Reward: 80.0\n",
      "Episode: 91, Reward: 70.0\n",
      "Episode: 92, Reward: 70.0\n",
      "Episode: 93, Reward: 60.0\n",
      "Episode: 94, Reward: 60.0\n",
      "Episode: 95, Reward: 50.0\n",
      "Episode: 96, Reward: 50.0\n",
      "Episode: 97, Reward: 50.0\n",
      "Episode: 98, Reward: 70.0\n",
      "Episode: 99, Reward: 70.0\n",
      "Episode: 100, Reward: 90.0\n",
      "Episode: 101, Reward: 90.0\n",
      "Episode: 102, Reward: 100.0\n",
      "Episode: 103, Reward: 100.0\n",
      "Episode: 104, Reward: 100.0\n",
      "Episode: 105, Reward: 100.0\n",
      "Episode: 106, Reward: 120.0\n",
      "Episode: 107, Reward: 120.0\n",
      "Episode: 108, Reward: 120.0\n",
      "Episode: 109, Reward: 120.0\n",
      "Episode: 110, Reward: 120.0\n",
      "Episode: 111, Reward: 150.0\n",
      "Episode: 112, Reward: 150.0\n",
      "Episode: 113, Reward: 120.0\n",
      "Episode: 114, Reward: 120.0\n",
      "Episode: 115, Reward: 120.0\n",
      "Episode: 116, Reward: 120.0\n",
      "Episode: 117, Reward: 120.0\n",
      "Episode: 118, Reward: 150.0\n",
      "Episode: 119, Reward: 150.0\n",
      "Episode: 120, Reward: 170.0\n",
      "Episode: 121, Reward: 170.0\n",
      "Episode: 122, Reward: 160.0\n",
      "Episode: 123, Reward: 160.0\n",
      "Episode: 124, Reward: 160.0\n",
      "Episode: 125, Reward: 150.0\n",
      "Episode: 126, Reward: 130.0\n",
      "Episode: 127, Reward: 130.0\n",
      "Episode: 128, Reward: 120.0\n",
      "Episode: 129, Reward: 120.0\n",
      "Episode: 130, Reward: 120.0\n",
      "Episode: 131, Reward: 120.0\n",
      "Episode: 132, Reward: 110.0\n",
      "Episode: 133, Reward: 110.0\n",
      "Episode: 134, Reward: 110.0\n",
      "Episode: 135, Reward: 110.0\n",
      "Episode: 136, Reward: 100.0\n",
      "Episode: 137, Reward: 100.0\n",
      "Episode: 138, Reward: 100.0\n",
      "Episode: 139, Reward: 120.0\n",
      "Episode: 140, Reward: 120.0\n",
      "Episode: 141, Reward: 120.0\n",
      "Episode: 142, Reward: 120.0\n",
      "Episode: 143, Reward: 120.0\n",
      "Episode: 144, Reward: 130.0\n",
      "Episode: 145, Reward: 130.0\n",
      "Episode: 146, Reward: 100.0\n",
      "Episode: 147, Reward: 80.0\n",
      "Episode: 148, Reward: 80.0\n",
      "Episode: 149, Reward: 80.0\n",
      "Episode: 150, Reward: 70.0\n",
      "Episode: 151, Reward: 70.0\n",
      "Episode: 152, Reward: 70.0\n",
      "Episode: 153, Reward: 70.0\n",
      "Episode: 154, Reward: 50.0\n",
      "Episode: 155, Reward: 50.0\n",
      "Episode: 156, Reward: 30.0\n",
      "Episode: 157, Reward: 10.0\n",
      "Episode: 158, Reward: 10.0\n",
      "Episode: 159, Reward: 0.0\n",
      "Episode: 160, Reward: 0.0\n",
      "Episode: 161, Reward: 0.0\n",
      "Episode: 162, Reward: 0.0\n",
      "Episode: 163, Reward: 30.0\n",
      "Episode: 164, Reward: 30.0\n",
      "Episode: 165, Reward: 30.0\n",
      "Episode: 166, Reward: 30.0\n",
      "Episode: 167, Reward: 30.0\n",
      "Episode: 168, Reward: 30.0\n",
      "Episode: 169, Reward: 30.0\n",
      "Episode: 170, Reward: 80.0\n",
      "Episode: 171, Reward: 80.0\n",
      "Episode: 172, Reward: 80.0\n",
      "Episode: 173, Reward: 80.0\n",
      "Episode: 174, Reward: 110.0\n",
      "Episode: 175, Reward: 110.0\n",
      "Episode: 176, Reward: 110.0\n",
      "Episode: 177, Reward: 110.0\n",
      "Episode: 178, Reward: 110.0\n",
      "Episode: 179, Reward: 140.0\n",
      "Episode: 180, Reward: 140.0\n",
      "Episode: 181, Reward: 140.0\n",
      "Episode: 182, Reward: 160.0\n",
      "Episode: 183, Reward: 160.0\n",
      "Episode: 184, Reward: 180.0\n",
      "Episode: 185, Reward: 180.0\n",
      "Episode: 186, Reward: 180.0\n",
      "Episode: 187, Reward: 190.0\n",
      "Episode: 188, Reward: 190.0\n",
      "Episode: 189, Reward: 190.0\n",
      "Episode: 190, Reward: 190.0\n",
      "Episode: 191, Reward: 200.0\n",
      "Episode: 192, Reward: 200.0\n",
      "Episode: 193, Reward: 200.0\n",
      "Episode: 194, Reward: 200.0\n",
      "Episode: 195, Reward: 200.0\n",
      "Episode: 196, Reward: 200.0\n",
      "Episode: 197, Reward: 200.0\n",
      "Episode: 198, Reward: 210.0\n",
      "Episode: 199, Reward: 210.0\n",
      "END - Date-Time: 2023-08-21 09:00:58\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[4, 5, 12, 30, 36, 38, 53, 54, 61, 64, 65, 72, 79, 87, 92, 94, 96, 103, 111, 112, 116, 117, 119, 124, 136, 140, 141, 150, 154, 158, 160, 161, 162, 169, 174, 176, 190, 191, 192, 196]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_WIZARDOFWOR-V5 EXPERIMENT 2: Date-Time: 2023-08-21 09:01:24, Capacity: 100k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 100000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 800.0\n",
      "Episode: 8, Reward: 400.0\n",
      "Episode: 9, Reward: 400.0\n",
      "Episode: 10, Reward: 266.67\n",
      "Episode: 11, Reward: 266.67\n",
      "Episode: 12, Reward: 266.67\n",
      "Episode: 13, Reward: 266.67\n",
      "Episode: 14, Reward: 225.0\n",
      "Episode: 15, Reward: 225.0\n",
      "Episode: 16, Reward: 225.0\n",
      "Episode: 17, Reward: 225.0\n",
      "Episode: 18, Reward: 220.0\n",
      "Episode: 19, Reward: 220.0\n",
      "Episode: 20, Reward: 220.0\n",
      "Episode: 21, Reward: 200.0\n",
      "Episode: 22, Reward: 200.0\n",
      "Episode: 23, Reward: 200.0\n",
      "Episode: 24, Reward: 185.71\n",
      "Episode: 25, Reward: 185.71\n",
      "Episode: 26, Reward: 175.0\n",
      "Episode: 27, Reward: 175.0\n",
      "Episode: 28, Reward: 155.56\n",
      "Episode: 29, Reward: 140.0\n",
      "Episode: 30, Reward: 140.0\n",
      "Episode: 31, Reward: 60.0\n",
      "Episode: 32, Reward: 60.0\n",
      "Episode: 33, Reward: 60.0\n",
      "Episode: 34, Reward: 60.0\n",
      "Episode: 35, Reward: 60.0\n",
      "Episode: 36, Reward: 60.0\n",
      "Episode: 37, Reward: 60.0\n",
      "Episode: 38, Reward: 60.0\n",
      "Episode: 39, Reward: 70.0\n",
      "Episode: 40, Reward: 70.0\n",
      "Episode: 41, Reward: 70.0\n",
      "Episode: 42, Reward: 70.0\n",
      "Episode: 43, Reward: 70.0\n",
      "Episode: 44, Reward: 80.0\n",
      "Episode: 45, Reward: 80.0\n",
      "Episode: 46, Reward: 80.0\n",
      "Episode: 47, Reward: 80.0\n",
      "Episode: 48, Reward: 80.0\n",
      "Episode: 49, Reward: 80.0\n",
      "Episode: 50, Reward: 80.0\n",
      "Episode: 51, Reward: 80.0\n",
      "Episode: 52, Reward: 80.0\n",
      "Episode: 53, Reward: 80.0\n",
      "Episode: 54, Reward: 80.0\n",
      "Episode: 55, Reward: 100.0\n",
      "Episode: 56, Reward: 100.0\n",
      "Episode: 57, Reward: 100.0\n",
      "Episode: 58, Reward: 100.0\n",
      "Episode: 59, Reward: 100.0\n",
      "Episode: 60, Reward: 100.0\n",
      "Episode: 61, Reward: 100.0\n",
      "Episode: 62, Reward: 100.0\n",
      "Episode: 63, Reward: 100.0\n",
      "Episode: 64, Reward: 100.0\n",
      "Episode: 65, Reward: 110.0\n",
      "Episode: 66, Reward: 110.0\n",
      "Episode: 67, Reward: 110.0\n",
      "Episode: 68, Reward: 110.0\n",
      "Episode: 69, Reward: 110.0\n",
      "Episode: 70, Reward: 110.0\n",
      "Episode: 71, Reward: 130.0\n",
      "Episode: 72, Reward: 130.0\n",
      "Episode: 73, Reward: 130.0\n",
      "Episode: 74, Reward: 120.0\n",
      "Episode: 75, Reward: 120.0\n",
      "Episode: 76, Reward: 110.0\n",
      "Episode: 77, Reward: 90.0\n",
      "Episode: 78, Reward: 90.0\n",
      "Episode: 79, Reward: 60.0\n",
      "Episode: 80, Reward: 60.0\n",
      "Episode: 81, Reward: 60.0\n",
      "Episode: 82, Reward: 60.0\n",
      "Episode: 83, Reward: 70.0\n",
      "Episode: 84, Reward: 70.0\n",
      "Episode: 85, Reward: 60.0\n",
      "Episode: 86, Reward: 60.0\n",
      "Episode: 87, Reward: 60.0\n",
      "Episode: 88, Reward: 60.0\n",
      "Episode: 89, Reward: 60.0\n",
      "Episode: 90, Reward: 60.0\n",
      "Episode: 91, Reward: 70.0\n",
      "Episode: 92, Reward: 70.0\n",
      "Episode: 93, Reward: 70.0\n",
      "Episode: 94, Reward: 50.0\n",
      "Episode: 95, Reward: 50.0\n",
      "Episode: 96, Reward: 60.0\n",
      "Episode: 97, Reward: 60.0\n",
      "Episode: 98, Reward: 70.0\n",
      "Episode: 99, Reward: 70.0\n",
      "Episode: 100, Reward: 70.0\n",
      "Episode: 101, Reward: 70.0\n",
      "Episode: 102, Reward: 70.0\n",
      "Episode: 103, Reward: 70.0\n",
      "Episode: 104, Reward: 70.0\n",
      "Episode: 105, Reward: 90.0\n",
      "Episode: 106, Reward: 90.0\n",
      "Episode: 107, Reward: 100.0\n",
      "Episode: 108, Reward: 100.0\n",
      "Episode: 109, Reward: 80.0\n",
      "Episode: 110, Reward: 80.0\n",
      "Episode: 111, Reward: 80.0\n",
      "Episode: 112, Reward: 80.0\n",
      "Episode: 113, Reward: 80.0\n",
      "Episode: 114, Reward: 80.0\n",
      "Episode: 115, Reward: 80.0\n",
      "Episode: 116, Reward: 60.0\n",
      "Episode: 117, Reward: 60.0\n",
      "Episode: 118, Reward: 70.0\n",
      "Episode: 119, Reward: 70.0\n",
      "Episode: 120, Reward: 70.0\n",
      "Episode: 121, Reward: 60.0\n",
      "Episode: 122, Reward: 60.0\n",
      "Episode: 123, Reward: 50.0\n",
      "Episode: 124, Reward: 40.0\n",
      "Episode: 125, Reward: 20.0\n",
      "Episode: 126, Reward: 20.0\n",
      "Episode: 127, Reward: 10.0\n",
      "Episode: 128, Reward: 10.0\n",
      "Episode: 129, Reward: 10.0\n",
      "Episode: 130, Reward: 10.0\n",
      "Episode: 131, Reward: 10.0\n",
      "Episode: 132, Reward: 10.0\n",
      "Episode: 133, Reward: 40.0\n",
      "Episode: 134, Reward: 40.0\n",
      "Episode: 135, Reward: 40.0\n",
      "Episode: 136, Reward: 40.0\n",
      "Episode: 137, Reward: 40.0\n",
      "Episode: 138, Reward: 40.0\n",
      "Episode: 139, Reward: 40.0\n",
      "Episode: 140, Reward: 70.0\n",
      "Episode: 141, Reward: 70.0\n",
      "Episode: 142, Reward: 70.0\n",
      "Episode: 143, Reward: 70.0\n",
      "Episode: 144, Reward: 70.0\n",
      "Episode: 145, Reward: 80.0\n",
      "Episode: 146, Reward: 80.0\n",
      "Episode: 147, Reward: 80.0\n",
      "Episode: 148, Reward: 80.0\n",
      "Episode: 149, Reward: 110.0\n",
      "Episode: 150, Reward: 110.0\n",
      "Episode: 151, Reward: 110.0\n",
      "Episode: 152, Reward: 110.0\n",
      "Episode: 153, Reward: 110.0\n",
      "Episode: 154, Reward: 110.0\n",
      "Episode: 155, Reward: 110.0\n",
      "Episode: 156, Reward: 110.0\n",
      "Episode: 157, Reward: 110.0\n",
      "Episode: 158, Reward: 110.0\n",
      "Episode: 159, Reward: 120.0\n",
      "Episode: 160, Reward: 120.0\n",
      "Episode: 161, Reward: 120.0\n",
      "Episode: 162, Reward: 120.0\n",
      "Episode: 163, Reward: 120.0\n",
      "Episode: 164, Reward: 130.0\n",
      "Episode: 165, Reward: 100.0\n",
      "Episode: 166, Reward: 100.0\n",
      "Episode: 167, Reward: 70.0\n",
      "Episode: 168, Reward: 60.0\n",
      "Episode: 169, Reward: 60.0\n",
      "Episode: 170, Reward: 60.0\n",
      "Episode: 171, Reward: 50.0\n",
      "Episode: 172, Reward: 50.0\n",
      "Episode: 173, Reward: 20.0\n",
      "Episode: 174, Reward: 20.0\n",
      "Episode: 175, Reward: 30.0\n",
      "Episode: 176, Reward: 30.0\n",
      "Episode: 177, Reward: 30.0\n",
      "Episode: 178, Reward: 30.0\n",
      "Episode: 179, Reward: 30.0\n",
      "Episode: 180, Reward: 30.0\n",
      "Episode: 181, Reward: 30.0\n",
      "Episode: 182, Reward: 30.0\n",
      "Episode: 183, Reward: 50.0\n",
      "Episode: 184, Reward: 50.0\n",
      "Episode: 185, Reward: 50.0\n",
      "Episode: 186, Reward: 70.0\n",
      "Episode: 187, Reward: 70.0\n",
      "Episode: 188, Reward: 70.0\n",
      "Episode: 189, Reward: 70.0\n",
      "Episode: 190, Reward: 90.0\n",
      "Episode: 191, Reward: 90.0\n",
      "Episode: 192, Reward: 90.0\n",
      "Episode: 193, Reward: 90.0\n",
      "Episode: 194, Reward: 90.0\n",
      "Episode: 195, Reward: 90.0\n",
      "Episode: 196, Reward: 90.0\n",
      "Episode: 197, Reward: 100.0\n",
      "Episode: 198, Reward: 100.0\n",
      "Episode: 199, Reward: 100.0\n",
      "END - Date-Time: 2023-08-21 09:17:18\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[9, 10, 16, 19, 28, 39, 43, 49, 50, 51, 57, 58, 67, 68, 69, 76, 81, 94, 98, 105, 116, 118, 119, 120, 122, 130, 137, 141, 142, 150, 154, 158, 170, 171, 173, 178, 191, 194, 198, 199]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_WIZARDOFWOR-V5 EXPERIMENT 3: Date-Time: 2023-08-21 09:17:49, Capacity: 50k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 50000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 0.0\n",
      "Episode: 8, Reward: 800.0\n",
      "Episode: 9, Reward: 400.0\n",
      "Episode: 10, Reward: 266.67\n",
      "Episode: 11, Reward: 266.67\n",
      "Episode: 12, Reward: 266.67\n",
      "Episode: 13, Reward: 266.67\n",
      "Episode: 14, Reward: 266.67\n",
      "Episode: 15, Reward: 200.0\n",
      "Episode: 16, Reward: 160.0\n",
      "Episode: 17, Reward: 160.0\n",
      "Episode: 18, Reward: 133.33\n",
      "Episode: 19, Reward: 133.33\n",
      "Episode: 20, Reward: 133.33\n",
      "Episode: 21, Reward: 133.33\n",
      "Episode: 22, Reward: 133.33\n",
      "Episode: 23, Reward: 133.33\n",
      "Episode: 24, Reward: 142.86\n",
      "Episode: 25, Reward: 142.86\n",
      "Episode: 26, Reward: 125.0\n",
      "Episode: 27, Reward: 111.11\n",
      "Episode: 28, Reward: 111.11\n",
      "Episode: 29, Reward: 111.11\n",
      "Episode: 30, Reward: 111.11\n",
      "Episode: 31, Reward: 111.11\n",
      "Episode: 32, Reward: 120.0\n",
      "Episode: 33, Reward: 120.0\n",
      "Episode: 34, Reward: 120.0\n",
      "Episode: 35, Reward: 120.0\n",
      "Episode: 36, Reward: 60.0\n",
      "Episode: 37, Reward: 60.0\n",
      "Episode: 38, Reward: 60.0\n",
      "Episode: 39, Reward: 60.0\n",
      "Episode: 40, Reward: 60.0\n",
      "Episode: 41, Reward: 80.0\n",
      "Episode: 42, Reward: 80.0\n",
      "Episode: 43, Reward: 80.0\n",
      "Episode: 44, Reward: 80.0\n",
      "Episode: 45, Reward: 80.0\n",
      "Episode: 46, Reward: 80.0\n",
      "Episode: 47, Reward: 80.0\n",
      "Episode: 48, Reward: 80.0\n",
      "Episode: 49, Reward: 80.0\n",
      "Episode: 50, Reward: 110.0\n",
      "Episode: 51, Reward: 110.0\n",
      "Episode: 52, Reward: 110.0\n",
      "Episode: 53, Reward: 110.0\n",
      "Episode: 54, Reward: 140.0\n",
      "Episode: 55, Reward: 140.0\n",
      "Episode: 56, Reward: 120.0\n",
      "Episode: 57, Reward: 120.0\n",
      "Episode: 58, Reward: 120.0\n",
      "Episode: 59, Reward: 120.0\n",
      "Episode: 60, Reward: 120.0\n",
      "Episode: 61, Reward: 150.0\n",
      "Episode: 62, Reward: 150.0\n",
      "Episode: 63, Reward: 160.0\n",
      "Episode: 64, Reward: 160.0\n",
      "Episode: 65, Reward: 140.0\n",
      "Episode: 66, Reward: 140.0\n",
      "Episode: 67, Reward: 120.0\n",
      "Episode: 68, Reward: 120.0\n",
      "Episode: 69, Reward: 120.0\n",
      "Episode: 70, Reward: 100.0\n",
      "Episode: 71, Reward: 100.0\n",
      "Episode: 72, Reward: 100.0\n",
      "Episode: 73, Reward: 100.0\n",
      "Episode: 74, Reward: 100.0\n",
      "Episode: 75, Reward: 120.0\n",
      "Episode: 76, Reward: 120.0\n",
      "Episode: 77, Reward: 120.0\n",
      "Episode: 78, Reward: 110.0\n",
      "Episode: 79, Reward: 110.0\n",
      "Episode: 80, Reward: 110.0\n",
      "Episode: 81, Reward: 110.0\n",
      "Episode: 82, Reward: 80.0\n",
      "Episode: 83, Reward: 80.0\n",
      "Episode: 84, Reward: 80.0\n",
      "Episode: 85, Reward: 80.0\n",
      "Episode: 86, Reward: 100.0\n",
      "Episode: 87, Reward: 100.0\n",
      "Episode: 88, Reward: 80.0\n",
      "Episode: 89, Reward: 80.0\n",
      "Episode: 90, Reward: 80.0\n",
      "Episode: 91, Reward: 80.0\n",
      "Episode: 92, Reward: 80.0\n",
      "Episode: 93, Reward: 80.0\n",
      "Episode: 94, Reward: 90.0\n",
      "Episode: 95, Reward: 90.0\n",
      "Episode: 96, Reward: 90.0\n",
      "Episode: 97, Reward: 90.0\n",
      "Episode: 98, Reward: 90.0\n",
      "Episode: 99, Reward: 90.0\n",
      "Episode: 100, Reward: 90.0\n",
      "Episode: 101, Reward: 90.0\n",
      "Episode: 102, Reward: 90.0\n",
      "Episode: 103, Reward: 70.0\n",
      "Episode: 104, Reward: 70.0\n",
      "Episode: 105, Reward: 70.0\n",
      "Episode: 106, Reward: 70.0\n",
      "Episode: 107, Reward: 70.0\n",
      "Episode: 108, Reward: 70.0\n",
      "Episode: 109, Reward: 60.0\n",
      "Episode: 110, Reward: 60.0\n",
      "Episode: 111, Reward: 60.0\n",
      "Episode: 112, Reward: 60.0\n",
      "Episode: 113, Reward: 40.0\n",
      "Episode: 114, Reward: 40.0\n",
      "Episode: 115, Reward: 40.0\n",
      "Episode: 116, Reward: 40.0\n",
      "Episode: 117, Reward: 40.0\n",
      "Episode: 118, Reward: 50.0\n",
      "Episode: 119, Reward: 50.0\n",
      "Episode: 120, Reward: 30.0\n",
      "Episode: 121, Reward: 30.0\n",
      "Episode: 122, Reward: 30.0\n",
      "Episode: 123, Reward: 30.0\n",
      "Episode: 124, Reward: 30.0\n",
      "Episode: 125, Reward: 60.0\n",
      "Episode: 126, Reward: 60.0\n",
      "Episode: 127, Reward: 60.0\n",
      "Episode: 128, Reward: 60.0\n",
      "Episode: 129, Reward: 60.0\n",
      "Episode: 130, Reward: 60.0\n",
      "Episode: 131, Reward: 60.0\n",
      "Episode: 132, Reward: 60.0\n",
      "Episode: 133, Reward: 60.0\n",
      "Episode: 134, Reward: 60.0\n",
      "Episode: 135, Reward: 60.0\n",
      "Episode: 136, Reward: 70.0\n",
      "Episode: 137, Reward: 70.0\n",
      "Episode: 138, Reward: 70.0\n",
      "Episode: 139, Reward: 70.0\n",
      "Episode: 140, Reward: 70.0\n",
      "Episode: 141, Reward: 70.0\n",
      "Episode: 142, Reward: 70.0\n",
      "Episode: 143, Reward: 70.0\n",
      "Episode: 144, Reward: 80.0\n",
      "Episode: 145, Reward: 80.0\n",
      "Episode: 146, Reward: 80.0\n",
      "Episode: 147, Reward: 80.0\n",
      "Episode: 148, Reward: 80.0\n",
      "Episode: 149, Reward: 80.0\n",
      "Episode: 150, Reward: 80.0\n",
      "Episode: 151, Reward: 50.0\n",
      "Episode: 152, Reward: 50.0\n",
      "Episode: 153, Reward: 50.0\n",
      "Episode: 154, Reward: 50.0\n",
      "Episode: 155, Reward: 50.0\n",
      "Episode: 156, Reward: 50.0\n",
      "Episode: 157, Reward: 50.0\n",
      "Episode: 158, Reward: 50.0\n",
      "Episode: 159, Reward: 70.0\n",
      "Episode: 160, Reward: 70.0\n",
      "Episode: 161, Reward: 70.0\n",
      "Episode: 162, Reward: 70.0\n",
      "Episode: 163, Reward: 70.0\n",
      "Episode: 164, Reward: 70.0\n",
      "Episode: 165, Reward: 80.0\n",
      "Episode: 166, Reward: 80.0\n",
      "Episode: 167, Reward: 80.0\n",
      "Episode: 168, Reward: 80.0\n",
      "Episode: 169, Reward: 80.0\n",
      "Episode: 170, Reward: 80.0\n",
      "Episode: 171, Reward: 90.0\n",
      "Episode: 172, Reward: 90.0\n",
      "Episode: 173, Reward: 90.0\n",
      "Episode: 174, Reward: 90.0\n",
      "Episode: 175, Reward: 110.0\n",
      "Episode: 176, Reward: 110.0\n",
      "Episode: 177, Reward: 110.0\n",
      "Episode: 178, Reward: 110.0\n",
      "Episode: 179, Reward: 100.0\n",
      "Episode: 180, Reward: 100.0\n",
      "Episode: 181, Reward: 100.0\n",
      "Episode: 182, Reward: 100.0\n",
      "Episode: 183, Reward: 100.0\n",
      "Episode: 184, Reward: 100.0\n",
      "Episode: 185, Reward: 100.0\n",
      "Episode: 186, Reward: 100.0\n",
      "Episode: 187, Reward: 150.0\n",
      "Episode: 188, Reward: 150.0\n",
      "Episode: 189, Reward: 150.0\n",
      "Episode: 190, Reward: 170.0\n",
      "Episode: 191, Reward: 170.0\n",
      "Episode: 192, Reward: 170.0\n",
      "Episode: 193, Reward: 190.0\n",
      "Episode: 194, Reward: 190.0\n",
      "Episode: 195, Reward: 190.0\n",
      "Episode: 196, Reward: 190.0\n",
      "Episode: 197, Reward: 170.0\n",
      "Episode: 198, Reward: 170.0\n",
      "Episode: 199, Reward: 180.0\n",
      "END - Date-Time: 2023-08-21 09:33:42\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[6, 15, 21, 25, 30, 31, 39, 42, 43, 45, 47, 58, 61, 70, 72, 81, 82, 91, 95, 96, 98, 111, 113, 114, 115, 121, 123, 138, 147, 148, 156, 159, 161, 162, 168, 171, 178, 192, 196, 199]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_WIZARDOFWOR-V5 EXPERIMENT 4: Date-Time: 2023-08-21 09:34:08, Capacity: 10k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 10000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 200.0\n",
      "Episode: 5, Reward: 200.0\n",
      "Episode: 6, Reward: 200.0\n",
      "Episode: 7, Reward: 200.0\n",
      "Episode: 8, Reward: 200.0\n",
      "Episode: 9, Reward: 200.0\n",
      "Episode: 10, Reward: 300.0\n",
      "Episode: 11, Reward: 300.0\n",
      "Episode: 12, Reward: 300.0\n",
      "Episode: 13, Reward: 300.0\n",
      "Episode: 14, Reward: 300.0\n",
      "Episode: 15, Reward: 300.0\n",
      "Episode: 16, Reward: 250.0\n",
      "Episode: 17, Reward: 200.0\n",
      "Episode: 18, Reward: 200.0\n",
      "Episode: 19, Reward: 200.0\n",
      "Episode: 20, Reward: 200.0\n",
      "Episode: 21, Reward: 200.0\n",
      "Episode: 22, Reward: 200.0\n",
      "Episode: 23, Reward: 200.0\n",
      "Episode: 24, Reward: 200.0\n",
      "Episode: 25, Reward: 171.43\n",
      "Episode: 26, Reward: 171.43\n",
      "Episode: 27, Reward: 171.43\n",
      "Episode: 28, Reward: 171.43\n",
      "Episode: 29, Reward: 171.43\n",
      "Episode: 30, Reward: 175.0\n",
      "Episode: 31, Reward: 175.0\n",
      "Episode: 32, Reward: 175.0\n",
      "Episode: 33, Reward: 155.56\n",
      "Episode: 34, Reward: 155.56\n",
      "Episode: 35, Reward: 155.56\n",
      "Episode: 36, Reward: 155.56\n",
      "Episode: 37, Reward: 155.56\n",
      "Episode: 38, Reward: 155.56\n",
      "Episode: 39, Reward: 150.0\n",
      "Episode: 40, Reward: 150.0\n",
      "Episode: 41, Reward: 150.0\n",
      "Episode: 42, Reward: 150.0\n",
      "Episode: 43, Reward: 160.0\n",
      "Episode: 44, Reward: 160.0\n",
      "Episode: 45, Reward: 160.0\n",
      "Episode: 46, Reward: 160.0\n",
      "Episode: 47, Reward: 130.0\n",
      "Episode: 48, Reward: 130.0\n",
      "Episode: 49, Reward: 130.0\n",
      "Episode: 50, Reward: 100.0\n",
      "Episode: 51, Reward: 100.0\n",
      "Episode: 52, Reward: 100.0\n",
      "Episode: 53, Reward: 100.0\n",
      "Episode: 54, Reward: 100.0\n",
      "Episode: 55, Reward: 110.0\n",
      "Episode: 56, Reward: 110.0\n",
      "Episode: 57, Reward: 120.0\n",
      "Episode: 58, Reward: 120.0\n",
      "Episode: 59, Reward: 100.0\n",
      "Episode: 60, Reward: 100.0\n",
      "Episode: 61, Reward: 100.0\n",
      "Episode: 62, Reward: 100.0\n",
      "Episode: 63, Reward: 90.0\n",
      "Episode: 64, Reward: 90.0\n",
      "Episode: 65, Reward: 90.0\n",
      "Episode: 66, Reward: 80.0\n",
      "Episode: 67, Reward: 50.0\n",
      "Episode: 68, Reward: 50.0\n",
      "Episode: 69, Reward: 50.0\n",
      "Episode: 70, Reward: 50.0\n",
      "Episode: 71, Reward: 50.0\n",
      "Episode: 72, Reward: 80.0\n",
      "Episode: 73, Reward: 80.0\n",
      "Episode: 74, Reward: 60.0\n",
      "Episode: 75, Reward: 60.0\n",
      "Episode: 76, Reward: 60.0\n",
      "Episode: 77, Reward: 60.0\n",
      "Episode: 78, Reward: 60.0\n",
      "Episode: 79, Reward: 70.0\n",
      "Episode: 80, Reward: 70.0\n",
      "Episode: 81, Reward: 70.0\n",
      "Episode: 82, Reward: 80.0\n",
      "Episode: 83, Reward: 80.0\n",
      "Episode: 84, Reward: 80.0\n",
      "Episode: 85, Reward: 80.0\n",
      "Episode: 86, Reward: 80.0\n",
      "Episode: 87, Reward: 70.0\n",
      "Episode: 88, Reward: 70.0\n",
      "Episode: 89, Reward: 70.0\n",
      "Episode: 90, Reward: 70.0\n",
      "Episode: 91, Reward: 70.0\n",
      "Episode: 92, Reward: 70.0\n",
      "Episode: 93, Reward: 70.0\n",
      "Episode: 94, Reward: 70.0\n",
      "Episode: 95, Reward: 70.0\n",
      "Episode: 96, Reward: 70.0\n",
      "Episode: 97, Reward: 70.0\n",
      "Episode: 98, Reward: 100.0\n",
      "Episode: 99, Reward: 100.0\n",
      "Episode: 100, Reward: 100.0\n",
      "Episode: 101, Reward: 80.0\n",
      "Episode: 102, Reward: 80.0\n",
      "Episode: 103, Reward: 80.0\n",
      "Episode: 104, Reward: 80.0\n",
      "Episode: 105, Reward: 80.0\n",
      "Episode: 106, Reward: 80.0\n",
      "Episode: 107, Reward: 80.0\n",
      "Episode: 108, Reward: 80.0\n",
      "Episode: 109, Reward: 60.0\n",
      "Episode: 110, Reward: 60.0\n",
      "Episode: 111, Reward: 60.0\n",
      "Episode: 112, Reward: 60.0\n",
      "Episode: 113, Reward: 70.0\n",
      "Episode: 114, Reward: 70.0\n",
      "Episode: 115, Reward: 70.0\n",
      "Episode: 116, Reward: 70.0\n",
      "Episode: 117, Reward: 70.0\n",
      "Episode: 118, Reward: 100.0\n",
      "Episode: 119, Reward: 100.0\n",
      "Episode: 120, Reward: 100.0\n",
      "Episode: 121, Reward: 100.0\n",
      "Episode: 122, Reward: 120.0\n",
      "Episode: 123, Reward: 120.0\n",
      "Episode: 124, Reward: 120.0\n",
      "Episode: 125, Reward: 120.0\n",
      "Episode: 126, Reward: 120.0\n",
      "Episode: 127, Reward: 150.0\n",
      "Episode: 128, Reward: 150.0\n",
      "Episode: 129, Reward: 150.0\n",
      "Episode: 130, Reward: 150.0\n",
      "Episode: 131, Reward: 180.0\n",
      "Episode: 132, Reward: 180.0\n",
      "Episode: 133, Reward: 150.0\n",
      "Episode: 134, Reward: 130.0\n",
      "Episode: 135, Reward: 130.0\n",
      "Episode: 136, Reward: 130.0\n",
      "Episode: 137, Reward: 130.0\n",
      "Episode: 138, Reward: 130.0\n",
      "Episode: 139, Reward: 130.0\n",
      "Episode: 140, Reward: 110.0\n",
      "Episode: 141, Reward: 80.0\n",
      "Episode: 142, Reward: 60.0\n",
      "Episode: 143, Reward: 60.0\n",
      "Episode: 144, Reward: 30.0\n",
      "Episode: 145, Reward: 30.0\n",
      "Episode: 146, Reward: 10.0\n",
      "Episode: 147, Reward: 10.0\n",
      "Episode: 148, Reward: 10.0\n",
      "Episode: 149, Reward: 20.0\n",
      "Episode: 150, Reward: 20.0\n",
      "Episode: 151, Reward: 20.0\n",
      "Episode: 152, Reward: 20.0\n",
      "Episode: 153, Reward: 40.0\n",
      "Episode: 154, Reward: 40.0\n",
      "Episode: 155, Reward: 40.0\n",
      "Episode: 156, Reward: 40.0\n",
      "Episode: 157, Reward: 40.0\n",
      "Episode: 158, Reward: 40.0\n",
      "Episode: 159, Reward: 40.0\n",
      "Episode: 160, Reward: 70.0\n",
      "Episode: 161, Reward: 70.0\n",
      "Episode: 162, Reward: 70.0\n",
      "Episode: 163, Reward: 70.0\n",
      "Episode: 164, Reward: 70.0\n",
      "Episode: 165, Reward: 70.0\n",
      "Episode: 166, Reward: 70.0\n",
      "Episode: 167, Reward: 70.0\n",
      "Episode: 168, Reward: 70.0\n",
      "Episode: 169, Reward: 70.0\n",
      "Episode: 170, Reward: 70.0\n",
      "Episode: 171, Reward: 70.0\n",
      "Episode: 172, Reward: 70.0\n",
      "Episode: 173, Reward: 70.0\n",
      "Episode: 174, Reward: 70.0\n",
      "Episode: 175, Reward: 70.0\n",
      "Episode: 176, Reward: 60.0\n",
      "Episode: 177, Reward: 60.0\n",
      "Episode: 178, Reward: 60.0\n",
      "Episode: 179, Reward: 50.0\n",
      "Episode: 180, Reward: 50.0\n",
      "Episode: 181, Reward: 50.0\n",
      "Episode: 182, Reward: 50.0\n",
      "Episode: 183, Reward: 50.0\n",
      "Episode: 184, Reward: 50.0\n",
      "Episode: 185, Reward: 50.0\n",
      "Episode: 186, Reward: 50.0\n",
      "Episode: 187, Reward: 50.0\n",
      "Episode: 188, Reward: 50.0\n",
      "Episode: 189, Reward: 50.0\n",
      "Episode: 190, Reward: 50.0\n",
      "Episode: 191, Reward: 50.0\n",
      "Episode: 192, Reward: 80.0\n",
      "Episode: 193, Reward: 80.0\n",
      "Episode: 194, Reward: 80.0\n",
      "Episode: 195, Reward: 80.0\n",
      "Episode: 196, Reward: 80.0\n",
      "Episode: 197, Reward: 110.0\n",
      "Episode: 198, Reward: 110.0\n",
      "Episode: 199, Reward: 110.0\n",
      "END - Date-Time: 2023-08-21 09:43:04\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[6, 7, 14, 21, 48, 59, 63, 67, 69, 70, 73, 81, 82, 91, 96, 97, 98, 99, 100, 105, 107, 108, 111, 118, 120, 121, 122, 127, 134, 139, 142, 145, 152, 171, 175, 176, 182, 184, 195, 197]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_WIZARDOFWOR-V5 EXPERIMENT 5: Date-Time: 2023-08-21 09:43:28, Capacity: 5k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 5000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 300.0\n",
      "Episode: 6, Reward: 300.0\n",
      "Episode: 7, Reward: 300.0\n",
      "Episode: 8, Reward: 300.0\n",
      "Episode: 9, Reward: 300.0\n",
      "Episode: 10, Reward: 300.0\n",
      "Episode: 11, Reward: 300.0\n",
      "Episode: 12, Reward: 300.0\n",
      "Episode: 13, Reward: 250.0\n",
      "Episode: 14, Reward: 166.67\n",
      "Episode: 15, Reward: 166.67\n",
      "Episode: 16, Reward: 125.0\n",
      "Episode: 17, Reward: 125.0\n",
      "Episode: 18, Reward: 100.0\n",
      "Episode: 19, Reward: 83.33\n",
      "Episode: 20, Reward: 83.33\n",
      "Episode: 21, Reward: 71.43\n",
      "Episode: 22, Reward: 71.43\n",
      "Episode: 23, Reward: 71.43\n",
      "Episode: 24, Reward: 71.43\n",
      "Episode: 25, Reward: 87.5\n",
      "Episode: 26, Reward: 87.5\n",
      "Episode: 27, Reward: 87.5\n",
      "Episode: 28, Reward: 87.5\n",
      "Episode: 29, Reward: 87.5\n",
      "Episode: 30, Reward: 87.5\n",
      "Episode: 31, Reward: 100.0\n",
      "Episode: 32, Reward: 100.0\n",
      "Episode: 33, Reward: 100.0\n",
      "Episode: 34, Reward: 100.0\n",
      "Episode: 35, Reward: 110.0\n",
      "Episode: 36, Reward: 110.0\n",
      "Episode: 37, Reward: 90.0\n",
      "Episode: 38, Reward: 90.0\n",
      "Episode: 39, Reward: 70.0\n",
      "Episode: 40, Reward: 70.0\n",
      "Episode: 41, Reward: 70.0\n",
      "Episode: 42, Reward: 70.0\n",
      "Episode: 43, Reward: 70.0\n",
      "Episode: 44, Reward: 70.0\n",
      "Episode: 45, Reward: 70.0\n",
      "Episode: 46, Reward: 70.0\n",
      "Episode: 47, Reward: 70.0\n",
      "Episode: 48, Reward: 70.0\n",
      "Episode: 49, Reward: 70.0\n",
      "Episode: 50, Reward: 70.0\n",
      "Episode: 51, Reward: 70.0\n",
      "Episode: 52, Reward: 70.0\n",
      "Episode: 53, Reward: 70.0\n",
      "Episode: 54, Reward: 70.0\n",
      "Episode: 55, Reward: 70.0\n",
      "Episode: 56, Reward: 70.0\n",
      "Episode: 57, Reward: 70.0\n",
      "Episode: 58, Reward: 90.0\n",
      "Episode: 59, Reward: 90.0\n",
      "Episode: 60, Reward: 80.0\n",
      "Episode: 61, Reward: 80.0\n",
      "Episode: 62, Reward: 80.0\n",
      "Episode: 63, Reward: 80.0\n",
      "Episode: 64, Reward: 80.0\n",
      "Episode: 65, Reward: 80.0\n",
      "Episode: 66, Reward: 80.0\n",
      "Episode: 67, Reward: 80.0\n",
      "Episode: 68, Reward: 60.0\n",
      "Episode: 69, Reward: 60.0\n",
      "Episode: 70, Reward: 50.0\n",
      "Episode: 71, Reward: 50.0\n",
      "Episode: 72, Reward: 50.0\n",
      "Episode: 73, Reward: 50.0\n",
      "Episode: 74, Reward: 50.0\n",
      "Episode: 75, Reward: 50.0\n",
      "Episode: 76, Reward: 50.0\n",
      "Episode: 77, Reward: 50.0\n",
      "Episode: 78, Reward: 100.0\n",
      "Episode: 79, Reward: 100.0\n",
      "Episode: 80, Reward: 100.0\n",
      "Episode: 81, Reward: 100.0\n",
      "Episode: 82, Reward: 100.0\n",
      "Episode: 83, Reward: 100.0\n",
      "Episode: 84, Reward: 100.0\n",
      "Episode: 85, Reward: 100.0\n",
      "Episode: 86, Reward: 100.0\n",
      "Episode: 87, Reward: 100.0\n",
      "Episode: 88, Reward: 110.0\n",
      "Episode: 89, Reward: 110.0\n",
      "Episode: 90, Reward: 110.0\n",
      "Episode: 91, Reward: 110.0\n",
      "Episode: 92, Reward: 110.0\n",
      "Episode: 93, Reward: 130.0\n",
      "Episode: 94, Reward: 130.0\n",
      "Episode: 95, Reward: 130.0\n",
      "Episode: 96, Reward: 130.0\n",
      "Episode: 97, Reward: 120.0\n",
      "Episode: 98, Reward: 120.0\n",
      "Episode: 99, Reward: 120.0\n",
      "Episode: 100, Reward: 120.0\n",
      "Episode: 101, Reward: 120.0\n",
      "Episode: 102, Reward: 140.0\n",
      "Episode: 103, Reward: 140.0\n",
      "Episode: 104, Reward: 140.0\n",
      "Episode: 105, Reward: 90.0\n",
      "Episode: 106, Reward: 90.0\n",
      "Episode: 107, Reward: 90.0\n",
      "Episode: 108, Reward: 90.0\n",
      "Episode: 109, Reward: 90.0\n",
      "Episode: 110, Reward: 90.0\n",
      "Episode: 111, Reward: 90.0\n",
      "Episode: 112, Reward: 90.0\n",
      "Episode: 113, Reward: 90.0\n",
      "Episode: 114, Reward: 90.0\n",
      "Episode: 115, Reward: 60.0\n",
      "Episode: 116, Reward: 60.0\n",
      "Episode: 117, Reward: 60.0\n",
      "Episode: 118, Reward: 60.0\n",
      "Episode: 119, Reward: 60.0\n",
      "Episode: 120, Reward: 50.0\n",
      "Episode: 121, Reward: 50.0\n",
      "Episode: 122, Reward: 50.0\n",
      "Episode: 123, Reward: 50.0\n",
      "Episode: 124, Reward: 70.0\n",
      "Episode: 125, Reward: 70.0\n",
      "Episode: 126, Reward: 70.0\n",
      "Episode: 127, Reward: 70.0\n",
      "Episode: 128, Reward: 70.0\n",
      "Episode: 129, Reward: 70.0\n",
      "Episode: 130, Reward: 60.0\n",
      "Episode: 131, Reward: 60.0\n",
      "Episode: 132, Reward: 60.0\n",
      "Episode: 133, Reward: 60.0\n",
      "Episode: 134, Reward: 60.0\n",
      "Episode: 135, Reward: 60.0\n",
      "Episode: 136, Reward: 60.0\n",
      "Episode: 137, Reward: 60.0\n",
      "Episode: 138, Reward: 60.0\n",
      "Episode: 139, Reward: 60.0\n",
      "Episode: 140, Reward: 60.0\n",
      "Episode: 141, Reward: 60.0\n",
      "Episode: 142, Reward: 60.0\n",
      "Episode: 143, Reward: 60.0\n",
      "Episode: 144, Reward: 80.0\n",
      "Episode: 145, Reward: 80.0\n",
      "Episode: 146, Reward: 80.0\n",
      "Episode: 147, Reward: 60.0\n",
      "Episode: 148, Reward: 60.0\n",
      "Episode: 149, Reward: 60.0\n",
      "Episode: 150, Reward: 30.0\n",
      "Episode: 151, Reward: 30.0\n",
      "Episode: 152, Reward: 30.0\n",
      "Episode: 153, Reward: 30.0\n",
      "Episode: 154, Reward: 20.0\n",
      "Episode: 155, Reward: 20.0\n",
      "Episode: 156, Reward: 20.0\n",
      "Episode: 157, Reward: 20.0\n",
      "Episode: 158, Reward: 20.0\n",
      "Episode: 159, Reward: 20.0\n",
      "Episode: 160, Reward: 20.0\n",
      "Episode: 161, Reward: 50.0\n",
      "Episode: 162, Reward: 50.0\n",
      "Episode: 163, Reward: 50.0\n",
      "Episode: 164, Reward: 50.0\n",
      "Episode: 165, Reward: 50.0\n",
      "Episode: 166, Reward: 50.0\n",
      "Episode: 167, Reward: 50.0\n",
      "Episode: 168, Reward: 100.0\n",
      "Episode: 169, Reward: 100.0\n",
      "Episode: 170, Reward: 100.0\n",
      "Episode: 171, Reward: 100.0\n",
      "Episode: 172, Reward: 130.0\n",
      "Episode: 173, Reward: 130.0\n",
      "Episode: 174, Reward: 130.0\n",
      "Episode: 175, Reward: 130.0\n",
      "Episode: 176, Reward: 130.0\n",
      "Episode: 177, Reward: 160.0\n",
      "Episode: 178, Reward: 160.0\n",
      "Episode: 179, Reward: 150.0\n",
      "Episode: 180, Reward: 150.0\n",
      "Episode: 181, Reward: 150.0\n",
      "Episode: 182, Reward: 150.0\n",
      "Episode: 183, Reward: 150.0\n",
      "Episode: 184, Reward: 150.0\n",
      "Episode: 185, Reward: 150.0\n",
      "Episode: 186, Reward: 150.0\n",
      "Episode: 187, Reward: 150.0\n",
      "Episode: 188, Reward: 150.0\n",
      "Episode: 189, Reward: 150.0\n",
      "Episode: 190, Reward: 150.0\n",
      "Episode: 191, Reward: 170.0\n",
      "Episode: 192, Reward: 170.0\n",
      "Episode: 193, Reward: 170.0\n",
      "Episode: 194, Reward: 170.0\n",
      "Episode: 195, Reward: 140.0\n",
      "Episode: 196, Reward: 140.0\n",
      "Episode: 197, Reward: 140.0\n",
      "Episode: 198, Reward: 90.0\n",
      "Episode: 199, Reward: 90.0\n",
      "END - Date-Time: 2023-08-21 09:50:33\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[18, 19, 24, 30, 37, 41, 51, 55, 58, 61, 67, 69, 70, 76, 77, 78, 80, 82, 83, 94, 97, 100, 103, 104, 108, 109, 112, 120, 127, 136, 140, 149, 155, 161, 163, 165, 177, 185, 192, 198]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_WIZARDOFWOR-V5 EXPERIMENT 6: Date-Time: 2023-08-21 09:50:58, Capacity: 1k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 1000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 200.0\n",
      "Episode: 4, Reward: 200.0\n",
      "Episode: 5, Reward: 100.0\n",
      "Episode: 6, Reward: 100.0\n",
      "Episode: 7, Reward: 100.0\n",
      "Episode: 8, Reward: 100.0\n",
      "Episode: 9, Reward: 100.0\n",
      "Episode: 10, Reward: 233.33\n",
      "Episode: 11, Reward: 233.33\n",
      "Episode: 12, Reward: 233.33\n",
      "Episode: 13, Reward: 233.33\n",
      "Episode: 14, Reward: 233.33\n",
      "Episode: 15, Reward: 325.0\n",
      "Episode: 16, Reward: 325.0\n",
      "Episode: 17, Reward: 325.0\n",
      "Episode: 18, Reward: 325.0\n",
      "Episode: 19, Reward: 325.0\n",
      "Episode: 20, Reward: 280.0\n",
      "Episode: 21, Reward: 280.0\n",
      "Episode: 22, Reward: 280.0\n",
      "Episode: 23, Reward: 280.0\n",
      "Episode: 24, Reward: 233.33\n",
      "Episode: 25, Reward: 200.0\n",
      "Episode: 26, Reward: 200.0\n",
      "Episode: 27, Reward: 200.0\n",
      "Episode: 28, Reward: 200.0\n",
      "Episode: 29, Reward: 187.5\n",
      "Episode: 30, Reward: 187.5\n",
      "Episode: 31, Reward: 187.5\n",
      "Episode: 32, Reward: 187.5\n",
      "Episode: 33, Reward: 166.67\n",
      "Episode: 34, Reward: 166.67\n",
      "Episode: 35, Reward: 166.67\n",
      "Episode: 36, Reward: 166.67\n",
      "Episode: 37, Reward: 170.0\n",
      "Episode: 38, Reward: 170.0\n",
      "Episode: 39, Reward: 170.0\n",
      "Episode: 40, Reward: 170.0\n",
      "Episode: 41, Reward: 170.0\n",
      "Episode: 42, Reward: 160.0\n",
      "Episode: 43, Reward: 160.0\n",
      "Episode: 44, Reward: 160.0\n",
      "Episode: 45, Reward: 160.0\n",
      "Episode: 46, Reward: 200.0\n",
      "Episode: 47, Reward: 200.0\n",
      "Episode: 48, Reward: 200.0\n",
      "Episode: 49, Reward: 170.0\n",
      "Episode: 50, Reward: 170.0\n",
      "Episode: 51, Reward: 110.0\n",
      "Episode: 52, Reward: 110.0\n",
      "Episode: 53, Reward: 120.0\n",
      "Episode: 54, Reward: 120.0\n",
      "Episode: 55, Reward: 120.0\n",
      "Episode: 56, Reward: 120.0\n",
      "Episode: 57, Reward: 120.0\n",
      "Episode: 58, Reward: 120.0\n",
      "Episode: 59, Reward: 120.0\n",
      "Episode: 60, Reward: 120.0\n",
      "Episode: 61, Reward: 120.0\n",
      "Episode: 62, Reward: 120.0\n",
      "Episode: 63, Reward: 120.0\n",
      "Episode: 64, Reward: 100.0\n",
      "Episode: 65, Reward: 90.0\n",
      "Episode: 66, Reward: 90.0\n",
      "Episode: 67, Reward: 50.0\n",
      "Episode: 68, Reward: 30.0\n",
      "Episode: 69, Reward: 30.0\n",
      "Episode: 70, Reward: 30.0\n",
      "Episode: 71, Reward: 30.0\n",
      "Episode: 72, Reward: 10.0\n",
      "Episode: 73, Reward: 10.0\n",
      "Episode: 74, Reward: 10.0\n",
      "Episode: 75, Reward: 10.0\n",
      "Episode: 76, Reward: 10.0\n",
      "Episode: 77, Reward: 10.0\n",
      "Episode: 78, Reward: 10.0\n",
      "Episode: 79, Reward: 10.0\n",
      "Episode: 80, Reward: 10.0\n",
      "Episode: 81, Reward: 10.0\n",
      "Episode: 82, Reward: 20.0\n",
      "Episode: 83, Reward: 20.0\n",
      "Episode: 84, Reward: 20.0\n",
      "Episode: 85, Reward: 20.0\n",
      "Episode: 86, Reward: 20.0\n",
      "Episode: 87, Reward: 20.0\n",
      "Episode: 88, Reward: 20.0\n",
      "Episode: 89, Reward: 20.0\n",
      "Episode: 90, Reward: 20.0\n",
      "Episode: 91, Reward: 20.0\n",
      "Episode: 92, Reward: 50.0\n",
      "Episode: 93, Reward: 50.0\n",
      "Episode: 94, Reward: 50.0\n",
      "Episode: 95, Reward: 60.0\n",
      "Episode: 96, Reward: 60.0\n",
      "Episode: 97, Reward: 60.0\n",
      "Episode: 98, Reward: 70.0\n",
      "Episode: 99, Reward: 70.0\n",
      "Episode: 100, Reward: 80.0\n",
      "Episode: 101, Reward: 80.0\n",
      "Episode: 102, Reward: 80.0\n",
      "Episode: 103, Reward: 80.0\n",
      "Episode: 104, Reward: 80.0\n",
      "Episode: 105, Reward: 120.0\n",
      "Episode: 106, Reward: 130.0\n",
      "Episode: 107, Reward: 130.0\n",
      "Episode: 108, Reward: 120.0\n",
      "Episode: 109, Reward: 120.0\n",
      "Episode: 110, Reward: 130.0\n",
      "Episode: 111, Reward: 130.0\n",
      "Episode: 112, Reward: 130.0\n",
      "Episode: 113, Reward: 130.0\n",
      "Episode: 114, Reward: 130.0\n",
      "Episode: 115, Reward: 150.0\n",
      "Episode: 116, Reward: 150.0\n",
      "Episode: 117, Reward: 160.0\n",
      "Episode: 118, Reward: 160.0\n",
      "Episode: 119, Reward: 160.0\n",
      "Episode: 120, Reward: 140.0\n",
      "Episode: 121, Reward: 140.0\n",
      "Episode: 122, Reward: 140.0\n",
      "Episode: 123, Reward: 140.0\n",
      "Episode: 124, Reward: 140.0\n",
      "Episode: 125, Reward: 140.0\n",
      "Episode: 126, Reward: 140.0\n",
      "Episode: 127, Reward: 140.0\n",
      "Episode: 128, Reward: 140.0\n",
      "Episode: 129, Reward: 140.0\n",
      "Episode: 130, Reward: 140.0\n",
      "Episode: 131, Reward: 140.0\n",
      "Episode: 132, Reward: 140.0\n",
      "Episode: 133, Reward: 140.0\n",
      "Episode: 134, Reward: 140.0\n",
      "Episode: 135, Reward: 140.0\n",
      "Episode: 136, Reward: 140.0\n",
      "Episode: 137, Reward: 100.0\n",
      "Episode: 138, Reward: 100.0\n",
      "Episode: 139, Reward: 100.0\n",
      "Episode: 140, Reward: 100.0\n",
      "Episode: 141, Reward: 100.0\n",
      "Episode: 142, Reward: 100.0\n",
      "Episode: 143, Reward: 140.0\n",
      "Episode: 144, Reward: 140.0\n",
      "Episode: 145, Reward: 140.0\n",
      "Episode: 146, Reward: 140.0\n",
      "Episode: 147, Reward: 140.0\n",
      "Episode: 148, Reward: 200.0\n",
      "Episode: 149, Reward: 200.0\n",
      "Episode: 150, Reward: 200.0\n",
      "Episode: 151, Reward: 220.0\n",
      "Episode: 152, Reward: 220.0\n",
      "Episode: 153, Reward: 220.0\n",
      "Episode: 154, Reward: 220.0\n",
      "Episode: 155, Reward: 250.0\n",
      "Episode: 156, Reward: 250.0\n",
      "Episode: 157, Reward: 250.0\n",
      "Episode: 158, Reward: 250.0\n",
      "Episode: 159, Reward: 250.0\n",
      "Episode: 160, Reward: 300.0\n",
      "Episode: 161, Reward: 300.0\n",
      "Episode: 162, Reward: 300.0\n",
      "Episode: 163, Reward: 300.0\n",
      "Episode: 164, Reward: 300.0\n",
      "Episode: 165, Reward: 300.0\n",
      "Episode: 166, Reward: 340.0\n",
      "Episode: 167, Reward: 340.0\n",
      "Episode: 168, Reward: 340.0\n",
      "Episode: 169, Reward: 340.0\n",
      "Episode: 170, Reward: 360.0\n",
      "Episode: 171, Reward: 360.0\n",
      "Episode: 172, Reward: 360.0\n",
      "Episode: 173, Reward: 350.0\n",
      "Episode: 174, Reward: 350.0\n",
      "Episode: 175, Reward: 350.0\n",
      "Episode: 176, Reward: 350.0\n",
      "Episode: 177, Reward: 350.0\n",
      "Episode: 178, Reward: 350.0\n",
      "Episode: 179, Reward: 350.0\n",
      "Episode: 180, Reward: 350.0\n",
      "Episode: 181, Reward: 350.0\n",
      "Episode: 182, Reward: 350.0\n",
      "Episode: 183, Reward: 350.0\n",
      "Episode: 184, Reward: 380.0\n",
      "Episode: 185, Reward: 380.0\n",
      "Episode: 186, Reward: 320.0\n",
      "Episode: 187, Reward: 320.0\n",
      "Episode: 188, Reward: 260.0\n",
      "Episode: 189, Reward: 260.0\n",
      "Episode: 190, Reward: 260.0\n",
      "Episode: 191, Reward: 260.0\n",
      "Episode: 192, Reward: 260.0\n",
      "Episode: 193, Reward: 260.0\n",
      "Episode: 194, Reward: 260.0\n",
      "Episode: 195, Reward: 260.0\n",
      "Episode: 196, Reward: 260.0\n",
      "Episode: 197, Reward: 230.0\n",
      "Episode: 198, Reward: 230.0\n",
      "Episode: 199, Reward: 230.0\n",
      "END - Date-Time: 2023-08-21 09:56:20\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[4, 7, 26, 30, 32, 37, 39, 40, 42, 46, 50, 53, 63, 65, 73, 80, 85, 89, 91, 96, 101, 104, 105, 109, 111, 124, 134, 135, 137, 138, 151, 154, 159, 162, 166, 178, 183, 192, 193, 198]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_WIZARDOFWOR-V5 EXPERIMENT 7: Date-Time: 2023-08-21 09:56:45, Capacity: 500\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 500\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 500.0\n",
      "Episode: 5, Reward: 500.0\n",
      "Episode: 6, Reward: 500.0\n",
      "Episode: 7, Reward: 500.0\n",
      "Episode: 8, Reward: 500.0\n",
      "Episode: 9, Reward: 500.0\n",
      "Episode: 10, Reward: 500.0\n",
      "Episode: 11, Reward: 500.0\n",
      "Episode: 12, Reward: 500.0\n",
      "Episode: 13, Reward: 400.0\n",
      "Episode: 14, Reward: 400.0\n",
      "Episode: 15, Reward: 325.0\n",
      "Episode: 16, Reward: 325.0\n",
      "Episode: 17, Reward: 325.0\n",
      "Episode: 18, Reward: 325.0\n",
      "Episode: 19, Reward: 300.0\n",
      "Episode: 20, Reward: 300.0\n",
      "Episode: 21, Reward: 300.0\n",
      "Episode: 22, Reward: 300.0\n",
      "Episode: 23, Reward: 283.33\n",
      "Episode: 24, Reward: 283.33\n",
      "Episode: 25, Reward: 283.33\n",
      "Episode: 26, Reward: 283.33\n",
      "Episode: 27, Reward: 283.33\n",
      "Episode: 28, Reward: 283.33\n",
      "Episode: 29, Reward: 283.33\n",
      "Episode: 30, Reward: 283.33\n",
      "Episode: 31, Reward: 283.33\n",
      "Episode: 32, Reward: 283.33\n",
      "Episode: 33, Reward: 283.33\n",
      "Episode: 34, Reward: 283.33\n",
      "Episode: 35, Reward: 283.33\n",
      "Episode: 36, Reward: 328.57\n",
      "Episode: 37, Reward: 328.57\n",
      "Episode: 38, Reward: 328.57\n",
      "Episode: 39, Reward: 328.57\n",
      "Episode: 40, Reward: 328.57\n",
      "Episode: 41, Reward: 328.57\n",
      "Episode: 42, Reward: 328.57\n",
      "Episode: 43, Reward: 328.57\n",
      "Episode: 44, Reward: 328.57\n",
      "Episode: 45, Reward: 328.57\n",
      "Episode: 46, Reward: 328.57\n",
      "Episode: 47, Reward: 328.57\n",
      "Episode: 48, Reward: 328.57\n",
      "Episode: 49, Reward: 337.5\n",
      "Episode: 50, Reward: 337.5\n",
      "Episode: 51, Reward: 300.0\n",
      "Episode: 52, Reward: 280.0\n",
      "Episode: 53, Reward: 280.0\n",
      "Episode: 54, Reward: 280.0\n",
      "Episode: 55, Reward: 280.0\n",
      "Episode: 56, Reward: 280.0\n",
      "Episode: 57, Reward: 260.0\n",
      "Episode: 58, Reward: 260.0\n",
      "Episode: 59, Reward: 260.0\n",
      "Episode: 60, Reward: 260.0\n",
      "Episode: 61, Reward: 230.0\n",
      "Episode: 62, Reward: 230.0\n",
      "Episode: 63, Reward: 230.0\n",
      "Episode: 64, Reward: 230.0\n",
      "Episode: 65, Reward: 240.0\n",
      "Episode: 66, Reward: 240.0\n",
      "Episode: 67, Reward: 240.0\n",
      "Episode: 68, Reward: 240.0\n",
      "Episode: 69, Reward: 250.0\n",
      "Episode: 70, Reward: 250.0\n",
      "Episode: 71, Reward: 250.0\n",
      "Episode: 72, Reward: 250.0\n",
      "Episode: 73, Reward: 250.0\n",
      "Episode: 74, Reward: 260.0\n",
      "Episode: 75, Reward: 260.0\n",
      "Episode: 76, Reward: 260.0\n",
      "Episode: 77, Reward: 260.0\n",
      "Episode: 78, Reward: 270.0\n",
      "Episode: 79, Reward: 220.0\n",
      "Episode: 80, Reward: 220.0\n",
      "Episode: 81, Reward: 220.0\n",
      "Episode: 82, Reward: 220.0\n",
      "Episode: 83, Reward: 220.0\n",
      "Episode: 84, Reward: 200.0\n",
      "Episode: 85, Reward: 200.0\n",
      "Episode: 86, Reward: 200.0\n",
      "Episode: 87, Reward: 200.0\n",
      "Episode: 88, Reward: 220.0\n",
      "Episode: 89, Reward: 220.0\n",
      "Episode: 90, Reward: 220.0\n",
      "Episode: 91, Reward: 220.0\n",
      "Episode: 92, Reward: 230.0\n",
      "Episode: 93, Reward: 230.0\n",
      "Episode: 94, Reward: 230.0\n",
      "Episode: 95, Reward: 230.0\n",
      "Episode: 96, Reward: 210.0\n",
      "Episode: 97, Reward: 210.0\n",
      "Episode: 98, Reward: 210.0\n",
      "Episode: 99, Reward: 210.0\n",
      "Episode: 100, Reward: 230.0\n",
      "Episode: 101, Reward: 230.0\n",
      "Episode: 102, Reward: 230.0\n",
      "Episode: 103, Reward: 220.0\n",
      "Episode: 104, Reward: 220.0\n",
      "Episode: 105, Reward: 220.0\n",
      "Episode: 106, Reward: 220.0\n",
      "Episode: 107, Reward: 220.0\n",
      "Episode: 108, Reward: 220.0\n",
      "Episode: 109, Reward: 220.0\n",
      "Episode: 110, Reward: 220.0\n",
      "Episode: 111, Reward: 220.0\n",
      "Episode: 112, Reward: 220.0\n",
      "Episode: 113, Reward: 220.0\n",
      "Episode: 114, Reward: 220.0\n",
      "Episode: 115, Reward: 220.0\n",
      "Episode: 116, Reward: 220.0\n",
      "Episode: 117, Reward: 240.0\n",
      "Episode: 118, Reward: 240.0\n",
      "Episode: 119, Reward: 240.0\n",
      "Episode: 120, Reward: 240.0\n",
      "Episode: 121, Reward: 240.0\n",
      "Episode: 122, Reward: 240.0\n",
      "Episode: 123, Reward: 240.0\n",
      "Episode: 124, Reward: 240.0\n",
      "Episode: 125, Reward: 240.0\n",
      "Episode: 126, Reward: 240.0\n",
      "Episode: 127, Reward: 240.0\n",
      "Episode: 128, Reward: 240.0\n",
      "Episode: 129, Reward: 240.0\n",
      "Episode: 130, Reward: 240.0\n",
      "Episode: 131, Reward: 240.0\n",
      "Episode: 132, Reward: 240.0\n",
      "Episode: 133, Reward: 240.0\n",
      "Episode: 134, Reward: 240.0\n",
      "Episode: 135, Reward: 240.0\n",
      "Episode: 136, Reward: 360.0\n",
      "Episode: 137, Reward: 360.0\n",
      "Episode: 138, Reward: 340.0\n",
      "Episode: 139, Reward: 320.0\n",
      "Episode: 140, Reward: 320.0\n",
      "Episode: 141, Reward: 300.0\n",
      "Episode: 142, Reward: 300.0\n",
      "Episode: 143, Reward: 290.0\n",
      "Episode: 144, Reward: 250.0\n",
      "Episode: 145, Reward: 250.0\n",
      "Episode: 146, Reward: 230.0\n",
      "Episode: 147, Reward: 230.0\n",
      "Episode: 148, Reward: 230.0\n",
      "Episode: 149, Reward: 230.0\n",
      "Episode: 150, Reward: 230.0\n",
      "Episode: 151, Reward: 230.0\n",
      "Episode: 152, Reward: 240.0\n",
      "Episode: 153, Reward: 240.0\n",
      "Episode: 154, Reward: 240.0\n",
      "Episode: 155, Reward: 240.0\n",
      "Episode: 156, Reward: 230.0\n",
      "Episode: 157, Reward: 230.0\n",
      "Episode: 158, Reward: 230.0\n",
      "Episode: 159, Reward: 230.0\n",
      "Episode: 160, Reward: 230.0\n",
      "Episode: 161, Reward: 200.0\n",
      "Episode: 162, Reward: 200.0\n",
      "Episode: 163, Reward: 200.0\n",
      "Episode: 164, Reward: 200.0\n",
      "Episode: 165, Reward: 90.0\n",
      "Episode: 166, Reward: 90.0\n",
      "Episode: 167, Reward: 90.0\n",
      "Episode: 168, Reward: 90.0\n",
      "Episode: 169, Reward: 120.0\n",
      "Episode: 170, Reward: 120.0\n",
      "Episode: 171, Reward: 120.0\n",
      "Episode: 172, Reward: 120.0\n",
      "Episode: 173, Reward: 150.0\n",
      "Episode: 174, Reward: 150.0\n",
      "Episode: 175, Reward: 150.0\n",
      "Episode: 176, Reward: 150.0\n",
      "Episode: 177, Reward: 150.0\n",
      "Episode: 178, Reward: 170.0\n",
      "Episode: 179, Reward: 170.0\n",
      "Episode: 180, Reward: 170.0\n",
      "Episode: 181, Reward: 170.0\n",
      "Episode: 182, Reward: 190.0\n",
      "Episode: 183, Reward: 190.0\n",
      "Episode: 184, Reward: 200.0\n",
      "Episode: 185, Reward: 200.0\n",
      "Episode: 186, Reward: 200.0\n",
      "Episode: 187, Reward: 200.0\n",
      "Episode: 188, Reward: 230.0\n",
      "Episode: 189, Reward: 230.0\n",
      "Episode: 190, Reward: 230.0\n",
      "Episode: 191, Reward: 230.0\n",
      "Episode: 192, Reward: 220.0\n",
      "Episode: 193, Reward: 220.0\n",
      "Episode: 194, Reward: 220.0\n",
      "Episode: 195, Reward: 220.0\n",
      "Episode: 196, Reward: 220.0\n",
      "Episode: 197, Reward: 220.0\n",
      "Episode: 198, Reward: 220.0\n",
      "Episode: 199, Reward: 220.0\n",
      "END - Date-Time: 2023-08-21 10:01:51\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[6, 17, 19, 24, 27, 31, 32, 35, 36, 41, 48, 55, 56, 62, 63, 84, 86, 94, 95, 100, 101, 106, 116, 126, 129, 139, 143, 144, 150, 155, 159, 160, 162, 169, 173, 178, 182, 190, 191, 199]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "Saving rewards to csv\n",
      "Saving boxplot of results\n",
      "Average Accumulated Reward: 203272.0\n",
      "ALE_YARSREVENGE-V5 EXPERIMENT 0: Date-Time: 2023-08-21 10:02:20, Capacity: 1M\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 1000000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 3726.0\n",
      "Episode: 5, Reward: 3726.0\n",
      "Episode: 6, Reward: 3726.0\n",
      "Episode: 7, Reward: 3726.0\n",
      "Episode: 8, Reward: 3726.0\n",
      "Episode: 9, Reward: 3622.5\n",
      "Episode: 10, Reward: 3622.5\n",
      "Episode: 11, Reward: 3622.5\n",
      "Episode: 12, Reward: 3622.5\n",
      "Episode: 13, Reward: 3622.5\n",
      "Episode: 14, Reward: 3622.5\n",
      "Episode: 15, Reward: 3622.5\n",
      "Episode: 16, Reward: 4140.0\n",
      "Episode: 17, Reward: 4140.0\n",
      "Episode: 18, Reward: 4140.0\n",
      "Episode: 19, Reward: 4140.0\n",
      "Episode: 20, Reward: 4140.0\n",
      "Episode: 21, Reward: 3845.0\n",
      "Episode: 22, Reward: 3845.0\n",
      "Episode: 23, Reward: 3845.0\n",
      "Episode: 24, Reward: 3845.0\n",
      "Episode: 25, Reward: 3845.0\n",
      "Episode: 26, Reward: 3718.2\n",
      "Episode: 27, Reward: 3718.2\n",
      "Episode: 28, Reward: 3718.2\n",
      "Episode: 29, Reward: 3718.2\n",
      "Episode: 30, Reward: 3605.5\n",
      "Episode: 31, Reward: 3605.5\n",
      "Episode: 32, Reward: 3718.14\n",
      "Episode: 33, Reward: 3718.14\n",
      "Episode: 34, Reward: 3802.62\n",
      "Episode: 35, Reward: 3802.62\n",
      "Episode: 36, Reward: 3802.62\n",
      "Episode: 37, Reward: 3802.62\n",
      "Episode: 38, Reward: 3802.62\n",
      "Episode: 39, Reward: 3802.62\n",
      "Episode: 40, Reward: 3793.22\n",
      "Episode: 41, Reward: 3793.22\n",
      "Episode: 42, Reward: 3793.22\n",
      "Episode: 43, Reward: 3793.22\n",
      "Episode: 44, Reward: 3793.22\n",
      "Episode: 45, Reward: 3793.22\n",
      "Episode: 46, Reward: 3793.22\n",
      "Episode: 47, Reward: 3793.22\n",
      "Episode: 48, Reward: 3793.22\n",
      "Episode: 49, Reward: 3793.22\n",
      "Episode: 50, Reward: 3793.22\n",
      "Episode: 51, Reward: 3793.22\n",
      "Episode: 52, Reward: 3793.22\n",
      "Episode: 53, Reward: 3793.22\n",
      "Episode: 54, Reward: 3793.22\n",
      "Episode: 55, Reward: 3793.22\n",
      "Episode: 56, Reward: 3793.22\n",
      "Episode: 57, Reward: 3413.9\n",
      "Episode: 58, Reward: 3413.9\n",
      "Episode: 59, Reward: 3413.9\n",
      "Episode: 60, Reward: 3413.9\n",
      "Episode: 61, Reward: 3413.9\n",
      "Episode: 62, Reward: 3413.9\n",
      "Episode: 63, Reward: 3413.9\n",
      "Episode: 64, Reward: 3413.9\n",
      "Episode: 65, Reward: 3075.1\n",
      "Episode: 66, Reward: 3075.1\n",
      "Episode: 67, Reward: 3075.1\n",
      "Episode: 68, Reward: 3075.1\n",
      "Episode: 69, Reward: 3075.1\n",
      "Episode: 70, Reward: 3075.1\n",
      "Episode: 71, Reward: 3075.1\n",
      "Episode: 72, Reward: 2824.6\n",
      "Episode: 73, Reward: 2824.6\n",
      "Episode: 74, Reward: 2824.6\n",
      "Episode: 75, Reward: 2824.6\n",
      "Episode: 76, Reward: 2824.6\n",
      "Episode: 77, Reward: 2824.6\n",
      "Episode: 78, Reward: 2824.6\n",
      "Episode: 79, Reward: 2824.6\n",
      "Episode: 80, Reward: 2824.6\n",
      "Episode: 81, Reward: 2824.6\n",
      "Episode: 82, Reward: 2307.1\n",
      "Episode: 83, Reward: 2307.1\n",
      "Episode: 84, Reward: 2307.1\n",
      "Episode: 85, Reward: 2307.1\n",
      "Episode: 86, Reward: 2307.1\n",
      "Episode: 87, Reward: 2307.1\n",
      "Episode: 88, Reward: 2307.1\n",
      "Episode: 89, Reward: 2307.1\n",
      "Episode: 90, Reward: 2307.1\n",
      "Episode: 91, Reward: 2170.1\n",
      "Episode: 92, Reward: 2170.1\n",
      "Episode: 93, Reward: 2170.1\n",
      "Episode: 94, Reward: 2170.1\n",
      "Episode: 95, Reward: 2170.1\n",
      "Episode: 96, Reward: 2170.1\n",
      "Episode: 97, Reward: 2170.1\n",
      "Episode: 98, Reward: 2051.8\n",
      "Episode: 99, Reward: 2051.8\n",
      "Episode: 100, Reward: 2051.8\n",
      "Episode: 101, Reward: 2051.8\n",
      "Episode: 102, Reward: 2051.8\n",
      "Episode: 103, Reward: 2051.8\n",
      "Episode: 104, Reward: 2051.8\n",
      "Episode: 105, Reward: 2051.8\n",
      "Episode: 106, Reward: 2051.8\n",
      "Episode: 107, Reward: 2051.8\n",
      "Episode: 108, Reward: 1747.6\n",
      "Episode: 109, Reward: 1747.6\n",
      "Episode: 110, Reward: 1747.6\n",
      "Episode: 111, Reward: 1747.6\n",
      "Episode: 112, Reward: 1747.6\n",
      "Episode: 113, Reward: 1747.6\n",
      "Episode: 114, Reward: 1747.6\n",
      "Episode: 115, Reward: 1308.2\n",
      "Episode: 116, Reward: 1308.2\n",
      "Episode: 117, Reward: 1308.2\n",
      "Episode: 118, Reward: 1308.2\n",
      "Episode: 119, Reward: 1308.2\n",
      "Episode: 120, Reward: 1308.2\n",
      "Episode: 121, Reward: 919.5\n",
      "Episode: 122, Reward: 919.5\n",
      "Episode: 123, Reward: 919.5\n",
      "Episode: 124, Reward: 919.5\n",
      "Episode: 125, Reward: 919.5\n",
      "Episode: 126, Reward: 919.5\n",
      "Episode: 127, Reward: 919.5\n",
      "Episode: 128, Reward: 547.7\n",
      "Episode: 129, Reward: 547.7\n",
      "Episode: 130, Reward: 547.7\n",
      "Episode: 131, Reward: 547.7\n",
      "Episode: 132, Reward: 547.7\n",
      "Episode: 133, Reward: 547.7\n",
      "Episode: 134, Reward: 547.7\n",
      "Episode: 135, Reward: 547.7\n",
      "Episode: 136, Reward: 547.7\n",
      "Episode: 137, Reward: 547.7\n",
      "Episode: 138, Reward: 547.7\n",
      "Episode: 139, Reward: 547.7\n",
      "Episode: 140, Reward: 547.7\n",
      "Episode: 141, Reward: 547.7\n",
      "Episode: 142, Reward: 513.9\n",
      "Episode: 143, Reward: 513.9\n",
      "Episode: 144, Reward: 513.9\n",
      "Episode: 145, Reward: 513.9\n",
      "Episode: 146, Reward: 513.9\n",
      "Episode: 147, Reward: 513.9\n",
      "Episode: 148, Reward: 513.9\n",
      "Episode: 149, Reward: 513.9\n",
      "Episode: 150, Reward: 513.9\n",
      "Episode: 151, Reward: 412.5\n",
      "Episode: 152, Reward: 412.5\n",
      "Episode: 153, Reward: 412.5\n",
      "Episode: 154, Reward: 412.5\n",
      "Episode: 155, Reward: 412.5\n",
      "Episode: 156, Reward: 412.5\n",
      "Episode: 157, Reward: 412.5\n",
      "Episode: 158, Reward: 463.2\n",
      "Episode: 159, Reward: 463.2\n",
      "Episode: 160, Reward: 463.2\n",
      "Episode: 161, Reward: 463.2\n",
      "Episode: 162, Reward: 463.2\n",
      "Episode: 163, Reward: 463.2\n",
      "Episode: 164, Reward: 422.5\n",
      "Episode: 165, Reward: 422.5\n",
      "Episode: 166, Reward: 422.5\n",
      "Episode: 167, Reward: 422.5\n",
      "Episode: 168, Reward: 422.5\n",
      "Episode: 169, Reward: 422.5\n",
      "Episode: 170, Reward: 422.5\n",
      "Episode: 171, Reward: 422.5\n",
      "Episode: 172, Reward: 422.5\n",
      "Episode: 173, Reward: 219.7\n",
      "Episode: 174, Reward: 219.7\n",
      "Episode: 175, Reward: 219.7\n",
      "Episode: 176, Reward: 219.7\n",
      "Episode: 177, Reward: 219.7\n",
      "Episode: 178, Reward: 219.7\n",
      "Episode: 179, Reward: 219.7\n",
      "Episode: 180, Reward: 219.7\n",
      "Episode: 181, Reward: 219.7\n",
      "Episode: 182, Reward: 219.7\n",
      "Episode: 183, Reward: 219.7\n",
      "Episode: 184, Reward: 219.7\n",
      "Episode: 185, Reward: 219.7\n",
      "Episode: 186, Reward: 219.7\n",
      "Episode: 187, Reward: 219.7\n",
      "Episode: 188, Reward: 219.7\n",
      "Episode: 189, Reward: 219.7\n",
      "Episode: 190, Reward: 219.7\n",
      "Episode: 191, Reward: 219.7\n",
      "Episode: 192, Reward: 219.7\n",
      "Episode: 193, Reward: 219.7\n",
      "Episode: 194, Reward: 169.0\n",
      "Episode: 195, Reward: 169.0\n",
      "Episode: 196, Reward: 169.0\n",
      "Episode: 197, Reward: 287.3\n",
      "Episode: 198, Reward: 287.3\n",
      "Episode: 199, Reward: 287.3\n",
      "END - Date-Time: 2023-08-21 10:18:12\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[2, 9, 15, 23, 34, 37, 45, 50, 53, 54, 64, 66, 67, 69, 72, 75, 78, 79, 98, 101, 104, 110, 111, 115, 123, 124, 129, 134, 138, 146, 147, 150, 151, 152, 153, 155, 157, 181, 182, 193]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_YARSREVENGE-V5 EXPERIMENT 1: Date-Time: 2023-08-21 10:18:41, Capacity: 500k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 500000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 3657.0\n",
      "Episode: 7, Reward: 3657.0\n",
      "Episode: 8, Reward: 3657.0\n",
      "Episode: 9, Reward: 3657.0\n",
      "Episode: 10, Reward: 3795.0\n",
      "Episode: 11, Reward: 3798.33\n",
      "Episode: 12, Reward: 3798.33\n",
      "Episode: 13, Reward: 3798.33\n",
      "Episode: 14, Reward: 4158.5\n",
      "Episode: 15, Reward: 4158.5\n",
      "Episode: 16, Reward: 4158.5\n",
      "Episode: 17, Reward: 4158.5\n",
      "Episode: 18, Reward: 4070.4\n",
      "Episode: 19, Reward: 4070.4\n",
      "Episode: 20, Reward: 4070.4\n",
      "Episode: 21, Reward: 3843.83\n",
      "Episode: 22, Reward: 3843.83\n",
      "Episode: 23, Reward: 3843.83\n",
      "Episode: 24, Reward: 3843.83\n",
      "Episode: 25, Reward: 4043.14\n",
      "Episode: 26, Reward: 4043.14\n",
      "Episode: 27, Reward: 4043.14\n",
      "Episode: 28, Reward: 4043.14\n",
      "Episode: 29, Reward: 4043.14\n",
      "Episode: 30, Reward: 4043.14\n",
      "Episode: 31, Reward: 4043.14\n",
      "Episode: 32, Reward: 3601.12\n",
      "Episode: 33, Reward: 3601.12\n",
      "Episode: 34, Reward: 3601.12\n",
      "Episode: 35, Reward: 3601.12\n",
      "Episode: 36, Reward: 3601.12\n",
      "Episode: 37, Reward: 3614.11\n",
      "Episode: 38, Reward: 3614.11\n",
      "Episode: 39, Reward: 3614.11\n",
      "Episode: 40, Reward: 3614.11\n",
      "Episode: 41, Reward: 3614.11\n",
      "Episode: 42, Reward: 3614.11\n",
      "Episode: 43, Reward: 3614.11\n",
      "Episode: 44, Reward: 3614.11\n",
      "Episode: 45, Reward: 3455.5\n",
      "Episode: 46, Reward: 3455.5\n",
      "Episode: 47, Reward: 3410.9\n",
      "Episode: 48, Reward: 3410.9\n",
      "Episode: 49, Reward: 3410.9\n",
      "Episode: 50, Reward: 3410.9\n",
      "Episode: 51, Reward: 3410.9\n",
      "Episode: 52, Reward: 3410.9\n",
      "Episode: 53, Reward: 3410.9\n",
      "Episode: 54, Reward: 3410.9\n",
      "Episode: 55, Reward: 3410.9\n",
      "Episode: 56, Reward: 3410.9\n",
      "Episode: 57, Reward: 3017.6\n",
      "Episode: 58, Reward: 3017.6\n",
      "Episode: 59, Reward: 3017.6\n",
      "Episode: 60, Reward: 3017.6\n",
      "Episode: 61, Reward: 3017.6\n",
      "Episode: 62, Reward: 3017.6\n",
      "Episode: 63, Reward: 3017.6\n",
      "Episode: 64, Reward: 3017.6\n",
      "Episode: 65, Reward: 3017.6\n",
      "Episode: 66, Reward: 2637.1\n",
      "Episode: 67, Reward: 2637.1\n",
      "Episode: 68, Reward: 2637.1\n",
      "Episode: 69, Reward: 2637.1\n",
      "Episode: 70, Reward: 2637.1\n",
      "Episode: 71, Reward: 2637.1\n",
      "Episode: 72, Reward: 2265.3\n",
      "Episode: 73, Reward: 2265.3\n",
      "Episode: 74, Reward: 2265.3\n",
      "Episode: 75, Reward: 2265.3\n",
      "Episode: 76, Reward: 2265.3\n",
      "Episode: 77, Reward: 2265.3\n",
      "Episode: 78, Reward: 2265.3\n",
      "Episode: 79, Reward: 2265.3\n",
      "Episode: 80, Reward: 2265.3\n",
      "Episode: 81, Reward: 2265.3\n",
      "Episode: 82, Reward: 2265.3\n",
      "Episode: 83, Reward: 2265.3\n",
      "Episode: 84, Reward: 1893.5\n",
      "Episode: 85, Reward: 1893.5\n",
      "Episode: 86, Reward: 1893.5\n",
      "Episode: 87, Reward: 1893.5\n",
      "Episode: 88, Reward: 1893.5\n",
      "Episode: 89, Reward: 1893.5\n",
      "Episode: 90, Reward: 1893.5\n",
      "Episode: 91, Reward: 1893.5\n",
      "Episode: 92, Reward: 1893.5\n",
      "Episode: 93, Reward: 1893.5\n",
      "Episode: 94, Reward: 1622.4\n",
      "Episode: 95, Reward: 1622.4\n",
      "Episode: 96, Reward: 1622.4\n",
      "Episode: 97, Reward: 1622.4\n",
      "Episode: 98, Reward: 1622.4\n",
      "Episode: 99, Reward: 1622.4\n",
      "Episode: 100, Reward: 1622.4\n",
      "Episode: 101, Reward: 1622.4\n",
      "Episode: 102, Reward: 1098.5\n",
      "Episode: 103, Reward: 1098.5\n",
      "Episode: 104, Reward: 1098.5\n",
      "Episode: 105, Reward: 1098.5\n",
      "Episode: 106, Reward: 1098.5\n",
      "Episode: 107, Reward: 1098.5\n",
      "Episode: 108, Reward: 1098.5\n",
      "Episode: 109, Reward: 1098.5\n",
      "Episode: 110, Reward: 1098.5\n",
      "Episode: 111, Reward: 1098.5\n",
      "Episode: 112, Reward: 1047.8\n",
      "Episode: 113, Reward: 1047.8\n",
      "Episode: 114, Reward: 1047.8\n",
      "Episode: 115, Reward: 1047.8\n",
      "Episode: 116, Reward: 1047.8\n",
      "Episode: 117, Reward: 1047.8\n",
      "Episode: 118, Reward: 811.2\n",
      "Episode: 119, Reward: 811.2\n",
      "Episode: 120, Reward: 811.2\n",
      "Episode: 121, Reward: 811.2\n",
      "Episode: 122, Reward: 811.2\n",
      "Episode: 123, Reward: 811.2\n",
      "Episode: 124, Reward: 811.2\n",
      "Episode: 125, Reward: 811.2\n",
      "Episode: 126, Reward: 811.2\n",
      "Episode: 127, Reward: 811.2\n",
      "Episode: 128, Reward: 777.4\n",
      "Episode: 129, Reward: 777.4\n",
      "Episode: 130, Reward: 777.4\n",
      "Episode: 131, Reward: 777.4\n",
      "Episode: 132, Reward: 777.4\n",
      "Episode: 133, Reward: 540.8\n",
      "Episode: 134, Reward: 540.8\n",
      "Episode: 135, Reward: 540.8\n",
      "Episode: 136, Reward: 540.8\n",
      "Episode: 137, Reward: 540.8\n",
      "Episode: 138, Reward: 540.8\n",
      "Episode: 139, Reward: 540.8\n",
      "Episode: 140, Reward: 540.8\n",
      "Episode: 141, Reward: 540.8\n",
      "Episode: 142, Reward: 540.8\n",
      "Episode: 143, Reward: 540.8\n",
      "Episode: 144, Reward: 540.8\n",
      "Episode: 145, Reward: 540.8\n",
      "Episode: 146, Reward: 540.8\n",
      "Episode: 147, Reward: 540.8\n",
      "Episode: 148, Reward: 557.7\n",
      "Episode: 149, Reward: 557.7\n",
      "Episode: 150, Reward: 557.7\n",
      "Episode: 151, Reward: 557.7\n",
      "Episode: 152, Reward: 557.7\n",
      "Episode: 153, Reward: 557.7\n",
      "Episode: 154, Reward: 557.7\n",
      "Episode: 155, Reward: 557.7\n",
      "Episode: 156, Reward: 557.7\n",
      "Episode: 157, Reward: 557.7\n",
      "Episode: 158, Reward: 642.2\n",
      "Episode: 159, Reward: 642.2\n",
      "Episode: 160, Reward: 642.2\n",
      "Episode: 161, Reward: 642.2\n",
      "Episode: 162, Reward: 642.2\n",
      "Episode: 163, Reward: 642.2\n",
      "Episode: 164, Reward: 642.2\n",
      "Episode: 165, Reward: 642.2\n",
      "Episode: 166, Reward: 642.2\n",
      "Episode: 167, Reward: 557.7\n",
      "Episode: 168, Reward: 557.7\n",
      "Episode: 169, Reward: 557.7\n",
      "Episode: 170, Reward: 557.7\n",
      "Episode: 171, Reward: 557.7\n",
      "Episode: 172, Reward: 557.7\n",
      "Episode: 173, Reward: 642.2\n",
      "Episode: 174, Reward: 642.2\n",
      "Episode: 175, Reward: 642.2\n",
      "Episode: 176, Reward: 642.2\n",
      "Episode: 177, Reward: 642.2\n",
      "Episode: 178, Reward: 642.2\n",
      "Episode: 179, Reward: 642.2\n",
      "Episode: 180, Reward: 642.2\n",
      "Episode: 181, Reward: 642.2\n",
      "Episode: 182, Reward: 642.2\n",
      "Episode: 183, Reward: 642.2\n",
      "Episode: 184, Reward: 692.9\n",
      "Episode: 185, Reward: 692.9\n",
      "Episode: 186, Reward: 692.9\n",
      "Episode: 187, Reward: 692.9\n",
      "Episode: 188, Reward: 692.9\n",
      "Episode: 189, Reward: 692.9\n",
      "Episode: 190, Reward: 692.9\n",
      "Episode: 191, Reward: 692.9\n",
      "Episode: 192, Reward: 692.9\n",
      "Episode: 193, Reward: 692.9\n",
      "Episode: 194, Reward: 750.5\n",
      "Episode: 195, Reward: 750.5\n",
      "Episode: 196, Reward: 750.5\n",
      "Episode: 197, Reward: 784.3\n",
      "Episode: 198, Reward: 784.3\n",
      "Episode: 199, Reward: 784.3\n",
      "END - Date-Time: 2023-08-21 10:36:21\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[1, 13, 18, 25, 29, 31, 37, 42, 45, 53, 58, 60, 80, 85, 89, 100, 101, 102, 106, 109, 115, 116, 121, 125, 138, 139, 141, 143, 145, 149, 150, 156, 157, 166, 173, 179, 184, 186, 189, 199]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_YARSREVENGE-V5 EXPERIMENT 2: Date-Time: 2023-08-21 10:36:56, Capacity: 100k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 100000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 2691.0\n",
      "Episode: 4, Reward: 2691.0\n",
      "Episode: 5, Reward: 2691.0\n",
      "Episode: 6, Reward: 2691.0\n",
      "Episode: 7, Reward: 2691.0\n",
      "Episode: 8, Reward: 2173.5\n",
      "Episode: 9, Reward: 2173.5\n",
      "Episode: 10, Reward: 2173.5\n",
      "Episode: 11, Reward: 2173.5\n",
      "Episode: 12, Reward: 2173.5\n",
      "Episode: 13, Reward: 2173.5\n",
      "Episode: 14, Reward: 3082.0\n",
      "Episode: 15, Reward: 3082.0\n",
      "Episode: 16, Reward: 3082.0\n",
      "Episode: 17, Reward: 3082.0\n",
      "Episode: 18, Reward: 3082.0\n",
      "Episode: 19, Reward: 3172.25\n",
      "Episode: 20, Reward: 3172.25\n",
      "Episode: 21, Reward: 3172.25\n",
      "Episode: 22, Reward: 2910.4\n",
      "Episode: 23, Reward: 2910.4\n",
      "Episode: 24, Reward: 2910.4\n",
      "Episode: 25, Reward: 2910.4\n",
      "Episode: 26, Reward: 2910.4\n",
      "Episode: 27, Reward: 2910.4\n",
      "Episode: 28, Reward: 3066.33\n",
      "Episode: 29, Reward: 3066.33\n",
      "Episode: 30, Reward: 3066.33\n",
      "Episode: 31, Reward: 3066.33\n",
      "Episode: 32, Reward: 3066.33\n",
      "Episode: 33, Reward: 3066.33\n",
      "Episode: 34, Reward: 3314.14\n",
      "Episode: 35, Reward: 3314.14\n",
      "Episode: 36, Reward: 3314.14\n",
      "Episode: 37, Reward: 3314.14\n",
      "Episode: 38, Reward: 3314.14\n",
      "Episode: 39, Reward: 3314.14\n",
      "Episode: 40, Reward: 3314.14\n",
      "Episode: 41, Reward: 3314.14\n",
      "Episode: 42, Reward: 3364.62\n",
      "Episode: 43, Reward: 3364.62\n",
      "Episode: 44, Reward: 3347.56\n",
      "Episode: 45, Reward: 3347.56\n",
      "Episode: 46, Reward: 3347.56\n",
      "Episode: 47, Reward: 3347.56\n",
      "Episode: 48, Reward: 3347.56\n",
      "Episode: 49, Reward: 3164.9\n",
      "Episode: 50, Reward: 3164.9\n",
      "Episode: 51, Reward: 3164.9\n",
      "Episode: 52, Reward: 3164.9\n",
      "Episode: 53, Reward: 3164.9\n",
      "Episode: 54, Reward: 3164.9\n",
      "Episode: 55, Reward: 3164.9\n",
      "Episode: 56, Reward: 2912.7\n",
      "Episode: 57, Reward: 2912.7\n",
      "Episode: 58, Reward: 2912.7\n",
      "Episode: 59, Reward: 2912.7\n",
      "Episode: 60, Reward: 2912.7\n",
      "Episode: 61, Reward: 2912.7\n",
      "Episode: 62, Reward: 2912.7\n",
      "Episode: 63, Reward: 2912.7\n",
      "Episode: 64, Reward: 2912.7\n",
      "Episode: 65, Reward: 2912.7\n",
      "Episode: 66, Reward: 2747.1\n",
      "Episode: 67, Reward: 2747.1\n",
      "Episode: 68, Reward: 2747.1\n",
      "Episode: 69, Reward: 2747.1\n",
      "Episode: 70, Reward: 2747.1\n",
      "Episode: 71, Reward: 2747.1\n",
      "Episode: 72, Reward: 2747.1\n",
      "Episode: 73, Reward: 2747.1\n",
      "Episode: 74, Reward: 2747.1\n",
      "Episode: 75, Reward: 2493.8\n",
      "Episode: 76, Reward: 2493.8\n",
      "Episode: 77, Reward: 2493.8\n",
      "Episode: 78, Reward: 2493.8\n",
      "Episode: 79, Reward: 2493.8\n",
      "Episode: 80, Reward: 2493.8\n",
      "Episode: 81, Reward: 2493.8\n",
      "Episode: 82, Reward: 2493.8\n",
      "Episode: 83, Reward: 2493.8\n",
      "Episode: 84, Reward: 2493.8\n",
      "Episode: 85, Reward: 2493.8\n",
      "Episode: 86, Reward: 2493.8\n",
      "Episode: 87, Reward: 2493.8\n",
      "Episode: 88, Reward: 2493.8\n",
      "Episode: 89, Reward: 2493.8\n",
      "Episode: 90, Reward: 2493.8\n",
      "Episode: 91, Reward: 2149.5\n",
      "Episode: 92, Reward: 2149.5\n",
      "Episode: 93, Reward: 2149.5\n",
      "Episode: 94, Reward: 2149.5\n",
      "Episode: 95, Reward: 2149.5\n",
      "Episode: 96, Reward: 2149.5\n",
      "Episode: 97, Reward: 2064.6\n",
      "Episode: 98, Reward: 2064.6\n",
      "Episode: 99, Reward: 2064.6\n",
      "Episode: 100, Reward: 2064.6\n",
      "Episode: 101, Reward: 2064.6\n",
      "Episode: 102, Reward: 2064.6\n",
      "Episode: 103, Reward: 2064.6\n",
      "Episode: 104, Reward: 2064.6\n",
      "Episode: 105, Reward: 2064.6\n",
      "Episode: 106, Reward: 2064.6\n",
      "Episode: 107, Reward: 1730.7\n",
      "Episode: 108, Reward: 1730.7\n",
      "Episode: 109, Reward: 1730.7\n",
      "Episode: 110, Reward: 1730.7\n",
      "Episode: 111, Reward: 1730.7\n",
      "Episode: 112, Reward: 1730.7\n",
      "Episode: 113, Reward: 1730.7\n",
      "Episode: 114, Reward: 1318.2\n",
      "Episode: 115, Reward: 1318.2\n",
      "Episode: 116, Reward: 1318.2\n",
      "Episode: 117, Reward: 1318.2\n",
      "Episode: 118, Reward: 1318.2\n",
      "Episode: 119, Reward: 1318.2\n",
      "Episode: 120, Reward: 1318.2\n",
      "Episode: 121, Reward: 1014.0\n",
      "Episode: 122, Reward: 1014.0\n",
      "Episode: 123, Reward: 1014.0\n",
      "Episode: 124, Reward: 1014.0\n",
      "Episode: 125, Reward: 1014.0\n",
      "Episode: 126, Reward: 1014.0\n",
      "Episode: 127, Reward: 1014.0\n",
      "Episode: 128, Reward: 828.1\n",
      "Episode: 129, Reward: 828.1\n",
      "Episode: 130, Reward: 828.1\n",
      "Episode: 131, Reward: 726.7\n",
      "Episode: 132, Reward: 726.7\n",
      "Episode: 133, Reward: 726.7\n",
      "Episode: 134, Reward: 811.2\n",
      "Episode: 135, Reward: 811.2\n",
      "Episode: 136, Reward: 811.2\n",
      "Episode: 137, Reward: 811.2\n",
      "Episode: 138, Reward: 811.2\n",
      "Episode: 139, Reward: 811.2\n",
      "Episode: 140, Reward: 811.2\n",
      "Episode: 141, Reward: 811.2\n",
      "Episode: 142, Reward: 811.2\n",
      "Episode: 143, Reward: 811.2\n",
      "Episode: 144, Reward: 811.2\n",
      "Episode: 145, Reward: 811.2\n",
      "Episode: 146, Reward: 811.2\n",
      "Episode: 147, Reward: 811.2\n",
      "Episode: 148, Reward: 811.2\n",
      "Episode: 149, Reward: 811.2\n",
      "Episode: 150, Reward: 811.2\n",
      "Episode: 151, Reward: 811.2\n",
      "Episode: 152, Reward: 811.2\n",
      "Episode: 153, Reward: 845.0\n",
      "Episode: 154, Reward: 845.0\n",
      "Episode: 155, Reward: 845.0\n",
      "Episode: 156, Reward: 845.0\n",
      "Episode: 157, Reward: 1183.0\n",
      "Episode: 158, Reward: 1183.0\n",
      "Episode: 159, Reward: 1183.0\n",
      "Episode: 160, Reward: 1183.0\n",
      "Episode: 161, Reward: 1183.0\n",
      "Episode: 162, Reward: 1183.0\n",
      "Episode: 163, Reward: 1183.0\n",
      "Episode: 164, Reward: 1216.8\n",
      "Episode: 165, Reward: 1216.8\n",
      "Episode: 166, Reward: 1216.8\n",
      "Episode: 167, Reward: 1216.8\n",
      "Episode: 168, Reward: 1216.8\n",
      "Episode: 169, Reward: 1216.8\n",
      "Episode: 170, Reward: 1216.8\n",
      "Episode: 171, Reward: 1216.8\n",
      "Episode: 172, Reward: 1216.8\n",
      "Episode: 173, Reward: 1166.1\n",
      "Episode: 174, Reward: 1166.1\n",
      "Episode: 175, Reward: 1166.1\n",
      "Episode: 176, Reward: 1166.1\n",
      "Episode: 177, Reward: 1166.1\n",
      "Episode: 178, Reward: 1166.1\n",
      "Episode: 179, Reward: 1166.1\n",
      "Episode: 180, Reward: 1098.5\n",
      "Episode: 181, Reward: 1098.5\n",
      "Episode: 182, Reward: 1098.5\n",
      "Episode: 183, Reward: 1098.5\n",
      "Episode: 184, Reward: 1098.5\n",
      "Episode: 185, Reward: 1098.5\n",
      "Episode: 186, Reward: 1030.9\n",
      "Episode: 187, Reward: 1030.9\n",
      "Episode: 188, Reward: 1030.9\n",
      "Episode: 189, Reward: 1030.9\n",
      "Episode: 190, Reward: 1030.9\n",
      "Episode: 191, Reward: 1030.9\n",
      "Episode: 192, Reward: 1030.9\n",
      "Episode: 193, Reward: 1030.9\n",
      "Episode: 194, Reward: 1030.9\n",
      "Episode: 195, Reward: 1030.9\n",
      "Episode: 196, Reward: 1030.9\n",
      "Episode: 197, Reward: 1030.9\n",
      "Episode: 198, Reward: 1030.9\n",
      "Episode: 199, Reward: 1030.9\n",
      "END - Date-Time: 2023-08-21 10:56:15\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[1, 3, 4, 8, 10, 11, 14, 26, 27, 37, 40, 45, 46, 47, 54, 55, 62, 67, 70, 79, 82, 85, 89, 98, 101, 105, 112, 136, 144, 145, 156, 157, 164, 169, 176, 180, 186, 189, 195, 197]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_YARSREVENGE-V5 EXPERIMENT 3: Date-Time: 2023-08-21 10:56:46, Capacity: 50k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 50000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 3243.0\n",
      "Episode: 5, Reward: 3243.0\n",
      "Episode: 6, Reward: 3243.0\n",
      "Episode: 7, Reward: 2518.5\n",
      "Episode: 8, Reward: 2518.5\n",
      "Episode: 9, Reward: 2518.5\n",
      "Episode: 10, Reward: 2941.67\n",
      "Episode: 11, Reward: 2941.67\n",
      "Episode: 12, Reward: 2941.67\n",
      "Episode: 13, Reward: 2689.25\n",
      "Episode: 14, Reward: 2689.25\n",
      "Episode: 15, Reward: 2689.25\n",
      "Episode: 16, Reward: 2689.25\n",
      "Episode: 17, Reward: 2875.0\n",
      "Episode: 18, Reward: 2875.0\n",
      "Episode: 19, Reward: 2875.0\n",
      "Episode: 20, Reward: 2875.0\n",
      "Episode: 21, Reward: 2875.0\n",
      "Episode: 22, Reward: 2875.0\n",
      "Episode: 23, Reward: 2875.0\n",
      "Episode: 24, Reward: 2875.0\n",
      "Episode: 25, Reward: 2875.0\n",
      "Episode: 26, Reward: 2875.0\n",
      "Episode: 27, Reward: 2875.0\n",
      "Episode: 28, Reward: 2875.0\n",
      "Episode: 29, Reward: 2875.0\n",
      "Episode: 30, Reward: 2875.0\n",
      "Episode: 31, Reward: 2875.0\n",
      "Episode: 32, Reward: 2875.0\n",
      "Episode: 33, Reward: 2875.0\n",
      "Episode: 34, Reward: 2846.5\n",
      "Episode: 35, Reward: 2846.5\n",
      "Episode: 36, Reward: 2846.5\n",
      "Episode: 37, Reward: 2846.5\n",
      "Episode: 38, Reward: 2846.5\n",
      "Episode: 39, Reward: 2846.5\n",
      "Episode: 40, Reward: 2846.5\n",
      "Episode: 41, Reward: 2846.5\n",
      "Episode: 42, Reward: 2846.5\n",
      "Episode: 43, Reward: 2560.57\n",
      "Episode: 44, Reward: 2560.57\n",
      "Episode: 45, Reward: 2560.57\n",
      "Episode: 46, Reward: 2560.57\n",
      "Episode: 47, Reward: 2789.75\n",
      "Episode: 48, Reward: 2789.75\n",
      "Episode: 49, Reward: 2789.75\n",
      "Episode: 50, Reward: 2789.75\n",
      "Episode: 51, Reward: 2789.75\n",
      "Episode: 52, Reward: 2498.56\n",
      "Episode: 53, Reward: 2498.56\n",
      "Episode: 54, Reward: 2498.56\n",
      "Episode: 55, Reward: 2498.56\n",
      "Episode: 56, Reward: 2498.56\n",
      "Episode: 57, Reward: 2498.56\n",
      "Episode: 58, Reward: 2498.56\n",
      "Episode: 59, Reward: 2498.56\n",
      "Episode: 60, Reward: 2498.56\n",
      "Episode: 61, Reward: 2367.0\n",
      "Episode: 62, Reward: 2367.0\n",
      "Episode: 63, Reward: 2367.0\n",
      "Episode: 64, Reward: 2367.0\n",
      "Episode: 65, Reward: 2367.0\n",
      "Episode: 66, Reward: 2367.0\n",
      "Episode: 67, Reward: 2367.0\n",
      "Episode: 68, Reward: 2367.0\n",
      "Episode: 69, Reward: 2211.7\n",
      "Episode: 70, Reward: 2211.7\n",
      "Episode: 71, Reward: 2211.7\n",
      "Episode: 72, Reward: 2211.7\n",
      "Episode: 73, Reward: 2083.0\n",
      "Episode: 74, Reward: 2083.0\n",
      "Episode: 75, Reward: 2083.0\n",
      "Episode: 76, Reward: 2083.0\n",
      "Episode: 77, Reward: 2083.0\n",
      "Episode: 78, Reward: 2083.0\n",
      "Episode: 79, Reward: 1754.9\n",
      "Episode: 80, Reward: 1754.9\n",
      "Episode: 81, Reward: 1754.9\n",
      "Episode: 82, Reward: 1754.9\n",
      "Episode: 83, Reward: 1754.9\n",
      "Episode: 84, Reward: 1754.9\n",
      "Episode: 85, Reward: 1696.9\n",
      "Episode: 86, Reward: 1696.9\n",
      "Episode: 87, Reward: 1696.9\n",
      "Episode: 88, Reward: 1696.9\n",
      "Episode: 89, Reward: 1696.9\n",
      "Episode: 90, Reward: 1696.9\n",
      "Episode: 91, Reward: 1696.9\n",
      "Episode: 92, Reward: 1696.9\n",
      "Episode: 93, Reward: 1335.1\n",
      "Episode: 94, Reward: 1335.1\n",
      "Episode: 95, Reward: 1335.1\n",
      "Episode: 96, Reward: 1335.1\n",
      "Episode: 97, Reward: 1554.8\n",
      "Episode: 98, Reward: 1554.8\n",
      "Episode: 99, Reward: 1554.8\n",
      "Episode: 100, Reward: 1554.8\n",
      "Episode: 101, Reward: 1554.8\n",
      "Episode: 102, Reward: 1554.8\n",
      "Episode: 103, Reward: 1554.8\n",
      "Episode: 104, Reward: 1554.8\n",
      "Episode: 105, Reward: 1554.8\n",
      "Episode: 106, Reward: 1554.8\n",
      "Episode: 107, Reward: 1554.8\n",
      "Episode: 108, Reward: 1554.8\n",
      "Episode: 109, Reward: 1554.8\n",
      "Episode: 110, Reward: 1470.3\n",
      "Episode: 111, Reward: 1470.3\n",
      "Episode: 112, Reward: 1470.3\n",
      "Episode: 113, Reward: 1470.3\n",
      "Episode: 114, Reward: 1470.3\n",
      "Episode: 115, Reward: 1470.3\n",
      "Episode: 116, Reward: 1470.3\n",
      "Episode: 117, Reward: 1470.3\n",
      "Episode: 118, Reward: 1030.9\n",
      "Episode: 119, Reward: 1030.9\n",
      "Episode: 120, Reward: 1030.9\n",
      "Episode: 121, Reward: 1030.9\n",
      "Episode: 122, Reward: 1030.9\n",
      "Episode: 123, Reward: 1030.9\n",
      "Episode: 124, Reward: 1030.9\n",
      "Episode: 125, Reward: 1030.9\n",
      "Episode: 126, Reward: 1014.0\n",
      "Episode: 127, Reward: 1014.0\n",
      "Episode: 128, Reward: 1014.0\n",
      "Episode: 129, Reward: 1014.0\n",
      "Episode: 130, Reward: 1014.0\n",
      "Episode: 131, Reward: 1014.0\n",
      "Episode: 132, Reward: 1014.0\n",
      "Episode: 133, Reward: 895.7\n",
      "Episode: 134, Reward: 895.7\n",
      "Episode: 135, Reward: 895.7\n",
      "Episode: 136, Reward: 895.7\n",
      "Episode: 137, Reward: 895.7\n",
      "Episode: 138, Reward: 777.4\n",
      "Episode: 139, Reward: 777.4\n",
      "Episode: 140, Reward: 777.4\n",
      "Episode: 141, Reward: 777.4\n",
      "Episode: 142, Reward: 777.4\n",
      "Episode: 143, Reward: 777.4\n",
      "Episode: 144, Reward: 1014.0\n",
      "Episode: 145, Reward: 1014.0\n",
      "Episode: 146, Reward: 1014.0\n",
      "Episode: 147, Reward: 1014.0\n",
      "Episode: 148, Reward: 1808.3\n",
      "Episode: 149, Reward: 1808.3\n",
      "Episode: 150, Reward: 1808.3\n",
      "Episode: 151, Reward: 1808.3\n",
      "Episode: 152, Reward: 1808.3\n",
      "Episode: 153, Reward: 1774.5\n",
      "Episode: 154, Reward: 1774.5\n",
      "Episode: 155, Reward: 1774.5\n",
      "Episode: 156, Reward: 1774.5\n",
      "Episode: 157, Reward: 1774.5\n",
      "Episode: 158, Reward: 1774.5\n",
      "Episode: 159, Reward: 1774.5\n",
      "Episode: 160, Reward: 1774.5\n",
      "Episode: 161, Reward: 1774.5\n",
      "Episode: 162, Reward: 1774.5\n",
      "Episode: 163, Reward: 1774.5\n",
      "Episode: 164, Reward: 1774.5\n",
      "Episode: 165, Reward: 1774.5\n",
      "Episode: 166, Reward: 1774.5\n",
      "Episode: 167, Reward: 1774.5\n",
      "Episode: 168, Reward: 1774.5\n",
      "Episode: 169, Reward: 1774.5\n",
      "Episode: 170, Reward: 1774.5\n",
      "Episode: 171, Reward: 1774.5\n",
      "Episode: 172, Reward: 1284.4\n",
      "Episode: 173, Reward: 1284.4\n",
      "Episode: 174, Reward: 1284.4\n",
      "Episode: 175, Reward: 1284.4\n",
      "Episode: 176, Reward: 1284.4\n",
      "Episode: 177, Reward: 1284.4\n",
      "Episode: 178, Reward: 1284.4\n",
      "Episode: 179, Reward: 1284.4\n",
      "Episode: 180, Reward: 1284.4\n",
      "Episode: 181, Reward: 1284.4\n",
      "Episode: 182, Reward: 1284.4\n",
      "Episode: 183, Reward: 1284.4\n",
      "Episode: 184, Reward: 1284.4\n",
      "Episode: 185, Reward: 1284.4\n",
      "Episode: 186, Reward: 1284.4\n",
      "Episode: 187, Reward: 1284.4\n",
      "Episode: 188, Reward: 1284.4\n",
      "Episode: 189, Reward: 1284.4\n",
      "Episode: 190, Reward: 1284.4\n",
      "Episode: 191, Reward: 1284.4\n",
      "Episode: 192, Reward: 1284.4\n",
      "Episode: 193, Reward: 1284.4\n",
      "Episode: 194, Reward: 1284.4\n",
      "Episode: 195, Reward: 1352.0\n",
      "Episode: 196, Reward: 1352.0\n",
      "Episode: 197, Reward: 1352.0\n",
      "Episode: 198, Reward: 1352.0\n",
      "Episode: 199, Reward: 1470.3\n",
      "END - Date-Time: 2023-08-21 11:16:11\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[2, 3, 8, 9, 30, 34, 37, 46, 47, 49, 57, 58, 62, 63, 64, 66, 81, 83, 87, 88, 89, 92, 98, 103, 111, 118, 119, 120, 131, 132, 133, 140, 147, 150, 161, 163, 174, 180, 188, 193]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_YARSREVENGE-V5 EXPERIMENT 4: Date-Time: 2023-08-21 11:16:57, Capacity: 10k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 10000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 2967.0\n",
      "Episode: 8, Reward: 2967.0\n",
      "Episode: 9, Reward: 2967.0\n",
      "Episode: 10, Reward: 2967.0\n",
      "Episode: 11, Reward: 2967.0\n",
      "Episode: 12, Reward: 2967.0\n",
      "Episode: 13, Reward: 2967.0\n",
      "Episode: 14, Reward: 2967.0\n",
      "Episode: 15, Reward: 2967.0\n",
      "Episode: 16, Reward: 3691.5\n",
      "Episode: 17, Reward: 3691.5\n",
      "Episode: 18, Reward: 3691.5\n",
      "Episode: 19, Reward: 3691.5\n",
      "Episode: 20, Reward: 3691.5\n",
      "Episode: 21, Reward: 3691.5\n",
      "Episode: 22, Reward: 2461.0\n",
      "Episode: 23, Reward: 2461.0\n",
      "Episode: 24, Reward: 2461.0\n",
      "Episode: 25, Reward: 2461.0\n",
      "Episode: 26, Reward: 2461.0\n",
      "Episode: 27, Reward: 2461.0\n",
      "Episode: 28, Reward: 1845.75\n",
      "Episode: 29, Reward: 1845.75\n",
      "Episode: 30, Reward: 1845.75\n",
      "Episode: 31, Reward: 1845.75\n",
      "Episode: 32, Reward: 1845.75\n",
      "Episode: 33, Reward: 1845.75\n",
      "Episode: 34, Reward: 1476.6\n",
      "Episode: 35, Reward: 1476.6\n",
      "Episode: 36, Reward: 1476.6\n",
      "Episode: 37, Reward: 1476.6\n",
      "Episode: 38, Reward: 1230.5\n",
      "Episode: 39, Reward: 1230.5\n",
      "Episode: 40, Reward: 1230.5\n",
      "Episode: 41, Reward: 1230.5\n",
      "Episode: 42, Reward: 1230.5\n",
      "Episode: 43, Reward: 1230.5\n",
      "Episode: 44, Reward: 1054.71\n",
      "Episode: 45, Reward: 1054.71\n",
      "Episode: 46, Reward: 1054.71\n",
      "Episode: 47, Reward: 1054.71\n",
      "Episode: 48, Reward: 1054.71\n",
      "Episode: 49, Reward: 922.88\n",
      "Episode: 50, Reward: 922.88\n",
      "Episode: 51, Reward: 922.88\n",
      "Episode: 52, Reward: 922.88\n",
      "Episode: 53, Reward: 922.88\n",
      "Episode: 54, Reward: 922.88\n",
      "Episode: 55, Reward: 922.88\n",
      "Episode: 56, Reward: 922.88\n",
      "Episode: 57, Reward: 922.88\n",
      "Episode: 58, Reward: 1026.89\n",
      "Episode: 59, Reward: 1026.89\n",
      "Episode: 60, Reward: 1026.89\n",
      "Episode: 61, Reward: 1025.6\n",
      "Episode: 62, Reward: 1025.6\n",
      "Episode: 63, Reward: 1025.6\n",
      "Episode: 64, Reward: 1025.6\n",
      "Episode: 65, Reward: 728.9\n",
      "Episode: 66, Reward: 728.9\n",
      "Episode: 67, Reward: 728.9\n",
      "Episode: 68, Reward: 728.9\n",
      "Episode: 69, Reward: 728.9\n",
      "Episode: 70, Reward: 728.9\n",
      "Episode: 71, Reward: 728.9\n",
      "Episode: 72, Reward: 371.8\n",
      "Episode: 73, Reward: 371.8\n",
      "Episode: 74, Reward: 371.8\n",
      "Episode: 75, Reward: 371.8\n",
      "Episode: 76, Reward: 371.8\n",
      "Episode: 77, Reward: 371.8\n",
      "Episode: 78, Reward: 371.8\n",
      "Episode: 79, Reward: 371.8\n",
      "Episode: 80, Reward: 371.8\n",
      "Episode: 81, Reward: 371.8\n",
      "Episode: 82, Reward: 371.8\n",
      "Episode: 83, Reward: 371.8\n",
      "Episode: 84, Reward: 371.8\n",
      "Episode: 85, Reward: 371.8\n",
      "Episode: 86, Reward: 371.8\n",
      "Episode: 87, Reward: 371.8\n",
      "Episode: 88, Reward: 371.8\n",
      "Episode: 89, Reward: 371.8\n",
      "Episode: 90, Reward: 371.8\n",
      "Episode: 91, Reward: 371.8\n",
      "Episode: 92, Reward: 371.8\n",
      "Episode: 93, Reward: 371.8\n",
      "Episode: 94, Reward: 371.8\n",
      "Episode: 95, Reward: 371.8\n",
      "Episode: 96, Reward: 371.8\n",
      "Episode: 97, Reward: 371.8\n",
      "Episode: 98, Reward: 371.8\n",
      "Episode: 99, Reward: 371.8\n",
      "Episode: 100, Reward: 371.8\n",
      "Episode: 101, Reward: 371.8\n",
      "Episode: 102, Reward: 371.8\n",
      "Episode: 103, Reward: 371.8\n",
      "Episode: 104, Reward: 371.8\n",
      "Episode: 105, Reward: 371.8\n",
      "Episode: 106, Reward: 371.8\n",
      "Episode: 107, Reward: 371.8\n",
      "Episode: 108, Reward: 371.8\n",
      "Episode: 109, Reward: 371.8\n",
      "Episode: 110, Reward: 371.8\n",
      "Episode: 111, Reward: 371.8\n",
      "Episode: 112, Reward: 371.8\n",
      "Episode: 113, Reward: 371.8\n",
      "Episode: 114, Reward: 371.8\n",
      "Episode: 115, Reward: 371.8\n",
      "Episode: 116, Reward: 371.8\n",
      "Episode: 117, Reward: 371.8\n",
      "Episode: 118, Reward: 371.8\n",
      "Episode: 119, Reward: 371.8\n",
      "Episode: 120, Reward: 371.8\n",
      "Episode: 121, Reward: 371.8\n",
      "Episode: 122, Reward: 371.8\n",
      "Episode: 123, Reward: 371.8\n",
      "Episode: 124, Reward: 371.8\n",
      "Episode: 125, Reward: 371.8\n",
      "Episode: 126, Reward: 185.9\n",
      "Episode: 127, Reward: 185.9\n",
      "Episode: 128, Reward: 185.9\n",
      "Episode: 129, Reward: 185.9\n",
      "Episode: 130, Reward: 185.9\n",
      "Episode: 131, Reward: 185.9\n",
      "Episode: 132, Reward: 185.9\n",
      "Episode: 133, Reward: 84.5\n",
      "Episode: 134, Reward: 84.5\n",
      "Episode: 135, Reward: 84.5\n",
      "Episode: 136, Reward: 84.5\n",
      "Episode: 137, Reward: 84.5\n",
      "Episode: 138, Reward: 84.5\n",
      "Episode: 139, Reward: 84.5\n",
      "Episode: 140, Reward: 238.7\n",
      "Episode: 141, Reward: 238.7\n",
      "Episode: 142, Reward: 238.7\n",
      "Episode: 143, Reward: 238.7\n",
      "Episode: 144, Reward: 238.7\n",
      "Episode: 145, Reward: 238.7\n",
      "Episode: 146, Reward: 154.2\n",
      "Episode: 147, Reward: 154.2\n",
      "Episode: 148, Reward: 154.2\n",
      "Episode: 149, Reward: 154.2\n",
      "Episode: 150, Reward: 154.2\n",
      "Episode: 151, Reward: 154.2\n",
      "Episode: 152, Reward: 154.2\n",
      "Episode: 153, Reward: 154.2\n",
      "Episode: 154, Reward: 154.2\n",
      "Episode: 155, Reward: 154.2\n",
      "Episode: 156, Reward: 154.2\n",
      "Episode: 157, Reward: 154.2\n",
      "Episode: 158, Reward: 154.2\n",
      "Episode: 159, Reward: 154.2\n",
      "Episode: 160, Reward: 154.2\n",
      "Episode: 161, Reward: 154.2\n",
      "Episode: 162, Reward: 154.2\n",
      "Episode: 163, Reward: 154.2\n",
      "Episode: 164, Reward: 154.2\n",
      "Episode: 165, Reward: 154.2\n",
      "Episode: 166, Reward: 154.2\n",
      "Episode: 167, Reward: 154.2\n",
      "Episode: 168, Reward: 154.2\n",
      "Episode: 169, Reward: 154.2\n",
      "Episode: 170, Reward: 154.2\n",
      "Episode: 171, Reward: 600.5\n",
      "Episode: 172, Reward: 600.5\n",
      "Episode: 173, Reward: 600.5\n",
      "Episode: 174, Reward: 600.5\n",
      "Episode: 175, Reward: 600.5\n",
      "Episode: 176, Reward: 600.5\n",
      "Episode: 177, Reward: 600.5\n",
      "Episode: 178, Reward: 600.5\n",
      "Episode: 179, Reward: 600.5\n",
      "Episode: 180, Reward: 600.5\n",
      "Episode: 181, Reward: 600.5\n",
      "Episode: 182, Reward: 600.5\n",
      "Episode: 183, Reward: 600.5\n",
      "Episode: 184, Reward: 600.5\n",
      "Episode: 185, Reward: 600.5\n",
      "Episode: 186, Reward: 600.5\n",
      "Episode: 187, Reward: 600.5\n",
      "Episode: 188, Reward: 600.5\n",
      "Episode: 189, Reward: 600.5\n",
      "Episode: 190, Reward: 600.5\n",
      "Episode: 191, Reward: 600.5\n",
      "Episode: 192, Reward: 1225.8\n",
      "Episode: 193, Reward: 1225.8\n",
      "Episode: 194, Reward: 1225.8\n",
      "Episode: 195, Reward: 1225.8\n",
      "Episode: 196, Reward: 1225.8\n",
      "Episode: 197, Reward: 1225.8\n",
      "Episode: 198, Reward: 1225.8\n",
      "Episode: 199, Reward: 1225.8\n",
      "END - Date-Time: 2023-08-21 11:30:03\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[4, 5, 13, 14, 16, 33, 35, 36, 39, 53, 58, 59, 67, 72, 73, 77, 86, 87, 102, 105, 107, 114, 116, 119, 120, 128, 132, 134, 143, 146, 147, 152, 169, 173, 182, 184, 188, 191, 194, 196]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_YARSREVENGE-V5 EXPERIMENT 5: Date-Time: 2023-08-21 11:30:39, Capacity: 5k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 5000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 4071.0\n",
      "Episode: 7, Reward: 4071.0\n",
      "Episode: 8, Reward: 4071.0\n",
      "Episode: 9, Reward: 3829.5\n",
      "Episode: 10, Reward: 3829.5\n",
      "Episode: 11, Reward: 3880.0\n",
      "Episode: 12, Reward: 3880.0\n",
      "Episode: 13, Reward: 3880.0\n",
      "Episode: 14, Reward: 5398.0\n",
      "Episode: 15, Reward: 5335.4\n",
      "Episode: 16, Reward: 5335.4\n",
      "Episode: 17, Reward: 5335.4\n",
      "Episode: 18, Reward: 5335.4\n",
      "Episode: 19, Reward: 5202.17\n",
      "Episode: 20, Reward: 5202.17\n",
      "Episode: 21, Reward: 5202.17\n",
      "Episode: 22, Reward: 5202.17\n",
      "Episode: 23, Reward: 5202.17\n",
      "Episode: 24, Reward: 5202.17\n",
      "Episode: 25, Reward: 5202.17\n",
      "Episode: 26, Reward: 5202.17\n",
      "Episode: 27, Reward: 5202.17\n",
      "Episode: 28, Reward: 4483.14\n",
      "Episode: 29, Reward: 4483.14\n",
      "Episode: 30, Reward: 4483.14\n",
      "Episode: 31, Reward: 4483.14\n",
      "Episode: 32, Reward: 4483.14\n",
      "Episode: 33, Reward: 4483.14\n",
      "Episode: 34, Reward: 4483.14\n",
      "Episode: 35, Reward: 4483.14\n",
      "Episode: 36, Reward: 4483.14\n",
      "Episode: 37, Reward: 4662.12\n",
      "Episode: 38, Reward: 4662.12\n",
      "Episode: 39, Reward: 4662.12\n",
      "Episode: 40, Reward: 4662.12\n",
      "Episode: 41, Reward: 4662.12\n",
      "Episode: 42, Reward: 4662.12\n",
      "Episode: 43, Reward: 4662.12\n",
      "Episode: 44, Reward: 4662.12\n",
      "Episode: 45, Reward: 4662.12\n",
      "Episode: 46, Reward: 4662.12\n",
      "Episode: 47, Reward: 4662.12\n",
      "Episode: 48, Reward: 4662.12\n",
      "Episode: 49, Reward: 4838.89\n",
      "Episode: 50, Reward: 4838.89\n",
      "Episode: 51, Reward: 4838.89\n",
      "Episode: 52, Reward: 4838.89\n",
      "Episode: 53, Reward: 4838.89\n",
      "Episode: 54, Reward: 4838.89\n",
      "Episode: 55, Reward: 4838.89\n",
      "Episode: 56, Reward: 4838.89\n",
      "Episode: 57, Reward: 4838.89\n",
      "Episode: 58, Reward: 4838.89\n",
      "Episode: 59, Reward: 4838.89\n",
      "Episode: 60, Reward: 4838.89\n",
      "Episode: 61, Reward: 4838.89\n",
      "Episode: 62, Reward: 4838.89\n",
      "Episode: 63, Reward: 4838.89\n",
      "Episode: 64, Reward: 4838.89\n",
      "Episode: 65, Reward: 4838.89\n",
      "Episode: 66, Reward: 4355.0\n",
      "Episode: 67, Reward: 4355.0\n",
      "Episode: 68, Reward: 4355.0\n",
      "Episode: 69, Reward: 4355.0\n",
      "Episode: 70, Reward: 4355.0\n",
      "Episode: 71, Reward: 4355.0\n",
      "Episode: 72, Reward: 4355.0\n",
      "Episode: 73, Reward: 4355.0\n",
      "Episode: 74, Reward: 4355.0\n",
      "Episode: 75, Reward: 3947.9\n",
      "Episode: 76, Reward: 3947.9\n",
      "Episode: 77, Reward: 3947.9\n",
      "Episode: 78, Reward: 3947.9\n",
      "Episode: 79, Reward: 3947.9\n",
      "Episode: 80, Reward: 3947.9\n",
      "Episode: 81, Reward: 3947.9\n",
      "Episode: 82, Reward: 3947.9\n",
      "Episode: 83, Reward: 4065.1\n",
      "Episode: 84, Reward: 4065.1\n",
      "Episode: 85, Reward: 4218.5\n",
      "Episode: 86, Reward: 4218.5\n",
      "Episode: 87, Reward: 4218.5\n",
      "Episode: 88, Reward: 3797.9\n",
      "Episode: 89, Reward: 3797.9\n",
      "Episode: 90, Reward: 3797.9\n",
      "Episode: 91, Reward: 3898.5\n",
      "Episode: 92, Reward: 3898.5\n",
      "Episode: 93, Reward: 3898.5\n",
      "Episode: 94, Reward: 3799.8\n",
      "Episode: 95, Reward: 3799.8\n",
      "Episode: 96, Reward: 3799.8\n",
      "Episode: 97, Reward: 3799.8\n",
      "Episode: 98, Reward: 4283.7\n",
      "Episode: 99, Reward: 4283.7\n",
      "Episode: 100, Reward: 4283.7\n",
      "Episode: 101, Reward: 4283.7\n",
      "Episode: 102, Reward: 4283.7\n",
      "Episode: 103, Reward: 4283.7\n",
      "Episode: 104, Reward: 4283.7\n",
      "Episode: 105, Reward: 4283.7\n",
      "Episode: 106, Reward: 4283.7\n",
      "Episode: 107, Reward: 4283.7\n",
      "Episode: 108, Reward: 4283.7\n",
      "Episode: 109, Reward: 4283.7\n",
      "Episode: 110, Reward: 3962.6\n",
      "Episode: 111, Reward: 3962.6\n",
      "Episode: 112, Reward: 3962.6\n",
      "Episode: 113, Reward: 3641.5\n",
      "Episode: 114, Reward: 3641.5\n",
      "Episode: 115, Reward: 3641.5\n",
      "Episode: 116, Reward: 3641.5\n",
      "Episode: 117, Reward: 3641.5\n",
      "Episode: 118, Reward: 3641.5\n",
      "Episode: 119, Reward: 3641.5\n",
      "Episode: 120, Reward: 3641.5\n",
      "Episode: 121, Reward: 3641.5\n",
      "Episode: 122, Reward: 3641.5\n",
      "Episode: 123, Reward: 3641.5\n",
      "Episode: 124, Reward: 3641.5\n",
      "Episode: 125, Reward: 3641.5\n",
      "Episode: 126, Reward: 3641.5\n",
      "Episode: 127, Reward: 3641.5\n",
      "Episode: 128, Reward: 3641.5\n",
      "Episode: 129, Reward: 3641.5\n",
      "Episode: 130, Reward: 3641.5\n",
      "Episode: 131, Reward: 3641.5\n",
      "Episode: 132, Reward: 3641.5\n",
      "Episode: 133, Reward: 3641.5\n",
      "Episode: 134, Reward: 3641.5\n",
      "Episode: 135, Reward: 3929.5\n",
      "Episode: 136, Reward: 3929.5\n",
      "Episode: 137, Reward: 3913.6\n",
      "Episode: 138, Reward: 3818.4\n",
      "Episode: 139, Reward: 3683.2\n",
      "Episode: 140, Reward: 3683.2\n",
      "Episode: 141, Reward: 3683.2\n",
      "Episode: 142, Reward: 3554.2\n",
      "Episode: 143, Reward: 3554.2\n",
      "Episode: 144, Reward: 3554.2\n",
      "Episode: 145, Reward: 3554.2\n",
      "Episode: 146, Reward: 3554.2\n",
      "Episode: 147, Reward: 3554.2\n",
      "Episode: 148, Reward: 3554.2\n",
      "Episode: 149, Reward: 3554.2\n",
      "Episode: 150, Reward: 3554.2\n",
      "Episode: 151, Reward: 3554.2\n",
      "Episode: 152, Reward: 3554.2\n",
      "Episode: 153, Reward: 3554.2\n",
      "Episode: 154, Reward: 3554.2\n",
      "Episode: 155, Reward: 3554.2\n",
      "Episode: 156, Reward: 3554.2\n",
      "Episode: 157, Reward: 3554.2\n",
      "Episode: 158, Reward: 3554.2\n",
      "Episode: 159, Reward: 3402.1\n",
      "Episode: 160, Reward: 3402.1\n",
      "Episode: 161, Reward: 3402.1\n",
      "Episode: 162, Reward: 3402.1\n",
      "Episode: 163, Reward: 3402.1\n",
      "Episode: 164, Reward: 3402.1\n",
      "Episode: 165, Reward: 3402.1\n",
      "Episode: 166, Reward: 3402.1\n",
      "Episode: 167, Reward: 3402.1\n",
      "Episode: 168, Reward: 3402.1\n",
      "Episode: 169, Reward: 2901.3\n",
      "Episode: 170, Reward: 2901.3\n",
      "Episode: 171, Reward: 2901.3\n",
      "Episode: 172, Reward: 2901.3\n",
      "Episode: 173, Reward: 2901.3\n",
      "Episode: 174, Reward: 2901.3\n",
      "Episode: 175, Reward: 2901.3\n",
      "Episode: 176, Reward: 2901.3\n",
      "Episode: 177, Reward: 2901.3\n",
      "Episode: 178, Reward: 2901.3\n",
      "Episode: 179, Reward: 2901.3\n",
      "Episode: 180, Reward: 2901.3\n",
      "Episode: 181, Reward: 2901.3\n",
      "Episode: 182, Reward: 2630.9\n",
      "Episode: 183, Reward: 2630.9\n",
      "Episode: 184, Reward: 2630.9\n",
      "Episode: 185, Reward: 2630.9\n",
      "Episode: 186, Reward: 2630.9\n",
      "Episode: 187, Reward: 2630.9\n",
      "Episode: 188, Reward: 2630.9\n",
      "Episode: 189, Reward: 2630.9\n",
      "Episode: 190, Reward: 2630.9\n",
      "Episode: 191, Reward: 2630.9\n",
      "Episode: 192, Reward: 2630.9\n",
      "Episode: 193, Reward: 2630.9\n",
      "Episode: 194, Reward: 2580.2\n",
      "Episode: 195, Reward: 3019.6\n",
      "Episode: 196, Reward: 3019.6\n",
      "Episode: 197, Reward: 3171.0\n",
      "Episode: 198, Reward: 3201.0\n",
      "Episode: 199, Reward: 3201.0\n",
      "END - Date-Time: 2023-08-21 11:41:49\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[1, 4, 12, 13, 35, 37, 38, 46, 55, 59, 68, 69, 73, 75, 81, 93, 94, 100, 101, 111, 116, 117, 119, 125, 128, 129, 131, 135, 137, 141, 144, 145, 146, 150, 156, 160, 174, 179, 180, 196]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_YARSREVENGE-V5 EXPERIMENT 6: Date-Time: 2023-08-21 11:42:27, Capacity: 1k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 1000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 3105.0\n",
      "Episode: 6, Reward: 3105.0\n",
      "Episode: 7, Reward: 3105.0\n",
      "Episode: 8, Reward: 2982.5\n",
      "Episode: 9, Reward: 2982.5\n",
      "Episode: 10, Reward: 2982.5\n",
      "Episode: 11, Reward: 2982.5\n",
      "Episode: 12, Reward: 2931.33\n",
      "Episode: 13, Reward: 2931.33\n",
      "Episode: 14, Reward: 2931.33\n",
      "Episode: 15, Reward: 2371.0\n",
      "Episode: 16, Reward: 2371.0\n",
      "Episode: 17, Reward: 2371.0\n",
      "Episode: 18, Reward: 2371.0\n",
      "Episode: 19, Reward: 2371.0\n",
      "Episode: 20, Reward: 2371.0\n",
      "Episode: 21, Reward: 2371.0\n",
      "Episode: 22, Reward: 2371.0\n",
      "Episode: 23, Reward: 2371.0\n",
      "Episode: 24, Reward: 2371.0\n",
      "Episode: 25, Reward: 2371.0\n",
      "Episode: 26, Reward: 2371.0\n",
      "Episode: 27, Reward: 2371.0\n",
      "Episode: 28, Reward: 2371.0\n",
      "Episode: 29, Reward: 2371.0\n",
      "Episode: 30, Reward: 2371.0\n",
      "Episode: 31, Reward: 2371.0\n",
      "Episode: 32, Reward: 2371.0\n",
      "Episode: 33, Reward: 2268.6\n",
      "Episode: 34, Reward: 2268.6\n",
      "Episode: 35, Reward: 2268.6\n",
      "Episode: 36, Reward: 2268.6\n",
      "Episode: 37, Reward: 2268.6\n",
      "Episode: 38, Reward: 2268.6\n",
      "Episode: 39, Reward: 2268.6\n",
      "Episode: 40, Reward: 2268.6\n",
      "Episode: 41, Reward: 2268.6\n",
      "Episode: 42, Reward: 2268.6\n",
      "Episode: 43, Reward: 2268.6\n",
      "Episode: 44, Reward: 2268.6\n",
      "Episode: 45, Reward: 2268.6\n",
      "Episode: 46, Reward: 2268.6\n",
      "Episode: 47, Reward: 2268.6\n",
      "Episode: 48, Reward: 2268.6\n",
      "Episode: 49, Reward: 2268.6\n",
      "Episode: 50, Reward: 2268.6\n",
      "Episode: 51, Reward: 2268.6\n",
      "Episode: 52, Reward: 2268.6\n",
      "Episode: 53, Reward: 2268.6\n",
      "Episode: 54, Reward: 2268.6\n",
      "Episode: 55, Reward: 2268.6\n",
      "Episode: 56, Reward: 2268.6\n",
      "Episode: 57, Reward: 2268.6\n",
      "Episode: 58, Reward: 2268.6\n",
      "Episode: 59, Reward: 2268.6\n",
      "Episode: 60, Reward: 2268.6\n",
      "Episode: 61, Reward: 2268.6\n",
      "Episode: 62, Reward: 2268.6\n",
      "Episode: 63, Reward: 2268.6\n",
      "Episode: 64, Reward: 2268.6\n",
      "Episode: 65, Reward: 2268.6\n",
      "Episode: 66, Reward: 2268.6\n",
      "Episode: 67, Reward: 2268.6\n",
      "Episode: 68, Reward: 2268.6\n",
      "Episode: 69, Reward: 2268.6\n",
      "Episode: 70, Reward: 2268.6\n",
      "Episode: 71, Reward: 2268.6\n",
      "Episode: 72, Reward: 2268.6\n",
      "Episode: 73, Reward: 2268.6\n",
      "Episode: 74, Reward: 2268.6\n",
      "Episode: 75, Reward: 2268.6\n",
      "Episode: 76, Reward: 2268.6\n",
      "Episode: 77, Reward: 2268.6\n",
      "Episode: 78, Reward: 2268.6\n",
      "Episode: 79, Reward: 2268.6\n",
      "Episode: 80, Reward: 2268.6\n",
      "Episode: 81, Reward: 2268.6\n",
      "Episode: 82, Reward: 2268.6\n",
      "Episode: 83, Reward: 2268.6\n",
      "Episode: 84, Reward: 2268.6\n",
      "Episode: 85, Reward: 2268.6\n",
      "Episode: 86, Reward: 2268.6\n",
      "Episode: 87, Reward: 2268.6\n",
      "Episode: 88, Reward: 2566.5\n",
      "Episode: 89, Reward: 2566.5\n",
      "Episode: 90, Reward: 2566.5\n",
      "Episode: 91, Reward: 2566.5\n",
      "Episode: 92, Reward: 2566.5\n",
      "Episode: 93, Reward: 2566.5\n",
      "Episode: 94, Reward: 2566.5\n",
      "Episode: 95, Reward: 2566.5\n",
      "Episode: 96, Reward: 2566.5\n",
      "Episode: 97, Reward: 2566.5\n",
      "Episode: 98, Reward: 2566.5\n",
      "Episode: 99, Reward: 2566.5\n",
      "Episode: 100, Reward: 2566.5\n",
      "Episode: 101, Reward: 2566.5\n",
      "Episode: 102, Reward: 2566.5\n",
      "Episode: 103, Reward: 2566.5\n",
      "Episode: 104, Reward: 2566.5\n",
      "Episode: 105, Reward: 2566.5\n",
      "Episode: 106, Reward: 2566.5\n",
      "Episode: 107, Reward: 2566.5\n",
      "Episode: 108, Reward: 2566.5\n",
      "Episode: 109, Reward: 2566.5\n",
      "Episode: 110, Reward: 2566.5\n",
      "Episode: 111, Reward: 2566.5\n",
      "Episode: 112, Reward: 2566.5\n",
      "Episode: 113, Reward: 2803.43\n",
      "Episode: 114, Reward: 2803.43\n",
      "Episode: 115, Reward: 2803.43\n",
      "Episode: 116, Reward: 2803.43\n",
      "Episode: 117, Reward: 2803.43\n",
      "Episode: 118, Reward: 2803.43\n",
      "Episode: 119, Reward: 2803.43\n",
      "Episode: 120, Reward: 2803.43\n",
      "Episode: 121, Reward: 2803.43\n",
      "Episode: 122, Reward: 2803.43\n",
      "Episode: 123, Reward: 2803.43\n",
      "Episode: 124, Reward: 2803.43\n",
      "Episode: 125, Reward: 2803.43\n",
      "Episode: 126, Reward: 2803.43\n",
      "Episode: 127, Reward: 2803.43\n",
      "Episode: 128, Reward: 2803.43\n",
      "Episode: 129, Reward: 2803.43\n",
      "Episode: 130, Reward: 2803.43\n",
      "Episode: 131, Reward: 2803.43\n",
      "Episode: 132, Reward: 2803.43\n",
      "Episode: 133, Reward: 2803.43\n",
      "Episode: 134, Reward: 2803.43\n",
      "Episode: 135, Reward: 2803.43\n",
      "Episode: 136, Reward: 2803.43\n",
      "Episode: 137, Reward: 2803.43\n",
      "Episode: 138, Reward: 2803.43\n",
      "Episode: 139, Reward: 2803.43\n",
      "Episode: 140, Reward: 2803.43\n",
      "Episode: 141, Reward: 2803.43\n",
      "Episode: 142, Reward: 2803.43\n",
      "Episode: 143, Reward: 2803.43\n",
      "Episode: 144, Reward: 2803.43\n",
      "Episode: 145, Reward: 2803.43\n",
      "Episode: 146, Reward: 2803.43\n",
      "Episode: 147, Reward: 2803.43\n",
      "Episode: 148, Reward: 2803.43\n",
      "Episode: 149, Reward: 2803.43\n",
      "Episode: 150, Reward: 2803.43\n",
      "Episode: 151, Reward: 2803.43\n",
      "Episode: 152, Reward: 2803.43\n",
      "Episode: 153, Reward: 2803.43\n",
      "Episode: 154, Reward: 2803.43\n",
      "Episode: 155, Reward: 2803.43\n",
      "Episode: 156, Reward: 2803.43\n",
      "Episode: 157, Reward: 2803.43\n",
      "Episode: 158, Reward: 2803.43\n",
      "Episode: 159, Reward: 2803.43\n",
      "Episode: 160, Reward: 2803.43\n",
      "Episode: 161, Reward: 2803.43\n",
      "Episode: 162, Reward: 2803.43\n",
      "Episode: 163, Reward: 2803.43\n",
      "Episode: 164, Reward: 2803.43\n",
      "Episode: 165, Reward: 2803.43\n",
      "Episode: 166, Reward: 2803.43\n",
      "Episode: 167, Reward: 2803.43\n",
      "Episode: 168, Reward: 2803.43\n",
      "Episode: 169, Reward: 2803.43\n",
      "Episode: 170, Reward: 2803.43\n",
      "Episode: 171, Reward: 2803.43\n",
      "Episode: 172, Reward: 2803.43\n",
      "Episode: 173, Reward: 2803.43\n",
      "Episode: 174, Reward: 2803.43\n",
      "Episode: 175, Reward: 2803.43\n",
      "Episode: 176, Reward: 2803.43\n",
      "Episode: 177, Reward: 2803.43\n",
      "Episode: 178, Reward: 2803.43\n",
      "Episode: 179, Reward: 2803.43\n",
      "Episode: 180, Reward: 2803.43\n",
      "Episode: 181, Reward: 2803.43\n",
      "Episode: 182, Reward: 2803.43\n",
      "Episode: 183, Reward: 2803.43\n",
      "Episode: 184, Reward: 2803.43\n",
      "Episode: 185, Reward: 2803.43\n",
      "Episode: 186, Reward: 2803.43\n",
      "Episode: 187, Reward: 2803.43\n",
      "Episode: 188, Reward: 2803.43\n",
      "Episode: 189, Reward: 2803.43\n",
      "Episode: 190, Reward: 2803.43\n",
      "Episode: 191, Reward: 2803.43\n",
      "Episode: 192, Reward: 2803.43\n",
      "Episode: 193, Reward: 2803.43\n",
      "Episode: 194, Reward: 2803.43\n",
      "Episode: 195, Reward: 2803.43\n",
      "Episode: 196, Reward: 2803.43\n",
      "Episode: 197, Reward: 2803.43\n",
      "Episode: 198, Reward: 2803.43\n",
      "Episode: 199, Reward: 2803.43\n",
      "END - Date-Time: 2023-08-21 11:50:56\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[8, 11, 12, 19, 25, 33, 38, 39, 41, 42, 60, 78, 83, 87, 91, 106, 109, 110, 116, 119, 129, 130, 136, 137, 139, 141, 151, 156, 164, 165, 174, 175, 176, 180, 181, 186, 189, 191, 194, 195]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_YARSREVENGE-V5 EXPERIMENT 7: Date-Time: 2023-08-21 11:51:34, Capacity: 500\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 500\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 2829.0\n",
      "Episode: 5, Reward: 2829.0\n",
      "Episode: 6, Reward: 2829.0\n",
      "Episode: 7, Reward: 2829.0\n",
      "Episode: 8, Reward: 2829.0\n",
      "Episode: 9, Reward: 2829.0\n",
      "Episode: 10, Reward: 2691.0\n",
      "Episode: 11, Reward: 2691.0\n",
      "Episode: 12, Reward: 2691.0\n",
      "Episode: 13, Reward: 2691.0\n",
      "Episode: 14, Reward: 2691.0\n",
      "Episode: 15, Reward: 2369.0\n",
      "Episode: 16, Reward: 2369.0\n",
      "Episode: 17, Reward: 2369.0\n",
      "Episode: 18, Reward: 2369.0\n",
      "Episode: 19, Reward: 2369.0\n",
      "Episode: 20, Reward: 2369.0\n",
      "Episode: 21, Reward: 2369.0\n",
      "Episode: 22, Reward: 2369.0\n",
      "Episode: 23, Reward: 2018.25\n",
      "Episode: 24, Reward: 2018.25\n",
      "Episode: 25, Reward: 2018.25\n",
      "Episode: 26, Reward: 2018.25\n",
      "Episode: 27, Reward: 2018.25\n",
      "Episode: 28, Reward: 2018.25\n",
      "Episode: 29, Reward: 2018.25\n",
      "Episode: 30, Reward: 1614.6\n",
      "Episode: 31, Reward: 1614.6\n",
      "Episode: 32, Reward: 1614.6\n",
      "Episode: 33, Reward: 1614.6\n",
      "Episode: 34, Reward: 1614.6\n",
      "Episode: 35, Reward: 1499.0\n",
      "Episode: 36, Reward: 1499.0\n",
      "Episode: 37, Reward: 1499.0\n",
      "Episode: 38, Reward: 1499.0\n",
      "Episode: 39, Reward: 1333.14\n",
      "Episode: 40, Reward: 1333.14\n",
      "Episode: 41, Reward: 1333.14\n",
      "Episode: 42, Reward: 1333.14\n",
      "Episode: 43, Reward: 1333.14\n",
      "Episode: 44, Reward: 1333.14\n",
      "Episode: 45, Reward: 1333.14\n",
      "Episode: 46, Reward: 1333.14\n",
      "Episode: 47, Reward: 1333.14\n",
      "Episode: 48, Reward: 1333.14\n",
      "Episode: 49, Reward: 1333.14\n",
      "Episode: 50, Reward: 1333.14\n",
      "Episode: 51, Reward: 1333.14\n",
      "Episode: 52, Reward: 1333.14\n",
      "Episode: 53, Reward: 1333.14\n",
      "Episode: 54, Reward: 1333.14\n",
      "Episode: 55, Reward: 1333.14\n",
      "Episode: 56, Reward: 1333.14\n",
      "Episode: 57, Reward: 1333.14\n",
      "Episode: 58, Reward: 1333.14\n",
      "Episode: 59, Reward: 1333.14\n",
      "Episode: 60, Reward: 1333.14\n",
      "Episode: 61, Reward: 1333.14\n",
      "Episode: 62, Reward: 1333.14\n",
      "Episode: 63, Reward: 1333.14\n",
      "Episode: 64, Reward: 1333.14\n",
      "Episode: 65, Reward: 1333.14\n",
      "Episode: 66, Reward: 1333.14\n",
      "Episode: 67, Reward: 1333.14\n",
      "Episode: 68, Reward: 1547.62\n",
      "Episode: 69, Reward: 1547.62\n",
      "Episode: 70, Reward: 1547.62\n",
      "Episode: 71, Reward: 1547.62\n",
      "Episode: 72, Reward: 1547.62\n",
      "Episode: 73, Reward: 1547.62\n",
      "Episode: 74, Reward: 1547.62\n",
      "Episode: 75, Reward: 1547.62\n",
      "Episode: 76, Reward: 1547.62\n",
      "Episode: 77, Reward: 1547.62\n",
      "Episode: 78, Reward: 1547.62\n",
      "Episode: 79, Reward: 1375.67\n",
      "Episode: 80, Reward: 1375.67\n",
      "Episode: 81, Reward: 1375.67\n",
      "Episode: 82, Reward: 1375.67\n",
      "Episode: 83, Reward: 1375.67\n",
      "Episode: 84, Reward: 1375.67\n",
      "Episode: 85, Reward: 1375.67\n",
      "Episode: 86, Reward: 1375.67\n",
      "Episode: 87, Reward: 1238.1\n",
      "Episode: 88, Reward: 1238.1\n",
      "Episode: 89, Reward: 1238.1\n",
      "Episode: 90, Reward: 1238.1\n",
      "Episode: 91, Reward: 1238.1\n",
      "Episode: 92, Reward: 1238.1\n",
      "Episode: 93, Reward: 1238.1\n",
      "Episode: 94, Reward: 955.2\n",
      "Episode: 95, Reward: 955.2\n",
      "Episode: 96, Reward: 955.2\n",
      "Episode: 97, Reward: 768.2\n",
      "Episode: 98, Reward: 768.2\n",
      "Episode: 99, Reward: 768.2\n",
      "Episode: 100, Reward: 768.2\n",
      "Episode: 101, Reward: 619.5\n",
      "Episode: 102, Reward: 619.5\n",
      "Episode: 103, Reward: 619.5\n",
      "Episode: 104, Reward: 619.5\n",
      "Episode: 105, Reward: 1049.3\n",
      "Episode: 106, Reward: 1049.3\n",
      "Episode: 107, Reward: 1049.3\n",
      "Episode: 108, Reward: 1049.3\n",
      "Episode: 109, Reward: 1049.3\n",
      "Episode: 110, Reward: 1049.3\n",
      "Episode: 111, Reward: 1049.3\n",
      "Episode: 112, Reward: 1049.3\n",
      "Episode: 113, Reward: 1049.3\n",
      "Episode: 114, Reward: 1049.3\n",
      "Episode: 115, Reward: 1049.3\n",
      "Episode: 116, Reward: 1049.3\n",
      "Episode: 117, Reward: 957.2\n",
      "Episode: 118, Reward: 957.2\n",
      "Episode: 119, Reward: 957.2\n",
      "Episode: 120, Reward: 957.2\n",
      "Episode: 121, Reward: 957.2\n",
      "Episode: 122, Reward: 957.2\n",
      "Episode: 123, Reward: 957.2\n",
      "Episode: 124, Reward: 923.4\n",
      "Episode: 125, Reward: 923.4\n",
      "Episode: 126, Reward: 923.4\n",
      "Episode: 127, Reward: 923.4\n",
      "Episode: 128, Reward: 923.4\n",
      "Episode: 129, Reward: 923.4\n",
      "Episode: 130, Reward: 923.4\n",
      "Episode: 131, Reward: 923.4\n",
      "Episode: 132, Reward: 618.5\n",
      "Episode: 133, Reward: 618.5\n",
      "Episode: 134, Reward: 618.5\n",
      "Episode: 135, Reward: 618.5\n",
      "Episode: 136, Reward: 618.5\n",
      "Episode: 137, Reward: 618.5\n",
      "Episode: 138, Reward: 618.5\n",
      "Episode: 139, Reward: 618.5\n",
      "Episode: 140, Reward: 618.5\n",
      "Episode: 141, Reward: 618.5\n",
      "Episode: 142, Reward: 618.5\n",
      "Episode: 143, Reward: 618.5\n",
      "Episode: 144, Reward: 618.5\n",
      "Episode: 145, Reward: 618.5\n",
      "Episode: 146, Reward: 618.5\n",
      "Episode: 147, Reward: 618.5\n",
      "Episode: 148, Reward: 618.5\n",
      "Episode: 149, Reward: 618.5\n",
      "Episode: 150, Reward: 618.5\n",
      "Episode: 151, Reward: 618.5\n",
      "Episode: 152, Reward: 618.5\n",
      "Episode: 153, Reward: 618.5\n",
      "Episode: 154, Reward: 937.6\n",
      "Episode: 155, Reward: 937.6\n",
      "Episode: 156, Reward: 937.6\n",
      "Episode: 157, Reward: 937.6\n",
      "Episode: 158, Reward: 937.6\n",
      "Episode: 159, Reward: 972.1\n",
      "Episode: 160, Reward: 972.1\n",
      "Episode: 161, Reward: 972.1\n",
      "Episode: 162, Reward: 972.1\n",
      "Episode: 163, Reward: 1023.5\n",
      "Episode: 164, Reward: 1023.5\n",
      "Episode: 165, Reward: 606.1\n",
      "Episode: 166, Reward: 606.1\n",
      "Episode: 167, Reward: 606.1\n",
      "Episode: 168, Reward: 606.1\n",
      "Episode: 169, Reward: 606.1\n",
      "Episode: 170, Reward: 606.1\n",
      "Episode: 171, Reward: 606.1\n",
      "Episode: 172, Reward: 1032.5\n",
      "Episode: 173, Reward: 1032.5\n",
      "Episode: 174, Reward: 1032.5\n",
      "Episode: 175, Reward: 1332.3\n",
      "Episode: 176, Reward: 1332.3\n",
      "Episode: 177, Reward: 1332.3\n",
      "Episode: 178, Reward: 1507.9\n",
      "Episode: 179, Reward: 1507.9\n",
      "Episode: 180, Reward: 1731.1\n",
      "Episode: 181, Reward: 1731.1\n",
      "Episode: 182, Reward: 1731.1\n",
      "Episode: 183, Reward: 1945.0\n",
      "Episode: 184, Reward: 1945.0\n",
      "Episode: 185, Reward: 2346.9\n",
      "Episode: 186, Reward: 2346.9\n",
      "Episode: 187, Reward: 2346.9\n",
      "Episode: 188, Reward: 2403.5\n",
      "Episode: 189, Reward: 2403.5\n",
      "Episode: 190, Reward: 2403.5\n",
      "Episode: 191, Reward: 2544.6\n",
      "Episode: 192, Reward: 2544.6\n",
      "Episode: 193, Reward: 2544.6\n",
      "Episode: 194, Reward: 2544.6\n",
      "Episode: 195, Reward: 2544.6\n",
      "Episode: 196, Reward: 2544.6\n",
      "Episode: 197, Reward: 2544.6\n",
      "Episode: 198, Reward: 2544.6\n",
      "Episode: 199, Reward: 2766.1\n",
      "END - Date-Time: 2023-08-21 11:59:34\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[15, 22, 29, 35, 43, 45, 52, 54, 55, 56, 59, 61, 62, 67, 71, 78, 86, 97, 107, 108, 111, 119, 123, 124, 126, 129, 130, 136, 141, 147, 155, 157, 159, 161, 163, 172, 176, 177, 180, 187]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "Saving rewards to csv\n",
      "Saving boxplot of results\n",
      "Average Accumulated Reward: 3213670.0\n",
      "ALE_ZAXXON-V5 EXPERIMENT 0: Date-Time: 2023-08-21 12:00:08, Capacity: 1M\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 1000000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 0.0\n",
      "Episode: 8, Reward: 0.0\n",
      "Episode: 9, Reward: 0.0\n",
      "Episode: 10, Reward: 0.0\n",
      "Episode: 11, Reward: 0.0\n",
      "Episode: 12, Reward: 0.0\n",
      "Episode: 13, Reward: 0.0\n",
      "Episode: 14, Reward: 0.0\n",
      "Episode: 15, Reward: 0.0\n",
      "Episode: 16, Reward: 0.0\n",
      "Episode: 17, Reward: 0.0\n",
      "Episode: 18, Reward: 0.0\n",
      "Episode: 19, Reward: 0.0\n",
      "Episode: 20, Reward: 0.0\n",
      "Episode: 21, Reward: 0.0\n",
      "Episode: 22, Reward: 0.0\n",
      "Episode: 23, Reward: 0.0\n",
      "Episode: 24, Reward: 0.0\n",
      "Episode: 25, Reward: 0.0\n",
      "Episode: 26, Reward: 0.0\n",
      "Episode: 27, Reward: 0.0\n",
      "Episode: 28, Reward: 0.0\n",
      "Episode: 29, Reward: 0.0\n",
      "Episode: 30, Reward: 0.0\n",
      "Episode: 31, Reward: 0.0\n",
      "Episode: 32, Reward: 0.0\n",
      "Episode: 33, Reward: 0.0\n",
      "Episode: 34, Reward: 0.0\n",
      "Episode: 35, Reward: 0.0\n",
      "Episode: 36, Reward: 0.0\n",
      "Episode: 37, Reward: 0.0\n",
      "Episode: 38, Reward: 0.0\n",
      "Episode: 39, Reward: 0.0\n",
      "Episode: 40, Reward: 0.0\n",
      "Episode: 41, Reward: 0.0\n",
      "Episode: 42, Reward: 0.0\n",
      "Episode: 43, Reward: 0.0\n",
      "Episode: 44, Reward: 0.0\n",
      "Episode: 45, Reward: 0.0\n",
      "Episode: 46, Reward: 0.0\n",
      "Episode: 47, Reward: 0.0\n",
      "Episode: 48, Reward: 0.0\n",
      "Episode: 49, Reward: 0.0\n",
      "Episode: 50, Reward: 0.0\n",
      "Episode: 51, Reward: 0.0\n",
      "Episode: 52, Reward: 0.0\n",
      "Episode: 53, Reward: 0.0\n",
      "Episode: 54, Reward: 0.0\n",
      "Episode: 55, Reward: 0.0\n",
      "Episode: 56, Reward: 0.0\n",
      "Episode: 57, Reward: 0.0\n",
      "Episode: 58, Reward: 0.0\n",
      "Episode: 59, Reward: 0.0\n",
      "Episode: 60, Reward: 0.0\n",
      "Episode: 61, Reward: 0.0\n",
      "Episode: 62, Reward: 0.0\n",
      "Episode: 63, Reward: 0.0\n",
      "Episode: 64, Reward: 0.0\n",
      "Episode: 65, Reward: 0.0\n",
      "Episode: 66, Reward: 0.0\n",
      "Episode: 67, Reward: 0.0\n",
      "Episode: 68, Reward: 0.0\n",
      "Episode: 69, Reward: 0.0\n",
      "Episode: 70, Reward: 0.0\n",
      "Episode: 71, Reward: 0.0\n",
      "Episode: 72, Reward: 0.0\n",
      "Episode: 73, Reward: 0.0\n",
      "Episode: 74, Reward: 0.0\n",
      "Episode: 75, Reward: 0.0\n",
      "Episode: 76, Reward: 0.0\n",
      "Episode: 77, Reward: 0.0\n",
      "Episode: 78, Reward: 0.0\n",
      "Episode: 79, Reward: 0.0\n",
      "Episode: 80, Reward: 0.0\n",
      "Episode: 81, Reward: 0.0\n",
      "Episode: 82, Reward: 0.0\n",
      "Episode: 83, Reward: 0.0\n",
      "Episode: 84, Reward: 0.0\n",
      "Episode: 85, Reward: 0.0\n",
      "Episode: 86, Reward: 0.0\n",
      "Episode: 87, Reward: 0.0\n",
      "Episode: 88, Reward: 0.0\n",
      "Episode: 89, Reward: 0.0\n",
      "Episode: 90, Reward: 0.0\n",
      "Episode: 91, Reward: 0.0\n",
      "Episode: 92, Reward: 0.0\n",
      "Episode: 93, Reward: 0.0\n",
      "Episode: 94, Reward: 0.0\n",
      "Episode: 95, Reward: 0.0\n",
      "Episode: 96, Reward: 0.0\n",
      "Episode: 97, Reward: 0.0\n",
      "Episode: 98, Reward: 0.0\n",
      "Episode: 99, Reward: 0.0\n",
      "Episode: 100, Reward: 0.0\n",
      "Episode: 101, Reward: 0.0\n",
      "Episode: 102, Reward: 0.0\n",
      "Episode: 103, Reward: 0.0\n",
      "Episode: 104, Reward: 0.0\n",
      "Episode: 105, Reward: 0.0\n",
      "Episode: 106, Reward: 0.0\n",
      "Episode: 107, Reward: 0.0\n",
      "Episode: 108, Reward: 0.0\n",
      "Episode: 109, Reward: 0.0\n",
      "Episode: 110, Reward: 0.0\n",
      "Episode: 111, Reward: 0.0\n",
      "Episode: 112, Reward: 0.0\n",
      "Episode: 113, Reward: 0.0\n",
      "Episode: 114, Reward: 0.0\n",
      "Episode: 115, Reward: 0.0\n",
      "Episode: 116, Reward: 0.0\n",
      "Episode: 117, Reward: 0.0\n",
      "Episode: 118, Reward: 0.0\n",
      "Episode: 119, Reward: 0.0\n",
      "Episode: 120, Reward: 0.0\n",
      "Episode: 121, Reward: 0.0\n",
      "Episode: 122, Reward: 0.0\n",
      "Episode: 123, Reward: 0.0\n",
      "Episode: 124, Reward: 0.0\n",
      "Episode: 125, Reward: 0.0\n",
      "Episode: 126, Reward: 0.0\n",
      "Episode: 127, Reward: 0.0\n",
      "Episode: 128, Reward: 0.0\n",
      "Episode: 129, Reward: 0.0\n",
      "Episode: 130, Reward: 0.0\n",
      "Episode: 131, Reward: 0.0\n",
      "Episode: 132, Reward: 0.0\n",
      "Episode: 133, Reward: 0.0\n",
      "Episode: 134, Reward: 0.0\n",
      "Episode: 135, Reward: 0.0\n",
      "Episode: 136, Reward: 0.0\n",
      "Episode: 137, Reward: 0.0\n",
      "Episode: 138, Reward: 0.0\n",
      "Episode: 139, Reward: 0.0\n",
      "Episode: 140, Reward: 0.0\n",
      "Episode: 141, Reward: 0.0\n",
      "Episode: 142, Reward: 0.0\n",
      "Episode: 143, Reward: 0.0\n",
      "Episode: 144, Reward: 0.0\n",
      "Episode: 145, Reward: 0.0\n",
      "Episode: 146, Reward: 0.0\n",
      "Episode: 147, Reward: 0.0\n",
      "Episode: 148, Reward: 0.0\n",
      "Episode: 149, Reward: 0.0\n",
      "Episode: 150, Reward: 0.0\n",
      "Episode: 151, Reward: 0.0\n",
      "Episode: 152, Reward: 0.0\n",
      "Episode: 153, Reward: 0.0\n",
      "Episode: 154, Reward: 0.0\n",
      "Episode: 155, Reward: 0.0\n",
      "Episode: 156, Reward: 0.0\n",
      "Episode: 157, Reward: 0.0\n",
      "Episode: 158, Reward: 0.0\n",
      "Episode: 159, Reward: 0.0\n",
      "Episode: 160, Reward: 0.0\n",
      "Episode: 161, Reward: 0.0\n",
      "Episode: 162, Reward: 0.0\n",
      "Episode: 163, Reward: 0.0\n",
      "Episode: 164, Reward: 0.0\n",
      "Episode: 165, Reward: 0.0\n",
      "Episode: 166, Reward: 0.0\n",
      "Episode: 167, Reward: 0.0\n",
      "Episode: 168, Reward: 0.0\n",
      "Episode: 169, Reward: 0.0\n",
      "Episode: 170, Reward: 0.0\n",
      "Episode: 171, Reward: 0.0\n",
      "Episode: 172, Reward: 0.0\n",
      "Episode: 173, Reward: 0.0\n",
      "Episode: 174, Reward: 0.0\n",
      "Episode: 175, Reward: 0.0\n",
      "Episode: 176, Reward: 0.0\n",
      "Episode: 177, Reward: 0.0\n",
      "Episode: 178, Reward: 0.0\n",
      "Episode: 179, Reward: 0.0\n",
      "Episode: 180, Reward: 0.0\n",
      "Episode: 181, Reward: 0.0\n",
      "Episode: 182, Reward: 0.0\n",
      "Episode: 183, Reward: 0.0\n",
      "Episode: 184, Reward: 0.0\n",
      "Episode: 185, Reward: 0.0\n",
      "Episode: 186, Reward: 0.0\n",
      "Episode: 187, Reward: 0.0\n",
      "Episode: 188, Reward: 0.0\n",
      "Episode: 189, Reward: 0.0\n",
      "Episode: 190, Reward: 0.0\n",
      "Episode: 191, Reward: 0.0\n",
      "Episode: 192, Reward: 0.0\n",
      "Episode: 193, Reward: 0.0\n",
      "Episode: 194, Reward: 0.0\n",
      "Episode: 195, Reward: 0.0\n",
      "Episode: 196, Reward: 0.0\n",
      "Episode: 197, Reward: 0.0\n",
      "Episode: 198, Reward: 0.0\n",
      "Episode: 199, Reward: 0.0\n",
      "END - Date-Time: 2023-08-21 12:24:51\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[0, 6, 13, 14, 17, 20, 27, 35, 38, 42, 44, 45, 51, 55, 63, 72, 92, 97, 99, 104, 110, 111, 114, 127, 132, 139, 148, 156, 158, 159, 162, 164, 168, 169, 173, 175, 179, 189, 190, 191]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_ZAXXON-V5 EXPERIMENT 1: Date-Time: 2023-08-21 12:25:44, Capacity: 500k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 500000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 0.0\n",
      "Episode: 8, Reward: 0.0\n",
      "Episode: 9, Reward: 0.0\n",
      "Episode: 10, Reward: 0.0\n",
      "Episode: 11, Reward: 0.0\n",
      "Episode: 12, Reward: 0.0\n",
      "Episode: 13, Reward: 0.0\n",
      "Episode: 14, Reward: 0.0\n",
      "Episode: 15, Reward: 0.0\n",
      "Episode: 16, Reward: 0.0\n",
      "Episode: 17, Reward: 0.0\n",
      "Episode: 18, Reward: 0.0\n",
      "Episode: 19, Reward: 0.0\n",
      "Episode: 20, Reward: 0.0\n",
      "Episode: 21, Reward: 0.0\n",
      "Episode: 22, Reward: 0.0\n",
      "Episode: 23, Reward: 0.0\n",
      "Episode: 24, Reward: 0.0\n",
      "Episode: 25, Reward: 0.0\n",
      "Episode: 26, Reward: 0.0\n",
      "Episode: 27, Reward: 0.0\n",
      "Episode: 28, Reward: 0.0\n",
      "Episode: 29, Reward: 0.0\n",
      "Episode: 30, Reward: 0.0\n",
      "Episode: 31, Reward: 0.0\n",
      "Episode: 32, Reward: 0.0\n",
      "Episode: 33, Reward: 0.0\n",
      "Episode: 34, Reward: 0.0\n",
      "Episode: 35, Reward: 0.0\n",
      "Episode: 36, Reward: 0.0\n",
      "Episode: 37, Reward: 0.0\n",
      "Episode: 38, Reward: 0.0\n",
      "Episode: 39, Reward: 0.0\n",
      "Episode: 40, Reward: 0.0\n",
      "Episode: 41, Reward: 0.0\n",
      "Episode: 42, Reward: 0.0\n",
      "Episode: 43, Reward: 0.0\n",
      "Episode: 44, Reward: 0.0\n",
      "Episode: 45, Reward: 0.0\n",
      "Episode: 46, Reward: 0.0\n",
      "Episode: 47, Reward: 0.0\n",
      "Episode: 48, Reward: 0.0\n",
      "Episode: 49, Reward: 0.0\n",
      "Episode: 50, Reward: 0.0\n",
      "Episode: 51, Reward: 0.0\n",
      "Episode: 52, Reward: 0.0\n",
      "Episode: 53, Reward: 0.0\n",
      "Episode: 54, Reward: 0.0\n",
      "Episode: 55, Reward: 0.0\n",
      "Episode: 56, Reward: 0.0\n",
      "Episode: 57, Reward: 0.0\n",
      "Episode: 58, Reward: 0.0\n",
      "Episode: 59, Reward: 0.0\n",
      "Episode: 60, Reward: 0.0\n",
      "Episode: 61, Reward: 0.0\n",
      "Episode: 62, Reward: 0.0\n",
      "Episode: 63, Reward: 0.0\n",
      "Episode: 64, Reward: 0.0\n",
      "Episode: 65, Reward: 0.0\n",
      "Episode: 66, Reward: 0.0\n",
      "Episode: 67, Reward: 0.0\n",
      "Episode: 68, Reward: 0.0\n",
      "Episode: 69, Reward: 0.0\n",
      "Episode: 70, Reward: 0.0\n",
      "Episode: 71, Reward: 0.0\n",
      "Episode: 72, Reward: 0.0\n",
      "Episode: 73, Reward: 0.0\n",
      "Episode: 74, Reward: 0.0\n",
      "Episode: 75, Reward: 0.0\n",
      "Episode: 76, Reward: 0.0\n",
      "Episode: 77, Reward: 0.0\n",
      "Episode: 78, Reward: 0.0\n",
      "Episode: 79, Reward: 0.0\n",
      "Episode: 80, Reward: 0.0\n",
      "Episode: 81, Reward: 0.0\n",
      "Episode: 82, Reward: 0.0\n",
      "Episode: 83, Reward: 0.0\n",
      "Episode: 84, Reward: 0.0\n",
      "Episode: 85, Reward: 0.0\n",
      "Episode: 86, Reward: 0.0\n",
      "Episode: 87, Reward: 0.0\n",
      "Episode: 88, Reward: 0.0\n",
      "Episode: 89, Reward: 0.0\n",
      "Episode: 90, Reward: 0.0\n",
      "Episode: 91, Reward: 0.0\n",
      "Episode: 92, Reward: 0.0\n",
      "Episode: 93, Reward: 0.0\n",
      "Episode: 94, Reward: 0.0\n",
      "Episode: 95, Reward: 0.0\n",
      "Episode: 96, Reward: 0.0\n",
      "Episode: 97, Reward: 0.0\n",
      "Episode: 98, Reward: 0.0\n",
      "Episode: 99, Reward: 0.0\n",
      "Episode: 100, Reward: 0.0\n",
      "Episode: 101, Reward: 0.0\n",
      "Episode: 102, Reward: 0.0\n",
      "Episode: 103, Reward: 0.0\n",
      "Episode: 104, Reward: 0.0\n",
      "Episode: 105, Reward: 0.0\n",
      "Episode: 106, Reward: 0.0\n",
      "Episode: 107, Reward: 0.0\n",
      "Episode: 108, Reward: 0.0\n",
      "Episode: 109, Reward: 0.0\n",
      "Episode: 110, Reward: 0.0\n",
      "Episode: 111, Reward: 0.0\n",
      "Episode: 112, Reward: 0.0\n",
      "Episode: 113, Reward: 0.0\n",
      "Episode: 114, Reward: 0.0\n",
      "Episode: 115, Reward: 0.0\n",
      "Episode: 116, Reward: 0.0\n",
      "Episode: 117, Reward: 0.0\n",
      "Episode: 118, Reward: 0.0\n",
      "Episode: 119, Reward: 0.0\n",
      "Episode: 120, Reward: 0.0\n",
      "Episode: 121, Reward: 0.0\n",
      "Episode: 122, Reward: 0.0\n",
      "Episode: 123, Reward: 0.0\n",
      "Episode: 124, Reward: 0.0\n",
      "Episode: 125, Reward: 0.0\n",
      "Episode: 126, Reward: 0.0\n",
      "Episode: 127, Reward: 0.0\n",
      "Episode: 128, Reward: 0.0\n",
      "Episode: 129, Reward: 0.0\n",
      "Episode: 130, Reward: 0.0\n",
      "Episode: 131, Reward: 0.0\n",
      "Episode: 132, Reward: 0.0\n",
      "Episode: 133, Reward: 0.0\n",
      "Episode: 134, Reward: 0.0\n",
      "Episode: 135, Reward: 0.0\n",
      "Episode: 136, Reward: 0.0\n",
      "Episode: 137, Reward: 0.0\n",
      "Episode: 138, Reward: 0.0\n",
      "Episode: 139, Reward: 0.0\n",
      "Episode: 140, Reward: 0.0\n",
      "Episode: 141, Reward: 0.0\n",
      "Episode: 142, Reward: 0.0\n",
      "Episode: 143, Reward: 0.0\n",
      "Episode: 144, Reward: 0.0\n",
      "Episode: 145, Reward: 0.0\n",
      "Episode: 146, Reward: 0.0\n",
      "Episode: 147, Reward: 0.0\n",
      "Episode: 148, Reward: 0.0\n",
      "Episode: 149, Reward: 0.0\n",
      "Episode: 150, Reward: 0.0\n",
      "Episode: 151, Reward: 0.0\n",
      "Episode: 152, Reward: 0.0\n",
      "Episode: 153, Reward: 0.0\n",
      "Episode: 154, Reward: 0.0\n",
      "Episode: 155, Reward: 0.0\n",
      "Episode: 156, Reward: 0.0\n",
      "Episode: 157, Reward: 0.0\n",
      "Episode: 158, Reward: 0.0\n",
      "Episode: 159, Reward: 0.0\n",
      "Episode: 160, Reward: 0.0\n",
      "Episode: 161, Reward: 0.0\n",
      "Episode: 162, Reward: 0.0\n",
      "Episode: 163, Reward: 0.0\n",
      "Episode: 164, Reward: 0.0\n",
      "Episode: 165, Reward: 0.0\n",
      "Episode: 166, Reward: 0.0\n",
      "Episode: 167, Reward: 0.0\n",
      "Episode: 168, Reward: 0.0\n",
      "Episode: 169, Reward: 0.0\n",
      "Episode: 170, Reward: 0.0\n",
      "Episode: 171, Reward: 0.0\n",
      "Episode: 172, Reward: 0.0\n",
      "Episode: 173, Reward: 0.0\n",
      "Episode: 174, Reward: 0.0\n",
      "Episode: 175, Reward: 0.0\n",
      "Episode: 176, Reward: 0.0\n",
      "Episode: 177, Reward: 0.0\n",
      "Episode: 178, Reward: 0.0\n",
      "Episode: 179, Reward: 0.0\n",
      "Episode: 180, Reward: 0.0\n",
      "Episode: 181, Reward: 0.0\n",
      "Episode: 182, Reward: 0.0\n",
      "Episode: 183, Reward: 0.0\n",
      "Episode: 184, Reward: 0.0\n",
      "Episode: 185, Reward: 0.0\n",
      "Episode: 186, Reward: 0.0\n",
      "Episode: 187, Reward: 0.0\n",
      "Episode: 188, Reward: 0.0\n",
      "Episode: 189, Reward: 0.0\n",
      "Episode: 190, Reward: 0.0\n",
      "Episode: 191, Reward: 0.0\n",
      "Episode: 192, Reward: 0.0\n",
      "Episode: 193, Reward: 0.0\n",
      "Episode: 194, Reward: 0.0\n",
      "Episode: 195, Reward: 0.0\n",
      "Episode: 196, Reward: 0.0\n",
      "Episode: 197, Reward: 0.0\n",
      "Episode: 198, Reward: 0.0\n",
      "Episode: 199, Reward: 0.0\n",
      "END - Date-Time: 2023-08-21 12:49:49\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[3, 7, 11, 32, 37, 38, 44, 47, 49, 51, 54, 56, 63, 66, 71, 77, 84, 90, 94, 96, 99, 105, 116, 118, 119, 120, 125, 130, 144, 153, 156, 157, 163, 167, 170, 171, 176, 177, 178, 189]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_ZAXXON-V5 EXPERIMENT 2: Date-Time: 2023-08-21 12:50:27, Capacity: 100k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 100000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 0.0\n",
      "Episode: 8, Reward: 0.0\n",
      "Episode: 9, Reward: 0.0\n",
      "Episode: 10, Reward: 0.0\n",
      "Episode: 11, Reward: 0.0\n",
      "Episode: 12, Reward: 0.0\n",
      "Episode: 13, Reward: 0.0\n",
      "Episode: 14, Reward: 0.0\n",
      "Episode: 15, Reward: 0.0\n",
      "Episode: 16, Reward: 0.0\n",
      "Episode: 17, Reward: 0.0\n",
      "Episode: 18, Reward: 0.0\n",
      "Episode: 19, Reward: 0.0\n",
      "Episode: 20, Reward: 0.0\n",
      "Episode: 21, Reward: 0.0\n",
      "Episode: 22, Reward: 0.0\n",
      "Episode: 23, Reward: 0.0\n",
      "Episode: 24, Reward: 0.0\n",
      "Episode: 25, Reward: 0.0\n",
      "Episode: 26, Reward: 0.0\n",
      "Episode: 27, Reward: 0.0\n",
      "Episode: 28, Reward: 0.0\n",
      "Episode: 29, Reward: 0.0\n",
      "Episode: 30, Reward: 0.0\n",
      "Episode: 31, Reward: 0.0\n",
      "Episode: 32, Reward: 0.0\n",
      "Episode: 33, Reward: 0.0\n",
      "Episode: 34, Reward: 0.0\n",
      "Episode: 35, Reward: 0.0\n",
      "Episode: 36, Reward: 0.0\n",
      "Episode: 37, Reward: 0.0\n",
      "Episode: 38, Reward: 0.0\n",
      "Episode: 39, Reward: 0.0\n",
      "Episode: 40, Reward: 0.0\n",
      "Episode: 41, Reward: 0.0\n",
      "Episode: 42, Reward: 0.0\n",
      "Episode: 43, Reward: 0.0\n",
      "Episode: 44, Reward: 0.0\n",
      "Episode: 45, Reward: 0.0\n",
      "Episode: 46, Reward: 0.0\n",
      "Episode: 47, Reward: 0.0\n",
      "Episode: 48, Reward: 0.0\n",
      "Episode: 49, Reward: 0.0\n",
      "Episode: 50, Reward: 0.0\n",
      "Episode: 51, Reward: 0.0\n",
      "Episode: 52, Reward: 0.0\n",
      "Episode: 53, Reward: 0.0\n",
      "Episode: 54, Reward: 0.0\n",
      "Episode: 55, Reward: 0.0\n",
      "Episode: 56, Reward: 0.0\n",
      "Episode: 57, Reward: 0.0\n",
      "Episode: 58, Reward: 0.0\n",
      "Episode: 59, Reward: 0.0\n",
      "Episode: 60, Reward: 0.0\n",
      "Episode: 61, Reward: 0.0\n",
      "Episode: 62, Reward: 0.0\n",
      "Episode: 63, Reward: 0.0\n",
      "Episode: 64, Reward: 0.0\n",
      "Episode: 65, Reward: 0.0\n",
      "Episode: 66, Reward: 0.0\n",
      "Episode: 67, Reward: 0.0\n",
      "Episode: 68, Reward: 0.0\n",
      "Episode: 69, Reward: 0.0\n",
      "Episode: 70, Reward: 0.0\n",
      "Episode: 71, Reward: 0.0\n",
      "Episode: 72, Reward: 0.0\n",
      "Episode: 73, Reward: 0.0\n",
      "Episode: 74, Reward: 0.0\n",
      "Episode: 75, Reward: 0.0\n",
      "Episode: 76, Reward: 0.0\n",
      "Episode: 77, Reward: 0.0\n",
      "Episode: 78, Reward: 0.0\n",
      "Episode: 79, Reward: 0.0\n",
      "Episode: 80, Reward: 0.0\n",
      "Episode: 81, Reward: 0.0\n",
      "Episode: 82, Reward: 0.0\n",
      "Episode: 83, Reward: 0.0\n",
      "Episode: 84, Reward: 0.0\n",
      "Episode: 85, Reward: 0.0\n",
      "Episode: 86, Reward: 0.0\n",
      "Episode: 87, Reward: 0.0\n",
      "Episode: 88, Reward: 0.0\n",
      "Episode: 89, Reward: 0.0\n",
      "Episode: 90, Reward: 0.0\n",
      "Episode: 91, Reward: 0.0\n",
      "Episode: 92, Reward: 0.0\n",
      "Episode: 93, Reward: 0.0\n",
      "Episode: 94, Reward: 0.0\n",
      "Episode: 95, Reward: 0.0\n",
      "Episode: 96, Reward: 0.0\n",
      "Episode: 97, Reward: 0.0\n",
      "Episode: 98, Reward: 0.0\n",
      "Episode: 99, Reward: 0.0\n",
      "Episode: 100, Reward: 0.0\n",
      "Episode: 101, Reward: 0.0\n",
      "Episode: 102, Reward: 0.0\n",
      "Episode: 103, Reward: 0.0\n",
      "Episode: 104, Reward: 0.0\n",
      "Episode: 105, Reward: 0.0\n",
      "Episode: 106, Reward: 0.0\n",
      "Episode: 107, Reward: 0.0\n",
      "Episode: 108, Reward: 0.0\n",
      "Episode: 109, Reward: 0.0\n",
      "Episode: 110, Reward: 0.0\n",
      "Episode: 111, Reward: 0.0\n",
      "Episode: 112, Reward: 0.0\n",
      "Episode: 113, Reward: 0.0\n",
      "Episode: 114, Reward: 0.0\n",
      "Episode: 115, Reward: 0.0\n",
      "Episode: 116, Reward: 0.0\n",
      "Episode: 117, Reward: 0.0\n",
      "Episode: 118, Reward: 0.0\n",
      "Episode: 119, Reward: 0.0\n",
      "Episode: 120, Reward: 0.0\n",
      "Episode: 121, Reward: 0.0\n",
      "Episode: 122, Reward: 0.0\n",
      "Episode: 123, Reward: 0.0\n",
      "Episode: 124, Reward: 0.0\n",
      "Episode: 125, Reward: 0.0\n",
      "Episode: 126, Reward: 0.0\n",
      "Episode: 127, Reward: 0.0\n",
      "Episode: 128, Reward: 0.0\n",
      "Episode: 129, Reward: 0.0\n",
      "Episode: 130, Reward: 0.0\n",
      "Episode: 131, Reward: 0.0\n",
      "Episode: 132, Reward: 0.0\n",
      "Episode: 133, Reward: 0.0\n",
      "Episode: 134, Reward: 0.0\n",
      "Episode: 135, Reward: 0.0\n",
      "Episode: 136, Reward: 0.0\n",
      "Episode: 137, Reward: 0.0\n",
      "Episode: 138, Reward: 0.0\n",
      "Episode: 139, Reward: 0.0\n",
      "Episode: 140, Reward: 0.0\n",
      "Episode: 141, Reward: 0.0\n",
      "Episode: 142, Reward: 0.0\n",
      "Episode: 143, Reward: 0.0\n",
      "Episode: 144, Reward: 0.0\n",
      "Episode: 145, Reward: 0.0\n",
      "Episode: 146, Reward: 0.0\n",
      "Episode: 147, Reward: 0.0\n",
      "Episode: 148, Reward: 0.0\n",
      "Episode: 149, Reward: 0.0\n",
      "Episode: 150, Reward: 0.0\n",
      "Episode: 151, Reward: 0.0\n",
      "Episode: 152, Reward: 0.0\n",
      "Episode: 153, Reward: 0.0\n",
      "Episode: 154, Reward: 0.0\n",
      "Episode: 155, Reward: 0.0\n",
      "Episode: 156, Reward: 0.0\n",
      "Episode: 157, Reward: 0.0\n",
      "Episode: 158, Reward: 0.0\n",
      "Episode: 159, Reward: 0.0\n",
      "Episode: 160, Reward: 0.0\n",
      "Episode: 161, Reward: 0.0\n",
      "Episode: 162, Reward: 0.0\n",
      "Episode: 163, Reward: 0.0\n",
      "Episode: 164, Reward: 0.0\n",
      "Episode: 165, Reward: 0.0\n",
      "Episode: 166, Reward: 0.0\n",
      "Episode: 167, Reward: 0.0\n",
      "Episode: 168, Reward: 0.0\n",
      "Episode: 169, Reward: 0.0\n",
      "Episode: 170, Reward: 0.0\n",
      "Episode: 171, Reward: 0.0\n",
      "Episode: 172, Reward: 0.0\n",
      "Episode: 173, Reward: 0.0\n",
      "Episode: 174, Reward: 0.0\n",
      "Episode: 175, Reward: 0.0\n",
      "Episode: 176, Reward: 0.0\n",
      "Episode: 177, Reward: 0.0\n",
      "Episode: 178, Reward: 0.0\n",
      "Episode: 179, Reward: 0.0\n",
      "Episode: 180, Reward: 0.0\n",
      "Episode: 181, Reward: 0.0\n",
      "Episode: 182, Reward: 0.0\n",
      "Episode: 183, Reward: 0.0\n",
      "Episode: 184, Reward: 0.0\n",
      "Episode: 185, Reward: 0.0\n",
      "Episode: 186, Reward: 0.0\n",
      "Episode: 187, Reward: 0.0\n",
      "Episode: 188, Reward: 0.0\n",
      "Episode: 189, Reward: 0.0\n",
      "Episode: 190, Reward: 0.0\n",
      "Episode: 191, Reward: 0.0\n",
      "Episode: 192, Reward: 0.0\n",
      "Episode: 193, Reward: 0.0\n",
      "Episode: 194, Reward: 0.0\n",
      "Episode: 195, Reward: 0.0\n",
      "Episode: 196, Reward: 0.0\n",
      "Episode: 197, Reward: 0.0\n",
      "Episode: 198, Reward: 0.0\n",
      "Episode: 199, Reward: 0.0\n",
      "END - Date-Time: 2023-08-21 13:16:13\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[2, 14, 42, 47, 53, 56, 65, 66, 73, 80, 81, 82, 90, 92, 101, 109, 115, 116, 117, 127, 128, 130, 131, 138, 144, 149, 151, 152, 154, 155, 158, 162, 167, 172, 174, 181, 186, 190, 192, 198]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_ZAXXON-V5 EXPERIMENT 3: Date-Time: 2023-08-21 13:16:51, Capacity: 50k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 50000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 0.0\n",
      "Episode: 8, Reward: 0.0\n",
      "Episode: 9, Reward: 0.0\n",
      "Episode: 10, Reward: 0.0\n",
      "Episode: 11, Reward: 0.0\n",
      "Episode: 12, Reward: 0.0\n",
      "Episode: 13, Reward: 0.0\n",
      "Episode: 14, Reward: 0.0\n",
      "Episode: 15, Reward: 0.0\n",
      "Episode: 16, Reward: 0.0\n",
      "Episode: 17, Reward: 0.0\n",
      "Episode: 18, Reward: 0.0\n",
      "Episode: 19, Reward: 0.0\n",
      "Episode: 20, Reward: 0.0\n",
      "Episode: 21, Reward: 0.0\n",
      "Episode: 22, Reward: 0.0\n",
      "Episode: 23, Reward: 0.0\n",
      "Episode: 24, Reward: 0.0\n",
      "Episode: 25, Reward: 0.0\n",
      "Episode: 26, Reward: 0.0\n",
      "Episode: 27, Reward: 0.0\n",
      "Episode: 28, Reward: 0.0\n",
      "Episode: 29, Reward: 0.0\n",
      "Episode: 30, Reward: 0.0\n",
      "Episode: 31, Reward: 0.0\n",
      "Episode: 32, Reward: 0.0\n",
      "Episode: 33, Reward: 0.0\n",
      "Episode: 34, Reward: 0.0\n",
      "Episode: 35, Reward: 0.0\n",
      "Episode: 36, Reward: 0.0\n",
      "Episode: 37, Reward: 0.0\n",
      "Episode: 38, Reward: 0.0\n",
      "Episode: 39, Reward: 0.0\n",
      "Episode: 40, Reward: 0.0\n",
      "Episode: 41, Reward: 0.0\n",
      "Episode: 42, Reward: 0.0\n",
      "Episode: 43, Reward: 0.0\n",
      "Episode: 44, Reward: 0.0\n",
      "Episode: 45, Reward: 0.0\n",
      "Episode: 46, Reward: 0.0\n",
      "Episode: 47, Reward: 0.0\n",
      "Episode: 48, Reward: 0.0\n",
      "Episode: 49, Reward: 0.0\n",
      "Episode: 50, Reward: 0.0\n",
      "Episode: 51, Reward: 0.0\n",
      "Episode: 52, Reward: 0.0\n",
      "Episode: 53, Reward: 0.0\n",
      "Episode: 54, Reward: 0.0\n",
      "Episode: 55, Reward: 0.0\n",
      "Episode: 56, Reward: 0.0\n",
      "Episode: 57, Reward: 0.0\n",
      "Episode: 58, Reward: 0.0\n",
      "Episode: 59, Reward: 0.0\n",
      "Episode: 60, Reward: 0.0\n",
      "Episode: 61, Reward: 0.0\n",
      "Episode: 62, Reward: 0.0\n",
      "Episode: 63, Reward: 0.0\n",
      "Episode: 64, Reward: 0.0\n",
      "Episode: 65, Reward: 0.0\n",
      "Episode: 66, Reward: 0.0\n",
      "Episode: 67, Reward: 0.0\n",
      "Episode: 68, Reward: 0.0\n",
      "Episode: 69, Reward: 0.0\n",
      "Episode: 70, Reward: 0.0\n",
      "Episode: 71, Reward: 0.0\n",
      "Episode: 72, Reward: 0.0\n",
      "Episode: 73, Reward: 0.0\n",
      "Episode: 74, Reward: 0.0\n",
      "Episode: 75, Reward: 0.0\n",
      "Episode: 76, Reward: 0.0\n",
      "Episode: 77, Reward: 0.0\n",
      "Episode: 78, Reward: 0.0\n",
      "Episode: 79, Reward: 0.0\n",
      "Episode: 80, Reward: 0.0\n",
      "Episode: 81, Reward: 0.0\n",
      "Episode: 82, Reward: 0.0\n",
      "Episode: 83, Reward: 0.0\n",
      "Episode: 84, Reward: 0.0\n",
      "Episode: 85, Reward: 0.0\n",
      "Episode: 86, Reward: 0.0\n",
      "Episode: 87, Reward: 0.0\n",
      "Episode: 88, Reward: 0.0\n",
      "Episode: 89, Reward: 0.0\n",
      "Episode: 90, Reward: 0.0\n",
      "Episode: 91, Reward: 0.0\n",
      "Episode: 92, Reward: 0.0\n",
      "Episode: 93, Reward: 0.0\n",
      "Episode: 94, Reward: 0.0\n",
      "Episode: 95, Reward: 0.0\n",
      "Episode: 96, Reward: 0.0\n",
      "Episode: 97, Reward: 0.0\n",
      "Episode: 98, Reward: 0.0\n",
      "Episode: 99, Reward: 0.0\n",
      "Episode: 100, Reward: 0.0\n",
      "Episode: 101, Reward: 0.0\n",
      "Episode: 102, Reward: 0.0\n",
      "Episode: 103, Reward: 0.0\n",
      "Episode: 104, Reward: 0.0\n",
      "Episode: 105, Reward: 0.0\n",
      "Episode: 106, Reward: 0.0\n",
      "Episode: 107, Reward: 0.0\n",
      "Episode: 108, Reward: 0.0\n",
      "Episode: 109, Reward: 0.0\n",
      "Episode: 110, Reward: 0.0\n",
      "Episode: 111, Reward: 0.0\n",
      "Episode: 112, Reward: 0.0\n",
      "Episode: 113, Reward: 0.0\n",
      "Episode: 114, Reward: 0.0\n",
      "Episode: 115, Reward: 0.0\n",
      "Episode: 116, Reward: 0.0\n",
      "Episode: 117, Reward: 0.0\n",
      "Episode: 118, Reward: 0.0\n",
      "Episode: 119, Reward: 0.0\n",
      "Episode: 120, Reward: 0.0\n",
      "Episode: 121, Reward: 0.0\n",
      "Episode: 122, Reward: 0.0\n",
      "Episode: 123, Reward: 0.0\n",
      "Episode: 124, Reward: 0.0\n",
      "Episode: 125, Reward: 0.0\n",
      "Episode: 126, Reward: 0.0\n",
      "Episode: 127, Reward: 0.0\n",
      "Episode: 128, Reward: 0.0\n",
      "Episode: 129, Reward: 0.0\n",
      "Episode: 130, Reward: 0.0\n",
      "Episode: 131, Reward: 0.0\n",
      "Episode: 132, Reward: 0.0\n",
      "Episode: 133, Reward: 0.0\n",
      "Episode: 134, Reward: 0.0\n",
      "Episode: 135, Reward: 0.0\n",
      "Episode: 136, Reward: 0.0\n",
      "Episode: 137, Reward: 0.0\n",
      "Episode: 138, Reward: 0.0\n",
      "Episode: 139, Reward: 0.0\n",
      "Episode: 140, Reward: 0.0\n",
      "Episode: 141, Reward: 0.0\n",
      "Episode: 142, Reward: 0.0\n",
      "Episode: 143, Reward: 0.0\n",
      "Episode: 144, Reward: 0.0\n",
      "Episode: 145, Reward: 0.0\n",
      "Episode: 146, Reward: 0.0\n",
      "Episode: 147, Reward: 0.0\n",
      "Episode: 148, Reward: 0.0\n",
      "Episode: 149, Reward: 0.0\n",
      "Episode: 150, Reward: 0.0\n",
      "Episode: 151, Reward: 0.0\n",
      "Episode: 152, Reward: 0.0\n",
      "Episode: 153, Reward: 0.0\n",
      "Episode: 154, Reward: 0.0\n",
      "Episode: 155, Reward: 0.0\n",
      "Episode: 156, Reward: 0.0\n",
      "Episode: 157, Reward: 0.0\n",
      "Episode: 158, Reward: 0.0\n",
      "Episode: 159, Reward: 0.0\n",
      "Episode: 160, Reward: 0.0\n",
      "Episode: 161, Reward: 0.0\n",
      "Episode: 162, Reward: 0.0\n",
      "Episode: 163, Reward: 0.0\n",
      "Episode: 164, Reward: 0.0\n",
      "Episode: 165, Reward: 0.0\n",
      "Episode: 166, Reward: 0.0\n",
      "Episode: 167, Reward: 0.0\n",
      "Episode: 168, Reward: 0.0\n",
      "Episode: 169, Reward: 0.0\n",
      "Episode: 170, Reward: 0.0\n",
      "Episode: 171, Reward: 0.0\n",
      "Episode: 172, Reward: 0.0\n",
      "Episode: 173, Reward: 0.0\n",
      "Episode: 174, Reward: 0.0\n",
      "Episode: 175, Reward: 0.0\n",
      "Episode: 176, Reward: 0.0\n",
      "Episode: 177, Reward: 0.0\n",
      "Episode: 178, Reward: 0.0\n",
      "Episode: 179, Reward: 0.0\n",
      "Episode: 180, Reward: 0.0\n",
      "Episode: 181, Reward: 0.0\n",
      "Episode: 182, Reward: 0.0\n",
      "Episode: 183, Reward: 0.0\n",
      "Episode: 184, Reward: 0.0\n",
      "Episode: 185, Reward: 0.0\n",
      "Episode: 186, Reward: 0.0\n",
      "Episode: 187, Reward: 0.0\n",
      "Episode: 188, Reward: 0.0\n",
      "Episode: 189, Reward: 0.0\n",
      "Episode: 190, Reward: 0.0\n",
      "Episode: 191, Reward: 0.0\n",
      "Episode: 192, Reward: 0.0\n",
      "Episode: 193, Reward: 0.0\n",
      "Episode: 194, Reward: 0.0\n",
      "Episode: 195, Reward: 0.0\n",
      "Episode: 196, Reward: 0.0\n",
      "Episode: 197, Reward: 0.0\n",
      "Episode: 198, Reward: 0.0\n",
      "Episode: 199, Reward: 0.0\n",
      "END - Date-Time: 2023-08-21 13:42:44\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[4, 11, 17, 34, 40, 41, 45, 50, 57, 59, 63, 66, 69, 74, 75, 78, 79, 83, 95, 97, 99, 103, 113, 114, 115, 117, 128, 134, 140, 143, 147, 158, 171, 172, 174, 177, 184, 190, 196, 198]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_ZAXXON-V5 EXPERIMENT 4: Date-Time: 2023-08-21 13:43:19, Capacity: 10k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 10000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 0.0\n",
      "Episode: 8, Reward: 0.0\n",
      "Episode: 9, Reward: 0.0\n",
      "Episode: 10, Reward: 0.0\n",
      "Episode: 11, Reward: 0.0\n",
      "Episode: 12, Reward: 0.0\n",
      "Episode: 13, Reward: 0.0\n",
      "Episode: 14, Reward: 0.0\n",
      "Episode: 15, Reward: 0.0\n",
      "Episode: 16, Reward: 0.0\n",
      "Episode: 17, Reward: 0.0\n",
      "Episode: 18, Reward: 0.0\n",
      "Episode: 19, Reward: 0.0\n",
      "Episode: 20, Reward: 0.0\n",
      "Episode: 21, Reward: 0.0\n",
      "Episode: 22, Reward: 0.0\n",
      "Episode: 23, Reward: 0.0\n",
      "Episode: 24, Reward: 0.0\n",
      "Episode: 25, Reward: 0.0\n",
      "Episode: 26, Reward: 0.0\n",
      "Episode: 27, Reward: 0.0\n",
      "Episode: 28, Reward: 0.0\n",
      "Episode: 29, Reward: 0.0\n",
      "Episode: 30, Reward: 0.0\n",
      "Episode: 31, Reward: 0.0\n",
      "Episode: 32, Reward: 0.0\n",
      "Episode: 33, Reward: 0.0\n",
      "Episode: 34, Reward: 0.0\n",
      "Episode: 35, Reward: 0.0\n",
      "Episode: 36, Reward: 0.0\n",
      "Episode: 37, Reward: 0.0\n",
      "Episode: 38, Reward: 0.0\n",
      "Episode: 39, Reward: 0.0\n",
      "Episode: 40, Reward: 0.0\n",
      "Episode: 41, Reward: 0.0\n",
      "Episode: 42, Reward: 0.0\n",
      "Episode: 43, Reward: 0.0\n",
      "Episode: 44, Reward: 0.0\n",
      "Episode: 45, Reward: 0.0\n",
      "Episode: 46, Reward: 0.0\n",
      "Episode: 47, Reward: 0.0\n",
      "Episode: 48, Reward: 0.0\n",
      "Episode: 49, Reward: 0.0\n",
      "Episode: 50, Reward: 0.0\n",
      "Episode: 51, Reward: 0.0\n",
      "Episode: 52, Reward: 0.0\n",
      "Episode: 53, Reward: 0.0\n",
      "Episode: 54, Reward: 0.0\n",
      "Episode: 55, Reward: 0.0\n",
      "Episode: 56, Reward: 0.0\n",
      "Episode: 57, Reward: 0.0\n",
      "Episode: 58, Reward: 0.0\n",
      "Episode: 59, Reward: 0.0\n",
      "Episode: 60, Reward: 0.0\n",
      "Episode: 61, Reward: 0.0\n",
      "Episode: 62, Reward: 0.0\n",
      "Episode: 63, Reward: 0.0\n",
      "Episode: 64, Reward: 0.0\n",
      "Episode: 65, Reward: 0.0\n",
      "Episode: 66, Reward: 0.0\n",
      "Episode: 67, Reward: 0.0\n",
      "Episode: 68, Reward: 0.0\n",
      "Episode: 69, Reward: 0.0\n",
      "Episode: 70, Reward: 0.0\n",
      "Episode: 71, Reward: 0.0\n",
      "Episode: 72, Reward: 0.0\n",
      "Episode: 73, Reward: 0.0\n",
      "Episode: 74, Reward: 0.0\n",
      "Episode: 75, Reward: 0.0\n",
      "Episode: 76, Reward: 0.0\n",
      "Episode: 77, Reward: 0.0\n",
      "Episode: 78, Reward: 0.0\n",
      "Episode: 79, Reward: 0.0\n",
      "Episode: 80, Reward: 0.0\n",
      "Episode: 81, Reward: 0.0\n",
      "Episode: 82, Reward: 0.0\n",
      "Episode: 83, Reward: 0.0\n",
      "Episode: 84, Reward: 0.0\n",
      "Episode: 85, Reward: 0.0\n",
      "Episode: 86, Reward: 0.0\n",
      "Episode: 87, Reward: 0.0\n",
      "Episode: 88, Reward: 0.0\n",
      "Episode: 89, Reward: 0.0\n",
      "Episode: 90, Reward: 0.0\n",
      "Episode: 91, Reward: 0.0\n",
      "Episode: 92, Reward: 0.0\n",
      "Episode: 93, Reward: 0.0\n",
      "Episode: 94, Reward: 0.0\n",
      "Episode: 95, Reward: 0.0\n",
      "Episode: 96, Reward: 0.0\n",
      "Episode: 97, Reward: 0.0\n",
      "Episode: 98, Reward: 0.0\n",
      "Episode: 99, Reward: 0.0\n",
      "Episode: 100, Reward: 0.0\n",
      "Episode: 101, Reward: 0.0\n",
      "Episode: 102, Reward: 0.0\n",
      "Episode: 103, Reward: 0.0\n",
      "Episode: 104, Reward: 0.0\n",
      "Episode: 105, Reward: 0.0\n",
      "Episode: 106, Reward: 0.0\n",
      "Episode: 107, Reward: 0.0\n",
      "Episode: 108, Reward: 0.0\n",
      "Episode: 109, Reward: 0.0\n",
      "Episode: 110, Reward: 0.0\n",
      "Episode: 111, Reward: 0.0\n",
      "Episode: 112, Reward: 0.0\n",
      "Episode: 113, Reward: 0.0\n",
      "Episode: 114, Reward: 0.0\n",
      "Episode: 115, Reward: 0.0\n",
      "Episode: 116, Reward: 0.0\n",
      "Episode: 117, Reward: 0.0\n",
      "Episode: 118, Reward: 0.0\n",
      "Episode: 119, Reward: 0.0\n",
      "Episode: 120, Reward: 0.0\n",
      "Episode: 121, Reward: 0.0\n",
      "Episode: 122, Reward: 0.0\n",
      "Episode: 123, Reward: 0.0\n",
      "Episode: 124, Reward: 0.0\n",
      "Episode: 125, Reward: 0.0\n",
      "Episode: 126, Reward: 0.0\n",
      "Episode: 127, Reward: 0.0\n",
      "Episode: 128, Reward: 0.0\n",
      "Episode: 129, Reward: 0.0\n",
      "Episode: 130, Reward: 0.0\n",
      "Episode: 131, Reward: 0.0\n",
      "Episode: 132, Reward: 0.0\n",
      "Episode: 133, Reward: 0.0\n",
      "Episode: 134, Reward: 0.0\n",
      "Episode: 135, Reward: 0.0\n",
      "Episode: 136, Reward: 0.0\n",
      "Episode: 137, Reward: 0.0\n",
      "Episode: 138, Reward: 0.0\n",
      "Episode: 139, Reward: 0.0\n",
      "Episode: 140, Reward: 0.0\n",
      "Episode: 141, Reward: 0.0\n",
      "Episode: 142, Reward: 0.0\n",
      "Episode: 143, Reward: 0.0\n",
      "Episode: 144, Reward: 0.0\n",
      "Episode: 145, Reward: 0.0\n",
      "Episode: 146, Reward: 0.0\n",
      "Episode: 147, Reward: 0.0\n",
      "Episode: 148, Reward: 0.0\n",
      "Episode: 149, Reward: 0.0\n",
      "Episode: 150, Reward: 0.0\n",
      "Episode: 151, Reward: 0.0\n",
      "Episode: 152, Reward: 0.0\n",
      "Episode: 153, Reward: 0.0\n",
      "Episode: 154, Reward: 0.0\n",
      "Episode: 155, Reward: 0.0\n",
      "Episode: 156, Reward: 0.0\n",
      "Episode: 157, Reward: 0.0\n",
      "Episode: 158, Reward: 0.0\n",
      "Episode: 159, Reward: 0.0\n",
      "Episode: 160, Reward: 0.0\n",
      "Episode: 161, Reward: 0.0\n",
      "Episode: 162, Reward: 0.0\n",
      "Episode: 163, Reward: 0.0\n",
      "Episode: 164, Reward: 0.0\n",
      "Episode: 165, Reward: 0.0\n",
      "Episode: 166, Reward: 0.0\n",
      "Episode: 167, Reward: 0.0\n",
      "Episode: 168, Reward: 0.0\n",
      "Episode: 169, Reward: 0.0\n",
      "Episode: 170, Reward: 0.0\n",
      "Episode: 171, Reward: 0.0\n",
      "Episode: 172, Reward: 0.0\n",
      "Episode: 173, Reward: 0.0\n",
      "Episode: 174, Reward: 0.0\n",
      "Episode: 175, Reward: 0.0\n",
      "Episode: 176, Reward: 0.0\n",
      "Episode: 177, Reward: 0.0\n",
      "Episode: 178, Reward: 0.0\n",
      "Episode: 179, Reward: 0.0\n",
      "Episode: 180, Reward: 0.0\n",
      "Episode: 181, Reward: 0.0\n",
      "Episode: 182, Reward: 0.0\n",
      "Episode: 183, Reward: 0.0\n",
      "Episode: 184, Reward: 0.0\n",
      "Episode: 185, Reward: 0.0\n",
      "Episode: 186, Reward: 0.0\n",
      "Episode: 187, Reward: 0.0\n",
      "Episode: 188, Reward: 0.0\n",
      "Episode: 189, Reward: 0.0\n",
      "Episode: 190, Reward: 0.0\n",
      "Episode: 191, Reward: 0.0\n",
      "Episode: 192, Reward: 0.0\n",
      "Episode: 193, Reward: 0.0\n",
      "Episode: 194, Reward: 0.0\n",
      "Episode: 195, Reward: 0.0\n",
      "Episode: 196, Reward: 0.0\n",
      "Episode: 197, Reward: 0.0\n",
      "Episode: 198, Reward: 0.0\n",
      "Episode: 199, Reward: 0.0\n",
      "END - Date-Time: 2023-08-21 14:00:07\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[0, 6, 14, 18, 24, 33, 43, 46, 47, 49, 51, 53, 54, 61, 64, 66, 76, 80, 86, 88, 90, 93, 99, 100, 101, 105, 117, 122, 124, 125, 143, 148, 149, 155, 166, 174, 178, 179, 183, 192]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_ZAXXON-V5 EXPERIMENT 5: Date-Time: 2023-08-21 14:00:43, Capacity: 5k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 5000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 0.0\n",
      "Episode: 8, Reward: 0.0\n",
      "Episode: 9, Reward: 0.0\n",
      "Episode: 10, Reward: 0.0\n",
      "Episode: 11, Reward: 0.0\n",
      "Episode: 12, Reward: 0.0\n",
      "Episode: 13, Reward: 0.0\n",
      "Episode: 14, Reward: 0.0\n",
      "Episode: 15, Reward: 0.0\n",
      "Episode: 16, Reward: 0.0\n",
      "Episode: 17, Reward: 0.0\n",
      "Episode: 18, Reward: 0.0\n",
      "Episode: 19, Reward: 0.0\n",
      "Episode: 20, Reward: 0.0\n",
      "Episode: 21, Reward: 0.0\n",
      "Episode: 22, Reward: 0.0\n",
      "Episode: 23, Reward: 0.0\n",
      "Episode: 24, Reward: 0.0\n",
      "Episode: 25, Reward: 0.0\n",
      "Episode: 26, Reward: 0.0\n",
      "Episode: 27, Reward: 0.0\n",
      "Episode: 28, Reward: 0.0\n",
      "Episode: 29, Reward: 0.0\n",
      "Episode: 30, Reward: 0.0\n",
      "Episode: 31, Reward: 0.0\n",
      "Episode: 32, Reward: 0.0\n",
      "Episode: 33, Reward: 0.0\n",
      "Episode: 34, Reward: 0.0\n",
      "Episode: 35, Reward: 0.0\n",
      "Episode: 36, Reward: 0.0\n",
      "Episode: 37, Reward: 0.0\n",
      "Episode: 38, Reward: 0.0\n",
      "Episode: 39, Reward: 0.0\n",
      "Episode: 40, Reward: 0.0\n",
      "Episode: 41, Reward: 0.0\n",
      "Episode: 42, Reward: 0.0\n",
      "Episode: 43, Reward: 0.0\n",
      "Episode: 44, Reward: 0.0\n",
      "Episode: 45, Reward: 0.0\n",
      "Episode: 46, Reward: 0.0\n",
      "Episode: 47, Reward: 0.0\n",
      "Episode: 48, Reward: 0.0\n",
      "Episode: 49, Reward: 0.0\n",
      "Episode: 50, Reward: 0.0\n",
      "Episode: 51, Reward: 0.0\n",
      "Episode: 52, Reward: 0.0\n",
      "Episode: 53, Reward: 0.0\n",
      "Episode: 54, Reward: 0.0\n",
      "Episode: 55, Reward: 0.0\n",
      "Episode: 56, Reward: 0.0\n",
      "Episode: 57, Reward: 0.0\n",
      "Episode: 58, Reward: 0.0\n",
      "Episode: 59, Reward: 0.0\n",
      "Episode: 60, Reward: 0.0\n",
      "Episode: 61, Reward: 0.0\n",
      "Episode: 62, Reward: 0.0\n",
      "Episode: 63, Reward: 0.0\n",
      "Episode: 64, Reward: 0.0\n",
      "Episode: 65, Reward: 0.0\n",
      "Episode: 66, Reward: 0.0\n",
      "Episode: 67, Reward: 0.0\n",
      "Episode: 68, Reward: 0.0\n",
      "Episode: 69, Reward: 0.0\n",
      "Episode: 70, Reward: 0.0\n",
      "Episode: 71, Reward: 0.0\n",
      "Episode: 72, Reward: 0.0\n",
      "Episode: 73, Reward: 0.0\n",
      "Episode: 74, Reward: 0.0\n",
      "Episode: 75, Reward: 0.0\n",
      "Episode: 76, Reward: 0.0\n",
      "Episode: 77, Reward: 0.0\n",
      "Episode: 78, Reward: 0.0\n",
      "Episode: 79, Reward: 0.0\n",
      "Episode: 80, Reward: 0.0\n",
      "Episode: 81, Reward: 0.0\n",
      "Episode: 82, Reward: 0.0\n",
      "Episode: 83, Reward: 0.0\n",
      "Episode: 84, Reward: 0.0\n",
      "Episode: 85, Reward: 0.0\n",
      "Episode: 86, Reward: 0.0\n",
      "Episode: 87, Reward: 0.0\n",
      "Episode: 88, Reward: 0.0\n",
      "Episode: 89, Reward: 0.0\n",
      "Episode: 90, Reward: 0.0\n",
      "Episode: 91, Reward: 0.0\n",
      "Episode: 92, Reward: 0.0\n",
      "Episode: 93, Reward: 0.0\n",
      "Episode: 94, Reward: 0.0\n",
      "Episode: 95, Reward: 0.0\n",
      "Episode: 96, Reward: 0.0\n",
      "Episode: 97, Reward: 0.0\n",
      "Episode: 98, Reward: 0.0\n",
      "Episode: 99, Reward: 0.0\n",
      "Episode: 100, Reward: 0.0\n",
      "Episode: 101, Reward: 0.0\n",
      "Episode: 102, Reward: 0.0\n",
      "Episode: 103, Reward: 0.0\n",
      "Episode: 104, Reward: 0.0\n",
      "Episode: 105, Reward: 0.0\n",
      "Episode: 106, Reward: 0.0\n",
      "Episode: 107, Reward: 0.0\n",
      "Episode: 108, Reward: 0.0\n",
      "Episode: 109, Reward: 0.0\n",
      "Episode: 110, Reward: 0.0\n",
      "Episode: 111, Reward: 0.0\n",
      "Episode: 112, Reward: 0.0\n",
      "Episode: 113, Reward: 0.0\n",
      "Episode: 114, Reward: 0.0\n",
      "Episode: 115, Reward: 0.0\n",
      "Episode: 116, Reward: 0.0\n",
      "Episode: 117, Reward: 0.0\n",
      "Episode: 118, Reward: 0.0\n",
      "Episode: 119, Reward: 0.0\n",
      "Episode: 120, Reward: 0.0\n",
      "Episode: 121, Reward: 0.0\n",
      "Episode: 122, Reward: 0.0\n",
      "Episode: 123, Reward: 0.0\n",
      "Episode: 124, Reward: 0.0\n",
      "Episode: 125, Reward: 0.0\n",
      "Episode: 126, Reward: 0.0\n",
      "Episode: 127, Reward: 0.0\n",
      "Episode: 128, Reward: 0.0\n",
      "Episode: 129, Reward: 0.0\n",
      "Episode: 130, Reward: 0.0\n",
      "Episode: 131, Reward: 0.0\n",
      "Episode: 132, Reward: 0.0\n",
      "Episode: 133, Reward: 0.0\n",
      "Episode: 134, Reward: 0.0\n",
      "Episode: 135, Reward: 0.0\n",
      "Episode: 136, Reward: 0.0\n",
      "Episode: 137, Reward: 0.0\n",
      "Episode: 138, Reward: 0.0\n",
      "Episode: 139, Reward: 0.0\n",
      "Episode: 140, Reward: 0.0\n",
      "Episode: 141, Reward: 0.0\n",
      "Episode: 142, Reward: 0.0\n",
      "Episode: 143, Reward: 0.0\n",
      "Episode: 144, Reward: 0.0\n",
      "Episode: 145, Reward: 0.0\n",
      "Episode: 146, Reward: 0.0\n",
      "Episode: 147, Reward: 0.0\n",
      "Episode: 148, Reward: 0.0\n",
      "Episode: 149, Reward: 0.0\n",
      "Episode: 150, Reward: 0.0\n",
      "Episode: 151, Reward: 0.0\n",
      "Episode: 152, Reward: 0.0\n",
      "Episode: 153, Reward: 0.0\n",
      "Episode: 154, Reward: 0.0\n",
      "Episode: 155, Reward: 0.0\n",
      "Episode: 156, Reward: 0.0\n",
      "Episode: 157, Reward: 0.0\n",
      "Episode: 158, Reward: 0.0\n",
      "Episode: 159, Reward: 0.0\n",
      "Episode: 160, Reward: 0.0\n",
      "Episode: 161, Reward: 0.0\n",
      "Episode: 162, Reward: 0.0\n",
      "Episode: 163, Reward: 0.0\n",
      "Episode: 164, Reward: 0.0\n",
      "Episode: 165, Reward: 0.0\n",
      "Episode: 166, Reward: 0.0\n",
      "Episode: 167, Reward: 0.0\n",
      "Episode: 168, Reward: 0.0\n",
      "Episode: 169, Reward: 0.0\n",
      "Episode: 170, Reward: 0.0\n",
      "Episode: 171, Reward: 0.0\n",
      "Episode: 172, Reward: 0.0\n",
      "Episode: 173, Reward: 0.0\n",
      "Episode: 174, Reward: 0.0\n",
      "Episode: 175, Reward: 0.0\n",
      "Episode: 176, Reward: 0.0\n",
      "Episode: 177, Reward: 0.0\n",
      "Episode: 178, Reward: 0.0\n",
      "Episode: 179, Reward: 0.0\n",
      "Episode: 180, Reward: 0.0\n",
      "Episode: 181, Reward: 0.0\n",
      "Episode: 182, Reward: 0.0\n",
      "Episode: 183, Reward: 0.0\n",
      "Episode: 184, Reward: 0.0\n",
      "Episode: 185, Reward: 0.0\n",
      "Episode: 186, Reward: 0.0\n",
      "Episode: 187, Reward: 0.0\n",
      "Episode: 188, Reward: 0.0\n",
      "Episode: 189, Reward: 0.0\n",
      "Episode: 190, Reward: 0.0\n",
      "Episode: 191, Reward: 0.0\n",
      "Episode: 192, Reward: 0.0\n",
      "Episode: 193, Reward: 0.0\n",
      "Episode: 194, Reward: 0.0\n",
      "Episode: 195, Reward: 0.0\n",
      "Episode: 196, Reward: 0.0\n",
      "Episode: 197, Reward: 0.0\n",
      "Episode: 198, Reward: 0.0\n",
      "Episode: 199, Reward: 0.0\n",
      "END - Date-Time: 2023-08-21 14:14:26\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[2, 12, 18, 43, 47, 49, 54, 60, 65, 68, 73, 82, 86, 87, 93, 104, 111, 116, 119, 121, 122, 123, 124, 127, 130, 133, 135, 142, 146, 148, 151, 155, 162, 163, 168, 177, 178, 179, 180, 184]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_ZAXXON-V5 EXPERIMENT 6: Date-Time: 2023-08-21 14:15:03, Capacity: 1k\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 1000\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 1000.0\n",
      "Episode: 7, Reward: 1000.0\n",
      "Episode: 8, Reward: 1000.0\n",
      "Episode: 9, Reward: 1000.0\n",
      "Episode: 10, Reward: 500.0\n",
      "Episode: 11, Reward: 500.0\n",
      "Episode: 12, Reward: 500.0\n",
      "Episode: 13, Reward: 500.0\n",
      "Episode: 14, Reward: 500.0\n",
      "Episode: 15, Reward: 333.33\n",
      "Episode: 16, Reward: 333.33\n",
      "Episode: 17, Reward: 333.33\n",
      "Episode: 18, Reward: 333.33\n",
      "Episode: 19, Reward: 250.0\n",
      "Episode: 20, Reward: 250.0\n",
      "Episode: 21, Reward: 250.0\n",
      "Episode: 22, Reward: 250.0\n",
      "Episode: 23, Reward: 250.0\n",
      "Episode: 24, Reward: 200.0\n",
      "Episode: 25, Reward: 200.0\n",
      "Episode: 26, Reward: 200.0\n",
      "Episode: 27, Reward: 200.0\n",
      "Episode: 28, Reward: 166.67\n",
      "Episode: 29, Reward: 166.67\n",
      "Episode: 30, Reward: 166.67\n",
      "Episode: 31, Reward: 166.67\n",
      "Episode: 32, Reward: 171.43\n",
      "Episode: 33, Reward: 171.43\n",
      "Episode: 34, Reward: 171.43\n",
      "Episode: 35, Reward: 171.43\n",
      "Episode: 36, Reward: 171.43\n",
      "Episode: 37, Reward: 150.0\n",
      "Episode: 38, Reward: 150.0\n",
      "Episode: 39, Reward: 150.0\n",
      "Episode: 40, Reward: 150.0\n",
      "Episode: 41, Reward: 133.33\n",
      "Episode: 42, Reward: 133.33\n",
      "Episode: 43, Reward: 133.33\n",
      "Episode: 44, Reward: 133.33\n",
      "Episode: 45, Reward: 133.33\n",
      "Episode: 46, Reward: 120.0\n",
      "Episode: 47, Reward: 120.0\n",
      "Episode: 48, Reward: 120.0\n",
      "Episode: 49, Reward: 120.0\n",
      "Episode: 50, Reward: 20.0\n",
      "Episode: 51, Reward: 20.0\n",
      "Episode: 52, Reward: 20.0\n",
      "Episode: 53, Reward: 20.0\n",
      "Episode: 54, Reward: 20.0\n",
      "Episode: 55, Reward: 20.0\n",
      "Episode: 56, Reward: 20.0\n",
      "Episode: 57, Reward: 20.0\n",
      "Episode: 58, Reward: 20.0\n",
      "Episode: 59, Reward: 20.0\n",
      "Episode: 60, Reward: 20.0\n",
      "Episode: 61, Reward: 20.0\n",
      "Episode: 62, Reward: 20.0\n",
      "Episode: 63, Reward: 20.0\n",
      "Episode: 64, Reward: 20.0\n",
      "Episode: 65, Reward: 20.0\n",
      "Episode: 66, Reward: 20.0\n",
      "Episode: 67, Reward: 20.0\n",
      "Episode: 68, Reward: 20.0\n",
      "Episode: 69, Reward: 20.0\n",
      "Episode: 70, Reward: 20.0\n",
      "Episode: 71, Reward: 20.0\n",
      "Episode: 72, Reward: 20.0\n",
      "Episode: 73, Reward: 20.0\n",
      "Episode: 74, Reward: 20.0\n",
      "Episode: 75, Reward: 20.0\n",
      "Episode: 76, Reward: 20.0\n",
      "Episode: 77, Reward: 0.0\n",
      "Episode: 78, Reward: 0.0\n",
      "Episode: 79, Reward: 0.0\n",
      "Episode: 80, Reward: 0.0\n",
      "Episode: 81, Reward: 0.0\n",
      "Episode: 82, Reward: 0.0\n",
      "Episode: 83, Reward: 0.0\n",
      "Episode: 84, Reward: 0.0\n",
      "Episode: 85, Reward: 0.0\n",
      "Episode: 86, Reward: 0.0\n",
      "Episode: 87, Reward: 0.0\n",
      "Episode: 88, Reward: 0.0\n",
      "Episode: 89, Reward: 0.0\n",
      "Episode: 90, Reward: 0.0\n",
      "Episode: 91, Reward: 0.0\n",
      "Episode: 92, Reward: 0.0\n",
      "Episode: 93, Reward: 0.0\n",
      "Episode: 94, Reward: 0.0\n",
      "Episode: 95, Reward: 0.0\n",
      "Episode: 96, Reward: 0.0\n",
      "Episode: 97, Reward: 0.0\n",
      "Episode: 98, Reward: 0.0\n",
      "Episode: 99, Reward: 0.0\n",
      "Episode: 100, Reward: 0.0\n",
      "Episode: 101, Reward: 0.0\n",
      "Episode: 102, Reward: 0.0\n",
      "Episode: 103, Reward: 0.0\n",
      "Episode: 104, Reward: 0.0\n",
      "Episode: 105, Reward: 0.0\n",
      "Episode: 106, Reward: 0.0\n",
      "Episode: 107, Reward: 0.0\n",
      "Episode: 108, Reward: 0.0\n",
      "Episode: 109, Reward: 0.0\n",
      "Episode: 110, Reward: 0.0\n",
      "Episode: 111, Reward: 0.0\n",
      "Episode: 112, Reward: 0.0\n",
      "Episode: 113, Reward: 0.0\n",
      "Episode: 114, Reward: 0.0\n",
      "Episode: 115, Reward: 0.0\n",
      "Episode: 116, Reward: 0.0\n",
      "Episode: 117, Reward: 0.0\n",
      "Episode: 118, Reward: 0.0\n",
      "Episode: 119, Reward: 0.0\n",
      "Episode: 120, Reward: 0.0\n",
      "Episode: 121, Reward: 0.0\n",
      "Episode: 122, Reward: 0.0\n",
      "Episode: 123, Reward: 0.0\n",
      "Episode: 124, Reward: 0.0\n",
      "Episode: 125, Reward: 0.0\n",
      "Episode: 126, Reward: 0.0\n",
      "Episode: 127, Reward: 0.0\n",
      "Episode: 128, Reward: 0.0\n",
      "Episode: 129, Reward: 0.0\n",
      "Episode: 130, Reward: 0.0\n",
      "Episode: 131, Reward: 0.0\n",
      "Episode: 132, Reward: 0.0\n",
      "Episode: 133, Reward: 0.0\n",
      "Episode: 134, Reward: 0.0\n",
      "Episode: 135, Reward: 0.0\n",
      "Episode: 136, Reward: 0.0\n",
      "Episode: 137, Reward: 0.0\n",
      "Episode: 138, Reward: 0.0\n",
      "Episode: 139, Reward: 0.0\n",
      "Episode: 140, Reward: 0.0\n",
      "Episode: 141, Reward: 0.0\n",
      "Episode: 142, Reward: 0.0\n",
      "Episode: 143, Reward: 0.0\n",
      "Episode: 144, Reward: 0.0\n",
      "Episode: 145, Reward: 0.0\n",
      "Episode: 146, Reward: 0.0\n",
      "Episode: 147, Reward: 0.0\n",
      "Episode: 148, Reward: 0.0\n",
      "Episode: 149, Reward: 0.0\n",
      "Episode: 150, Reward: 0.0\n",
      "Episode: 151, Reward: 0.0\n",
      "Episode: 152, Reward: 0.0\n",
      "Episode: 153, Reward: 0.0\n",
      "Episode: 154, Reward: 0.0\n",
      "Episode: 155, Reward: 0.0\n",
      "Episode: 156, Reward: 0.0\n",
      "Episode: 157, Reward: 0.0\n",
      "Episode: 158, Reward: 0.0\n",
      "Episode: 159, Reward: 0.0\n",
      "Episode: 160, Reward: 0.0\n",
      "Episode: 161, Reward: 0.0\n",
      "Episode: 162, Reward: 0.0\n",
      "Episode: 163, Reward: 0.0\n",
      "Episode: 164, Reward: 0.0\n",
      "Episode: 165, Reward: 0.0\n",
      "Episode: 166, Reward: 0.0\n",
      "Episode: 167, Reward: 0.0\n",
      "Episode: 168, Reward: 0.0\n",
      "Episode: 169, Reward: 0.0\n",
      "Episode: 170, Reward: 0.0\n",
      "Episode: 171, Reward: 0.0\n",
      "Episode: 172, Reward: 0.0\n",
      "Episode: 173, Reward: 0.0\n",
      "Episode: 174, Reward: 0.0\n",
      "Episode: 175, Reward: 0.0\n",
      "Episode: 176, Reward: 0.0\n",
      "Episode: 177, Reward: 0.0\n",
      "Episode: 178, Reward: 0.0\n",
      "Episode: 179, Reward: 0.0\n",
      "Episode: 180, Reward: 0.0\n",
      "Episode: 181, Reward: 0.0\n",
      "Episode: 182, Reward: 0.0\n",
      "Episode: 183, Reward: 0.0\n",
      "Episode: 184, Reward: 0.0\n",
      "Episode: 185, Reward: 0.0\n",
      "Episode: 186, Reward: 0.0\n",
      "Episode: 187, Reward: 0.0\n",
      "Episode: 188, Reward: 0.0\n",
      "Episode: 189, Reward: 0.0\n",
      "Episode: 190, Reward: 0.0\n",
      "Episode: 191, Reward: 0.0\n",
      "Episode: 192, Reward: 0.0\n",
      "Episode: 193, Reward: 0.0\n",
      "Episode: 194, Reward: 0.0\n",
      "Episode: 195, Reward: 0.0\n",
      "Episode: 196, Reward: 0.0\n",
      "Episode: 197, Reward: 0.0\n",
      "Episode: 198, Reward: 0.0\n",
      "Episode: 199, Reward: 0.0\n",
      "END - Date-Time: 2023-08-21 14:25:26\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[5, 6, 10, 12, 16, 17, 19, 22, 23, 24, 55, 56, 59, 60, 66, 68, 70, 73, 74, 79, 80, 93, 100, 103, 119, 125, 127, 133, 137, 140, 142, 151, 154, 163, 170, 171, 175, 180, 189, 198]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "ALE_ZAXXON-V5 EXPERIMENT 7: Date-Time: 2023-08-21 14:26:05, Capacity: 500\n",
      "Setting up environment\n",
      "Creating Agent with capacity set to: 500\n",
      "Simulating environment\n",
      "Episode: 0, Reward: 0.0\n",
      "Episode: 1, Reward: 0.0\n",
      "Episode: 2, Reward: 0.0\n",
      "Episode: 3, Reward: 0.0\n",
      "Episode: 4, Reward: 0.0\n",
      "Episode: 5, Reward: 0.0\n",
      "Episode: 6, Reward: 0.0\n",
      "Episode: 7, Reward: 0.0\n",
      "Episode: 8, Reward: 0.0\n",
      "Episode: 9, Reward: 0.0\n",
      "Episode: 10, Reward: 0.0\n",
      "Episode: 11, Reward: 0.0\n",
      "Episode: 12, Reward: 0.0\n",
      "Episode: 13, Reward: 0.0\n",
      "Episode: 14, Reward: 0.0\n",
      "Episode: 15, Reward: 0.0\n",
      "Episode: 16, Reward: 0.0\n",
      "Episode: 17, Reward: 0.0\n",
      "Episode: 18, Reward: 0.0\n",
      "Episode: 19, Reward: 0.0\n",
      "Episode: 20, Reward: 0.0\n",
      "Episode: 21, Reward: 0.0\n",
      "Episode: 22, Reward: 0.0\n",
      "Episode: 23, Reward: 0.0\n",
      "Episode: 24, Reward: 0.0\n",
      "Episode: 25, Reward: 0.0\n",
      "Episode: 26, Reward: 0.0\n",
      "Episode: 27, Reward: 0.0\n",
      "Episode: 28, Reward: 0.0\n",
      "Episode: 29, Reward: 0.0\n",
      "Episode: 30, Reward: 0.0\n",
      "Episode: 31, Reward: 0.0\n",
      "Episode: 32, Reward: 0.0\n",
      "Episode: 33, Reward: 0.0\n",
      "Episode: 34, Reward: 0.0\n",
      "Episode: 35, Reward: 0.0\n",
      "Episode: 36, Reward: 0.0\n",
      "Episode: 37, Reward: 0.0\n",
      "Episode: 38, Reward: 0.0\n",
      "Episode: 39, Reward: 0.0\n",
      "Episode: 40, Reward: 0.0\n",
      "Episode: 41, Reward: 0.0\n",
      "Episode: 42, Reward: 0.0\n",
      "Episode: 43, Reward: 0.0\n",
      "Episode: 44, Reward: 0.0\n",
      "Episode: 45, Reward: 0.0\n",
      "Episode: 46, Reward: 0.0\n",
      "Episode: 47, Reward: 0.0\n",
      "Episode: 48, Reward: 0.0\n",
      "Episode: 49, Reward: 0.0\n",
      "Episode: 50, Reward: 0.0\n",
      "Episode: 51, Reward: 0.0\n",
      "Episode: 52, Reward: 0.0\n",
      "Episode: 53, Reward: 0.0\n",
      "Episode: 54, Reward: 0.0\n",
      "Episode: 55, Reward: 0.0\n",
      "Episode: 56, Reward: 0.0\n",
      "Episode: 57, Reward: 0.0\n",
      "Episode: 58, Reward: 0.0\n",
      "Episode: 59, Reward: 0.0\n",
      "Episode: 60, Reward: 0.0\n",
      "Episode: 61, Reward: 0.0\n",
      "Episode: 62, Reward: 0.0\n",
      "Episode: 63, Reward: 0.0\n",
      "Episode: 64, Reward: 0.0\n",
      "Episode: 65, Reward: 0.0\n",
      "Episode: 66, Reward: 0.0\n",
      "Episode: 67, Reward: 0.0\n",
      "Episode: 68, Reward: 0.0\n",
      "Episode: 69, Reward: 0.0\n",
      "Episode: 70, Reward: 0.0\n",
      "Episode: 71, Reward: 0.0\n",
      "Episode: 72, Reward: 0.0\n",
      "Episode: 73, Reward: 0.0\n",
      "Episode: 74, Reward: 0.0\n",
      "Episode: 75, Reward: 0.0\n",
      "Episode: 76, Reward: 0.0\n",
      "Episode: 77, Reward: 0.0\n",
      "Episode: 78, Reward: 0.0\n",
      "Episode: 79, Reward: 0.0\n",
      "Episode: 80, Reward: 0.0\n",
      "Episode: 81, Reward: 0.0\n",
      "Episode: 82, Reward: 0.0\n",
      "Episode: 83, Reward: 0.0\n",
      "Episode: 84, Reward: 0.0\n",
      "Episode: 85, Reward: 0.0\n",
      "Episode: 86, Reward: 0.0\n",
      "Episode: 87, Reward: 0.0\n",
      "Episode: 88, Reward: 0.0\n",
      "Episode: 89, Reward: 0.0\n",
      "Episode: 90, Reward: 0.0\n",
      "Episode: 91, Reward: 0.0\n",
      "Episode: 92, Reward: 0.0\n",
      "Episode: 93, Reward: 0.0\n",
      "Episode: 94, Reward: 0.0\n",
      "Episode: 95, Reward: 0.0\n",
      "Episode: 96, Reward: 0.0\n",
      "Episode: 97, Reward: 0.0\n",
      "Episode: 98, Reward: 0.0\n",
      "Episode: 99, Reward: 0.0\n",
      "Episode: 100, Reward: 0.0\n",
      "Episode: 101, Reward: 0.0\n",
      "Episode: 102, Reward: 0.0\n",
      "Episode: 103, Reward: 0.0\n",
      "Episode: 104, Reward: 0.0\n",
      "Episode: 105, Reward: 0.0\n",
      "Episode: 106, Reward: 0.0\n",
      "Episode: 107, Reward: 0.0\n",
      "Episode: 108, Reward: 0.0\n",
      "Episode: 109, Reward: 0.0\n",
      "Episode: 110, Reward: 0.0\n",
      "Episode: 111, Reward: 0.0\n",
      "Episode: 112, Reward: 0.0\n",
      "Episode: 113, Reward: 0.0\n",
      "Episode: 114, Reward: 0.0\n",
      "Episode: 115, Reward: 0.0\n",
      "Episode: 116, Reward: 0.0\n",
      "Episode: 117, Reward: 0.0\n",
      "Episode: 118, Reward: 0.0\n",
      "Episode: 119, Reward: 0.0\n",
      "Episode: 120, Reward: 0.0\n",
      "Episode: 121, Reward: 0.0\n",
      "Episode: 122, Reward: 0.0\n",
      "Episode: 123, Reward: 0.0\n",
      "Episode: 124, Reward: 0.0\n",
      "Episode: 125, Reward: 0.0\n",
      "Episode: 126, Reward: 0.0\n",
      "Episode: 127, Reward: 0.0\n",
      "Episode: 128, Reward: 0.0\n",
      "Episode: 129, Reward: 0.0\n",
      "Episode: 130, Reward: 0.0\n",
      "Episode: 131, Reward: 0.0\n",
      "Episode: 132, Reward: 0.0\n",
      "Episode: 133, Reward: 0.0\n",
      "Episode: 134, Reward: 0.0\n",
      "Episode: 135, Reward: 0.0\n",
      "Episode: 136, Reward: 0.0\n",
      "Episode: 137, Reward: 0.0\n",
      "Episode: 138, Reward: 0.0\n",
      "Episode: 139, Reward: 0.0\n",
      "Episode: 140, Reward: 0.0\n",
      "Episode: 141, Reward: 0.0\n",
      "Episode: 142, Reward: 0.0\n",
      "Episode: 143, Reward: 0.0\n",
      "Episode: 144, Reward: 0.0\n",
      "Episode: 145, Reward: 0.0\n",
      "Episode: 146, Reward: 0.0\n",
      "Episode: 147, Reward: 0.0\n",
      "Episode: 148, Reward: 0.0\n",
      "Episode: 149, Reward: 0.0\n",
      "Episode: 150, Reward: 0.0\n",
      "Episode: 151, Reward: 0.0\n",
      "Episode: 152, Reward: 0.0\n",
      "Episode: 153, Reward: 0.0\n",
      "Episode: 154, Reward: 0.0\n",
      "Episode: 155, Reward: 0.0\n",
      "Episode: 156, Reward: 0.0\n",
      "Episode: 157, Reward: 0.0\n",
      "Episode: 158, Reward: 0.0\n",
      "Episode: 159, Reward: 0.0\n",
      "Episode: 160, Reward: 0.0\n",
      "Episode: 161, Reward: 0.0\n",
      "Episode: 162, Reward: 0.0\n",
      "Episode: 163, Reward: 0.0\n",
      "Episode: 164, Reward: 0.0\n",
      "Episode: 165, Reward: 0.0\n",
      "Episode: 166, Reward: 0.0\n",
      "Episode: 167, Reward: 0.0\n",
      "Episode: 168, Reward: 0.0\n",
      "Episode: 169, Reward: 0.0\n",
      "Episode: 170, Reward: 0.0\n",
      "Episode: 171, Reward: 0.0\n",
      "Episode: 172, Reward: 0.0\n",
      "Episode: 173, Reward: 0.0\n",
      "Episode: 174, Reward: 0.0\n",
      "Episode: 175, Reward: 0.0\n",
      "Episode: 176, Reward: 0.0\n",
      "Episode: 177, Reward: 0.0\n",
      "Episode: 178, Reward: 0.0\n",
      "Episode: 179, Reward: 0.0\n",
      "Episode: 180, Reward: 0.0\n",
      "Episode: 181, Reward: 0.0\n",
      "Episode: 182, Reward: 0.0\n",
      "Episode: 183, Reward: 0.0\n",
      "Episode: 184, Reward: 0.0\n",
      "Episode: 185, Reward: 0.0\n",
      "Episode: 186, Reward: 0.0\n",
      "Episode: 187, Reward: 0.0\n",
      "Episode: 188, Reward: 0.0\n",
      "Episode: 189, Reward: 0.0\n",
      "Episode: 190, Reward: 0.0\n",
      "Episode: 191, Reward: 0.0\n",
      "Episode: 192, Reward: 0.0\n",
      "Episode: 193, Reward: 0.0\n",
      "Episode: 194, Reward: 0.0\n",
      "Episode: 195, Reward: 0.0\n",
      "Episode: 196, Reward: 0.0\n",
      "Episode: 197, Reward: 0.0\n",
      "Episode: 198, Reward: 0.0\n",
      "Episode: 199, Reward: 0.0\n",
      "END - Date-Time: 2023-08-21 14:36:39\n",
      "Saving SHAP graphs\n",
      "40 test images available:\n",
      "Episodes samples were taken from:\n",
      "[7, 12, 20, 26, 37, 49, 50, 56, 57, 64, 72, 75, 77, 81, 83, 84, 85, 86, 89, 94, 99, 105, 115, 116, 119, 120, 121, 132, 133, 135, 136, 138, 145, 146, 152, 157, 165, 175, 184, 190]\n",
      "Shap training set: \n",
      "20\n",
      "Masks created:\n",
      "20\n",
      "Moving CNN to GPU and creating a mask loader\n",
      "Training Deep SHAP Explainer please wait...\n",
      "Generating SHAP images and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Reward Graphs...\n",
      "Saving Q-value/action graphs...\n",
      "Saving rewards to csv\n",
      "Saving boxplot of results\n",
      "Average Accumulated Reward: 13694.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vector = False # run tests on vector or image data\n",
    "\n",
    "if vector:\n",
    "    sims = ['CartPole-v1', \n",
    "    'HRLSim-v0',\n",
    "    'LunarLander-v2',]\n",
    "    for sim in sims:\n",
    "        sim_name = sim # obs_type=\"ram\", frameskip=4, repeat_action_probability=0.25\n",
    "        filename = sim_name.replace(\"/\", \"_\").lower()\n",
    "        # stella emulator for atari = https://stella-emu.github.io/\n",
    "        # https://stella-emu.github.io/docs/index.html#Remapping:~:text=count%20and%20associated-,frames%20per%20second,-%2C%20bankswitch%20and%20display\n",
    "        # assume 60 fpS\n",
    "\n",
    "        capacity = [1000000, 500000, 100000, 50000, 10000, 5000, 1000, 500]\n",
    "        labels = ['1M', '500k', '100k', '50k', '10k', '5k', '1k', '500']\n",
    "\n",
    "        episodes = 200 #200\n",
    "        n = 10 # n-steps\n",
    "        samples = 200 #step samples to take per episode\n",
    "        bat = 128 + 26 #training batches randomly sampled from experience replay + extra samples to accommodate shap training\n",
    "        rw = 10 # reward window (e.g 100 steps)\n",
    "        shap_test_sample_ratio = 0.20 # e.g 10%\n",
    "\n",
    "\n",
    "        #create table for evaluating capacity against reward\n",
    "        df_rewards = pd.DataFrame(columns=['sim','capacity', 'episodes', 'reward'])\n",
    "\n",
    "        for i, cap in enumerate(capacity):\n",
    "            #get current timestamp\n",
    "            start_datetime = datetime.datetime.now()\n",
    "            start_datetime = start_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")# Format the date and time as a string\n",
    "            print(filename.upper() + \" EXPERIMENT \" + str(i) + \": Date-Time: \" + str(start_datetime) + \", Capacity: \" + str(labels[i]))\n",
    "\n",
    "            #### Setup Preprocessed Environment\n",
    "            print(\"Setting up environment\")\n",
    "\n",
    "            title = sim_name[4:-3]\n",
    "\n",
    "            #environment\n",
    "            env = gym.make(sim)#render_mode='human'\n",
    "            state, info = env.reset(seed=42)\n",
    "            print(\"actions: \" + str(env.action_space.n))\n",
    "            print(env.action_space)\n",
    "            print(\"observation vector: \" + str(env.observation_space.shape[0]))\n",
    "            print(state)\n",
    "\n",
    "            ##### Create DCQL Agent\n",
    "            print(\"Creating Agent with capacity set to: \" + str(cap))\n",
    "            # Agent - a neural network that represents our Q-function\n",
    "            s = env.observation_space.shape[0] # sensors\n",
    "            a = env.action_space.n # actions\n",
    "            g = 0.99 #gamma\n",
    "            c = cap #1000000 #10000 #memory capacity\n",
    "            b = bat #training batches #128\n",
    "            l = 0.001 #learning rate\n",
    "            t = 1.0 #softmax policy temperature rate (tau). T controls the level of randomness or exploration in the action selection process. T is temperature high, meaning other actions are more explored\n",
    "\n",
    "            #define a random selection size such as 10%\n",
    "            random_select_size = math.ceil(episodes * shap_test_sample_ratio) \n",
    "\n",
    "\n",
    "            # Create an array of random episode numbers\n",
    "            random_episodes = np.random.choice(range(episodes), size=random_select_size, replace=False)\n",
    "\n",
    "            agent = Dqn(s,a,g,c,l,t,b, random_episodes)\n",
    "\n",
    "            ma = MA(rw) #used to get the average of the last n-step rewards\n",
    "            \n",
    "            #### Simulate the environment\n",
    "            print(\"Simulating environment\")\n",
    "            for episode in range(episodes):\n",
    "                state, info = env.reset()\n",
    "                done = False\n",
    "                reward = 0\n",
    "                while not done:\n",
    "                    env.render()       \n",
    "                    action, qValues, transitionProbs = agent.update(reward, state, episode)\n",
    "                    next_state, r, terminated, truncated, info = env.step(int(action))\n",
    "                    done = terminated or truncated #if  game has some kind of max_steps or timeout, read 'truncated' with 'terminated'\n",
    "                    reward += r #sum reward for every step\n",
    "                    done = terminated or truncated #max duration should be 200 for episode length\n",
    "                \n",
    "                ma.add(reward) #100 rewards kept\n",
    "\n",
    "                avg_reward = round(ma.average(),2) #average 100 rewards\n",
    "                print(\"Episode: %s, Reward: %s\" % (str(episode), str(avg_reward)))\n",
    "\n",
    "                #save rewards per given nth step\n",
    "                new_row = [title, labels[i], episode, avg_reward]\n",
    "                df_rewards.loc[len(df_rewards)] = new_row\n",
    "            env.close()\n",
    "            \n",
    "            #Current sum of all values in the reward window\n",
    "            #print(agent.score())\n",
    "            \n",
    "            #get end timestamp\n",
    "            end_datetime = datetime.datetime.now()\n",
    "            end_datetime = end_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")# Format the date and time as a string\n",
    "            print(\"END - Date-Time: \" + str(end_datetime))\n",
    "            #SHAP here...\n",
    "\n",
    "else:\n",
    "    \"\"\"\n",
    "    #split into different runs as full 20 difficult on limited hardware\n",
    "    sims = ['ALE/AirRaid-v5', \n",
    "    'ALE/Asterix-v5', \n",
    "    'ALE/Asteroids-v5', \n",
    "    'ALE/Bowling-v5', \n",
    "    'ALE/Breakout-v5',\n",
    "    'ALE/DemonAttack-v5',\n",
    "    'ALE/Freeway-v5',\n",
    "    'ALE/Gravitar-v5']\n",
    "\n",
    "    sims = ['ALE/Jamesbond-v5',\n",
    "    'ALE/MontezumaRevenge-v5',\n",
    "    'ALE/MsPacman-v5',\n",
    "    'ALE/Pong-v5',\n",
    "    'ALE/PrivateEye-v5',\n",
    "    'ALE/Qbert-v5',\n",
    "    'ALE/Seaquest-v5',\n",
    "    'ALE/SpaceInvaders-v5', \n",
    "    'ALE/Venture-v5',\n",
    "    'ALE/WizardOfWor-v5',\n",
    "    'ALE/YarsRevenge-v5',\n",
    "    'ALE/Zaxxon-v5'\n",
    "    ]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    sims = ['ALE/SpaceInvaders-v5', \n",
    "    'ALE/Venture-v5',\n",
    "    'ALE/WizardOfWor-v5',\n",
    "    'ALE/YarsRevenge-v5',\n",
    "    'ALE/Zaxxon-v5']\n",
    "\n",
    "\n",
    "    for sim in sims:\n",
    "        sim_name = sim # obs_type=\"ram\", frameskip=4, repeat_action_probability=0.25\n",
    "        filename = sim_name.replace(\"/\", \"_\").lower()\n",
    "        # stella emulator for atari = https://stella-emu.github.io/\n",
    "        # https://stella-emu.github.io/docs/index.html#Remapping:~:text=count%20and%20associated-,frames%20per%20second,-%2C%20bankswitch%20and%20display\n",
    "        # assume 60 fpS\n",
    "\n",
    "        capacity = [1000000, 500000, 100000, 50000, 10000, 5000, 1000, 500]\n",
    "        labels = ['1M', '500k', '100k', '50k', '10k', '5k', '1k', '500']\n",
    "\n",
    "        episodes = 200 #200\n",
    "        n = 10 # n-steps\n",
    "        samples = 200 #step samples to take per episode\n",
    "        bat = 128 + 26 #training batches randomly sampled from experience replay + extra samples to accommodate shap training\n",
    "        rw = 10 # reward window (e.g 100 steps)\n",
    "        shap_test_sample_ratio = 0.20 # e.g 10%\n",
    "\n",
    "        #create table for evaluating capacity against reward\n",
    "        df_rewards = pd.DataFrame(columns=['sim','capacity', 'episodes', 'reward'])\n",
    "\n",
    "\n",
    "        for i, cap in enumerate(capacity):\n",
    "            #get current timestamp\n",
    "            start_datetime = datetime.datetime.now()\n",
    "            start_datetime = start_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")# Format the date and time as a string\n",
    "            print(filename.upper() + \" EXPERIMENT \" + str(i) + \": Date-Time: \" + str(start_datetime) + \", Capacity: \" + str(labels[i]))\n",
    "            \n",
    "            #### Setup Preprocessed Environment\n",
    "            print(\"Setting up environment\")\n",
    "            #env = gym.make(sim)\n",
    "            #We first preprocess the image by applying a greyscale and reducing the size to 80px.\n",
    "            title = sim_name[4:-3]\n",
    "            env = ImagePreprocessor(gym.make(sim_name), width=80, height=80, grayscale=True) #width=210, height=160 # , render_mode='human'\n",
    "            state, info = env.reset(seed=42)\n",
    "            \n",
    "            ##### Create DCQL Agent\n",
    "            print(\"Creating Agent with capacity set to: \" + str(cap))\n",
    "            a = env.action_space.n # actions\n",
    "            g = 0.99 #gamma\n",
    "            c = cap #1000000 #10000 #memory capacity\n",
    "            b = bat #training batches #128\n",
    "            l = 0.001 #learning rate\n",
    "            t = 1.0 #softmax policy temperature rate (tau). T controls the level of randomness or exploration in the action selection process. T is temperature high, meaning other actions are more explored\n",
    "        \n",
    "            \n",
    "            #Build the Agent\n",
    "            cnn = CNN(a)\n",
    "            softmax = SoftmaxPolicy(T=t)\n",
    "\n",
    "            agent = DCQ(CNN=cnn, SoftmaxPolicy=softmax)\n",
    "\n",
    "            # Set up Experience Replay\n",
    "            n_steps = NStepProgress(env=env, ai=agent, n_step=n) #instead of learning every transition we learn every nth transition\n",
    "            memory = ReplayMemory(n_steps=n_steps, capacity=c) #store the last c steps in memory e.g 1millm 500k etc.\n",
    "\n",
    "            #set learning parameters\n",
    "            loss = nn.MSELoss()#calculate mean squared error loss\n",
    "            optimizer = optim.Adam(cnn.parameters(), lr=l) #use adams optimiser with a learning rate of 0.001\n",
    "\n",
    "            ma = MA(rw) #used to get the average of the last n-step rewards\n",
    "\n",
    "            # Initialize an empty list to store the sampled inputs for SHAP Explainer\n",
    "            # set a sampling rate based on episodes as batches could be zero if not enough available at start\n",
    "\n",
    "            #define a random selection size such as 10%\n",
    "            random_select_size = math.ceil(episodes * shap_test_sample_ratio) \n",
    "\n",
    "            # Create an array of random episode numbers\n",
    "            random_episodes = np.random.choice(range(episodes), size=random_select_size, replace=False)\n",
    "\n",
    "            # Initialize an empty list to store the sampled inputs for SHAP Explainer\n",
    "            sampling_episode = []\n",
    "            sampled_inputs = []\n",
    "            sampled_targets = []\n",
    "            episode_sampled = False\n",
    "\n",
    "            #### Simulate the environment\n",
    "            print(\"Simulating environment\")\n",
    "            for episode in range(episodes):\n",
    "                #run the game for 200 runs of 10 steps and push sample transitions into memory\n",
    "                memory.run_steps(steps=samples) # e.g 200 steps sampled per episode\n",
    "                #sample 128 x10['state', 'action', 'reward', 'done'] or 1,280 transitions from memory if there is enough in memory to sample otherwise skip\n",
    "                for batch in memory.sample_batch(b): #b= e.g 128 batches\n",
    "                    #agent training\n",
    "\n",
    "                    #creates the training set for the agent, \n",
    "                    # we get target discounted q values for the first state in the batch over 10 steps\n",
    "                    inputs, targets = eligibility_trace(batch, cnn, g)\n",
    "\n",
    "                    #We take some training samples for shap.deepxplainer to create heatmap images or we use them for training. Not both!\n",
    "                    if episode in random_episodes and not episode_sampled:\n",
    "                        sampling_episode.append(episode) #record when sample was taken\n",
    "                        sampled_inputs.append(inputs)\n",
    "                        sampled_targets.append(targets)\n",
    "                        episode_sampled = True # Set the flag to True\n",
    "                    else:\n",
    "                        #we convert them to tensor variables\n",
    "                        inputs, targets = Variable(inputs), Variable(targets)\n",
    "                        #like during eligibility_trace we get predicted q values from the cnn model\n",
    "                        predictions = cnn(inputs)\n",
    "                        loss_error = loss(predictions, targets)\n",
    "                        optimizer.zero_grad()\n",
    "                        loss_error.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                episode_sampled = False # Reset the flag for the next iteration\n",
    "                        \n",
    "                rewards_steps = n_steps.rewards_steps() # accumulated reward per 200 steps\n",
    "                ma.add(rewards_steps) #100 rewards kept\n",
    "\n",
    "                avg_reward = round(ma.average(),2) #average 100 rewards\n",
    "                print(\"Episode: %s, Reward: %s\" % (str(episode), str(avg_reward)))\n",
    "                \n",
    "                #save rewards per given nth step\n",
    "                new_row = [title, labels[i], episode, avg_reward]\n",
    "                df_rewards.loc[len(df_rewards)] = new_row\n",
    "            env.close()\n",
    "\n",
    "            #get end timestamp\n",
    "            end_datetime = datetime.datetime.now()\n",
    "            end_datetime = end_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")# Format the date and time as a string\n",
    "            print(\"END - Date-Time: \" + str(end_datetime))\n",
    "\n",
    "            print(\"Saving SHAP graphs\")\n",
    "            #### Shap graphs\n",
    "            #took 10% of total episodes played as sample experience replay to be used as shap training/test data. So if 200 episodes we took 20 episodes. The agent has not seen these images yet\n",
    "            print(str(len(sampled_inputs)) + \" test images available:\")\n",
    "\n",
    "            print(\"Episodes samples were taken from:\")\n",
    "            print(sampling_episode)\n",
    "            \n",
    "            #convert sample states into PIL images\n",
    "            sampled_inputs_reshaped = []\n",
    "            for tensor in sampled_inputs:\n",
    "                # Convert tensor to numpy array and reshape\n",
    "                image_array = tensor.numpy().squeeze()  # Remove singleton dimensions\n",
    "            \n",
    "                # Convert the numpy array to a PIL Image\n",
    "                pil_image = Image.fromarray((image_array * 255).astype(np.uint8), mode='L')  # Convert to grayscale\n",
    "                sampled_inputs_reshaped.append(pil_image)\n",
    "            \n",
    "            #shap training set\n",
    "            print(\"Shap training set: \")\n",
    "            mask = sampled_inputs_reshaped[::2] #get all even images from index zero as training\n",
    "            print(len(mask))\n",
    "\n",
    "            #  turning mask to pytorch dataset then into tensors\n",
    "            mask = CustomMask(mask, transforms=transforms.ToTensor())\n",
    "            print(\"Masks created:\")\n",
    "            print(len(mask))\n",
    "            \n",
    "            print(\"Moving CNN to GPU and creating a mask loader\")\n",
    "            # Move the model to the same device as the input data\n",
    "            cnn.to(device)\n",
    "\n",
    "            # Convert the model weights to the same data type as the input data\n",
    "            cnn.float()  # Or whatever appropriate data type\n",
    "\n",
    "            #  creating dataloader for mask\n",
    "            mask_loader = DataLoader(mask, batch_size=10)\n",
    "\n",
    "            print(\"Training Deep SHAP Explainer please wait...\")\n",
    "            #  creating explainer for model behaviour\n",
    "            for images in mask_loader:\n",
    "                images = images.to(device)\n",
    "                explainer = shap.DeepExplainer(cnn, images)\n",
    "                break\n",
    "\n",
    "            print(\"Generating SHAP images and saving...\")\n",
    "            #  converting image to tensor\n",
    "            test_images = sampled_inputs_reshaped[1::2] # get all odd values from index 1 to use as test images\n",
    "            test_episodes = sampling_episode[1::2]\n",
    "            for t, test_image in enumerate(test_images):\n",
    "                \n",
    "                image = transforms.ToTensor()(test_image)\n",
    "                image = image.to(device)\n",
    "\n",
    "                #  deriving shap values for image of interest based on model behaviour\n",
    "                shap_values = explainer.shap_values(image.view(-1, 1, 80, 80))\n",
    "\n",
    "                #  preparing for visualization by changing channel arrangement\n",
    "                shap_numpy = [np.swapaxes(np.swapaxes(x, 1, -1), 1, 2) for x in shap_values]\n",
    "                image_numpy = np.swapaxes(np.swapaxes(image.view(-1, 1, 80, 80).cpu().numpy(), 1, -1), 1, 2)\n",
    "                shap_fig = plt.figure()\n",
    "                #  producing shap plots\n",
    "                shap.image_plot(shap_numpy, image_numpy, show=False, labels=env.unwrapped.get_action_meanings())\n",
    "                plt.savefig(\"./../plots/shap/\" + filename +\"_\"+ str(labels[i]) + \"_shap_ep_\"+ str(test_episodes[t]) +\".png\")\n",
    "                plt.close()\n",
    "\n",
    "            print(\"Saving Reward Graphs...\")\n",
    "            #### reward/episode graph\n",
    "            # Save and plot reward\n",
    "            reward_fig = plt.figure()\n",
    "            rewards_data = df_rewards[df_rewards['capacity'] == labels[i]]['reward'].values\n",
    "            plt.title(title.capitalize() + \": \" + str(labels[i]))\n",
    "            plt.xlabel(\"Episodes\")\n",
    "            plt.ylabel(\"Average Reward/\" + str(rw) + \" steps\")\n",
    "            plt.plot(rewards_data)\n",
    "\n",
    "            # Draw a vertical line at the optimal point\n",
    "            plt.axhline(y=round(np.mean(rewards_data),2), color='r', linestyle='--', label='Optimal Point')\n",
    "\n",
    "            # Draw red dots at the sampled experiences SHAP values will appear from\n",
    "            plt.scatter(test_episodes, [rewards_data[exp] for exp in test_episodes],\n",
    "                        marker='x', color='r', label='Experience Sampled', zorder=5)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            reward_fig.savefig(\"./../plots/rewardplots/\" + filename +\"_\"+ str(labels[i]) + \"_reward.png\") #must be before show to save correctly\n",
    "            #plt.show()\n",
    "            plt.close()\n",
    "\n",
    "            print(\"Saving Q-value/action graphs...\")\n",
    "            #### Q-values/Actions Taken/Episode graph\n",
    "\n",
    "            #save and plot q-values from sampled experience\n",
    "            # Iterate through sampled_targets\n",
    "\n",
    "            test_targets = sampled_targets[1::2]\n",
    "            action_labels = env.unwrapped.get_action_meanings()\n",
    "\n",
    "            for s in range(len(test_targets)):\n",
    "                # Create a figure\n",
    "                qvalue_fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "                # Iterate through the actions\n",
    "                for al in range(len(action_labels)):\n",
    "                    # Initialize an empty array to store the y-values for this action\n",
    "                    y_values = []\n",
    "\n",
    "                    # Extract the y-values for the current action 'i' from all series\n",
    "                    for st in range(len(test_targets)):\n",
    "                        y_values.append(np.array(test_targets[st][0][al]))\n",
    "\n",
    "                    # Create a line plot for this action using all series' y-values\n",
    "                    plt.plot(test_episodes, y_values, label='Action ' + str(action_labels[al]))\n",
    "\n",
    "                # Set the labels and title\n",
    "                plt.xlabel('Episodes')\n",
    "                plt.ylabel('Q-values')\n",
    "\n",
    "                # Draw a vertical line at sample point point\n",
    "                plt.axvline(x=test_episodes[s], color='r', linestyle='--', label='State: '+ str(test_episodes[s]))\n",
    "\n",
    "                # Set x-axis ticks for each value in test_episodes\n",
    "                plt.xticks(test_episodes,  rotation=90)\n",
    "\n",
    "                # Add a legend\n",
    "                plt.legend()\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                # Save the line chart to a file\n",
    "                qvalue_fig.savefig(\"./../plots/qvalueplots/\" + filename +\"_\"+ str(labels[i]) + \"_qvalues_ep_\"+ str(test_episodes[s]) +\".png\")\n",
    "                \n",
    "                # Display the line chart\n",
    "                #plt.show()\n",
    "                plt.close()\n",
    "\n",
    "            #### reward graph showing sample points\n",
    "            for s in range(len(test_targets)):\n",
    "            \n",
    "                # Save and plot reward\n",
    "                reward_test_fig = plt.figure(figsize=(5, 5))\n",
    "                plt.title(title.capitalize() + \": \" + str(labels[i]))\n",
    "                plt.xlabel(\"Episodes\")\n",
    "                plt.ylabel(\"Average Reward/\" + str(rw) + \" steps\")\n",
    "                plt.plot(rewards_data)\n",
    "\n",
    "                # Draw a vertical line at sample point point\n",
    "                plt.axvline(x=test_episodes[s], color='r', linestyle='--', label='State: '+ str(test_episodes[s]))\n",
    "\n",
    "                # Draw red dots at the sampled experiences\n",
    "                plt.scatter(test_episodes, [rewards_data[exp] for exp in test_episodes],\n",
    "                                marker='x', color='r', label='Experience Sampled', zorder=5)\n",
    "            \n",
    "                plt.tight_layout()\n",
    "                reward_test_fig.savefig(\"./../plots/rewardtest/\" + filename +\"_\"+ str(labels[i]) + \"_reward_ep_\"+ str(test_episodes[s]) +\".png\") #must be before show to save correctly\n",
    "                #plt.show()\n",
    "                plt.close()\n",
    "\n",
    "            #CREATE SHAP GIF\n",
    "            # List to store frames for the GIF\n",
    "            gif_frames = []\n",
    "\n",
    "            for s in range(len(test_targets)):\n",
    "                # Load images\n",
    "                reward_sample = Image.open('./../plots/rewardtest/' + filename +'_' + str(labels[i]) +'_reward_ep_' + str(test_episodes[s]) +'.png') \n",
    "                q_values = Image.open('./../plots/qvalueplots/' + filename +'_' + str(labels[i]) + '_qvalues_ep_' + str(test_episodes[s]) +'.png')\n",
    "                shap_values = Image.open('./../plots/shap/' + filename + '_' + str(labels[i]) +'_shap_ep_' + str(test_episodes[s]) + '.png')\n",
    "\n",
    "                # Get dimensions of input images\n",
    "                rs_width, rs_height = reward_sample.size  # Assuming the square images have the same dimensions\n",
    "                qv_width, qv_height = q_values.size\n",
    "                s_width, s_height = shap_values.size\n",
    "                new_width = s_width\n",
    "                new_height = (qv_height + s_height)\n",
    "\n",
    "                # Create a new image with the calculated dimensions\n",
    "                new_image = Image.new('RGB', (new_width, (new_height)), (255, 255, 255))\n",
    "\n",
    "\n",
    "                # Paste the square images on top\n",
    "                new_image.paste(reward_sample, (240, 0))\n",
    "                new_image.paste(q_values, (310 + s_width - rs_width - qv_width, 1))\n",
    "\n",
    "                # Paste the landscape image on the bottom\n",
    "                new_image.paste(shap_values, (0, qv_height))\n",
    "\n",
    "                # Save the new image\n",
    "                new_image.save('./../plots/shapexplainer/'+ filename +'_'+ str(labels[i]) +'_ep_' + str(test_episodes[s]) +'.png')\n",
    "\n",
    "                #pil_image = Image.open('images/thumbnail.webp')\n",
    "                #display(new_image)\n",
    "\n",
    "                #add image to gif array\n",
    "                gif_frames.append(new_image)\n",
    "\n",
    "            # Save the list of frames as a GIF\n",
    "            gif_frames[0].save('./../plots/shapexplainer/'+ filename +'_'+ str(labels[i]) +'_shap.gif', save_all=True, append_images=gif_frames[1:], loop=0, duration=200)\n",
    "            #gif_frames[0].show()\n",
    "                \n",
    "        print(\"Saving rewards to csv\")\n",
    "        x = datetime.datetime.now()\n",
    "        file_name = str(x.year) + \"_\" + str(x.month) + \"_\" + str(x.day) + \"_\" + str(x.strftime(\"%H\")) + \"_\" + str(x.strftime(\"%M\")) + \"_\" + str(x.strftime(\"%S\")) + \"_\" + filename + \".csv\"\n",
    "        df_rewards.to_csv(file_name, index=False, encoding='utf-8')\n",
    "\n",
    "        # Create a box plots using Seaborn for Evaluation\n",
    "        boxplot_fig = plt.figure()\n",
    "        unique_capacities = df_rewards['capacity'].unique()\n",
    "\n",
    "        print(\"Saving boxplot of results\")\n",
    "        #### Agent's final score to determine how it performed\n",
    "        average_accumulated_reward = round(sum(df_rewards['reward'].values),0)\n",
    "        print(\"Average Accumulated Reward: \" + str(average_accumulated_reward))\n",
    "        num_unique_capacities = len(unique_capacities)\n",
    "        p = []\n",
    "        for c in range(num_unique_capacities):\n",
    "            if c<1:\n",
    "                p.append('#FFF380')\n",
    "            else:\n",
    "                p.append('#8FD9F6')\n",
    "\n",
    "        ax = sns.boxplot(x='capacity', y='reward', data=df_rewards, width=0.5,\n",
    "                        palette=p)  # Specify colors for each box\n",
    "\n",
    "        # Adding labels and title to the plot\n",
    "        ax.set(ylabel='Average Reward/' + str(rw) + ' steps', xlabel='Experience Replay Capacity',\n",
    "            title=title.capitalize() + \": \" + str(episodes) + \" episodes\")  # Set labels and title for the axes\n",
    "\n",
    "        # Calculate the average value for the first box plot\n",
    "        average_value = df_rewards[df_rewards['capacity'] == df_rewards['capacity'].unique()[0]]['reward'].mean()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        boxplot_fig.savefig(\"./../plots/boxplot/\" + filename +\".png\") #must be before show to save correctly\n",
    "        # Show the plot\n",
    "        #plt.show()\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
