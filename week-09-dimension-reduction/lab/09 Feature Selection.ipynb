{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_rev = pd.read_csv('data/HotelRevHelpfulness.csv')\n",
    "print(hotel_rev.shape)\n",
    "hotel_rev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hotel_rev.pop('reviewHelpfulness').values\n",
    "hotel_rev.pop('hotelId')\n",
    "X = hotel_rev.values\n",
    "hotel_rev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter-based Feature Selection\n",
    "### Feature Scoring - two methods  \n",
    "1. Chi square statistic\n",
    "2. Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chi2_scores, pvals = chi2(X, y)\n",
    "chi2_scores\n",
    "# The chi square scores for all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pvals\n",
    "pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_scores = mutual_info_classif(X,y)\n",
    "i_scores\n",
    "# The i-gain scores for all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.spearmanr(chi2_scores, i_scores)\n",
    "# correlation is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = dict()\n",
    "\n",
    "for i,j in zip(hotel_rev.columns,i_scores):\n",
    "    mi[i]=j\n",
    "\n",
    "df_mi = pd.DataFrame.from_dict(mi,orient='index',columns=['I-Gain'])\n",
    "df_mi.sort_values(by=['I-Gain'],ascending=False,inplace=True)\n",
    "df_mi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi = dict()\n",
    "        \n",
    "chi = {k: (v1, v2) for k, v1, v2 in zip(hotel_rev.columns,chi2_scores, pvals)}        \n",
    "\n",
    "df_chi = pd.DataFrame.from_dict(chi,orient='index',columns=['Chi2','PVal'])\n",
    "df_chi.sort_values(by=['Chi2'],ascending=False,inplace=True)\n",
    "df_chi[df_chi[\"PVal\"] <= 0.05]     # keep those with pvalue of 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Segmentation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_data = pd.read_csv('data/segmentation-all.csv')\n",
    "print(seg_data.shape)\n",
    "seg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = seg_data.pop('Class').values\n",
    "X = seg_data.values\n",
    "feature_names = seg_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "mnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = dict()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2, test_size=1/2)\n",
    "i_scores = mutual_info_classif(X_train, y_train)\n",
    "\n",
    "for i,j in zip(feature_names,i_scores):\n",
    "    mi[i]=j\n",
    " \n",
    "df = pd.DataFrame.from_dict(mi,orient='index',columns=['I-Gain'])\n",
    "df.sort_values(by=['I-Gain'],ascending=False,inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "n = len(df.index)\n",
    "rr = range(1,n)\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(df.index, df[\"I-Gain\"], label='I-Gain',width=.35)\n",
    "\n",
    "ax.xaxis.set_major_locator(mticker.FixedLocator(range(0,n)))\n",
    "ax.set_xticklabels(list(df.index), rotation = 90)\n",
    "\n",
    "ax.set_xlabel('Features')\n",
    "ax.set_ylabel('I-Gain')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select *k* Best Features\n",
    "We rank the features using information gain (well mutual information) and select the _k_ best to build a classifier.  \n",
    "We iterate through increasing values of *k*.  \n",
    "`SelectKBest` is a _transform_ that transforms the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_scores = []\n",
    "for kk in range(1, X.shape[1]+1):\n",
    "    FS_trans = SelectKBest(mutual_info_classif, \n",
    "                           k=kk).fit(X_train, y_train)\n",
    "    X_tR_new = FS_trans.transform(X_train)\n",
    "    X_tS_new = FS_trans.transform(X_test)\n",
    "    seg_NB = mnb.fit(X_tR_new, y_train)\n",
    "    y_dash = seg_NB.predict(X_tS_new)\n",
    "    acc = accuracy_score(y_test, y_dash)\n",
    "    acc_scores.append(acc)\n",
    "\n",
    "df['Accuracy'] = acc_scores\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "n = len(df.index)\n",
    "rr = range(1,n)\n",
    "fig, ax = plt.subplots()\n",
    "ax2 = ax.twinx()\n",
    "ax.bar(df.index, df[\"I-Gain\"], label='I-Gain',width=.35)\n",
    "ax2.plot(df.index, df[\"Accuracy\"], color='red', label='Accuracy')\n",
    "\n",
    "ax.xaxis.set_major_locator(mticker.FixedLocator(range(0,n)))\n",
    "\n",
    "ax.set_xticklabels(list(df.index), rotation = 90)\n",
    "\n",
    "ax.set_xlabel('Features')\n",
    "ax.set_ylabel('I-Gain')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Wrapper\n",
    "Forward Sequential Search on Image Segmentation data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "seg_data = pd.read_csv('data/segmentation-all.csv')\n",
    "print(seg_data.shape)\n",
    "seg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = seg_data.pop('Class').values\n",
    "X = seg_data.values\n",
    "feature_names = seg_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run forward sequential wrapper search to search across all features using 10-fold xval.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sfs_forward = SFS(knn, \n",
    "                  k_features=10, \n",
    "                  forward=True, \n",
    "                  floating=False, \n",
    "                  verbose=1,\n",
    "                  scoring='accuracy',\n",
    "                  cv=5)\n",
    "\n",
    "\n",
    "sfs_forward = sfs_forward.fit(X, y, \n",
    "                              custom_feature_names=feature_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and see that performance stabilises after 6 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig1 = plot_sfs(sfs_forward.get_metric_dict(), \n",
    "                ylabel='Accuracy',\n",
    "                kind='std_dev')\n",
    "\n",
    "plt.ylim([0.6, 1])\n",
    "plt.title('Sequential Forward Selection (w. StdDev)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(sfs_forward.k_feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try backward selection back to 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_backward = SFS(knn, \n",
    "                  k_features=4, \n",
    "                  forward=False, \n",
    "                  floating=False, \n",
    "                  verbose=1,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10, n_jobs = -1)\n",
    "\n",
    "sfs_backward = sfs_backward.fit(X, y, \n",
    "                              custom_feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and see similar performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig1 = plot_sfs(sfs_backward.get_metric_dict(), \n",
    "                ylabel='Accuracy',\n",
    "                kind='std_dev')\n",
    "\n",
    "plt.ylim([0.7, 1])\n",
    "plt.title('Sequential Backward Selection (w. StdDev)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(sfs_backward.k_feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso feature selection\n",
    "Logistic regression with L1 regularisation.   \n",
    "`SelectFromModel` will select the top features out of max features   \n",
    "The `C` parameter in `LogisticRegression` is the regularisation parameter, smaller values means stronger regularisation, default is 1.  You can experiment with the value of `C` to see how many features go to zero.     \n",
    "You can select a specific number of features from `SelectFromModel` using the `max_features` parameter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_data = pd.read_csv('data/segmentation-all.csv')\n",
    "print(seg_data.shape)\n",
    "seg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = seg_data.pop('Class').values\n",
    "X = seg_data.values\n",
    "feature_names = seg_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_selector = SelectFromModel(LogisticRegression(penalty=\"l1\", \n",
    "                     C=.001, solver=\"liblinear\"), max_features=X.shape[1])\n",
    "lr_selector.fit(X, y)\n",
    "\n",
    "X=pd.DataFrame(X)\n",
    "lr_support = lr_selector.get_support()\n",
    "lr_feature = X.loc[:,lr_support].columns.tolist()\n",
    "print(str(len(lr_feature)), 'selected features')  \n",
    "print('Selected features:')\n",
    "lr_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lr_feature:\n",
    "    print(feature_names[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest feature selection\n",
    "Algorithm will select top features out of max features.   \n",
    "Note that the features selected are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100),  max_features=X.shape[1])\n",
    "rf_selector.fit(X, y)\n",
    "\n",
    "X=pd.DataFrame(X)\n",
    "rf_support = rf_selector.get_support()\n",
    "rf_feature = X.loc[:,rf_support].columns.tolist()\n",
    "print(str(len(rf_feature)), 'selected features')   \n",
    "print('Selected features:')\n",
    "rf_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
